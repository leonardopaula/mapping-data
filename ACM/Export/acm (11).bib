@inproceedings{10.1145/2441776.2441885,
author = {Bateman, Scott S. and Gutwin, Carl A. and McCalla, Gordon I.},
title = {Social Navigation for Loosely-Coupled Information Seeking in Tightly-Knit Groups Using Webwear},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441885},
doi = {10.1145/2441776.2441885},
abstract = {Many web-based information-seeking tasks are set in a social context where other people's knowledge and advice improves success in finding information. However, when tightly-knit contacts (friends, family, colleagues) are not available, information seeking becomes more difficult. Inspired by previous work in social navigation, we developed WebWear, a system that collects and displays traces of activity for tightly-knit groups. WebWear allows people to use contextual knowledge of contacts' interests and activities to interpret the meaning of the traces, improving their usefulness. In a comparative study, we found that WebWear helped people complete information-seeking tasks more accurately, without requiring additional effort. A one-week field trial found that WebWear was both usable and useful, and that privacy concerns were reduced in the small-group context. WebWear shows that small-scale social navigation systems are feasible, and that they can improve the effectiveness of information seeking on the World-Wide Web.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {955–966},
numpages = {12},
keywords = {social navigation, collaborative information seeking},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2441776.2441840,
author = {Al-Ani, Ban and Bietz, Matthew J. and Wang, Yi and Trainer, Erik and Koehne, Benjamin and Marczak, Sabrina and Redmiles, David and Prikladnicki, Rafael},
title = {Globally Distributed System Developers: Their Trust Expectations and Processes},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441840},
doi = {10.1145/2441776.2441840},
abstract = {Trust remains a challenge in globally distributed development teams. In order to investigate how trust plays out in this context, we conducted a qualitative study of 5 multi-national IT organizations. We interviewed 58 individuals across 10 countries and made two principal findings. First, study participants described trust in terms of their expectations of their colleagues. These expectations fell into one of three dimensions: that socially correct behavior will persist, that team members possess technical competency, and that individuals will demonstrate concern for others. Second, our study participants described trust as a dynamic process, with phases including formation, dissolution, adjustment and restoration. We provide new insights into these dimensions and phases of trust within distributed teams which extend existing literature. Our study also provides guidelines on effective practices within distributed teams in addition to providing implications for the extension of software engineering and collaboration tools.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {563–574},
numpages = {12},
keywords = {trust processes, multi-national organizations, systems development, trust expectations, globally distributed teams, empirical study, trust},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2441776.2441791,
author = {Singer, Leif and Figueira Filho, Fernando and Cleary, Brendan and Treude, Christoph and Storey, Margaret-Anne and Schneider, Kurt},
title = {Mutual Assessment in the Social Programmer Ecosystem: An Empirical Investigation of Developer Profile Aggregators},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441791},
doi = {10.1145/2441776.2441791},
abstract = {The multitude of social media channels that programmers can use to participate in software development has given rise to online developer profiles that aggregate activity across many services. Studying members of such developer profile aggregators, we found an ecosystem that revolves around the social programmer. Developers are assessing each other to evaluate whether other developers are interesting, worth following, or worth collaborating with. They are self-conscious about being assessed, and thus manage their public images. They value passion for software development, new technologies, and learning. Some recruiters participate in the ecosystem and use it to find candidates for hiring; other recruiters struggle with the interpretation of signals and issues of trust. This mutual assessment is changing how software engineers collaborate and how they advance their skills.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {103–116},
numpages = {14},
keywords = {social media, social code sharing, motivation, virtual communities, reputation, software development, gamification, software engineering},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2441776.2441902,
author = {Jackson, Steven J. and Steinhardt, Stephanie B. and Buyuktur, Ayse},
title = {Why CSCW Needs Science Policy (and Vice Versa)},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441902},
doi = {10.1145/2441776.2441902},
abstract = {This paper explores the relationship between CSCW studies of scientific collaboration and the larger worlds of science practice and policy they are embedded in. We argue that CSCW has much to learn from debates in science policy, including questions around the changing nature of science and science-society relations that are partly but obliquely referenced in technology- or data-centered accounts of scientific change. At the same time, science policy has much to learn from CSCW -- about design, infrastructure, and the organizational complexities of distributed collaborative practice. We conclude with recommendations for a better integration of the CSCW and science policy literatures around collaboration and new infrastructure development in the sciences, and speculation around what a post-normal cyberinfrastructure -- and post-normal CSCW -- might look like.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {1113–1124},
numpages = {12},
keywords = {collaboration, collaborative tools, cyberinfrastructure, e-research, policy, science},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2441776.2441940,
author = {Kim, Sunyoung and Mankoff, Jennifer and Paulos, Eric},
title = {Sensr: Evaluating a Flexible Framework for Authoring Mobile Data-Collection Tools for Citizen Science},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441940},
doi = {10.1145/2441776.2441940},
abstract = {Across HCI and social computing platforms, mobile applications that support citizen science, empowering non-experts to explore, collect, and share data have emerged. While many of these efforts have been successful, it remains difficult to create citizen science applications without extensive programming expertise. To address this concern, we present Sensr, an authoring environment that enables people without programming skills to build mobile data collection and management tools for citizen science. We demonstrate how Sensr allows people without technical skills to create mobile applications. Findings from our case study demonstrate that our system successfully overcomes technical constraints and provides a simple way to create mobile data collection tools.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {1453–1462},
numpages = {10},
keywords = {citizen science, sustainability, mobile applications},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2441776.2441942,
author = {Wiggins, Andrea},
title = {Free as in Puppies: Compensating for Ict Constraints in Citizen Science},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441942},
doi = {10.1145/2441776.2441942},
abstract = {Citizen science is a form of collaborative research engaging the public with professional scientists. Information and communication technologies (ICT) are a leading factor in the recent spread of this phenomenon. A common assumption is that money and ICT are the ideal solutions to issues of data quality and participant engagement. The reality is instead that resource limitations often require adopting suboptimal ICT, including tools that are "free as in puppies" with hidden costs from poor usability and lack of appropriate functionality.A comparative case study of three citizen science projects, eBird, The Great Sunflower Project, and Mountain Watch, found that projects with few ICT resources employed a broader range of strategies to address these issues than expected. The most practical and effective strategies integrated available ICT with other resources to open up new solutions and options for supporting citizen science outcomes in spite of resource limitations.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {1469–1480},
numpages = {12},
keywords = {case study, data quality, citizen science, scientific collaboration, distributed work, technology-mediated participation},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2444776.2444791,
author = {Chakraborty, Supriyo and Raghavan, Kasturi Rangan and Johnson, Matthew P. and Srivastava, Mani B.},
title = {A Framework for Context-Aware Privacy of Sensor Data on Mobile Systems},
year = {2013},
isbn = {9781450314213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2444776.2444791},
doi = {10.1145/2444776.2444791},
abstract = {We study the competing goals of utility and privacy as they arise when a user shares personal sensor data with apps on a smartphone. On the one hand, there can be value to the user for sharing data in the form of various personalized services and recommendations; on the other hand, there is the risk of revealing behaviors to the app producers that the user would like to keep private. The current approaches to privacy, usually defined in multi-user settings, rely on anonymization to prevent such sensitive behaviors from being traced back to the user---a strategy which does not apply if user identity is already known, as is the case here.Instead of protecting identity, we focus on the more general problem of choosing what data to share, in such a way that certain kinds of inferences---i.e., those indicating the user's sensitive behavior---cannot be drawn. The use of inference functions allows us to establish a terminology to unify prior notions of privacy as special cases of this more general problem. We identify several information disclosure regimes, each corresponding to a specific privacy-utility tradeoff, as well as privacy mechanisms designed to realize these tradeoff points. Finally, we propose ipShield as a privacy-aware framework which uses current user context together with a model of user behavior to quantify an adversary's knowledge regarding a sensitive inference, and obfuscate data accordingly before sharing. We conclude by describing initial work towards realizing this framework.},
booktitle = {Proceedings of the 14th Workshop on Mobile Computing Systems and Applications},
articleno = {11},
numpages = {6},
keywords = {inferences, Android, behavioral privacy, ipShield, model-based privacy, context-awareness},
location = {Jekyll Island, Georgia},
series = {HotMobile '13}
}

@inproceedings{10.1145/2483977.2483998,
author = {Ye, Jun and Hua, Kien A.},
title = {Exploiting Depth Camera for 3D Spatial Relationship Interpretation},
year = {2013},
isbn = {9781450318945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2483977.2483998},
doi = {10.1145/2483977.2483998},
abstract = {Interpretation of spatial relations between objects is essential to many applications such as robotics, video surveillance, spatial reasoning, and scene understanding. Current models for spatial logic are two-dimensional. With the advance in new sensing technology, inexpensive depth sensors become widely available and 3D scene reconstruction can be applied in various application scenarios. In this paper, we propose a 3D spatial logic and algorithms for interpretation of spatial relationships among objects in 3D space. More specifically, these techniques are developed for LVDBMS (Live Video DataBase Management System), a generic platform for live video computing. We extend the original directional relationships into 3D directional relationships, and introduce a simple yet effective way to build 3D object models based on depth sensors. A highly accurate and efficient algorithm is also proposed to compute the spatial relationships between two objects by sampling the entire space from the reference object. Experimental results based on a real indoor scene and an RGB-D dataset are given to demonstrate the effectiveness of our techniques.},
booktitle = {Proceedings of the 4th ACM Multimedia Systems Conference},
pages = {151–161},
numpages = {11},
keywords = {depth sensor, directional relationships, spatial relation interpretation, 3D video surveillance},
location = {Oslo, Norway},
series = {MMSys '13}
}

@article{10.1145/2427076.2427086,
author = {Churchill, Elizabeth F. and Bowser, Anne and Preece, Jennifer},
title = {Teaching and Learning Human-Computer Interaction: Past, Present, and Future},
year = {2013},
issue_date = {March + April 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {2},
issn = {1072-5520},
url = {https://doi.org/10.1145/2427076.2427086},
doi = {10.1145/2427076.2427086},
journal = {Interactions},
month = mar,
pages = {44–53},
numpages = {10}
}

@article{10.1145/2432596.2432599,
author = {Martin, C. Dianne},
title = {The Internet as a Reverse Panopticon},
year = {2013},
issue_date = {March 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
issn = {2153-2184},
url = {https://doi.org/10.1145/2432596.2432599},
doi = {10.1145/2432596.2432599},
journal = {ACM Inroads},
month = mar,
pages = {8–9},
numpages = {2}
}

@inproceedings{10.5555/2447556.2447564,
author = {Leite, Iolanda and Henriques, Rui and Martinho, Carlos and Paiva, Ana},
title = {Sensors in the Wild: Exploring Electrodermal Activity in Child-Robot Interaction},
year = {2013},
isbn = {9781467330558},
publisher = {IEEE Press},
abstract = {Recent advances in biosensor technology enabled the appearance of commercial wireless sensors that can measure electrodermal activity (EDA) in user's everyday settings. In this paper, we investigate the potential benefits of measuring EDA to better understand children-robot interaction in two distinct directions: to characterize and evaluate the interaction, and to dynamically recognize user's affective states. To do so, we present a study in which 38 children interacted with an iCat robot while wearing a wireless sensor that measured their electrodermal activity. We found that different patterns of electrodermal variation emerge for different supportive behaviours elicited by the robot and for different affective states of the children. The results also yield significant correlations between statistical features extracted from the signal and surveyed parameters regarding how children perceived the interaction and their affective state.},
booktitle = {Proceedings of the 8th ACM/IEEE International Conference on Human-Robot Interaction},
pages = {41–48},
numpages = {8},
keywords = {children, affect recognition, electrodermal activity, social robots},
location = {Tokyo, Japan},
series = {HRI '13}
}

@inproceedings{10.1145/2445196.2445287,
author = {Buffardi, Kevin and Edwards, Stephen H.},
title = {Impacts of Adaptive Feedback on Teaching Test-Driven Development},
year = {2013},
isbn = {9781450318686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2445196.2445287},
doi = {10.1145/2445196.2445287},
abstract = {Studies have found that following Test-Driven Development (TDD) can improve code and testing quality. However, a preliminary investigation was consistent with concerns raised by other educators about programmers resisting TDD. In this paper, we describe an adaptive, pedagogical system for tracking and encouraging students' adherence to TDD. Along with an empirical evaluation of the system, we discuss challenges and opportunities for persuading student behavior through adaptive technology.},
booktitle = {Proceeding of the 44th ACM Technical Symposium on Computer Science Education},
pages = {293–298},
numpages = {6},
keywords = {web-cat, unit testing, test-first, test-driven development (TDD), automated testing, adherence, instructional technology},
location = {Denver, Colorado, USA},
series = {SIGCSE '13}
}

@inproceedings{10.1145/2445196.2445288,
author = {Etlinger, Henry A.},
title = {Adding a Contributing Student Pedagogy Component to an Introductory Database Course},
year = {2013},
isbn = {9781450318686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2445196.2445288},
doi = {10.1145/2445196.2445288},
abstract = {An introductory database course is well established within computer science curricula. Instructors in this course are challenged to select a subset of possible topics to cover and emphasize and also to design appropriate assignments to help students master those topics. As theories regarding effective educational practice continue to emerge and become known, we also seek to invigorate our courses by including some of these newer techniques.Contributing Student Pedagogy is an umbrella term that refers to a family of techniques that involves finding ways for students to become directly involved in the production of course content utilized by other students. Students not only make use of content provided by other students, but they come to view that content as valuable. This paper reports on initial efforts to incorporate an assignment based on contributing student pedagogy into a standard database course. Several iterations took place, with improvements made between the first and second iterations. Plans for future iterations are included and implications, not only for the database course, but other Computer Science courses, are discussed.},
booktitle = {Proceeding of the 44th ACM Technical Symposium on Computer Science Education},
pages = {299–304},
numpages = {6},
keywords = {active learning, database course design and tradeoffs, contributing student pedagogy},
location = {Denver, Colorado, USA},
series = {SIGCSE '13}
}

@inproceedings{10.1145/2459236.2459261,
author = {Peck, Evan M. and Afergan, Daniel and Jacob, Robert J. K.},
title = {Investigation of FNIRS Brain Sensing as Input to Information Filtering Systems},
year = {2013},
isbn = {9781450319041},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459236.2459261},
doi = {10.1145/2459236.2459261},
abstract = {Today's users interact with an increasing amount of information, demanding a similar increase in attention and cognition. To help cope with information overload, recommendation engines direct users' attention to content that is most relevant to them. We suggest that functional near-infrared spectroscopy (fNIRS) brain measures can be used as an additional channel to information filtering systems. Using fNIRS, we acquire an implicit measure that correlates with user preference, thus avoiding the cognitive interruption that accompanies explicit preference ratings. We explore the use of fNIRS in information filtering systems by building and evaluating a brain-computer movie recommender. We find that our system recommends movies that are rated higher than in a control condition, improves recommendations with increased interaction with the system, and provides recommendations that are unique to each individual.},
booktitle = {Proceedings of the 4th Augmented Human International Conference},
pages = {142–149},
numpages = {8},
keywords = {brain-computer interfaces, fNIRS, adaptive interfaces, information filtering, passive input},
location = {Stuttgart, Germany},
series = {AH '13}
}

@inproceedings{10.1145/2459236.2459247,
author = {Carton, Anthony and Dunne, Lucy E.},
title = {Tactile Distance Feedback for Firefighters: Design and Preliminary Evaluation of a Sensory Augmentation Glove},
year = {2013},
isbn = {9781450319041},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459236.2459247},
doi = {10.1145/2459236.2459247},
abstract = {In this paper, we describe the design and preliminary evaluation of a vibrotactile glove for distance display in low vision search contexts. Specifically, this glove was developed for firefighting applications in which users experience compromised vision due to a combination of smoke and low ambient light levels. The glove maps an ultrasonic rangefinder to a pair of vibrating motors on the dorsal surface of the hand. Initial perceptibility testing with 15 participants showed participants were consistently able to detect the presence and absence of obstacles in a gap-detection task (93% correct detection) and to detect relative changes in the proximity of an obstacle (74% correct identification of relative position). Mapping tactile stimuli to absolute position was more challenging, with an accuracy rate of 57% (adjusted to 89% within one unit of actual position). Challenges to implementation of the concept include response time-lag, challenges of absolute judgment, and width of the sensor signal cone.},
booktitle = {Proceedings of the 4th Augmented Human International Conference},
pages = {58–64},
numpages = {7},
keywords = {glove, sensory augmentation, wearable technology, smart clothing, vibrotactile display, distance sensing},
location = {Stuttgart, Germany},
series = {AH '13}
}

@inproceedings{10.1145/2458523.2458529,
author = {Mistry, Perhaad and Ukidave, Yash and Schaa, Dana and Kaeli, David},
title = {Valar: A Benchmark Suite to Study the Dynamic Behavior of Heterogeneous Systems},
year = {2013},
isbn = {9781450320177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2458523.2458529},
doi = {10.1145/2458523.2458529},
abstract = {Heterogeneous systems have grown in popularity within the commercial platform and application developer communities. We have seen a growing number of systems incorporating CPUs, Graphics Processors (GPUs) and Accelerated Processing Units (APUs combine a CPU and GPU on the same chip). These emerging class of platforms are now being targeted to accelerate applications where the host processor (typically a CPU) and compute device (typically a GPU) co-operate on a computation. In this scenario, the performance of the application is not only dependent on the processing power of the respective heterogeneous processors, but also on the efficient interaction and communication between them.To help architects and application developers to quantify many of the key aspects of heterogeneous execution, this paper presents a new set of benchmarks called the Valar. The Valar benchmarks are applications specifically chosen to study the dynamic behavior of OpenCL applications that will benefit from host-device interaction. We describe the general characteristics of our benchmarks, focusing on specific characteristics that can help characterize heterogeneous applications. For the purposes of this paper we focus on OpenCL as our programming environment, though we envision versions of Valar in additional heterogeneous programming languages.We profile the Valar benchmarks based on their mapping and execution on different heterogeneous systems. Our evaluation examines optimizations for host-device communication and the effects of closely-coupled execution of the benchmarks on the multiple OpenCL devices present in heterogeneous systems.},
booktitle = {Proceedings of the 6th Workshop on General Purpose Processor Using Graphics Processing Units},
pages = {54–65},
numpages = {12},
keywords = {GPGPU, computer vision, benchmarking, benchmark suite, OpenCL, profiling, heterogeneous computing},
location = {Houston, Texas, USA},
series = {GPGPU-6}
}

@inproceedings{10.1145/2451116.2451125,
author = {Delimitrou, Christina and Kozyrakis, Christos},
title = {Paragon: QoS-Aware Scheduling for Heterogeneous Datacenters},
year = {2013},
isbn = {9781450318709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451116.2451125},
doi = {10.1145/2451116.2451125},
abstract = {Large-scale datacenters (DCs) host tens of thousands of diverse applications each day. However, interference between colocated workloads and the difficulty to match applications to one of the many hardware platforms available can degrade performance, violating the quality of service (QoS) guarantees that many cloud workloads require. While previous work has identified the impact of heterogeneity and interference, existing solutions are computationally intensive, cannot be applied online and do not scale beyond few applications.We present Paragon, an online and scalable DC scheduler that is heterogeneity and interference-aware. Paragon is derived from robust analytical methods and instead of profiling each application in detail, it leverages information the system already has about applications it has previously seen. It uses collaborative filtering techniques to quickly and accurately classify an unknown, incoming workload with respect to heterogeneity and interference in multiple shared resources, by identifying similarities to previously scheduled applications. The classification allows Paragon to greedily schedule applications in a manner that minimizes interference and maximizes server utilization. Paragon scales to tens of thousands of servers with marginal scheduling overheads in terms of time or state.We evaluate Paragon with a wide range of workload scenarios, on both small and large-scale systems, including 1,000 servers on EC2. For a 2,500-workload scenario, Paragon enforces performance guarantees for 91% of applications, while significantly improving utilization. In comparison, heterogeneity-oblivious, interference-oblivious and least-loaded schedulers only provide similar guarantees for 14%, 11% and 3% of workloads. The differences are more striking in oversubscribed scenarios where resource efficiency is more critical.},
booktitle = {Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {77–88},
numpages = {12},
keywords = {interference, scheduling, datacenter, heterogeneity, cloud computing, qos},
location = {Houston, Texas, USA},
series = {ASPLOS '13}
}

@article{10.1145/2490301.2451125,
author = {Delimitrou, Christina and Kozyrakis, Christos},
title = {Paragon: QoS-Aware Scheduling for Heterogeneous Datacenters},
year = {2013},
issue_date = {March 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0163-5964},
url = {https://doi.org/10.1145/2490301.2451125},
doi = {10.1145/2490301.2451125},
abstract = {Large-scale datacenters (DCs) host tens of thousands of diverse applications each day. However, interference between colocated workloads and the difficulty to match applications to one of the many hardware platforms available can degrade performance, violating the quality of service (QoS) guarantees that many cloud workloads require. While previous work has identified the impact of heterogeneity and interference, existing solutions are computationally intensive, cannot be applied online and do not scale beyond few applications.We present Paragon, an online and scalable DC scheduler that is heterogeneity and interference-aware. Paragon is derived from robust analytical methods and instead of profiling each application in detail, it leverages information the system already has about applications it has previously seen. It uses collaborative filtering techniques to quickly and accurately classify an unknown, incoming workload with respect to heterogeneity and interference in multiple shared resources, by identifying similarities to previously scheduled applications. The classification allows Paragon to greedily schedule applications in a manner that minimizes interference and maximizes server utilization. Paragon scales to tens of thousands of servers with marginal scheduling overheads in terms of time or state.We evaluate Paragon with a wide range of workload scenarios, on both small and large-scale systems, including 1,000 servers on EC2. For a 2,500-workload scenario, Paragon enforces performance guarantees for 91% of applications, while significantly improving utilization. In comparison, heterogeneity-oblivious, interference-oblivious and least-loaded schedulers only provide similar guarantees for 14%, 11% and 3% of workloads. The differences are more striking in oversubscribed scenarios where resource efficiency is more critical.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {77–88},
numpages = {12},
keywords = {cloud computing, interference, qos, datacenter, heterogeneity, scheduling}
}

@article{10.1145/2499368.2451125,
author = {Delimitrou, Christina and Kozyrakis, Christos},
title = {Paragon: QoS-Aware Scheduling for Heterogeneous Datacenters},
year = {2013},
issue_date = {April 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2499368.2451125},
doi = {10.1145/2499368.2451125},
abstract = {Large-scale datacenters (DCs) host tens of thousands of diverse applications each day. However, interference between colocated workloads and the difficulty to match applications to one of the many hardware platforms available can degrade performance, violating the quality of service (QoS) guarantees that many cloud workloads require. While previous work has identified the impact of heterogeneity and interference, existing solutions are computationally intensive, cannot be applied online and do not scale beyond few applications.We present Paragon, an online and scalable DC scheduler that is heterogeneity and interference-aware. Paragon is derived from robust analytical methods and instead of profiling each application in detail, it leverages information the system already has about applications it has previously seen. It uses collaborative filtering techniques to quickly and accurately classify an unknown, incoming workload with respect to heterogeneity and interference in multiple shared resources, by identifying similarities to previously scheduled applications. The classification allows Paragon to greedily schedule applications in a manner that minimizes interference and maximizes server utilization. Paragon scales to tens of thousands of servers with marginal scheduling overheads in terms of time or state.We evaluate Paragon with a wide range of workload scenarios, on both small and large-scale systems, including 1,000 servers on EC2. For a 2,500-workload scenario, Paragon enforces performance guarantees for 91% of applications, while significantly improving utilization. In comparison, heterogeneity-oblivious, interference-oblivious and least-loaded schedulers only provide similar guarantees for 14%, 11% and 3% of workloads. The differences are more striking in oversubscribed scenarios where resource efficiency is more critical.},
journal = {SIGPLAN Not.},
month = mar,
pages = {77–88},
numpages = {12},
keywords = {interference, scheduling, cloud computing, heterogeneity, qos, datacenter}
}

@inproceedings{10.1145/2451116.2451162,
author = {Phothilimthana, Phitchaya Mangpo and Ansel, Jason and Ragan-Kelley, Jonathan and Amarasinghe, Saman},
title = {Portable Performance on Heterogeneous Architectures},
year = {2013},
isbn = {9781450318709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451116.2451162},
doi = {10.1145/2451116.2451162},
abstract = {Trends in both consumer and high performance computing are bringing not only more cores, but also increased heterogeneity among the computational resources within a single machine. In many machines, one of the greatest computational resources is now their graphics coprocessors (GPUs), not just their primary CPUs. But GPU programming and memory models differ dramatically from conventional CPUs, and the relative performance characteristics of the different processors vary widely between machines. Different processors within a system often perform best with different algorithms and memory usage patterns, and achieving the best overall performance may require mapping portions of programs across all types of resources in the machine.To address the problem of efficiently programming machines with increasingly heterogeneous computational resources, we propose a programming model in which the best mapping of programs to processors and memories is determined empirically. Programs define choices in how their individual algorithms may work, and the compiler generates further choices in how they can map to CPU and GPU processors and memory systems. These choices are given to an empirical autotuning framework that allows the space of possible implementations to be searched at installation time. The rich choice space allows the autotuner to construct poly-algorithms that combine many different algorithmic techniques, using both the CPU and the GPU, to obtain better performance than any one technique alone. Experimental results show that algorithmic changes, and the varied use of both CPUs and GPUs, are necessary to obtain up to a 16.5x speedup over using a single program configuration for all architectures.},
booktitle = {Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {431–444},
numpages = {14},
keywords = {gpgpu, compilers, heterogeneous, autotuning},
location = {Houston, Texas, USA},
series = {ASPLOS '13}
}

@article{10.1145/2490301.2451162,
author = {Phothilimthana, Phitchaya Mangpo and Ansel, Jason and Ragan-Kelley, Jonathan and Amarasinghe, Saman},
title = {Portable Performance on Heterogeneous Architectures},
year = {2013},
issue_date = {March 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0163-5964},
url = {https://doi.org/10.1145/2490301.2451162},
doi = {10.1145/2490301.2451162},
abstract = {Trends in both consumer and high performance computing are bringing not only more cores, but also increased heterogeneity among the computational resources within a single machine. In many machines, one of the greatest computational resources is now their graphics coprocessors (GPUs), not just their primary CPUs. But GPU programming and memory models differ dramatically from conventional CPUs, and the relative performance characteristics of the different processors vary widely between machines. Different processors within a system often perform best with different algorithms and memory usage patterns, and achieving the best overall performance may require mapping portions of programs across all types of resources in the machine.To address the problem of efficiently programming machines with increasingly heterogeneous computational resources, we propose a programming model in which the best mapping of programs to processors and memories is determined empirically. Programs define choices in how their individual algorithms may work, and the compiler generates further choices in how they can map to CPU and GPU processors and memory systems. These choices are given to an empirical autotuning framework that allows the space of possible implementations to be searched at installation time. The rich choice space allows the autotuner to construct poly-algorithms that combine many different algorithmic techniques, using both the CPU and the GPU, to obtain better performance than any one technique alone. Experimental results show that algorithmic changes, and the varied use of both CPUs and GPUs, are necessary to obtain up to a 16.5x speedup over using a single program configuration for all architectures.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {431–444},
numpages = {14},
keywords = {compilers, heterogeneous, gpgpu, autotuning}
}

@article{10.1145/2499368.2451162,
author = {Phothilimthana, Phitchaya Mangpo and Ansel, Jason and Ragan-Kelley, Jonathan and Amarasinghe, Saman},
title = {Portable Performance on Heterogeneous Architectures},
year = {2013},
issue_date = {April 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2499368.2451162},
doi = {10.1145/2499368.2451162},
abstract = {Trends in both consumer and high performance computing are bringing not only more cores, but also increased heterogeneity among the computational resources within a single machine. In many machines, one of the greatest computational resources is now their graphics coprocessors (GPUs), not just their primary CPUs. But GPU programming and memory models differ dramatically from conventional CPUs, and the relative performance characteristics of the different processors vary widely between machines. Different processors within a system often perform best with different algorithms and memory usage patterns, and achieving the best overall performance may require mapping portions of programs across all types of resources in the machine.To address the problem of efficiently programming machines with increasingly heterogeneous computational resources, we propose a programming model in which the best mapping of programs to processors and memories is determined empirically. Programs define choices in how their individual algorithms may work, and the compiler generates further choices in how they can map to CPU and GPU processors and memory systems. These choices are given to an empirical autotuning framework that allows the space of possible implementations to be searched at installation time. The rich choice space allows the autotuner to construct poly-algorithms that combine many different algorithmic techniques, using both the CPU and the GPU, to obtain better performance than any one technique alone. Experimental results show that algorithmic changes, and the varied use of both CPUs and GPUs, are necessary to obtain up to a 16.5x speedup over using a single program configuration for all architectures.},
journal = {SIGPLAN Not.},
month = mar,
pages = {431–444},
numpages = {14},
keywords = {gpgpu, autotuning, heterogeneous, compilers}
}

@inproceedings{10.1145/2480362.2480397,
author = {Ll. Berral, Josep and Gavald\`{a}, Ricard and Torres, Jordi},
title = {Empowering Automatic Data-Center Management with Machine Learning},
year = {2013},
isbn = {9781450316569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2480362.2480397},
doi = {10.1145/2480362.2480397},
abstract = {The Cloud as computing paradigm has become nowadays crucial for most Internet business models. Managing and optimizing its performance on a moment-by-moment basis is not easy given as the amount and diversity of elements involved (hardware, applications, workloads, customer needs...). Here we show how a combination of scheduling algorithms and data mining techniques helps improving the performance and profitability of a data-center running virtualized web-services. We model the data-center's main resources (CPU, memory, IO), quality of service (viewed as response time), and workloads (incoming streams of requests) from past executions. We show how these models to help scheduling algorithms make better decisions about job and resource allocation, aiming for a balance between throughput, quality of service, and power consumption.},
booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
pages = {170–172},
numpages = {3},
keywords = {web-services, modeling, machine learning, cloud computing},
location = {Coimbra, Portugal},
series = {SAC '13}
}

@inproceedings{10.1145/2457317.2457330,
author = {Ferrara, Alfio and Genta, Lorenzo and Montanelli, Stefano},
title = {Linked Data Classification: A Feature-Based Approach},
year = {2013},
isbn = {9781450315999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2457317.2457330},
doi = {10.1145/2457317.2457330},
abstract = {The availability of large collections of linked data that can be accessed through public services and search endpoints requires methods and techniques for reducing the data complexity and providing high-level views of data contents defined according to users specific needs. To this end, a crucial step is the definition of data classification methods and techniques for the thematic aggregation of linked data. In this paper, we propose matching and clustering techniques specifically conceived for linked data classification, by focusing on the high level of heterogeneity of data descriptions in terms of the number and kind of their descriptive features.},
booktitle = {Proceedings of the Joint EDBT/ICDT 2013 Workshops},
pages = {75–82},
numpages = {8},
keywords = {similarity-based aggregation of linked data, linked data matching, feature-based hierarchical clustering},
location = {Genoa, Italy},
series = {EDBT '13}
}

@inproceedings{10.1145/2452376.2452435,
author = {Liarou, Erietta and Idreos, Stratos and Manegold, Stefan and Kersten, Martin},
title = {Enhanced Stream Processing in a DBMS Kernel},
year = {2013},
isbn = {9781450315975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2452376.2452435},
doi = {10.1145/2452376.2452435},
abstract = {Continuous query processing has emerged as a promising query processing paradigm with numerous applications. A recent development is the need to handle both streaming queries and typical one-time queries in the same application. For example, data warehousing can greatly benefit from the integration of stream semantics, i.e., online analysis of incoming data and combination with existing data. This is especially useful to provide low latency in data-intensive analysis in big data warehouses that are augmented with new data on a daily basis.However, state-of-the-art database technology cannot handle streams efficiently due to their "continuous" nature. At the same time, state-of-the-art stream technology is purely focused on stream applications. The research efforts are mostly geared towards the creation of specialized stream management systems built with a different philosophy than a DBMS. The drawback of this approach is the limited opportunities to exploit successful past data processing technology, e.g., query optimization techniques.For this new problem we need to combine the best of both worlds. Here we take a completely different route by designing a stream engine on top of an existing relational database kernel. This includes reuse of both its storage/execution engine and its optimizer infrastructure. The major challenge then becomes the efficient support for specialized stream features. This paper focuses on incremental window-based processing, arguably the most crucial streamspecific requirement. In order to maintain and reuse the generic storage and execution model of the DBMS, we elevate the problem at the query plan level. Proper optimizer rules, scheduling and intermediate result caching and reuse, allow us to modify the DBMS query plans for efficient incremental processing. We describe in detail the new approach and we demonstrate efficient performance even against specialized stream engines, especially when scalability becomes a crucial factor.},
booktitle = {Proceedings of the 16th International Conference on Extending Database Technology},
pages = {501–512},
numpages = {12},
location = {Genoa, Italy},
series = {EDBT '13}
}

@inproceedings{10.1145/2480362.2480498,
author = {Hogenboom, Alexander and Bal, Daniella and Frasincar, Flavius and Bal, Malissa and de Jong, Franciska and Kaymak, Uzay},
title = {Exploiting Emoticons in Sentiment Analysis},
year = {2013},
isbn = {9781450316569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2480362.2480498},
doi = {10.1145/2480362.2480498},
abstract = {As people increasingly use emoticons in text in order to express, stress, or disambiguate their sentiment, it is crucial for automated sentiment analysis tools to correctly account for such graphical cues for sentiment. We analyze how emoticons typically convey sentiment and demonstrate how we can exploit this by using a novel, manually created emoticon sentiment lexicon in order to improve a state-of-the-art lexicon-based sentiment classification method. We evaluate our approach on 2,080 Dutch tweets and forum messages, which all contain emoticons and have been manually annotated for sentiment. On this corpus, paragraph-level accounting for sentiment implied by emoticons significantly improves sentiment classification accuracy. This indicates that whenever emoticons are used, their associated sentiment dominates the sentiment conveyed by textual cues and forms a good proxy for intended sentiment.},
booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
pages = {703–710},
numpages = {8},
keywords = {emoticons, sentiment analysis, sentiment lexicon},
location = {Coimbra, Portugal},
series = {SAC '13}
}

@inproceedings{10.5555/2485288.2485333,
author = {Casale-Rossi, Marco and Sangiovanni-Vincentelli, Alberto and Carloni, Luca and Courtois, Bernard and de Man, Hugo and Domic, Antun and Rabaey, Jan M.},
title = {Panel: The Heritage of Mead &amp; Conway: What Has Remained the Same, What Was Missed, What Has Changed, What Lies Ahead},
year = {2013},
isbn = {9781450321532},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {Thirty-two years ago, Electronics Magazine honored Carver Mead and Lynn Conway with its Achievement Award for their contributions to VLSI chip design. The 'Mead &amp; Conway methods' were being taught at 100+ universities all over the world, and "not only have helped spawn a common design culture so necessary in the VLSI era, but have greatly increased interaction between university and industry so as to stimulate research by both." Concepts such as simplified design methods, new, electronic representations of digital design data, scalable design rules, 'clean' formalized digital interfaces between design and manufacturing, and widely accessible silicon foundries suddenly enabled many thousands of chip designers to create many tens of thousands of chip designs. Today, as Moore's Law -- a term coined by Carver Mead -- has brought as from 10 microns to 10 nanometers, what is the heritage of Mead &amp; Conway?UCB Professor Alberto Sangiovanni-Vincentelli will moderate an industry and research panel, to discuss what has remained the same, what was missed, what has changed, and what lies ahead.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {171–175},
numpages = {5},
location = {Grenoble, France},
series = {DATE '13}
}

@inproceedings{10.5555/2485288.2485616,
author = {Chantem, Thidapat and Xiang, Yun and Hu, X. Sharon and Dick, Robert P.},
title = {Enhancing Multicore Reliability through Wear Compensation in Online Assignment and Scheduling},
year = {2013},
isbn = {9781450321532},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {System reliability is a crucial concern especially in multicore systems which tend to have high power density and hence temperature. Existing reliability-aware methods are either slow and non-adaptive (offline techniques) or do not use task assignment and scheduling to compensate for uneven core wear states (online techniques). In this article, we present a dynamically-activated task assignment and scheduling algorithm based on theoretical results that explicitly optimizes system lifetime. We also propose a data distillation method that dramatically reduces the size of the thermal profiles to make full system reliability analysis viable online. Simulation results show that our algorithm results in between 27--291% improvement to system lifetime compared to existing techniques for four-core systems.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {1373–1378},
numpages = {6},
location = {Grenoble, France},
series = {DATE '13}
}

@inproceedings{10.1145/2480362.2480574,
author = {Hunny, Umme and Zulkernine, Mohammad and Weldemariam, Komminist},
title = {OSDC: Adapting ODC for Developing More Secure Software},
year = {2013},
isbn = {9781450316569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2480362.2480574},
doi = {10.1145/2480362.2480574},
abstract = {Software defect data provide an invaluable source of information for developers, testers and so forth. A concise view of a software profile, its development process, and their relationships can be systematically extracted and analyzed to deduce adequate corrective measures based on previously discovered weaknesses. This kind of approach is being widely used in various projects to improve the quality of a software system. This paper builds on top of the orthogonal defect classification (ODC) scheme to provide a structured security-specific defect classification. We perform a detailed analysis on the classified data and obtain in-process feedback so that the next version of the software can be more secure and reliable. We experimented our customized methodology on Firefox and Chrome defect repositories using six consecutive versions and milestones, respectively. We found that in-process feedback can help development team to take corrective actions as early as possible. We also studied the correlations between software defect types and software development lifecycle to understand development improvement.},
booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
pages = {1131–1136},
numpages = {6},
keywords = {security, ODC, software development, software defect},
location = {Coimbra, Portugal},
series = {SAC '13}
}

@inproceedings{10.1145/2449396.2449427,
author = {Tan, Chiew Seng Sean and Sch\"{o}ning, Johannes and Luyten, Kris and Coninx, Karin},
title = {Informing Intelligent User Interfaces by Inferring Affective States from Body Postures in Ubiquitous Computing Environments},
year = {2013},
isbn = {9781450319652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2449396.2449427},
doi = {10.1145/2449396.2449427},
abstract = {Intelligent User Interfaces can benefit from having knowledge on the user's emotion. However, current implementations to detect affective states, are often constraining the user's freedom of movement by instrumenting her with sensors. This prevents affective computing from being deployed in naturalistic and ubiquitous computing contexts. In this paper, we present a novel system called mASqUE, which uses a set of association rules to infer someone's affective state from their body postures. This is done without any user instrumentation and using off-the-shelf and non-expensive commodity hardware: a depth camera tracks the body posture of the users and their postures are also used as an indicator of their openness. By combining the posture information with physiological sensors measurements we were able to mine a set of association rules relating postures to affective states. We demonstrate the possibility of inferring affective states from body postures in ubiquitous computing environments and our study also provides insights how this opens up new possibilities for IUI to access the affective states of users from body postures in a nonintrusive way.},
booktitle = {Proceedings of the 2013 International Conference on Intelligent User Interfaces},
pages = {235–246},
numpages = {12},
keywords = {emotion recognition, social behavior, intelligent user interfaces, ubicomp, affective computing, posture tracking, posture detection},
location = {Santa Monica, California, USA},
series = {IUI '13}
}

@inproceedings{10.1145/2449396.2449428,
author = {Wang, Weihong and Li, Zhidong and Wang, Yang and Chen, Fang},
title = {Indexing Cognitive Workload Based on Pupillary Response under Luminance and Emotional Changes},
year = {2013},
isbn = {9781450319652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2449396.2449428},
doi = {10.1145/2449396.2449428},
abstract = {Pupillary response is a popular physiological index of cognitive workload that can be used for design and evaluation of adaptive interface in various areas of human-computer interaction (HCI) research. However, in practice various confounding factors unrelated to workload, including changes of luminance condition and emotional arousal might degrade pupillary response based workload measures such as commonly used mean pupil diameter. This work investigates pupillary response as a cognitive workload measure under the influence of such confounding factors. Video-based eye tracker is used to record pupillary response during arithmetic tasks under luminance and emotional changes. Machine learning based feature selection and classification techniques are proposed to robustly index cognitive workload based on pupillary response even with the influence of noisy factors unrelated to workload.},
booktitle = {Proceedings of the 2013 International Conference on Intelligent User Interfaces},
pages = {247–256},
numpages = {10},
keywords = {machine learning, cognitive workload, pupillary response, feature extraction},
location = {Santa Monica, California, USA},
series = {IUI '13}
}

@inproceedings{10.1145/2449396.2449415,
author = {Putze, Felix and Hild, Jutta and K\"{a}rgel, Rainer and Herff, Christian and Redmann, Alexander and Beyerer, J\"{u}rgen and Schultz, Tanja},
title = {Locating User Attention Using Eye Tracking and EEG for Spatio-Temporal Event Selection},
year = {2013},
isbn = {9781450319652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2449396.2449415},
doi = {10.1145/2449396.2449415},
abstract = {In expert video analysis, the selection of certain events in a continuous video stream is a frequently occurring operation, e.g., in surveillance applications. Due to the dynamic and rich visual input, the constantly high attention and the required hand-eye coordination for mouse interaction, this is a very demanding and exhausting task. Hence, relevant events might be missed. We propose to use eye tracking and electroencephalography (EEG) as additional input modalities for event selection. From eye tracking, we derive the spatial location of a perceived event and from patterns in the EEG signal we derive its temporal location within the video stream. This reduces the amount of the required active user input in the selection process, and thus has the potential to reduce the user's workload. In this paper, we describe the employed methods for the localization processes and introduce the developed scenario in which we investigate the feasibility of this approach. Finally, we present and discuss results on the accuracy and the speed of the method and investigate how the modalities interact.},
booktitle = {Proceedings of the 2013 International Conference on Intelligent User Interfaces},
pages = {129–136},
numpages = {8},
keywords = {eye tracking, eeg, event detection, expert video analysis},
location = {Santa Monica, California, USA},
series = {IUI '13}
}

@inproceedings{10.1145/2466816.2466850,
author = {Bertolotti, Tommaso and Magnani, Lorenzo},
title = {Terminator Niches},
year = {2013},
isbn = {9781450318754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2466816.2466850},
doi = {10.1145/2466816.2466850},
abstract = {The aim of this paper is to connect studies in cognitive niches with the diffusion of high-technologies, cyborgs and robots, so to obtain a new framework for analyzing some dilemmas of future technological developments. Digital technologies dramatically boosted the niche constructing dynamics by allowing the construction of new informational environments and by the addition of pseudo-minds that are able to carry on the niche-construction activity side-to-side with human beings. Cognitive niches, structured to ease the environmental selective pressure, may progressively degenerate causing an increase in selective pressure and hence a reduction in welfare for the individuals: yet, when the failure is caused exactly by what was meant to benefit the population, and when the reversal of niche is (or seems to be) unfeasible, it is possible to individuate a "terminator niche."},
booktitle = {Proceedings of the Virtual Reality International Conference: Laval Virtual},
articleno = {31},
numpages = {10},
location = {Laval, France},
series = {VRIC '13}
}

@article{10.1145/2435227.2435229,
author = {Nikitakis, Antonis and Papaioannou, Savvas and Papaefstathiou, Ioannis},
title = {A Novel Low-Power Embedded Object Recognition System Working at Multi-Frames per Second},
year = {2013},
issue_date = {March 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1s},
issn = {1539-9087},
url = {https://doi.org/10.1145/2435227.2435229},
doi = {10.1145/2435227.2435229},
abstract = {One very important challenge in the field of multimedia is the implementation of fast and detailed Object Detection and Recognition systems. In particular, in the current state-of-the-art mobile multimedia systems, it is highly desirable to detect and locate certain objects within a video frame in real time. Although a significant number of Object Detection and Recognition schemes have been developed and implemented, triggering very accurate results, the vast majority of them cannot be applied in state-of-the-art mobile multimedia devices; this is mainly due to the fact that they are highly complex schemes that require a significant amount of processing power, while they are also time consuming and very power hungry. In this article, we present a novel FPGA-based embedded implementation of a very efficient object recognition algorithm called Receptive Field Cooccurrence Histograms Algorithm (RFCH). Our main focus was to increase its performance so as to be able to handle the object recognition task of today's highly sophisticated embedded multimedia systems while keeping its energy consumption at very low levels. Our low-power embedded reconfigurable system is at least 15 times faster than the software implementation on a low-voltage high-end CPU, while consuming at least 60 times less energy. Our novel system is also 88 times more energy efficient than the recently introduced low-power multi-core Intel devices which are optimized for embedded systems. This is, to the best of our knowledge, the first system presented that can execute the complete complex object recognition task at a multi frame per second rate while consuming minimal amounts of energy, making it an ideal candidate for future embedded multimedia systems.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = mar,
articleno = {33},
numpages = {20},
keywords = {FPGAs, object detection, Multimedia, computer vision, performance, embedded design}
}

@inproceedings{10.5555/2499592.2499598,
author = {Williams, Sean and Eidenbenz, Stephan},
title = {Themis-1: An Agent-Based Model of a Modern Monetary Reserve System},
year = {2013},
isbn = {9781627480291},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {We present Themis, an agent-based simulation of a modern reserve system, along with the financial components of the public sector, and a proxy for the nonbank members of the private sector. The simulation primarily revolves around the key interest rate that benchmarks private lending, which arises from agents' trading within a market for bonds and loans, along with the financial implications of that interest rate. Several tunable parameters allow a user to experiment with different policy configurations and levels of private demand for loans. We both validate the simulation against real-world data, and show the results of three unconventional policy settings: one in which the central bank "loses its appetite" for public debt, a second in which the treasury runs deficits without corresponding debt issuance, and a third in which the central bank uses other policy tools to correct for some of the consequences of the second scenario.},
booktitle = {Proceedings of the Agent-Directed Simulation Symposium},
articleno = {6},
numpages = {8},
keywords = {monetary theory, agent-based finance, agent-based economics},
location = {San Diego, California},
series = {ADSS 13}
}

@inproceedings{10.1145/2460296.2460341,
author = {Camilleri, Vanessa and de Freitas, Sara and Montebello, Matthew and McDonagh-Smith, Paul},
title = {A Case Study inside Virtual Worlds: Use of Analytics for Immersive Spaces},
year = {2013},
isbn = {9781450317856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460296.2460341},
doi = {10.1145/2460296.2460341},
abstract = {In this paper we describe some case studies of the use of virtual worlds in corporate training as well as Higher Education. In particular for Higher Education we describe how the Virtual World constructed using the platform Avaya Live Engage, is used as an immersive environment with pre-service teachers, who are undergoing a 1-year teacher training program, and how the data analytics collected in-world is being used to monitor and direct content development. We focus our studies on the initial hypothesis that 3D immersive environments are highly engaging and offer an experience that goes beyond the 'traditional' online education. We want to combine different analysis methods to be able to get empirical evidence showing the students' engagement with the 3D space in ways that can help us in the design of the learning experience accompanying the learners in their journey. In this paper we describe the research methods we use for the study, and give an overview of the information we can collect from the in-world analytics. We also propose how these analytics can be used for a predictive model with the intention of refocusing the virtual world experience to match learner needs.},
booktitle = {Proceedings of the Third International Conference on Learning Analytics and Knowledge},
pages = {230–234},
numpages = {5},
keywords = {higher education, virtual worlds, data analytics, pre-service teachers, corporate training},
location = {Leuven, Belgium},
series = {LAK '13}
}

@inproceedings{10.1145/2502524.2502550,
author = {Han, Song and Mok, Aloysius K. and Meng, Jianyong and Wei, Yi-Hung and Huang, Pei-Chi and Leng, Quan and Zhu, Xiuming and Sentis, Luis and Kim, Kwan Suk and Miikkulainen, Risto},
title = {Architecture of a Cyberphysical Avatar},
year = {2013},
isbn = {9781450319966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2502524.2502550},
doi = {10.1145/2502524.2502550},
abstract = {This paper introduces the concept of a cyberphysical avatar which is defined to be a semi-autonomous robotic system that adjusts to an unstructured environment and performs physical tasks subject to critical timing constraints while under human supervision. Cyberphysical avatar integrates the recent advance in three technologies: body-compliant control in robotics, neuroevolution in machine learning and QoS guarantees in real-time communication. Body-compliant control is essential for operator safety since cyberphysical avatars perform cooperative tasks in close proximity to humans. Neuroevolution technique is essential for "programming" cyberphysical avatars inasmuch as they are to be used by non-experts for a large array of tasks, some unforeseen, in an unstructured environment. QoS-guaranteed real-time communication is essential to provide predictable, bounded-time response in human-avatar interaction. By integrating these technologies, we have built a prototype cyberphysical avatar testbed.},
booktitle = {Proceedings of the ACM/IEEE 4th International Conference on Cyber-Physical Systems},
pages = {189–198},
numpages = {10},
location = {Philadelphia, Pennsylvania},
series = {ICCPS '13}
}

@article{10.1145/2442116.2442134,
author = {Zimmerman, Andrew T. and Lynch, Jerome P. and Ferrese, Frank T.},
title = {Market-Based Resource Allocation for Distributed Data Processing in Wireless Sensor Networks},
year = {2013},
issue_date = {March 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {1539-9087},
url = {https://doi.org/10.1145/2442116.2442134},
doi = {10.1145/2442116.2442134},
abstract = {In recent years, improved wireless technologies have enabled the low-cost deployment of large numbers of sensors for a wide range of monitoring applications. Because of the computational resources (processing capability, storage capacity, etc.) collocated with each sensor in a wireless network, it is often possible to perform advanced data analysis tasks autonomously and in-network, eliminating the need for the post-processing of sensor data. With new parallel algorithms being developed for in-network computation, it has become necessary to create a framework in which all of a wireless network's scarce resources (CPU time, wireless bandwidth, storage capacity, battery power, etc.) can be best utilized in the midst of competing computational requirements. In this study, a market-based method is developed to autonomously distribute these scarce network resources across various computational tasks with competing objectives and/or resource demands. This method is experimentally validated on a network of wireless sensing prototypes, where it is shown to be capable of Pareto-optimally allocating scarce network resources. Then, it is applied to the real-world problem of rupture detection in shipboard chilled water systems.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = apr,
articleno = {84},
numpages = {28},
keywords = {pricing, Wireless sensor networks, distributed algorithms, optimization}
}

@inproceedings{10.1145/2460296.2460344,
author = {Prinsloo, Paul and Slade, Sharon},
title = {An Evaluation of Policy Frameworks for Addressing Ethical Considerations in Learning Analytics},
year = {2013},
isbn = {9781450317856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460296.2460344},
doi = {10.1145/2460296.2460344},
abstract = {Higher education institutions have collected and analysed student data for years, with their focus largely on reporting and management needs. A range of institutional policies exist which broadly set out the purposes for which data will be used and how data will be protected. The growing advent of learning analytics has seen the uses to which student data is put expanding rapidly. Generally though the policies setting out institutional use of student data have not kept pace with this change.Institutional policy frameworks should provide not only an enabling environment for the optimal and ethical harvesting and use of data, but also clarify: who benefits and under what conditions, establish conditions for consent and the de-identification of data, and address issues of vulnerability and harm. A directed content analysis of the policy frameworks of two large distance education institutions shows that current policy frameworks do not facilitate the provision of an enabling environment for learning analytics to fulfil its promise.},
booktitle = {Proceedings of the Third International Conference on Learning Analytics and Knowledge},
pages = {240–244},
numpages = {5},
keywords = {learning analytics, policy, distance learning, ethics},
location = {Leuven, Belgium},
series = {LAK '13}
}

@inproceedings{10.1145/2460296.2460301,
author = {Santos, Jose Luis and Verbert, Katrien and Govaerts, Sten and Duval, Erik},
title = {Addressing Learner Issues with StepUp! An Evaluation},
year = {2013},
isbn = {9781450317856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460296.2460301},
doi = {10.1145/2460296.2460301},
abstract = {This paper reports on our research on the use of learning analytics dashboards to support awareness, self-reflection, sensemaking and impact for learners. So far, little research has been done to evaluate such dashboards with students and to assess their impact on learning. In this paper, we present the results of an evaluation study of our dashboard, called StepUp!, and the extent to which it addresses issues and needs of our students. Through brainstorming sessions with our students, we identified and prioritized learning issues and needs. In a second step, we deployed StepUp! during one month and we evaluated to which extent our dashboard addresses the issues and needs identified earlier in different courses. The results show that our tool has potentially higher impact for students working in groups and sharing a topic than students working individually on different topics.},
booktitle = {Proceedings of the Third International Conference on Learning Analytics and Knowledge},
pages = {14–22},
numpages = {9},
keywords = {evaluation, learning analytics, design based research, reflection, visualization},
location = {Leuven, Belgium},
series = {LAK '13}
}

@article{10.1145/2442087.2442088,
author = {Kornaros, Georgios and Pnevmatikatos, Dionisios},
title = {A Survey and Taxonomy of On-Chip Monitoring of Multicore Systems-on-Chip},
year = {2013},
issue_date = {March 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1084-4309},
url = {https://doi.org/10.1145/2442087.2442088},
doi = {10.1145/2442087.2442088},
abstract = {Billion transistor systems-on-chip increasingly require dynamic management of their hardware components and careful coordination of the tasks that they carry out. Diverse real-time monitoring functions assist towards this objective through the collection of important system metrics, such as throughput of processing elements, communication latency, or resource utilization for each application. The online evaluation of these metrics can result in localized or global decisions that attempt to improve aspects of system behavior, system performance, quality-of-service, power and thermal effects under nominal conditions. This work provides a comprehensive categorization of monitoring approaches used in multiprocessor SoCs. As adaptive systems are encountered in many disciplines, it is imperative to present the prominent research efforts in developing online monitoring methods. To this end we offer a taxonomy that groups strongly related techniques that designers increasingly use to produce more efficient and adaptive chips. The provided classification helps to understand and compare architectural mechanisms that can be used in systems, while one can envisage the innovations required to build real adaptive and intelligent systems-on-chip.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = apr,
articleno = {17},
numpages = {38},
keywords = {fault tolerance, security, dynamic management, adaptive SoC, network-on-chip, run-time optimization, multicore, On-chip monitoring, diagnosis, on-line debugging, proactive SoC management, reconfiguration}
}

@article{10.1145/2442106.2442110,
author = {Quek, Francis and Oliveira, Francisco},
title = {Enabling the Blind to See Gestures},
year = {2013},
issue_date = {March 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1},
issn = {1073-0516},
url = {https://doi.org/10.1145/2442106.2442110},
doi = {10.1145/2442106.2442110},
abstract = {Human discourse is an embodied activity emerging from the embodied imagery and construction of our talk. Gesture and speech are coexpressive, conveying this imagery and meaning simultaneously. Mathematics instruction and discourse typically involve two modes of communication: speech and graphical presentation. Our goal is to assist Individuals who are Blind or Severely Visually Impaired (IBSVI) to access such instruction/communication. We employ a haptic glove interface to furnish the IBSVI with awareness of the deictic gestures performed by the instructor over the graphic in conjunction with speech. We present a series of studies spanning two years where we show how our Haptic Deictic System (HDS) can support learning in inclusive classrooms where IBSVI receive instruction alongside sighted students. We discuss how the introduction of the HDS was advantageous to all parties: IBSVI, instructor, and sighted students. The HDS created more learning opportunities, increasing mutual understanding and promoting greater engagement.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = apr,
articleno = {4},
numpages = {32},
keywords = {embodied skill, Multimodal, discourse, gaming, assistive technology}
}

@inproceedings{10.1145/2460999.2461034,
author = {Licorish, Sherlock A. and MacDonell, Stephen G.},
title = {The True Role of Active Communicators: An Empirical Study of Jazz Core Developers},
year = {2013},
isbn = {9781450318488},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460999.2461034},
doi = {10.1145/2460999.2461034},
abstract = {Context: Interest in software engineering (SE) methodologies and tools has been complemented in recent years by research efforts oriented towards understanding the human processes involved in software development. This shift has been imperative given reports of inadequately performing teams and the consequent growing emphasis on individuals and team relations in contemporary SE methods. Objective: While software repositories have frequently been studied with a view to explaining such human processes, research has tended to use primarily quantitative analysis approaches. There is concern, however, that such approaches can provide only a partial picture of the software process. Given the way human behavior is nuanced within psychological and social contexts, it has been asserted that a full understanding may only be achieved through deeper contextual enquiries. Method: We have followed such an approach and have applied data mining, SNA, psycholinguistic analysis and directed content analysis (CA) to study the way core developers at IBM Rational Jazz contribute their social and intellectual capital, and have compared the attitudes, interactions and activities of these members to those of their less active counterparts. Results: Among our results, we uncovered that Jazz's core developers worked across multiple roles, and were crucial to their teams' organizational, intra-personal and interpersonal processes. Additionally, although these individuals were highly task- and achievement-focused, they were also largely responsible for maintaining positive team atmosphere. Further, we uncovered that, as a group, Jazz developers spent a large amount of time providing context awareness in support of their colleagues. Conclusion: Our results suggest that high-performing distributed agile teams rely on both individual and collective efforts, as well as organizational environments that promote informal and organic work structures.},
booktitle = {Proceedings of the 17th International Conference on Evaluation and Assessment in Software Engineering},
pages = {228–239},
numpages = {12},
keywords = {software development, core developers, roles, content analysis, psycholinguistics, behaviors, Jazz},
location = {Porto de Galinhas, Brazil},
series = {EASE '13}
}

@inproceedings{10.1145/2460999.2461028,
author = {Cavalcanti, Yguarat\~{a} Cerqueira and da Mota Silveira Neto, Paulo Anselmo and do Carmo Machado, Ivan and de Almeida, Eduardo Santana and de Lemos Meira, Silvio Romero},
title = {Towards Understanding Software Change Request Assignment: A Survey with Practitioners},
year = {2013},
isbn = {9781450318488},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460999.2461028},
doi = {10.1145/2460999.2461028},
abstract = {Context: Change Request (CR) repositories play an important role in the software maintenance and evolution process. Through a CR repository, software changes are reported and assigned to developers. Finding the appropriate developer to a CR is crucial for obtaining the lowest, economically feasible, fixing time. Nevertheless, assigning CRs is a labor-intensive and time consuming task. Although many work have proposed automated approaches for CR assignment, they have been implemented without investigating the fundamental aspects which characterize the task itself. Objective: This paper investigates the effort that is taken to assign CR to appropriate developers and identifies the fundamental aspects that characterize it, such as the strategies to perform the assignments and the complexity involved in them. Such investigation improves the current knowledge on the topic, providing researchers and practitioners with useful information towards developing effective solutions. Method: A survey was performed with software developers to understand CR assignment in the Brazilian Federal Organization for Data Processing. The questionnaire was composed of 38 questions, being them both open-ended and closed-ended. We analyzed the answers of 36 respondents. Results: We find that: there is a significant amount of time being spent on assignments (e.g., assigning 20 CRs can take up to 3.3 hours); there are many strategies used to assign CRs, which are complementary to those used in current automated solutions; and CR assignment is very complexity due to a process that requires cognitive abilities for information seeking, communication, and memorization. Conclusion: CR repositories are fundamental to software maintenance, however assigning CRs to developers is an expensive activity. Although we understand that fully and totally accurate automation of assignments is unlikely, further improvements on this direction are feasible and necessary to reduce costs. This way, this paper brings relevant findings to guide new research on automated CR assignment.},
booktitle = {Proceedings of the 17th International Conference on Evaluation and Assessment in Software Engineering},
pages = {195–206},
numpages = {12},
keywords = {issue tracking, bug triage, software maintenance, change request assignment, bug tracking},
location = {Porto de Galinhas, Brazil},
series = {EASE '13}
}

@inproceedings{10.1145/2460999.2461035,
author = {Licorish, Sherlock A. and MacDonell, Stephen G.},
title = {Adopting Softer Approaches in the Study of Repository Data: A Comparative Analysis},
year = {2013},
isbn = {9781450318488},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460999.2461035},
doi = {10.1145/2460999.2461035},
abstract = {Context: Given the acknowledged need to understand the people processes enacted during software development, software repositories and mailing lists have become a focus for many studies. However, researchers have tended to use mostly mathematical and frequency-based techniques to examine the software artifacts contained within them. Objective: There is growing recognition that these approaches uncover only a partial picture of what happens during software projects, and deeper contextual approaches may provide further understanding of the intricate nature of software teams' dynamics. We demonstrate the relevance and utility of such approaches in this study. Method: We use psycholinguistics and directed content analysis (CA) to study the way project tasks drive teams' attitudes and knowledge sharing. We compare the outcomes of these two approaches and offer methodological advice for researchers using similar forms of repository data. Results: Our analysis reveals significant differences in the way teams work given their portfolio of tasks and the distribution of roles. Conclusion: We overcome the limitations associated with employing purely quantitative approaches, while avoiding the time-intensive and potentially invasive nature of field work required in full case studies.},
booktitle = {Proceedings of the 17th International Conference on Evaluation and Assessment in Software Engineering},
pages = {240–245},
numpages = {6},
keywords = {content analysis, Jazz, software teams, psycholinguistics, communication},
location = {Porto de Galinhas, Brazil},
series = {EASE '13}
}

@inproceedings{10.1145/2465351.2465355,
author = {Agarwal, Sameer and Mozafari, Barzan and Panda, Aurojit and Milner, Henry and Madden, Samuel and Stoica, Ion},
title = {BlinkDB: Queries with Bounded Errors and Bounded Response Times on Very Large Data},
year = {2013},
isbn = {9781450319942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2465351.2465355},
doi = {10.1145/2465351.2465355},
abstract = {In this paper, we present BlinkDB, a massively parallel, approximate query engine for running interactive SQL queries on large volumes of data. BlinkDB allows users to trade-off query accuracy for response time, enabling interactive queries over massive data by running queries on data samples and presenting results annotated with meaningful error bars. To achieve this, BlinkDB uses two key ideas: (1) an adaptive optimization framework that builds and maintains a set of multi-dimensional stratified samples from original data over time, and (2) a dynamic sample selection strategy that selects an appropriately sized sample based on a query's accuracy or response time requirements. We evaluate BlinkDB against the well-known TPC-H benchmarks and a real-world analytic workload derived from Conviva Inc., a company that manages video distribution over the Internet. Our experiments on a 100 node cluster show that BlinkDB can answer queries on up to 17 TBs of data in less than 2 seconds (over 200 x faster than Hive), within an error of 2-10%.},
booktitle = {Proceedings of the 8th ACM European Conference on Computer Systems},
pages = {29–42},
numpages = {14},
location = {Prague, Czech Republic},
series = {EuroSys '13}
}

@inproceedings{10.1145/2465351.2465369,
author = {Khayyat, Zuhair and Awara, Karim and Alonazi, Amani and Jamjoom, Hani and Williams, Dan and Kalnis, Panos},
title = {Mizan: A System for Dynamic Load Balancing in Large-Scale Graph Processing},
year = {2013},
isbn = {9781450319942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2465351.2465369},
doi = {10.1145/2465351.2465369},
abstract = {Pregel [23] was recently introduced as a scalable graph mining system that can provide significant performance improvements over traditional MapReduce implementations. Existing implementations focus primarily on graph partitioning as a preprocessing step to balance computation across compute nodes. In this paper, we examine the runtime characteristics of a Pregel system. We show that graph partitioning alone is insufficient for minimizing end-to-end computation. Especially where data is very large or the runtime behavior of the algorithm is unknown, an adaptive approach is needed. To this end, we introduce Mizan, a Pregel system that achieves efficient load balancing to better adapt to changes in computing needs. Unlike known implementations of Pregel, Mizan does not assume any a priori knowledge of the structure of the graph or behavior of the algorithm. Instead, it monitors the runtime characteristics of the system. Mizan then performs efficient fine-grained vertex migration to balance computation and communication. We have fully implemented Mizan; using extensive evaluation we show that---especially for highly-dynamic workloads---Mizan provides up to 84% improvement over techniques leveraging static graph pre-partitioning.},
booktitle = {Proceedings of the 8th ACM European Conference on Computer Systems},
pages = {169–182},
numpages = {14},
location = {Prague, Czech Republic},
series = {EuroSys '13}
}

@inproceedings{10.1145/2465351.2465370,
author = {Cruz, Francisco and Maia, Francisco and Matos, Miguel and Oliveira, Rui and Paulo, Jo\~{a}o and Pereira, Jos\'{e} and Vila\c{c}a, Ricardo},
title = {MeT: Workload Aware Elasticity for NoSQL},
year = {2013},
isbn = {9781450319942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2465351.2465370},
doi = {10.1145/2465351.2465370},
abstract = {NoSQL databases manage the bulk of data produced by modern Web applications such as social networks. This stems from their ability to partition and spread data to all available nodes, allowing NoSQL systems to scale. Unfortunately, current solutions' scale out is oblivious to the underlying data access patterns, resulting in both highly skewed load across nodes and suboptimal node configurations.In this paper, we first show that judicious placement of HBase partitions taking into account data access patterns can improve overall throughput by 35%. Next, we go beyond current state of the art elastic systems limited to uninformed replica addition and removal by: i) reconfiguring existing replicas according to access patterns and ii) adding replicas specifically configured to the expected access pattern.MeT is a prototype for a Cloud-enabled framework that can be used alone or in conjunction with OpenStack for the automatic and heterogeneous reconfiguration of a HBase deployment. Our evaluation, conducted using the YCSB workload generator and a TPC-C workload, shows that MeT is able to i) autonomously achieve the performance of a manual configured cluster and ii) quickly reconfigure the cluster according to unpredicted workload changes.},
booktitle = {Proceedings of the 8th ACM European Conference on Computer Systems},
pages = {183–196},
numpages = {14},
location = {Prague, Czech Republic},
series = {EuroSys '13}
}

@inproceedings{10.1145/2465351.2465379,
author = {Zhang, Liang and Zhou, Fangfei and Mislove, Alan and Sundaram, Ravi},
title = {Maygh: Building a CDN from Client Web Browsers},
year = {2013},
isbn = {9781450319942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2465351.2465379},
doi = {10.1145/2465351.2465379},
abstract = {Over the past two decades, the web has provided dramatic improvements in the ease of sharing content. Unfortunately, the costs of distributing this content are largely incurred by web site operators; popular web sites are required to make substantial monetary investments in serving infrastructure or cloud computing resources---or must pay other organizations (e.g., content distribution networks)---to help serve content. Previous approaches to offloading some of the distribution costs onto end users have relied on client-side software or web browser plug-ins, providing poor user incentives and dramatically limiting their scope in practice.In this paper, we present Maygh, a system that builds a content distribution network from client web browsers, without the need for additional plug-ins or client-side software. The result is an organically scalable system that distributes the cost of serving web content across the users of a web site. Through simulations based on real-world access logs from Etsy (a large e-commerce web site that is the 50th most popular web site in the U.S.), microbenchmarks, and a small-scale deployment, we demonstrate that Maygh provides substantial savings to site operators, imposes only modest costs on clients, and can be deployed on the web sites and browsers of today. In fact, if Maygh was deployed to Etsy, it would reduce network bandwidth due to static content by 75% and require only a single coordinating server.},
booktitle = {Proceedings of the 8th ACM European Conference on Computer Systems},
pages = {281–294},
numpages = {14},
keywords = {JavaScript, content distribution network, distributed},
location = {Prague, Czech Republic},
series = {EuroSys '13}
}

@inproceedings{10.1145/2461466.2461470,
author = {Moise, Diana and Shestakov, Denis and Gudmundsson, Gylfi and Amsaleg, Laurent},
title = {Indexing and Searching 100M Images with Map-Reduce},
year = {2013},
isbn = {9781450320337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2461466.2461470},
doi = {10.1145/2461466.2461470},
abstract = {Most researchers working on high-dimensional indexing agree on the following three trends: (i) the size of the multimedia collections to index are now reaching millions if not billions of items, (ii) the computers we use every day now come with multiple cores and (iii) hardware becomes more available, thanks to easier access to Grids and/or Clouds. This paper shows how the Map-Reduce paradigm can be applied to indexing algorithms and demonstrates that great scalability can be achieved using Hadoop, a popular Map-Reduce-based framework. Dramatic performance improvements are not however guaranteed a priori: such frameworks are rigid, they severely constrain the possible access patterns to data and scares resource RAM has to be shared. Furthermore, algorithms require major redesign, and may have to settle for sub-optimal behavior. The benefits, however, are many: simplicity for programmers, automatic distribution, fault tolerance, failure detection and automatic re-runs and, last but not least, scalability. We share our experience of adapting a clustering-based high-dimensional indexing algorithm to the Map-Reduce model, and of testing it at large scale with Hadoop as we index 30 billion SIFT descriptors. We foresee that lessons drawn from our work could minimize time, effort and energy invested by other researchers and practitioners working in similar directions.},
booktitle = {Proceedings of the 3rd ACM Conference on International Conference on Multimedia Retrieval},
pages = {17–24},
numpages = {8},
keywords = {high-dimensional indexing, map-reduce, hadoop},
location = {Dallas, Texas, USA},
series = {ICMR '13}
}

@inproceedings{10.1145/2462096.2462100,
author = {Chakradeo, Saurabh and Reaves, Bradley and Traynor, Patrick and Enck, William},
title = {MAST: Triage for Market-Scale Mobile Malware Analysis},
year = {2013},
isbn = {9781450319980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2462096.2462100},
doi = {10.1145/2462096.2462100},
abstract = {Malware is a pressing concern for mobile application market operators. While current mitigation techniques are keeping pace with the relatively infrequent presence of malicious code, the rapidly increasing rate of application development makes manual and resource-intensive automated analysis costly at market-scale. To address this resource imbalance, we present the Mobile Application Security Triage (MAST) architecture, a tool that helps to direct scarce malware analysis resources towards the applications with the greatest potential to exhibit malicious behavior. MAST analyzes attributes extracted from just the application package using Multiple Correspondence Analysis (MCA), a statistical method that measures the correlation between multiple categorical (i.e., qualitative) data. We train MAST using over 15,000 applications from Google Play and a dataset of 732 known-malicious applications. We then use MAST to perform triage on three third-party markets of different size and malware composition---36,710 applications in total. Our experiments show that MAST is both effective and performant. Using MAST ordered ranking, malware-analysis tools can find 95% of malware at the cost of analyzing 13% of the non-malicious applications on average across multiple markets, and MAST triage processes markets in less than a quarter of the time required to perform signature detection. More importantly, we show that successful triage can dramatically reduce the costs of removing malicious applications from markets.},
booktitle = {Proceedings of the Sixth ACM Conference on Security and Privacy in Wireless and Mobile Networks},
pages = {13–24},
numpages = {12},
keywords = {multiple correspondence analysis, triage, mobile application security},
location = {Budapest, Hungary},
series = {WiSec '13}
}

@inproceedings{10.1145/2462096.2462113,
author = {Henne, Benjamin and Szongott, Christian and Smith, Matthew},
title = {SnapMe If You Can: Privacy Threats of Other Peoples' Geo-Tagged Media and What We Can Do about It},
year = {2013},
isbn = {9781450319980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2462096.2462113},
doi = {10.1145/2462096.2462113},
abstract = {The amount of media uploaded to the Web is still rapidly expanding. The ease-of-use of modern smartphones in combination with the proliferation of high-speed mobile networks facilitates a culture of spontaneous and often carefree sharing of user-generated content, especially photos and videos. An increasing number of modern devices are capable of embedding location information and other metadata into created content. However, currently there is not much user awareness of possible privacy consequences of such data. While in most cases users upload their own media consciously, the flood of media uploaded by others is so huge that it is almost impossible for users to stay aware of all media that might be relevant to them. Current social network services and photo-sharing sites mainly focus on the privacy of users' own media in terms of access control, but offer few possibilities to deal with privacy implications created by other users' actions. We conducted an online survey with 414 participants. The results show that users would like to get more information about media shared by others. Based on an analysis of prevalent sharing services like Flickr, Facebook, or Google+ and an analysis of metadata of three different sets of crawled photos, we discuss privacy implications and potentials of the emerging trend of (geo-)tagged media. Finally, we present a novel concept on how location information can actually help users to control the flood of potentially infringing or interesting media.},
booktitle = {Proceedings of the Sixth ACM Conference on Security and Privacy in Wireless and Mobile Networks},
pages = {95–106},
numpages = {12},
keywords = {photo-sharing, awareness, privacy, geo-tagging, social media},
location = {Budapest, Hungary},
series = {WiSec '13}
}

@inproceedings{10.1145/2462307.2462317,
author = {Valv\r{a}g, Steffen Viken and Johansen, Dag and Kvalnes, \r{A}ge},
title = {Position Paper: Elastic Processing and Storage at the Edge of the Cloud},
year = {2013},
isbn = {9781450320511},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2462307.2462317},
doi = {10.1145/2462307.2462317},
abstract = {Cloud services traditionally have a centralized architecture, where all clients communicate individually with the central service, and not directly with each other. Data is primarily stored in the cloud, and computations that touch data are performed in the cloud. We present Rusta, a platform that allows cloud services to deploy in a more flexible and decentralized manner, potentially involving the client machines at the edge of the cloud both for storage and processing of data. This can reduce operational costs both by leveraging freely available client resources, and by reducing data traffic to and from the cloud.Rusta includes a group abstraction to delineate webs of trusted peers, a light-weight process abstraction based on asynchronous message passing, and a distributed data storage layer. For elasticity, processes may migrate freely among the clients of a group, and can be replicated in a transparent manner. A central hub service executes in the cloud and maintains critical system state, while delegating work to clients as appropriate. This paper describes the design and current implementation of Rusta, its high-level programming model, and some of its potential applications, in particular as a foundation for highly elastic computations at the edge of the cloud.},
booktitle = {Proceedings of the 2013 International Workshop on Hot Topics in Cloud Services},
pages = {43–50},
numpages = {8},
keywords = {light-weight processes, migration, rusta},
location = {Prague, Czech Republic},
series = {HotTopiCS '13}
}

@article{10.1145/2448116.2448120,
author = {Console, Luca and Antonelli, Fabrizio and Biamino, Giulia and Carmagnola, Francesca and Cena, Federica and Chiabrando, Elisa and Cuciti, Vincenzo and Demichelis, Matteo and Fassio, Franco and Franceschi, Fabrizio and Furnari, Roberto and Gena, Cristina and Geymonat, Marina and Grimaldi, Piercarlo and Grillo, Pierluige and Likavec, Silvia and Lombardi, Ilaria and Mana, Dario and Marcengo, Alessandro and Mioli, Michele and Mirabelli, Mario and Perrero, Monica and Picardi, Claudia and Protti, Federica and Rapp, Amon and Simeoni, Rossana and Dupr\'{e}, Daniele Theseider and Torre, Ilaria and Toso, Andrea and Torta, Fabio and Vernero, Fabiana},
title = {Interacting with Social Networks of Intelligent Things and People in the World of Gastronomy},
year = {2013},
issue_date = {April 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
issn = {2160-6455},
url = {https://doi.org/10.1145/2448116.2448120},
doi = {10.1145/2448116.2448120},
abstract = {This article introduces a framework for creating rich augmented environments based on a social web of intelligent things and people. We target outdoor environments, aiming to transform a region into a smart environment that can share its cultural heritage with people, promoting itself and its special qualities. Using the applications developed in the framework, people can interact with things, listen to the stories that these things tell them, and make their own contributions. The things are intelligent in the sense that they aggregate information provided by users and behave in a socially active way. They can autonomously establish social relationships on the basis of their properties and their interaction with users. Hence when a user gets in touch with a thing, she is also introduced to its social network consisting of other things and of users; she can navigate this network to discover and explore the world around the thing itself. Thus the system supports serendipitous navigation in a network of things and people that evolves according to the behavior of users. An innovative interaction model was defined that allows users to interact with objects in a natural, playful way using smartphones without the need for a specially created infrastructure.The framework was instantiated into a suite of applications called WantEat, in which objects from the domain of tourism and gastronomy (such as cheese wheels or bottles of wine) are taken as testimonials of the cultural roots of a region. WantEat includes an application that allows the definition and registration of things, a mobile application that allows users to interact with things, and an application that supports stakeholders in getting feedback about the things that they have registered in the system. WantEat was developed and tested in a real-world context which involved a region and gastronomy-related items from it (such as products, shops, restaurants, and recipes), through an early evaluation with stakeholders and a final evaluation with hundreds of users.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = apr,
articleno = {4},
numpages = {38},
keywords = {social networking, smart objects, real-world testing, gastronomy, Social web of things, social intelligence, preserving cultural heritage and keeping it alive, playful interaction, mobile intelligent applications}
}

@article{10.1145/2448116.2448119,
author = {Poesio, Massimo and Chamberlain, Jon and Kruschwitz, Udo and Robaldo, Livio and Ducceschi, Luca},
title = {Phrase Detectives: Utilizing Collective Intelligence for Internet-Scale Language Resource Creation},
year = {2013},
issue_date = {April 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
issn = {2160-6455},
url = {https://doi.org/10.1145/2448116.2448119},
doi = {10.1145/2448116.2448119},
abstract = {We are witnessing a paradigm shift in Human Language Technology (HLT) that may well have an impact on the field comparable to the statistical revolution: acquiring large-scale resources by exploiting collective intelligence. An illustration of this new approach is Phrase Detectives, an interactive online game with a purpose for creating anaphorically annotated resources that makes use of a highly distributed population of contributors with different levels of expertise.The purpose of this article is to first of all give an overview of all aspects of Phrase Detectives, from the design of the game and the HLT methods we used to the results we have obtained so far. It furthermore summarizes the lessons that we have learned in developing this game which should help other researchers to design and implement similar games.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = apr,
articleno = {3},
numpages = {44},
keywords = {Web cooperation, corpus annotation, human language technology, anaphora, games with a purpose, resource creation}
}

@article{10.1145/2445583.2445588,
author = {Das, Sudipto and Agrawal, Divyakant and El Abbadi, Amr},
title = {ElasTraS: An Elastic, Scalable, and Self-Managing Transactional Database for the Cloud},
year = {2013},
issue_date = {April 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0362-5915},
url = {https://doi.org/10.1145/2445583.2445588},
doi = {10.1145/2445583.2445588},
abstract = {A database management system (DBMS) serving a cloud platform must handle large numbers of application databases (or tenants) that are characterized by diverse schemas, varying footprints, and unpredictable load patterns. Scaling out using clusters of commodity servers and sharing resources among tenants (i.e., multitenancy) are important features of such systems. Moreover, when deployed on a pay-per-use infrastructure, minimizing the system's operating cost while ensuring good performance is also an important goal. Traditional DBMSs were not designed for such scenarios and hence do not possess the mentioned features critical for DBMSs in the cloud.We present ElasTraS, which combines three design principles to build an elastically-scalable multitenant DBMS for transaction processing workloads. These design principles are gleaned from a careful analysis of the years of research in building scalable key-value stores and decades of research in high performance transaction processing systems. ElasTraS scales to thousands of tenants, effectively consolidates tenants with small footprints while scaling-out large tenants across multiple servers in a cluster. ElasTraS also supports low-latency multistep ACID transactions, is fault-tolerant, self-managing, and highly available to support mission critical applications. ElasTraS leverages Albatross, a low overhead on-demand live database migration technique, for elastic load balancing by adding more servers during high load and consolidating to fewer servers during usage troughs. This elastic scaling minimizes the operating cost and ensures good performance even in the presence of unpredictable changes to the workload.We elucidate the design principles, explain the architecture, describe a prototype implementation, present the detailed design and implementation of Albatross, and experimentally evaluate the implementation using a variety of transaction processing workloads. On a cluster of 20 commodity servers, our prototype serves thousands of tenants and serves more than 1 billion transactions per day while migrating tenant databases with minimal overhead to allow lightweight elastic scaling. Using a cluster of 30 commodity servers, ElasTraS can scale-out a terabyte TPC-C database serving an aggregate throughput of approximately one quarter of a million TPC-C transactions per minute.},
journal = {ACM Trans. Database Syst.},
month = apr,
articleno = {5},
numpages = {45},
keywords = {ACID, transactions, scalability, fault-tolerance, elastic data management, Cloud computing}
}

@inproceedings{10.1145/2470654.2481365,
author = {Yamashita, Naomi and Kuzuoka, Hideaki and Hirata, Keiji and Kudo, Takashi},
title = {Understanding the Conflicting Demands of Family Caregivers Caring for Depressed Family Members},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481365},
doi = {10.1145/2470654.2481365},
abstract = {Depression is one of the most common disabilities in developed countries. Despite its often devastating impact on families, scant research has focused on how to facilitate the well-being of family caregivers. The aim of this paper is to uncover the challenges faced by family caregivers and support their well-being with the use of technologies. To understand the emotional and social burden of caregivers and how they handle their stress, we conducted in-depth interviews with 15 individuals who have cared for a depressed family member. Our findings reveal the multifaceted dilemma of caring for a depressed family member as well as the various strategies engaged in by caregivers to improve their own situations. Based on our findings, we suggest design implications for healthcare technologies to improve the wellness of caregivers who are looking after depressed family members.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2637–2646},
numpages = {10},
keywords = {depression, family caregivers, stress, healthcare technology},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2468356.2468753,
author = {Vidyarthi, Jay and Riecke, Bernhard E.},
title = {Mediated Meditation: Cultivating Mindfulness with Sonic Cradle},
year = {2013},
isbn = {9781450319522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2468356.2468753},
doi = {10.1145/2468356.2468753},
abstract = {Sonic Cradle enables users to shape sound with their breath while suspended in a completely dark chamber. We conducted a qualitative investigation to understand 39 na\"{\i}ve participants' subjective responses to this design artifact. Systematic analysis with 3 independent data coders produced 11 findings which richly describe the Sonic Cradle experience as clearly comparable to mindfulness meditation (e.g. clarity of mind, loss of intention). This paper shows how persuasive media have the potential to promote long-term psychological health by experientially introducing a stress-relieving, contemplative practice to non-practitioners.},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
pages = {2305–2314},
numpages = {10},
keywords = {stress, biofeedback, qualitative, persuasive, meditation, deprivation, sound, respiration., mindfulness, music},
location = {Paris, France},
series = {CHI EA '13}
}

@inproceedings{10.1145/2470654.2470697,
author = {Bulling, Andreas and Weichel, Christian and Gellersen, Hans},
title = {EyeContext: Recognition of High-Level Contextual Cues from Human Visual Behaviour},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470697},
doi = {10.1145/2470654.2470697},
abstract = {In this work we present EyeContext, a system to infer high-level contextual cues from human visual behaviour. We conducted a user study to record eye movements of four participants over a full day of their daily life, totalling 42.5 hours of eye movement data. Participants were asked to self-annotate four non-mutually exclusive cues: social (interacting with somebody vs. no interaction), cognitive (concentrated work vs. leisure), physical (physically active vs. not active), and spatial (inside vs. outside a building). We evaluate a proof-of-concept EyeContext system that combines encoding of eye movements into strings and a spectrum string kernel support vector machine (SVM) classifier. Our results demonstrate the large information content available in long-term human visual behaviour and opens up new venues for research on eye-based behavioural monitoring and life logging.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {305–308},
numpages = {4},
keywords = {visual behaviour, electrooculography (eog), eye movement analysis, context recognition},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481364,
author = {Bardram, Jakob E. and Frost, Mads and Sz\'{a}nt\'{o}, K\'{a}roly and Faurholt-Jepsen, Maria and Vinberg, Maj and Kessing, Lars Vedel},
title = {Designing Mobile Health Technology for Bipolar Disorder: A Field Trial of the Monarca System},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481364},
doi = {10.1145/2470654.2481364},
abstract = {An increasing number of pervasive healthcare systems are being designed, that allow people to monitor and get feedback on their health and wellness. To address the challenges of self-management of mental illnesses, we have developed the MONARCA system - a personal monitoring system for bipolar patients. We conducted a 14 week field trial in which 12 patients used the system, and we report findings focusing on their experiences. The results were positive; compared to using paper-based forms, the adherence to self-assessment improved; the system was considered very easy to use; and the perceived usefulness of the system was high. Based on this study, the paper discusses three HCI questions related to the design of personal health technologies; how to design for disease awareness and self-treatment, how to ensure adherence to personal health technologies, and the roles of different types of technology platforms.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2627–2636},
numpages = {10},
keywords = {mobile application, bipolar disorder, personal health systems, mental health},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466152,
author = {Rodden, Tom A. and Fischer, Joel E. and Pantidi, Nadia and Bachour, Khaled and Moran, Stuart},
title = {At Home with Agents: Exploring Attitudes towards Future Smart Energy Infrastructures},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466152},
doi = {10.1145/2470654.2466152},
abstract = {Energy systems researchers are proposing a broad range of future "smart" energy infrastructures to promote more efficient management of energy resources. This paper considers how consumers might relate to these future smart grids within the UK. To address this challenge we exploited a combination of demonstration and animated sketches to convey the nature of a future smart energy infrastructure based on software agents. Users' reactions suggested that although they felt an obligation to engage with energy issues, they were principally disinterested. Users showed a considerable lack of trust in energy companies raising a dilemma of design. While users might welcome agents to help in engaging with complex energy infrastructures, they had little faith in those that might provide them. This suggests the need to consider how to design software agents to enhance trust in these socio-economic settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1173–1182},
numpages = {10},
keywords = {smart grid, sketching, participatory design, focus groups, agent-based systems, envisioning, whiteboard animations},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466134,
author = {Harmon, Ellie and Mazmanian, Melissa},
title = {Stories of the Smartphone in Everyday Discourse: Conflict, Tension &amp; Instability},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466134},
doi = {10.1145/2470654.2466134},
abstract = {As the smartphone proliferates in American society, so too do stories about its value and impact. In this paper we draw on advertisements and news articles to analyze cultural discourse about the smartphone. We highlight two common tropes: one calling for increased technological integration, the other urging individuals to dis-integrate the smartphone from daily life. We examine the idealized subject positions of these two stories and show how both simplistic tropes call on the same overarching values to compel individuals to take opposing actions. We then reflect on the conflicts individuals experience in trying to align and account for their actions in relation to multiple contradictory narratives. Finally, we call for CHI researchers to tell and provoke more complicated stories of technologies and their relationships with values in conversations, publications, and future designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1051–1060},
numpages = {10},
keywords = {values and design, smartphones, cultural discourse},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466447,
author = {De Choudhury, Munmun and Counts, Scott and Horvitz, Eric},
title = {Predicting Postpartum Changes in Emotion and Behavior via Social Media},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466447},
doi = {10.1145/2470654.2466447},
abstract = {We consider social media as a promising tool for public health, focusing on the use of Twitter posts to build predictive models about the forthcoming influence of childbirth on the behavior and mood of new mothers. Using Twitter posts, we quantify postpartum changes in 376 mothers along dimensions of social engagement, emotion, social network, and linguistic style. We then construct statistical models from a training set of observations of these measures before and after the reported childbirth, to forecast significant postpartum changes in mothers. The predictive models can classify mothers who will change significantly following childbirth with an accuracy of 71%, using observations about their prenatal behavior, and as accurately as 80-83% when additionally leveraging the initial 2-3 weeks of postnatal data. The study is motivated by the opportunity to use social media to identify mothers at risk of postpartum depression, an underreported health concern among large populations, and to inform the design of low-cost, privacy-sensitive early-warning systems and intervention programs aimed at promoting wellness postpartum.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3267–3276},
numpages = {10},
keywords = {postpartum, depression, social media, behavioral health, wellness, childbirth, language, emotion, ppd, twitter, health},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470753,
author = {Huang, Jeff and Zimmermann, Thomas and Nagapan, Nachiappan and Harrison, Charles and Phillips, Bruce C.},
title = {Mastering the Art of War: How Patterns of Gameplay Influence Skill in Halo},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470753},
doi = {10.1145/2470654.2470753},
abstract = {How do video game skills develop, and what sets the top players apart? We study this question of skill through a rating generated from repeated multiplayer matches called TrueSkill. Using these ratings from 7 months of games from over 3 million players, we look at how play intensity, breaks in play, skill change over time, and other games affect skill. These analyzed factors are then combined to model future skill and games played; the results show that skill change in early matches is a useful metric for modeling future skill, while play intensity explains eventual games played. The best players in the 7-month period, who we call "Master Blasters", have varied skill patterns that often run counter to the trends we see for typical players. The data analysis is supplemented with a 70 person survey to explore how players' self-perceptions compare to the gameplay data; most survey responses align well with the data and provide insight into player beliefs and motivation. Finally, we wrap up with a discussion about hiding skill information from players, and implications for game designers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {695–704},
numpages = {10},
keywords = {online multiplayer, gaming skill, learning, video games},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466241,
author = {Sas, Corina and Whittaker, Steve},
title = {Design for Forgetting: Disposing of Digital Possessions after a Breakup},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466241},
doi = {10.1145/2470654.2466241},
abstract = {People are increasingly acquiring huge collections of digital possessions. Despite some pleas for 'forgetting', most theorists argue for retaining all these possessions to enhance 'total recall' of our everyday lives. However, there has been little exploration of the negative role of digital possessions when people want to forget aspects of their lives. We report on interviews with 24 people about their possessions after a romantic breakup. We found that digital possessions were often evocative and upsetting in this context, leading to distinct disposal strategies with different outcomes. We advance theory by finding strong evidence for the value of intentional forgetting and provide new data about complex practices associated with the disposal of digital possessions. Our findings led to a number of design implications to help people better manage this process, including automatic harvesting of digital possessions, tools for self-control, artifact crafting as sense-making, and digital spaces for shared possessions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1823–1832},
numpages = {10},
keywords = {digital possessions, relationship dissolution, autobiographical memories, intentional forgetting, sense of self, disposal},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466436,
author = {Marcu, Gabriela and Tassini, Kevin and Carlson, Quintin and Goodwyn, Jillian and Rivkin, Gabrielle and Schaefer, Kevin J. and Dey, Anind K. and Kiesler, Sara},
title = {Why Do They Still Use Paper? Understanding Data Collection and Use in Autism Education},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466436},
doi = {10.1145/2470654.2466436},
abstract = {Autism education programs for children collect and use large amounts of behavioral data on each student. Staff use paper almost exclusively to collect these data, despite significant problems they face in tracking student data in situ, filling out data sheets and graphs on a daily basis, and using the sheets in collaborative decision making. We conducted fieldwork to understand data collection and use in the domain of autism education to explain why current technology had not met staff needs. We found that data needs are complex and unstandardized, immediate demands of the job interfere with staff ability to collect in situ data, and existing technology for data collection is inadequate. We also identified opportunities for technology to improve sharing and use of data. We found that data sheets are idiosyncratic and not useful without human mediation; improved communication with parents could benefit children's development; and staff are willing, and even eager, to incorporate technology. These factors explain the continued dependence on paper for data collection in this environment, and reveal opportunities for technology to support data collection and improve use of collected data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3177–3186},
numpages = {10},
keywords = {contextual inquiry, cscw, fieldwork},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466207,
author = {Chong, Ming Ki and Gellersen, Hans W.},
title = {How Groups of Users Associate Wireless Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466207},
doi = {10.1145/2470654.2466207},
abstract = {Group association, the process of connecting a group of devices, opens up new opportunities for users to spontaneously share resources. Research has shown numerous techniques and protocols for group association; however, what people intuitively do to associate a group of devices remains an open question. We contribute a study of eliciting device association techniques from groups of non-technical people. In all, we collected and analysed 496 techniques from 61 participants. Our results show that mobility and physicality of devices influence how people perceive groups association. We present a complete set of user-defined techniques with subjective ratings and popularity scores. We examined people's rationale and the effects of different device form factors. We analysed the techniques based on the roles that users assume with respect to device association. Our findings draw out insights from the perspective of users for design of group association.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1559–1568},
numpages = {10},
keywords = {pairing, group, wireless, input techniques, device association, spontaneous interaction, guessability study},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470700,
author = {Gibson, Lorna and Hanson, Vicki L.},
title = {Digital Motherhood: How Does Technology Help New Mothers?},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470700},
doi = {10.1145/2470654.2470700},
abstract = {New mothers can experience social exclusion, particularly during the early weeks when infants are solely dependent on their mothers. We used ethnographic methods to investigate whether technology plays a role in supporting new mothers. Our research identified two core themes: (1) the need to improve confidence as a mother; and (2) the need to be more than '18just' a mother. We reflect on these findings both in terms of those interested in designing applications and services for motherhood and also the wider CHI community.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {313–322},
numpages = {10},
keywords = {new mothers, motherhood, ethnography, social support},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470663,
author = {Liu, Leslie S. and Huh, Jina and Neogi, Tina and Inkpen, Kori and Pratt, Wanda},
title = {Health Vlogger-Viewer Interaction in Chronic Illness Management},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470663},
doi = {10.1145/2470654.2470663},
abstract = {Health video blogs (vlogs) allow individuals with chronic illnesses to share their stories, experiences, and knowledge with the general public. Furthermore, health vlogs help in creating a connection between the vlogger and the viewers. In this work, we present a qualitative study examining the various methods that health vloggers use to establish a connection with their viewers. We found that vloggers used genres to express specific messages to their viewers while using the uniqueness of video to establish a deeper connection with their viewers. Health vloggers also explicitly sought interaction with their viewers. Based on these results, we present design implications to help facilitate and build sustainable communities for vloggers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {49–58},
numpages = {10},
keywords = {communication, chronic illness management, video blogging, patient-centered, youtube, health vlogs},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466210,
author = {Prior, Suzanne and Waller, Annalu and Black, Rolf and Kroll, Thilo},
title = {Use of an Agile Bridge in the Development of Assistive Technology},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466210},
doi = {10.1145/2470654.2466210},
abstract = {Engaging with end users in the development of assistive technologies remains one of the major challenges for researchers and developers in the field of accessibility and HCI. Developing usable software systems for people with complex disabilities is problematic, software developers are wary of using user-centred design, one of the main methods by which usability can be improved, due to concerns about how best to work with adults with complex disabilities, in particular Severe Speech and Physical Impairments (SSPI) and how to involve them in research. This paper reports on how the adoption of an adapted agile approach involving the incorporation of a user advocate on the research team helped in meeting this challenge in one software project and offers suggestions for how this could be used by other development teams.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1579–1588},
numpages = {10},
keywords = {assistive technology, user centred design, agile methodology, severe speech and physical impairments},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466260,
author = {Wyche, Susan P. and Murphy, Laura L.},
title = {Powering the Cellphone Revolution: Findings from Mobile Phone Charging Trials in off-Grid Kenya},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466260},
doi = {10.1145/2470654.2466260},
abstract = {Can human-powered devices solve the electricity gap for the millions of rural Africans adopting mobile phones? Findings from our long-term evaluation of two personal crank-based charging systems in Kenya reveal that small hand and leg-powered devices do have potential to meet the needs of rural mobile phone users. Unfortunately, device breakage, theft and incompatibility with handsets, coupled with lack of consumer credit and poorly functioning markets for these goods mean these represent only a partial solution to the mobile phone charging problem. Drawing from our fieldwork, we motivate a HCI4D/ICTD design and evaluation agenda that better accounts for unique individuals' geographic, financial, and economic circumstances or their human computer ecosystem. Key strategies for implementing this agenda are engaging with diverse users on their own terms and conducting long-term qualitative evaluations to reveal how acceptance and usability change over time.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1959–1968},
numpages = {10},
keywords = {hci4d/ictd, off-grid power, design, mobile phones, human-powered, human factors, rural africa},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466223,
author = {Tam, Diane and MacLean, Karon E. and McGrenere, Joanna and Kuchenbecker, Katherine J.},
title = {The Design and Field Observation of a Haptic Notification System for Timing Awareness during Oral Presentations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466223},
doi = {10.1145/2470654.2466223},
abstract = {To moderate oral presentations a chair must manage time, and communicate time parameters to speakers through a variety of means. But speakers often miss time cues, chairs cannot confirm their receipt, and the broken dialogue can be a sideshow for the audience. We developed HaNS, a wireless wrist-worn chair-speaker Haptic Notification System that delivers tactile cues for time-managing oral presentations, and performed field observations at university research seminars and two mid-sized academic conferences (input from 66 speakers, 21 chairs, and 65 audience members). Results indicate that HaNS can improve a user's awareness of time, facilitate chair-speaker coordination, and reduce distraction of speaker and audience through its private communication channel. Eliminating overruns will require improvement in speaker 'internal' control, which our results suggest HaNS can also support given practice. We conclude with design guidelines for both conference-deployed and personal timing tools, using touch or another notification modality.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1689–1698},
numpages = {10},
keywords = {oral presentation, vibrotactile, field study, wearable haptics},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466261,
author = {Shrinivasan, Yedendra B. and Jain, Mohit and Seetharam, Deva P. and Choudhary, Abhishek and Huang, Elaine M. and Dillahunt, Tawanna and Mankoff, Jennifer},
title = {Deep Conservation in Urban India and Its Implications for the Design of Conservation Technologies},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466261},
doi = {10.1145/2470654.2466261},
abstract = {Rapid depletion of fossil fuels and water resources has become an international problem. Urban residential households are among the primary consumers of resources and are deeply affected by resource shortages. Despite the global nature of these problems, most of the solutions being developed to address these issues are based on studies done in the developed world. We present a study of energy, water and fuel conservation practices in urban India. Our study highlights a culture of deep conservation and the results raise questions about the viability of typical solutions such as home energy monitors. We identify new opportunities for design such as point-of-use feedback technologies, modular solutions, distributed energy storage, harnessing by-products and automated load shifting.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1969–1978},
numpages = {10},
keywords = {developing world, energy, sustainability, ict4d},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470685,
author = {Chilana, Parmit K. and Ko, Andrew J. and Wobbrock, Jacob O. and Grossman, Tovi},
title = {A Multi-Site Field Study of Crowdsourced Contextual Help: Usage and Perspectives of End Users and Software Teams},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470685},
doi = {10.1145/2470654.2470685},
abstract = {We present a multi-site field study to evaluate LemonAid, a crowdsourced contextual help approach that allows users to retrieve relevant questions and answers by making selections within the interface. We deployed LemonAid on 4 different web sites used by thousands of users and collected data over several weeks, gathering over 1,200 usage logs, 168 exit surveys, and 36 one-on-one interviews. Our results indicate that over 70% of users found LemonAid to be helpful, intuitive, and desirable for reuse. Software teams found LemonAid easy to integrate with their sites and found the analytics data aggregated by LemonAid a novel way of learning about users' popular questions. Our work provides the first holistic picture of the adoption and use of a crowdsourced contextual help system and offers several insights into the social and organizational dimensions of implementing such help systems for real-world applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {217–226},
numpages = {10},
keywords = {contextual help, field deployments, crowdsourced help, software support=., help systems, field studies},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481368,
author = {Kang, Ruogu and Brown, Stephanie and Kiesler, Sara},
title = {Why Do People Seek Anonymity on the Internet? Informing Policy and Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481368},
doi = {10.1145/2470654.2481368},
abstract = {In this research we set out to discover why and how people seek anonymity in their online interactions. Our goal is to inform policy and the design of future Internet architecture and applications. We interviewed 44 people from America, Asia, Europe, and Africa who had sought anonymity and asked them about their experiences. A key finding of our research is the very large variation in interviewees' past experiences and life situations leading them to seek anonymity, and how they tried to achieve it. Our results suggest implications for the design of online communities, challenges for policy, and ways to improve anonymity tools and educate users about the different routes and threats to anonymity on the Internet.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2657–2666},
numpages = {10},
keywords = {anonymity, online community, information disclosure, privacy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466448,
author = {Sleeper, Manya and Cranshaw, Justin and Kelley, Patrick Gage and Ur, Blase and Acquisti, Alessandro and Cranor, Lorrie Faith and Sadeh, Norman},
title = {"i Read My Twitter the next Morning and Was Astonished": A Conversational Perspective on Twitter Regrets},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466448},
doi = {10.1145/2470654.2466448},
abstract = {We present the results of an online survey of 1,221 Twitter users, comparing messages individuals regretted either saying during in-person conversations or posting on Twitter. Participants generally reported similar types of regrets in person and on Twitter. In particular, they often regretted messages that were critical of others. However, regretted messages that were cathartic/expressive or revealed too much information were reported at a higher rate for Twitter. Regretted messages on Twitter also reached broader audiences. In addition, we found that participants who posted on Twitter became aware of, and tried to repair, regret more slowly than those reporting in-person regrets. From this comparison of Twitter and in-person regrets, we provide preliminary ideas for tools to help Twitter users avoid and cope with regret.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3277–3286},
numpages = {10},
keywords = {conversation, survey, regrets, twitter, messaging},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481313,
author = {Voida, Amy and Olson, Judith S. and Olson, Gary M.},
title = {Turbulence in the Clouds: Challenges of Cloud-Based Information Work},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481313},
doi = {10.1145/2470654.2481313},
abstract = {We report on a qualitative study of the user experience of cloud-based information work. We characterize the information work practices and challenges that exist largely at the different intersections of three constructs - cloud-based services, collaborations, and digital identifiers. We also demonstrate how the misalignment of these three constructs is experienced as a "losing battle" that has led to miscommunication among collaborators, the abandonment of cloud-based services, and the irreparable blurring of digital identities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2273–2282},
numpages = {10},
keywords = {information management, cloud computing, information work, digital identifiers},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470660,
author = {Shi, Pan and Xu, Heng and Chen, Yunan},
title = {Using Contextual Integrity to Examine Interpersonal Information Boundary on Social Network Sites},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470660},
doi = {10.1145/2470654.2470660},
abstract = {Although privacy problems in Social Network Sites (SNS) have become more salient than ever in recent years, interpersonal privacy issues in SNS remain understudied. This study aims to generate insights in understanding users' interpersonal privacy concerns by expounding interpersonal privacy boundaries in SNS. Through a case analysis of Friendship Pages on Facebook, this paper identifies users' interpersonal privacy concerns that are rooted from informational norms outlined in the theory of contextual integrity, as well as the tensions that occur within and cross these informational norms. This paper concludes with a discussion of design implications and future research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {35–38},
numpages = {4},
keywords = {friendship pages, social network sites (sns), facebook, privacy boundary, interpersonal privacy concerns},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481380,
author = {Kim, Sunyoung and Paulos, Eric and Mankoff, Jennifer},
title = {InAir: A Longitudinal Study of Indoor Air Quality Measurements and Visualizations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481380},
doi = {10.1145/2470654.2481380},
abstract = {Indoor air quality (IAQ) is important for health as people spend the majority of time indoors, and it is particularly interesting over outdoor air because it strongly ties to indoor activities. Some activities easily exacerbate IAQ, resulting in serious pollution. However, people may not notice such changes because many pollutants are colorless and odorless, while many activities are inconspicuous and routine. We implemented inAir, a system that measures and visualizes IAQ that households appropriate and integrate into everyday life. The research goals of this work include understanding the IAQ dynamics with respect to habitual behaviors and analyzing behavioral and quantitative changes towards improving IAQ by the use of inAir. From our longitudinal study for four months, we found that inAir successfully elicited the reflection upon, and the modification of habitual behaviors for healthy domestic environments, which resulted in the significant improvement of IAQ.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2745–2754},
numpages = {10},
keywords = {sustainability, domestic computing, health, air quality},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466256,
author = {O'Leary, Kathleen and Wobbrock, Jacob O. and Riskin, Eve A.},
title = {Q-Methodology as a Research and Design Tool for HCI},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466256},
doi = {10.1145/2470654.2466256},
abstract = {A "discount" version of Q-methodology for HCI, called "HCI-Q", can be used in iterative design cycles to explore, from the point of view of users and other stakeholders, what makes technologies personally significant. Initially, designers critically reflect on their own assumptions about how a design may affect social and individual behavior. Then, designers use these assumptions as stimuli to elicit other people's points of view. This process of critical self-reflection and evaluation helps the designer to assess the fit between a design and its intended social context of use. To demonstrate the utility of HCI-Q for research and design, we use HCI-Q to explore stakeholders' responses to a prototype Alternative and Augmentative Communication (AAC) application called Vid2Speech. We show that our adaptation of Q-methodology is useful for revealing the structure of consensus and conflict among stakeholder perspectives, helping to situate design within the context of relevant value tensions and norms.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1941–1950},
numpages = {10},
keywords = {quantitative methods, qualitative methods, personal significance, psychology, user studies, design methodology},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466231,
author = {Curmi, Franco and Ferrario, Maria Angela and Southern, Jen and Whittle, Jon},
title = {HeartLink: Open Broadcast of Live Biometric Data to Social Networks},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466231},
doi = {10.1145/2470654.2466231},
abstract = {A number of studies in the literature have looked into the use of real-time biometric data to improve one's own physiological performance and wellbeing. However, there is limited research that looks into the effects that sharing biometric data with others could have on one's social network. Following a period of research on existing mobile applications and prototype testing, we developed a system, HeartLink, which collects real-time personal biometric data such as heart rate and broadcasts this data online. Insights gained on designing systems to broadcast real-time biometric data are presented. In this paper we also report emerging results from testing HeartLink in a pilot study and a user study that were conducted during sport events. The results showed that sharing heart rate data does influence the relationship of the persons involved and that the degree of influence seems related to the tie strength prior to visualizing the data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1749–1758},
numpages = {10},
keywords = {data broadcast, social networks, biometric data, digital economy, mobile computing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466144,
author = {Annett, Michelle and Bischof, Walter F.},
title = {Your Left Hand Can Do It Too! Investigating Intermanual, Symmetric Gesture Transfer on Touchscreens},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466144},
doi = {10.1145/2470654.2466144},
abstract = {This work examines intermanual gesture transfer, i.e., learning a gesture with one hand and performing it with the other. Using a traditional retention and transfer paradigm from the motor learning literature, participants learned four gestures on a touchscreen. The study found that touchscreen gestures transfer, and do so symmetrically. Regardless of the hand used during training, gestures were performed with a comparable level of error and speed by the untrained hand, even after 24 hours. In addition, the form of a gesture, i.e., its length or curvature, was found to have no influence on transferability. These results have important implications for the design of stroke-based gestural interfaces: acquisition could occur with either hand and it is possible to interchange the hand used to perform gestures. The work concludes with a discussion of these implications and highlights how they can be applied to gesture learning and current gestural systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1119–1128},
numpages = {10},
keywords = {symmetric transfer, touchscreen, gesture transfer, motor learning, skill acquisition, gestures, intermanual transfer},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481379,
author = {Lomas, Derek and Kumar, Anuj and Patel, Kishan and Ching, Dixie and Lakshmanan, Meera and Kam, Matthew and Forlizzi, Jodi L.},
title = {The Power of Play: Design Lessons for Increasing the Lifespan of Outdated Computers},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481379},
doi = {10.1145/2470654.2481379},
abstract = {One consequence of rapid advances in computer technology is the obsolescence of hundreds of millions of computers each year. This paper explores strategies for increasing the reuse of outdated computers through an investigation of an 8-bit home computer that is still popular in developing countries. We observed the use of the computers in 16 households in Ahmedabad and Bangalore, India in order to gain insight into the contextual factors that support the continued popularity of the device. While most computers become obsolete in less than a decade, this 30-year-old computer technology remains useful because it provides exciting, multi-user family entertainment. While having minimal processing power and virtually no connectivity, the 8-bit computer supports input and output channels that are especially suited for co-located social game play. In contrast, PCs are primarily designed for individual use. Therefore, we offer low-cost design recommendations that would enable outdated PCs to support greater shared use and increased utility within the constrained material context of low-income households. These simple interventions, if adopted by computer refurbishment industries, have the potential to significantly extend the useful lifespan of PCs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2735–2744},
numpages = {10},
keywords = {ethnography, obsolescence, games, social computing, hci4d, abandonware, ict4d, sustainability},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466477,
author = {Denef, Sebastian and Bayerl, Petra S. and Kaptein, Nico A.},
title = {Social Media and the Police: Tweeting Practices of British Police Forces during the August 2011 Riots},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466477},
doi = {10.1145/2470654.2466477},
abstract = {With this paper we take a first step to understand the appropriation of social media by the police. For this purpose we analyzed the Twitter communication by the London Metropolitan Police (MET) and the Greater Manchester Police (GMP) during the riots in August 2011. The systematic comparison of tweets demonstrates that the two forces developed very different practices for using Twitter. While MET followed an instrumental approach in their communication, in which the police aimed to remain in a controlled position and keep a distance to the general public, GMP developed an expressive approach, in which the police actively decreased the distance to the citizens. In workshops and interviews, we asked the police officers about their perspectives, which confirmed the identified practices. Our study discusses benefits and risks of the two approaches and the potential impact of social media on the evolution of the role of police in society.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3471–3480},
numpages = {10},
keywords = {twitter, microblogging, uk riots, crisis communication, police},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481354,
author = {Lee, Jaebong and Choi, Seungmoon},
title = {Real-Time Perception-Level Translation from Audio Signals to Vibrotactile Effects},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481354},
doi = {10.1145/2470654.2481354},
abstract = {In this paper, we propose a real-time perception-level audio-to-vibrotactile translation algorithm. Unlike previous signal-level conversion methods, our algorithm considers only perceptual characteristics, such as loudness and roughness, of audio and tactile stimuli. This perception-level approach allows for designing intuitive and explicit conversion models with clear understandings of their perceptual consequences. Our current implementation is tailored to accurate detection of special sound effects to provide well-synchronized audio-tactile feedback in immersive applications. We also assessed the performance of our translation algorithm in terms of the detection rate of special sound effects, computational performance, and user preference. All the experimental results supported that our algorithm works well as intended with better performance than the signal-level conversion methods, especially for games. Our algorithm can be easily realized in current products, including mobile devices, gaming devices, and 4D home theater systems, for richer user experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2567–2576},
numpages = {10},
keywords = {vibrotactile effect, haptics, perceived intensity, audio, perceived roughness, automatic conversion},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466130,
author = {Kharrufa, Ahmed and Balaam, Madeline and Heslop, Phil and Leat, David and Dolan, Paul and Olivier, Patrick},
title = {Tables in the Wild: Lessons Learned from a Large-Scale Multi-Tabletop Deployment},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466130},
doi = {10.1145/2470654.2466130},
abstract = {This paper presents the results and experiences of a six-week deployment of multiple digital tabletops in a school. Dillenbourg's orchestration framework was used both to guide the design and analysis of the study. Four themes, which directly relate to the design of the technology for the classroom, out of the 15 orchestration factors are considered. For each theme, we present our design choices, the relevant observations, feedback from teachers and students, and we conclude with a number of lessons learned in the form of design recommendations. The distinguishing factors of our study are its scale (in terms of duration, number of classes, subjects, and teachers), and its 'in-the-wild' character, with the entire study being conducted in a school, led by the teachers, and using teacher-prepared, curriculum-based tasks. Our primary contributions are the analysis of our observations and design recommendations for future multi-tabletop applications designed for and deployed within the classroom. Our analyses and recommendations meaningfully extend HCI's current design understandings of such settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1021–1030},
numpages = {10},
keywords = {tabletops, collaborative learning, classroom orchestration},
location = {Paris, France},
series = {CHI '13}
}

@article{10.1145/2481244.2481247,
author = {Lin, Jimmy and Ryaboy, Dmitriy},
title = {Scaling Big Data Mining Infrastructure: The Twitter Experience},
year = {2013},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1931-0145},
url = {https://doi.org/10.1145/2481244.2481247},
doi = {10.1145/2481244.2481247},
abstract = {The analytics platform at Twitter has experienced tremendous growth over the past few years in terms of size, complexity, number of users, and variety of use cases. In this paper, we discuss the evolution of our infrastructure and the development of capabilities for data mining on "big data". One important lesson is that successful big data mining in practice is about much more than what most academics would consider data mining: life "in the trenches" is occupied by much preparatory work that precedes the application of data mining algorithms and followed by substantial effort to turn preliminary models into robust solutions. In this context, we discuss two topics: First, schemas play an important role in helping data scientists understand petabyte-scale data stores, but they're insufficient to provide an overall "big picture" of the data available to generate insights. Second, we observe that a major challenge in building data analytics platforms stems from the heterogeneity of the various components that must be integrated together into production workflows---we refer to this as "plumbing". This paper has two goals: For practitioners, we hope to share our experiences to flatten bumps in the road for those who come after us. For academic researchers, we hope to provide a broader context for data mining in production environments, pointing out opportunities for future work.},
journal = {SIGKDD Explor. Newsl.},
month = apr,
pages = {6–19},
numpages = {14}
}

@article{10.1145/2481244.2481246,
author = {Fan, Wei and Bifet, Albert},
title = {Mining Big Data: Current Status, and Forecast to the Future},
year = {2013},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1931-0145},
url = {https://doi.org/10.1145/2481244.2481246},
doi = {10.1145/2481244.2481246},
abstract = {Big Data is a new term used to identify datasets that we can not manage with current methodologies or data mining software tools due to their large size and complexity. Big Data mining is the capability of extracting useful information from these large datasets or streams of data. New mining techniques are necessary due to the volume, variability, and velocity, of such data. The Big Data challenge is becoming one of the most exciting opportunities for the years to come. We present in this issue, a broad overview of the topic, its current status, controversy, and a forecast to the future. We introduce four articles, written by influential scientists in the field, covering the most interesting and state-of-the-art topics on Big Data mining.},
journal = {SIGKDD Explor. Newsl.},
month = apr,
pages = {1–5},
numpages = {5}
}

@article{10.1145/2451856.2451869,
author = {Kim, Jeffrey and Lund, Arnie and Dombrowski, Caroline},
title = {Telling the Story in Big Data},
year = {2013},
issue_date = {May + June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {3},
issn = {1072-5520},
url = {https://doi.org/10.1145/2451856.2451869},
doi = {10.1145/2451856.2451869},
journal = {Interactions},
month = may,
pages = {48–51},
numpages = {4}
}

@article{10.1145/2505414.2505417,
author = {Bodle, Robert},
title = {The Ethics of Online Anonymity or Zuckerberg vs. "Moot"},
year = {2013},
issue_date = {May 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {0095-2737},
url = {https://doi.org/10.1145/2505414.2505417},
doi = {10.1145/2505414.2505417},
abstract = {This paper argues that anonymity in networked digital communications is indispensable as an enabler of other inalienable rights including informational privacy and freedom of expression. Yet, an alignment of industry norms, practices, ethics, and techno-social design asserts a persistent identity ecosystem, making online anonymity more difficult to achieve. This paper reappraises the democratic uses, affordances, and human rights dimensions of online anonymity in order to advance an ethical justification for its protection.},
journal = {SIGCAS Comput. Soc.},
month = may,
pages = {22–35},
numpages = {14}
}

@inproceedings{10.1145/2462197.2462199,
author = {Dimitrova, Vania and Lau, Lydia and Thakker, Dhavalkumar and Yang-Turner, Fan and Despotakis, Dimoklis},
title = {Exploring Exploratory Search: A User Study with Linked Semantic Data},
year = {2013},
isbn = {9781450320061},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2462197.2462199},
doi = {10.1145/2462197.2462199},
abstract = {The maturation of semantic technologies and the growing popularity of the Linked Open Data (LOD) cloud make it possible to expose linked semantic data sets to end users in order to empower a range of analytical tasks taking advantage of knowledge integration and semantic linking. Linked semantic data appears to offer a great potential for exploratory search, which is open-ended, multi-faceted, and iterative in nature. However, there is limited insight into how browsing through linked semantic data sets can support exploratory search. This paper presents a user study with a uni-focal semantic browsing interface for exploratory search through several data sets linked via domain ontologies. The study, which is qualitative and exploratory in nature and uses music as an illustrative domain, examines (i) obstacles and challenges related to user exploratory search in LOD and (ii) the serendipitous learning effect and the role semantics plays in that. The approach and lessons learnt can benefit future human factor studies to evaluate interactive exploration of linked semantic data, as well as technology developers to become aware of issues that have to be addressed in to facilitate exploratory search with LOD.},
booktitle = {Proceedings of the 2nd International Workshop on Intelligent Exploration of Semantic Data},
articleno = {2},
numpages = {8},
keywords = {linked open data, exploratory search, semantic data exploration, user interaction},
location = {Paris, France},
series = {IESD '13}
}

@inproceedings{10.1145/2481492.2481499,
author = {Vigo, Markel and Harper, Simon},
title = {Challenging Information Foraging Theory: Screen Reader Users Are Not Always Driven by Information Scent},
year = {2013},
isbn = {9781450319676},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2481492.2481499},
doi = {10.1145/2481492.2481499},
abstract = {Little is known about the navigation tactics employed by screen reader users when they face problematic situations on the Web. Understanding how these tactics are operationalised and knowing the situations that bring about such tactics paves the way towards modeling navigation behaviour. Modeling the navigation of users is of utmost importance as it allows not only to predict interactive behaviour, but also to assess the appropriateness of the content in a link, the information architecture of a site and the design of a web page. Current navigation models do not consider the extreme adaptations, namely coping tactics, that screen reader users undergo on the Web. Consequently, their prediction power is lessened and coping tactics are mistakenly considered outlying behaviours. We draw from existing navigation models for sighted users to suggest the incorporation of emerging behaviours in navigation models for screen reader users. To do so, we identify the navigation coping tactics screen reader users exhibit on the Web, including deliberately clicking on low scented links, escaping from useless or inaccessible content and backtracking to a shelter. Our findings suggest that, especially in problematic situations, navigation is not driven by information scent or utility, but by the need of increasing autonomy and the need of escaping from the current web patch.},
booktitle = {Proceedings of the 24th ACM Conference on Hypertext and Social Media},
pages = {60–68},
numpages = {9},
keywords = {accessibility, blind users, coping tactics, information foraging theory, information scent, low vision, navigation models, screen readers, web},
location = {Paris, France},
series = {HT '13}
}

@inproceedings{10.1145/2464464.2464521,
author = {Rao, Tushar and Srivastava, Saket},
title = {Modeling Movements in Oil, Gold, Forex and Market Indices Using Search Volume Index and Twitter Sentiments},
year = {2013},
isbn = {9781450318891},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2464464.2464521},
doi = {10.1145/2464464.2464521},
abstract = {Study of the forecasting models using large scale microblog discussions and the search behavior data can provide a good insight for better understanding the market movements. In this work we collected a dataset of 2 million tweets and search volume index (SVI from Google) for a period of June 2010 to September 2011. We model a set of comprehensive causative relationships over this dataset for various market securities like equity (Dow Jones Industrial Average-DJIA and NASDAQ-100), commodity markets (oil and gold) and Euro Forex rates. We also investigate the lagged and statistically causative relations of Twitter sentiments developed during active trading days and market inactive days in combination with the search behavior of public before any change in the prices/indices. Our results show extent of lagged significance with high correlation value upto 0.82 between search volumes and gold price in USD. We find weekly accuracy in direction (up and down prediction) uptil 94.3% for DJIA and 90% for NASDAQ-100 with significant reduction in mean average percentage error for all the forecasting models.},
booktitle = {Proceedings of the 5th Annual ACM Web Science Conference},
pages = {336–345},
numpages = {10},
keywords = {gold, social network analysis, Twitter, sentiment analysis, forex, data mining, stock market, oil, microblogging},
location = {Paris, France},
series = {WebSci '13}
}

@inproceedings{10.1145/2464464.2464520,
author = {Metaxas, Panagiotis and Mustafaraj, Eni},
title = {The Rise and the Fall of a Citizen Reporter},
year = {2013},
isbn = {9781450318891},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2464464.2464520},
doi = {10.1145/2464464.2464520},
abstract = {Recently, there has been some research interest in the development of online communities sharing news and information curated by "citizen reporters". Using "Big Data" techniques researchers try to discover influence groups and some of the major events in the lives of such communities. However, the big picture may sometimes miss important stories that are essential to the development and evolution of online communities. In particular, how does one identify and verify events when the important actors are operating anonymously and without sufficient news coverage due to safety concerns, as in drug war-torn Mexico? In this paper we present some techniques that allow us to make sense of the data collected, identify important dates of significant events in them, and direct our limited resources to discover hidden stories that, in our case, affect the lives and safety of prominent citizen reporters. In particular, we describe how focused analysis enabled us to discover an important story in the life of this community involving the reputation of an anonymous leader, and how trust was built in order to verify the validity of the story.},
booktitle = {Proceedings of the 5th Annual ACM Web Science Conference},
pages = {248–257},
numpages = {10},
keywords = {social computing, drug war, webscience, news, crowdsourcing, Mexico, social media, microblogging, citizen reporters, crisis informatics, narcotweets, Twitter, civic media},
location = {Paris, France},
series = {WebSci '13}
}

@inproceedings{10.1145/2464464.2464524,
author = {Yip, Michael and Shadbolt, Nigel and Webber, Craig},
title = {Why Forums? An Empirical Analysis into the Facilitating Factors of Carding Forums},
year = {2013},
isbn = {9781450318891},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2464464.2464524},
doi = {10.1145/2464464.2464524},
abstract = {Over the last decade, the nature of cybercrime has transformed from naive vandalism to profit-driven, leading to the emergence of a global underground economy. A noticeable trend which has surfaced in this economy is the repeated use of forums to operate online stolen data markets. Using interaction data from three prominent carding forums: Shadowcrew, Cardersmarket and Darkmarket, this study sets out to understand why forums are repeatedly chosen to operate online stolen data markets despite numerous successful infiltrations by law enforcement in the past. Drawing on theories from criminology, social psychology, economics and network science, this study has identified four fundamental socio-economic mechanisms offered by carding forums: (1) formal control and coordination; (2) social networking; (3) identity uncertainty mitigation; (4) quality uncertainty mitigation. Together, they give rise to a sophisticated underground market regulatory system that facilitates underground trading over the Internet and thus drives the expansion of the underground economy.},
booktitle = {Proceedings of the 5th Annual ACM Web Science Conference},
pages = {453–462},
numpages = {10},
keywords = {cybercrime, web 2.0, carding, underground economy, social computing},
location = {Paris, France},
series = {WebSci '13}
}

@inproceedings{10.4108/icst.pervasivehealth.2013.252025,
author = {Weibel, Nadir and Ashfaq, Shazia and Calvitti, Alan and Hollan, James D. and Agha, Zia},
title = {Multimodal Data Analysis and Visualization to Study the Usage of Electronic Health Records},
year = {2013},
isbn = {9781936968800},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.pervasivehealth.2013.252025},
doi = {10.4108/icst.pervasivehealth.2013.252025},
abstract = {Understanding interaction with Electronic Health Records (EHR), often means to understand the multimodal nature of the physician-patient interaction, as well as the interaction with other materials (e.g. paper charts), in addition to analyze the tasks fulfilled by the doctor on his computerized system. Recent approaches started to analyze and quantify speech, gaze, body movements, etc. and represent a very promising way to complement classic software usability. However, it is hard to characterize multimodal activity, since often it requires manual coding of hours of video data. We present our approach to use automatic tracking of body, audio signals and gaze in the medical office to achieve multimodal analysis of EHR.},
booktitle = {Proceedings of the 7th International Conference on Pervasive Computing Technologies for Healthcare},
pages = {282–283},
numpages = {2},
location = {Venice, Italy},
series = {PervasiveHealth '13}
}

@inproceedings{10.4108/icst.pervasivehealth.2013.252011,
author = {Sharma, Nandita and Gedeon, Tom},
title = {Modeling Stress Recognition in Typical Virtual Environments},
year = {2013},
isbn = {9781936968800},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.pervasivehealth.2013.252011},
doi = {10.4108/icst.pervasivehealth.2013.252011},
abstract = {Stress is a major problem in our world today motivating objective understanding of how average individuals respond to stress in a typical activities. The main aim for this paper is to determine whether stress can be recognized using individual-independent computational models from sensor based stress response signals induced by films with typical stressful content. Another aim is to determine whether a consumer electroencephalogram (EEG) sensor device, which is portable, less obtrusive and relatively inexpensive, can be used for stress recognition. A support vector machine and an artificial neural network based models were developed to recognize stress using various physiological and physical signals. The models produced stress classification with 95% accuracy. Using the data obtained from the consumer device, the models produced stress classification with 91% accuracy. Statistical analysis of the results showed that the classification results from the physiological and physical signals are not statistically different to the results from the consumer device implying that the consumer device can be used for recognizing stress in typical virtual environments.},
booktitle = {Proceedings of the 7th International Conference on Pervasive Computing Technologies for Healthcare},
pages = {17–24},
numpages = {8},
keywords = {physiological signals, EEG, genetic algorithms, artificial neural networks, support vector machines, stress recognition, physical signals, films},
location = {Venice, Italy},
series = {PervasiveHealth '13}
}

@inproceedings{10.4108/icst.pervasivehealth.2013.252181,
author = {Bousefsaf, Fr\'{e}d\'{e}ric and Maaoui, Choubeila and Pruski, Alain},
title = {Remote Assessment of the Heart Rate Variability to Detect Mental Stress},
year = {2013},
isbn = {9781936968800},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.pervasivehealth.2013.252181},
doi = {10.4108/icst.pervasivehealth.2013.252181},
abstract = {In the present paper, we introduce a new framework for detecting workload changes using video frames obtained from a low-cost webcam. The measurements are performed on human faces and the proposed algorithms were developed to be motion-tolerant. An interactive Stroop color word test is employed to induce stress on a set of twelve participants. We record the skin conductance and compare these responses to the stress curve assessed by a webcam-derived heart rate variability analysis. The results offer further support for the applicability of stress detection by remote and low-cost means, providing an alternative to conventional contact techniques.},
booktitle = {Proceedings of the 7th International Conference on Pervasive Computing Technologies for Healthcare},
pages = {348–351},
numpages = {4},
keywords = {mental stress detection, non-contact, emotions, heart rate variability, webcam, virtual reality},
location = {Venice, Italy},
series = {PervasiveHealth '13}
}

@inproceedings{10.4108/icst.pervasivehealth.2013.252087,
author = {Robben, Saskia and Kr\"{o}se, Ben},
title = {Longitudinal Residential Ambient Monitoring: Correlating Sensor Data to Functional Health Status},
year = {2013},
isbn = {9781936968800},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.pervasivehealth.2013.252087},
doi = {10.4108/icst.pervasivehealth.2013.252087},
abstract = {Wireless sensor networks are becoming popular in the field of ambient assisted living. In this paper we report our study on the relationship between a functional health metric and features derived from the sensor data. Sensor systems are installed in the houses of nine people who are also quarterly visited by an occupational therapist for functional health assessments. Different features are extracted and these are correlated with a metric of functional health (the AMPS motor). Though the sample is small, the results indicate that some features are better in describing the functional health in the population, but individual differences should also be taken into account when developing a sensor system for functional health assessment.},
booktitle = {Proceedings of the 7th International Conference on Pervasive Computing Technologies for Healthcare},
pages = {244–247},
numpages = {4},
location = {Venice, Italy},
series = {PervasiveHealth '13}
}

@inproceedings{10.4108/icst.pervasivehealth.2013.252095,
author = {Kealy, Andrea and McDaid, Kevin and Loane, John and Walsh, Lorcan and Doyle, Julie},
title = {Derivation of Night Time Behaviour Metrics Using Ambient Sensors},
year = {2013},
isbn = {9781936968800},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.pervasivehealth.2013.252095},
doi = {10.4108/icst.pervasivehealth.2013.252095},
abstract = {Sleep problems have been shown to have significant negative impact on health. As such it is important to examine night time behaviour to objectively determine when sleep disturbances arise. Due to the large night-to-night variability in sleep quality for older adults, it is important to objectively measure behaviour over a significant period to establish trends or changes in patterns of sleep. In this paper we present a means of ambiently monitoring sleep through the use of sensors installed in each of sixteen independent living apartments. We investigate the effect of time outside the home and movement within the home on sleep. These measures are validated against comparative measures from two actigraph datasets. The first consisting of five adults, two of whom are healthy subjects and the other three adults have previously fallen, gathered over a period of between two and four nights. The second consisting of three older adults recorded over seven nights in their own homes. Results relating time outside the home and movement within the home to sleep are presented for three individuals spanning a period of between 630 and 650 days.},
booktitle = {Proceedings of the 7th International Conference on Pervasive Computing Technologies for Healthcare},
pages = {33–40},
numpages = {8},
keywords = {sleep measures, AAL, aging in place, ambient monitoring},
location = {Venice, Italy},
series = {PervasiveHealth '13}
}

@inproceedings{10.4108/icst.pervasivehealth.2013.252103,
author = {M\"{u}ller, Claudia and Wan, Lin and Wulf, Volker},
title = {Dealing with Wandering in Institutional Care: Exploring the Field},
year = {2013},
isbn = {9781936968800},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.pervasivehealth.2013.252103},
doi = {10.4108/icst.pervasivehealth.2013.252103},
abstract = {We will present a case study on institutional care workers' strategies in dealing with wandering dementia patients. We will highlight their day-to-day practices, permanently balancing conflicting demands around keeping harm away from residents with wandering behavior. The risk of harm is multifactorial and also socially, culturally and organizationally defined. A closer examination of how the staff uses non-tech, low-tech and information and communication technology (ICT) artifacts in their daily practice helps us gain a better understanding of their practical problems and rationales for further ICT design.},
booktitle = {Proceedings of the 7th International Conference on Pervasive Computing Technologies for Healthcare},
pages = {101–104},
numpages = {4},
keywords = {institutional care, dementia care, wandering management},
location = {Venice, Italy},
series = {PervasiveHealth '13}
}

@inproceedings{10.4108/icst.pervasivehealth.2013.252106,
author = {De Choudhury, Munmun and Gamon, Michael and Hoff, Aaron and Roseway, Asta},
title = {"Moon Phrases": A Social Media Faciliated Tool for Emotional Reflection and Wellness},
year = {2013},
isbn = {9781936968800},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.pervasivehealth.2013.252106},
doi = {10.4108/icst.pervasivehealth.2013.252106},
abstract = {We propose an early prototype: a web-based tool "Moon Phrases" that leverages an individual's social activity online for promoting emotional reflection and wellness. Specifically, Moon Phrases tracks the emotion and linguistic expression of individuals as manifested on the social media Twitter, and presents a novel visualization---an analogy to the phases of the moon, to reveal their longitudinal trends. Social media platforms, including Twitter and Facebook provide a window onto the thoughts and feelings of individuals around small and big happenings in their lives. Motivated from research in psychology and HCI, we hypothesize that identifying the changes in language, emotion, and social activity on social media would enable individuals to reflect on their own behavior over time and in a fine-grained manner, which are otherwise known to be difficult to keep track of. We believe Moon Phrases thus bears the potential to act as a self-narrative or "behavioral fingerprint", and thereby serve as an unobtrusive mechanism to facilitate emotional wellness in individuals.},
booktitle = {Proceedings of the 7th International Conference on Pervasive Computing Technologies for Healthcare},
pages = {41–44},
numpages = {4},
location = {Venice, Italy},
series = {PervasiveHealth '13}
}

@inproceedings{10.4108/icst.pervasivehealth.2013.252134,
author = {Andrew, Adrienne H. and Eustice, Kevin and Hickl, Andy},
title = {Using Location Lifelogs to Make Meaning of Food and Physical Activity Behaviors},
year = {2013},
isbn = {9781936968800},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.pervasivehealth.2013.252134},
doi = {10.4108/icst.pervasivehealth.2013.252134},
abstract = {In this paper, we take the position that location and information derived from location adds value to health and wellness logs. Traditional health and wellness logs such as food and physical activity diaries do not include location information in a meaningful way. As the ability to track and make sense of location is improving, it will be possible to associate high-quality data regarding the user location and location-derived activities to health and wellness logs. This can significantly improve the ability of these logs to expose meaning to the user, specifically around food and physical activity behaviors. We address four dimensions of location related information: location in terms of places and travels; information derived from location such as roles and transitions; routines identified from places and place transitions; and finally, identifying cohorts and aggregating over routines.},
booktitle = {Proceedings of the 7th International Conference on Pervasive Computing Technologies for Healthcare},
pages = {408–411},
numpages = {4},
keywords = {physical activity sensing, lifelog, location, food diary, cohort identification, routine identification, behavioral tendencies},
location = {Venice, Italy},
series = {PervasiveHealth '13}
}

@inproceedings{10.4108/icst.pervasivehealth.2013.252069,
author = {Altini, Marco and Penders, Julien and Amft, Oliver},
title = {Personalizing Energy Expenditure Estimation Using a Cardiorespiratory Fitness Predicate},
year = {2013},
isbn = {9781936968800},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.pervasivehealth.2013.252069},
doi = {10.4108/icst.pervasivehealth.2013.252069},
abstract = {Accurate Energy Expenditure (EE) estimation is key in understanding how behavior and daily physical activity (PA) patterns affect health, especially in today's sedentary society. Wearable accelerometers (ACC) and heart rate (HR) sensors have been widely used to monitor physical activity and estimate EE. However, current EE estimation algorithms have not taken into account a person's cardiorespiratory fitness (CRF), even though CRF is the main cause of inter-individual variation in HR during exercise. In this paper we propose a new algorithm, which is able to significantly reduce EE estimate error and inter-individual variability, by automatically modeling CRF, without requiring users to perform specific fitness tests. Results show a decrease in Root Mean Square Error (RMSE) between 28 and 33% for walking, running and biking activities, compared to state of the art activity-specific EE algorithms combining ACC and HR.},
booktitle = {Proceedings of the 7th International Conference on Pervasive Computing Technologies for Healthcare},
pages = {65–72},
numpages = {8},
location = {Venice, Italy},
series = {PervasiveHealth '13}
}

