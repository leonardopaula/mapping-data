@inproceedings{10.1145/1796900.1796946,
author = {Gupta, Saurabh and Bostrom, Robert P. and Anson, Robert},
title = {Do I Matter? The Impact of Individual Differences on Training Process},
year = {2010},
isbn = {9781450300049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1796900.1796946},
doi = {10.1145/1796900.1796946},
abstract = {The increasing investment in technology for training and learning in organizations underscores the fundamental importance for researchers to understand and investigate technology-mediated learning (TML). Currently, a great deal of Information Systems (IS) training for both IS professionals and end-users has a TML component. With the continuing growth of TML and advances in information technology, there will be a likely increate in TML-based IS training in the future. Advances in technology have created opportunities to deliver mass training as well as to personalize learning. To facilitate understanding in this area, this research analyzes the impact of individual differences on end-user training (EUT) in a TML environment. Using Adaptive Structuration Theory (AST), the learning process is modeled as the appropriation of a training method. Individual differences, or internal structures, are argued to have a significant direct effect on training outcomes and to impact the level of faithfulness of appropriation of learning/training method, thus, having an important indirect effect on learning outcomes. In this study, multiple individual differences were investigated in a laboratory experiment. Data was analyzed using SEM. The results of the study provide a vehicle for researchers, both in IS and Education, to better design and develop training methods and technology tools.},
booktitle = {Proceedings of the 2010 Special Interest Group on Management Information System's 48th Annual Conference on Computer Personnel Research on Computer Personnel Research},
pages = {112–120},
numpages = {9},
keywords = {SEM, technology mediated learning, personalization, learning process, individual differences, end-user training, e-learning},
location = {Vancouver, BC, Canada},
series = {SIGMIS-CPR '10}
}

@inproceedings{10.1145/1815695.1815697,
author = {Giat, Avichai and Pelleg, Dan and Raichstein, Eran and Ronen, Amir},
title = {Using Machine Learning Techniques to Enhance the Performance of an Automatic Backup and Recovery System},
year = {2010},
isbn = {9781605589084},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1815695.1815697},
doi = {10.1145/1815695.1815697},
abstract = {A typical disaster recovery system will have mirrored storage at a site that is geographically separate from the main operational site. In many cases, communication between the local site and the backup repository site is performed over a network which is inherently slow, such as a WAN, or is highly strained, for example due to a whole-site disaster recovery operation.The goal of this work is to alleviate the performance impact of the network in such a scenario, and to do so using machine learning techniques. We focus on two main areas, prefetching and read-ahead size determination. In both cases we significantly improve the performance of the system.Our main contributions are as follows: We introduce a theoretical model of the system and the problem we are trying to solve and bound the gain from prefetching techniques. We construct two frequent pattern mining algorithms and use them for prefetching. A framework for controlling and combining multiple prefetch algorithms is presented as well. These algorithms, as well as various simple prefetch algorithms, are compared on a simulation environment. We introduce a novel algorithm for determining the amount of read ahead on such a system that is based on intuition from online competitive analysis and on regression techniques. The significant positive impact of this algorithm is demonstrated on IBM's FastBack system.Much of our improvements have been applied with little or no modification of the current implementation's internals. We therefore feel confident in stating that the techniques are general and are likely to have applications elsewhere.},
booktitle = {Proceedings of the 3rd Annual Haifa Experimental Systems Conference},
articleno = {1},
numpages = {10},
keywords = {systems, file and storage systems, readahead, machine learning, prefetching},
location = {Haifa, Israel},
series = {SYSTOR '10}
}

@inproceedings{10.1145/1815695.1815714,
author = {Ishizaki, Kazuaki and Mizuno, Ken and Suganuma, Toshio and Silva, Daniel and Koseki, Akira and Komatsu, Hideaki and Ueda, Yohei and Nakatani, Toshio},
title = {Parallel Programming Framework for Large Batch Transaction Processing on Scale-out Systems},
year = {2010},
isbn = {9781605589084},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1815695.1815714},
doi = {10.1145/1815695.1815714},
abstract = {A scale-out system is a cluster of commodity machines, and offers a good platform to support steadily increasing workloads that process growing data sets. Sharding [4] is a method of partitioning data and processing a computation on a scale-out system. In a database system, a large table can be partitioned into small tables so each node can process its part of the computation. The sharding approach in a large batch transaction processing, which is important in financial area, presents two hard problems to programmers. Programmers have to write complex code (1) to transfer the input data so as to align the computations with the data partitions, and (2) to manage the distributed transactions. This paper presents a new parallel programming framework that makes parallel transactional programming easier by specifying transaction scopes and partitioners to simplify the code. Transaction scopes include series of subtransactions, each of which performs local operations. The system manages the distributed transactions automatically. A partitioner represents how the computation should be decomposed and aligned with the data partitions to avoid remote database accesses. Between paired of subtransactions, the system handles the data shuffling across the network. We implemented our parallel programming framework as a new Java class library. We hide all of the complex details of data transfer and distributed transaction management in the library. Our programming framework can eliminate almost 66% of the lines of code compared to a current programming approach without programming framework support. We also confirmed good scalability, with a scaling factor of 20.6 on 24 nodes using our modified batch program for the TPC-C benchmark.},
booktitle = {Proceedings of the 3rd Annual Haifa Experimental Systems Conference},
articleno = {15},
numpages = {14},
keywords = {scale-out, programming framework, batch transaction, sharding},
location = {Haifa, Israel},
series = {SYSTOR '10}
}

@inproceedings{10.1145/1842993.1843008,
author = {McCrae, James and Glueck, Michael and Grossman, Tovi and Khan, Azam and Singh, Karan},
title = {Exploring the Design Space of Multiscale 3D Orientation},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843008},
doi = {10.1145/1842993.1843008},
abstract = {Recently, research in 3D computer graphics and interaction has started to move beyond the narrow domain of single object authoring and inspection, and has begun to consider complex multiscale objects and environments. This generalization of problem scope calls for more general solutions, which are more akin to information visualization techniques than traditional computer graphics approaches.We consider the general problem of the user's understanding of their position and orientation within a multiscale 3D scene and propose a classification of the design space. To ground this theoretical discussion, we present initial explorations into grouping techniques, visualizations, and interactions to facilitate multiscale 3D orientation.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {81–88},
numpages = {8},
keywords = {3D orientation, design space, multiscale, visualization},
location = {Roma, Italy},
series = {AVI '10}
}

@article{10.1145/1754428.1754430,
author = {Kandylas, Vasileios and Upham, S. Phineas and Ungar, Lyle H.},
title = {Analyzing Knowledge Communities Using Foreground and Background Clusters},
year = {2010},
issue_date = {May 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {2},
issn = {1556-4681},
url = {https://doi.org/10.1145/1754428.1754430},
doi = {10.1145/1754428.1754430},
abstract = {Insight into the growth (or shrinkage) of “knowledge communities” of authors that build on each other's work can be gained by studying the evolution over time of clusters of documents. We cluster documents based on the documents they cite in common using the Streemer clustering method, which finds cohesive foreground clusters (the knowledge communities) embedded in a diffuse background. We build predictive models with features based on the citation structure, the vocabulary of the papers, and the affiliations and prestige of the authors and use these models to study the drivers of community growth and the predictors of how widely a paper will be cited. We find that scientific knowledge communities tend to grow more rapidly if their publications build on diverse information and use narrow vocabulary and that papers that lie on the periphery of a community have the highest impact, while those not in any community have the lowest impact.},
journal = {ACM Trans. Knowl. Discov. Data},
month = may,
articleno = {7},
numpages = {35},
keywords = {knowledge communities, community evolution, clustering, citation analysis, Text mining}
}

@article{10.1145/1743546.1743582,
author = {Kietzmann, Jan and Angell, Ian},
title = {Panopticon Revisited},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/1743546.1743582},
doi = {10.1145/1743546.1743582},
journal = {Commun. ACM},
month = jun,
pages = {135–138},
numpages = {4}
}

@inproceedings{10.1145/1810085.1810118,
author = {Bisset, Keith R. and Chen, Jiangzhuo and Feng, Xizhou and Ma, Yifei and Marathe, Madhav V.},
title = {Indemics: An Interactive Data Intensive Framework for High Performance Epidemic Simulation},
year = {2010},
isbn = {9781450300186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1810085.1810118},
doi = {10.1145/1810085.1810118},
abstract = {To respond to the serious threat of pandemics (e.g. 2009 H1N1 influenza) to human society, we developed Indemics (<u>In</u>teractive Epi<u>demic</u> <u>S</u>imulation), an interactive, data intensive, high performance modeling environment for realtime pandemic planning, situation assessment, and course of action analysis. Indemics was built upon a model of interactive data intensive scientific computation, supporting online interactions between users and simulations and enabling epidemic simulations over detailed social contact networks and realistic representations of complex public policies and intervention strategies.Instead of simply making a highly optimized parallel application run even faster, Indemics introduced several innovative ideas such as online interactive computation and HPC-DBMS integration that significantly improved the functionality, flexibility, modularity, and usability of HPC software. Our performance evaluation suggests that additional computational overhead incurred by Indemics compared to non-interactive simulations is easily offset by its new capabilities. Preliminary results show that Indemics significantly broadens the range of course of action scenarios that can be simulated and enables domain experts to analyze problems that were previously not possible to study.},
booktitle = {Proceedings of the 24th ACM International Conference on Supercomputing},
pages = {233–242},
numpages = {10},
keywords = {infectious disease, interactive computation, modeling and simulation, network dynamics, parallel computation},
location = {Tsukuba, Ibaraki, Japan},
series = {ICS '10}
}

@inproceedings{10.5555/1867735.1867740,
author = {von Etter, Peter and Huttunen, Silja and Vihavainen, Arto and Vuorinen, Matti and Yangarber, Roman},
title = {Assessment of Utility in Web Mining for the Domain of Public Health},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {This paper presents ongoing work on application of Information Extraction (IE) technology to domain of Public Health, in a real-world scenario. A central issue in IE is the quality of the results. We present two novel points. First, we distinguish the criteria for quality: the objective criteria that measure correctness of the system's analysis in traditional terms (F-measure, recall and precision), and, on the other hand, subjective criteria that measure the utility of the results to the end-user.Second, to obtain measures of utility, we build an environment that allows users to interact with the system by rating the analyzed content. We then build and compare several classifiers that learn from the user's responses to predict the relevance scores for new events. We conduct experiments with learning to predict relevance, and discuss the results and their implications for text mining in the domain of Public Health.},
booktitle = {Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents},
pages = {29–37},
numpages = {9},
location = {Los Angeles, California},
series = {Louhi '10}
}

@inproceedings{10.5555/1867735.1867737,
author = {Bhatia, Ramanjot S. and Graystone, Amber and Davies, Ross A. and McClinton, Susan and Morin, Jason and Davies, Richard F.},
title = {Extracting Information for Generating a Diabetes Report Card from Free Text in Physicians Notes},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Achieving guideline-based targets in patients with diabetes is crucial for improving clinical outcomes and preventing long-term complications. Using electronic heath records (EHRs) to identify high-risk patients for further intervention by screening large populations is limited because many EHRs store clinical information as dictated and transcribed free text notes that are not amenable to statistical analysis. This paper presents the process of extracting elements needed for generating a diabetes report card from free text notes written in English. Numerical measurements, representing lab values and physical examinations results are extracted from free text documents and then stored in a structured database. Extracting diagnosis information and medication lists are work in progress. The complete dataset for this project is comprised of 81,932 documents from 30,459 patients collected over a period of 5 years. The patient population is considered high risk for diabetes as they have existing cardiovascular complications. Experimental results validate our method, demonstrating high precision (88.8--100%).},
booktitle = {Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents},
pages = {8–14},
numpages = {7},
location = {Los Angeles, California},
series = {Louhi '10}
}

@inproceedings{10.5555/1867735.1867743,
author = {Allvin, Helen and Carlsson, Elin and Dalianis, Hercules and Danielsson-Ojala, Riitta and Daudaravi\v{c}ius, Vidas and Hassel, Martin and Kokkinakis, Dimitrios and Lundgren-Laine, Helj\"{a} and Nilsson, Gunnar and Nytr\o{}, \O{}ystein and Salanter\"{a}, Sanna and Skeppstedt, Maria and Suominen, Hanna and Velupillai, Sumithra},
title = {Characteristics and Analysis of Finnish and Swedish Clinical Intensive Care Nursing Narratives},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {We present a comparative study of Finnish and Swedish free-text nursing narratives from intensive care. Although the two languages are linguistically very dissimilar, our hypothesis is that there are similarities that are important and interesting from a language technology point of view. This may have implications when building tools to support producing and using health care documentation. We perform a comparative qualitative analysis based on structure and content, as well as a comparative quantitative analysis on Finnish and Swedish Intensive Care Unit (ICU) nursing narratives. Our findings are that ICU nursing narratives in Finland and Sweden have many properties in common, but that many of these are challenging when it comes to developing language technology tools.},
booktitle = {Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents},
pages = {53–60},
numpages = {8},
location = {Los Angeles, California},
series = {Louhi '10}
}

@inproceedings{10.5555/1860631.1860644,
author = {Lloret, Elena and Saggion, Horacio and Palomar, Manuel},
title = {Experiments on Summary-Based Opinion Classification},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {We investigate the effect of text summarisation in the problem of rating-inference -- the task of associating a fine-grained numerical rating to an opinionated document. We set-up a comparison framework to study the effect of different summarisation algorithms of various compression rates in this task and compare the classification accuracy of summaries and documents for associating documents to classes. We make use of SVM algorithms to associate numerical ratings to opinionated documents. The algorithms are informed by linguistic and sentiment-based features computed from full documents and summaries. Preliminary results show that some types of summaries could be as effective or better as full documents in this problem.},
booktitle = {Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text},
pages = {107–115},
numpages = {9},
location = {Los Angeles, California},
series = {CAAGET '10}
}

@inproceedings{10.5555/1860631.1860643,
author = {Volkova, Ekaterina P. and Mohler, Betty J. and Meurers, Detmar and Gerdemann, Dale and B\"{u}lthoff, Heinrich H.},
title = {Emotional Perception of Fairy Tales: Achieving Agreement in Emotion Annotation of Text},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Emotion analysis (EA) is a rapidly developing area in computational linguistics. An EA system can be extremely useful in fields such as information retrieval and emotion-driven computer animation. For most EA systems, the number of emotion classes is very limited and the text units the classes are assigned to are discrete and predefined. The question we address in this paper is whether the set of emotion categories can be enriched and whether the units to which the categories are assigned can be more flexibly defined. We present an experiment showing how an annotation task can be set up so that untrained participants can perform emotion analysis with high agreement even when not restricted to a predetermined annotation unit and using a rich set of emotion categories. As such it sets the stage for the development of more complex EA systems which are closer to the actual human emotional perception of text.},
booktitle = {Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text},
pages = {98–106},
numpages = {9},
location = {Los Angeles, California},
series = {CAAGET '10}
}

@inproceedings{10.5555/1860649.1860653,
author = {Gerv\'{a}s, Pablo},
title = {Engineering Linguistic Creativity: Bird Flight and Jet Planes},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Man achieved flight by studying how birds fly, and yet the solution that engineers came up with (jet planes) is very different from the one birds apply. In this paper I review a number of efforts in automated story telling and poetry generation, identifying which human abilities are being modelled in each case. In an analogy to the classic example of bird-flight and jet planes, I explore how the computational models relate to (the little we know about) human performance, what the similarities are between the case for linguistic creativity and the case for flight, and what the analogy might have to say about artificial linguistic creativity if it were valid.},
booktitle = {Proceedings of the NAACL HLT 2010 Second Workshop on Computational Approaches to Linguistic Creativity},
pages = {23–30},
numpages = {8},
location = {Los Angeles, California},
series = {CALC '10}
}

@inproceedings{10.5555/1860631.1860632,
author = {Bellegarda, Jerome R.},
title = {Emotion Analysis Using Latent Affective Folding and Embedding},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Though data-driven in nature, emotion analysis based on latent semantic analysis still relies on some measure of expert knowledge in order to isolate the emotional keywords or keysets necessary to the construction of affective categories. This makes it vulnerable to any discrepancy between the ensuing taxonomy of affective states and the underlying domain of discourse. This paper proposes a more general strategy which leverages two distincts semantic levels, one that encapsulates the foundations of the domain considered, and one that specifically accounts for the overall affective fabric of the language. Exposing the emergent relationship between these two levels advantageously informs the emotion classification process. Empirical evidence suggests that this is a promising solution for automatic emotion detection in text.},
booktitle = {Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text},
pages = {1–9},
numpages = {9},
location = {Los Angeles, California},
series = {CAAGET '10}
}

@inproceedings{10.1145/1807167.1807247,
author = {Rastogi, Vibhor and Nath, Suman},
title = {Differentially Private Aggregation of Distributed Time-Series with Transformation and Encryption},
year = {2010},
isbn = {9781450300322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807167.1807247},
doi = {10.1145/1807167.1807247},
abstract = {We propose the first differentially private aggregation algorithm for distributed time-series data that offers good practical utility without any trusted server. This addresses two important challenges in participatory data-mining applications where (i) individual users collect temporally correlated time-series data (such as location traces, web history, personal health data), and (ii) an untrusted third-party aggregator wishes to run aggregate queries on the data.To ensure differential privacy for time-series data despite the presence of temporal correlation, we propose the Fourier Perturbation Algorithm (FPAk). Standard differential privacy techniques perform poorly for time-series data. To answer n queries, such techniques can result in a noise of Θ(n) to each query answer, making the answers practically useless if n is large. Our FPAk algorithm perturbs the Discrete Fourier Transform of the query answers. For answering n queries, FPAk improves the expected error from Θ(n) to roughly Θ(k) where k is the number of Fourier coefficients that can (approximately) reconstruct all the n query answers. Our experiments show that k &lt;&lt; n for many real-life data-sets resulting in a huge error-improvement for FPAk.To deal with the absence of a trusted central server, we propose the Distributed Laplace Perturbation Algorithm (DLPA) to add noise in a distributed way in order to guarantee differential privacy. To the best of our knowledge, DLPA is the first distributed differentially private algorithm that can scale with a large number of users: DLPA outperforms the only other distributed solution for differential privacy proposed so far, by reducing the computational load per user from O(U) to O(1) where U is the number of users.},
booktitle = {Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data},
pages = {735–746},
numpages = {12},
keywords = {time-series data, participatory data mining, private data analysis, distributed noise addition, output perturbation},
location = {Indianapolis, Indiana, USA},
series = {SIGMOD '10}
}

@inproceedings{10.1145/1807085.1807101,
author = {Nelson, Jelani and Woodruff, David P.},
title = {Fast Manhattan Sketches in Data Streams},
year = {2010},
isbn = {9781450300339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807085.1807101},
doi = {10.1145/1807085.1807101},
abstract = {The L1-distance, also known as the Manhattan or taxicab distance, between two vectors x, y in Rn is ∑_{i=1}overn |xi-y_i|. Approximating this distance is a fundamental primitive on massive databases, with applications to clustering, nearest neighbor search, network monitoring, regression, sampling, and support vector machines. We give the first 1-pass streaming algorithm for this problem in the turnstile model with O*(1/ε2) space and O*(1) update time. The O* notation hides polylogarithmic factors in ε, n, and the precision required to store vector entries. All previous algorithms either required Ω(1/ε3) space or Ω(1/ε2) update time and/or could not work in the turnstile model (i.e., support an arbitrary number of updates to each coordinate). Our bounds are optimal up to O*(1) factors.},
booktitle = {Proceedings of the Twenty-Ninth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
pages = {99–110},
numpages = {12},
keywords = {streaming, data mining, sketching, clustering},
location = {Indianapolis, Indiana, USA},
series = {PODS '10}
}

@inproceedings{10.1145/1807085.1807106,
author = {Kifer, Daniel and Lin, Bing-Rong},
title = {Towards an Axiomatization of Statistical Privacy and Utility},
year = {2010},
isbn = {9781450300339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807085.1807106},
doi = {10.1145/1807085.1807106},
abstract = {"Privacy" and "utility" are words that frequently appear in the literature on statistical privacy. But what do these words really mean? In recent years, many problems with intuitive notions of privacy and utility have been uncovered. Thus more formal notions of privacy and utility, which are amenable to mathematical analysis, are needed. In this paper we present our initial work on an axiomatization of privacy and utility. In particular, we study how these concepts are affected by randomized algorithms. Our analysis yields new insights into the construction of both privacy definitions and mechanisms that generate data according to such definitions. In particular, it characterizes a class of relaxations of differential privacy and shows that desirable outputs of a differentially private mechanism are best interpreted as certain graphs rather than query answers or synthetic data.},
booktitle = {Proceedings of the Twenty-Ninth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
pages = {147–158},
numpages = {12},
keywords = {privacy, axioms, utility},
location = {Indianapolis, Indiana, USA},
series = {PODS '10}
}

@inproceedings{10.5555/1866696.1866697,
author = {Callison-Burch, Chris and Dredze, Mark},
title = {Creating Speech and Language Data with Amazon's Mechanical Turk},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {In this paper we give an introduction to using Amazon's Mechanical Turk crowdsourcing platform for the purpose of collecting data for human language technologies. We survey the papers published in the NAACL-2010 Workshop. 24 researchers participated in the workshop's shared task to create data for speech and language applications with $100.},
booktitle = {Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon's Mechanical Turk},
pages = {1–12},
numpages = {12},
location = {Los Angeles, California},
series = {CSLDAMT '10}
}

@inproceedings{10.1145/1807167.1807291,
author = {Biem, Alain and Bouillet, Eric and Feng, Hanhua and Ranganathan, Anand and Riabov, Anton and Verscheure, Olivier and Koutsopoulos, Haris and Moran, Carlos},
title = {IBM Infosphere Streams for Scalable, Real-Time, Intelligent Transportation Services},
year = {2010},
isbn = {9781450300322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807167.1807291},
doi = {10.1145/1807167.1807291},
abstract = {With the widespread adoption of location tracking technologies like GPS, the domain of intelligent transportation services has seen growing interest in the last few years. Services in this domain make use of real-time location-based data from a variety of sources, combine this data with static location-based data such as maps and points of interest databases, and provide useful information to end-users. Some of the major challenges in this domain include i) scalability, in terms of processing large volumes of real-time and static data; ii) extensibility, in terms of being able to add new kinds of analyses on the data rapidly, and iii) user interaction, in terms of being able to support different kinds of one-time and continuous queries from the end-user. In this paper, we demonstrate the use of IBM InfoSphere Streams, a scalable stream processing platform, for tackling these challenges. We describe a prototype system that generates dynamic, multi-faceted views of transportation information for the city of Stockholm, using real vehicle GPS and road-network data. The system also continuously derives current traffic statistics, and provides useful value-added information such as shortest-time routes from real-time observed and inferred traffic conditions. Our performance experiments illustrate the scalability of the system. For instance, our system can process over 120000 incoming GPS points per second, combine it with a map containing over 600,000 links, continuously generate different kinds of traffic statistics and answer user queries.},
booktitle = {Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data},
pages = {1093–1104},
numpages = {12},
keywords = {geostreaming, transportation, stream processing},
location = {Indianapolis, Indiana, USA},
series = {SIGMOD '10}
}

@inproceedings{10.1145/1807167.1807292,
author = {Castellanos, Malu and Wang, Song and Dayal, Umeshwar and Gupta, Chetan},
title = {SIE-OBI: A Streaming Information Extraction Platform for Operational Business Intelligence},
year = {2010},
isbn = {9781450300322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807167.1807292},
doi = {10.1145/1807167.1807292},
abstract = {Emerging business intelligence (BI) applications aim to provide situational awareness, i.e., information about real-world events that might affect the business operations of an enterprise. For instance, an enterprise might want to know whether customers are posting positive or negative comments about a new product it has just introduced; or whether some natural disaster affects its contracted suppliers. It is difficult to develop such applications today because they require extracting and correlating facts from multiple streaming and stored data sources, typically including unstructured data, which is not well supported by BI platforms today. In this paper, we describe SIE-OBI, a system that we are developing to enable the development and execution of such applications. We describe the novel features of this system, including a declarative interface for rapidly developing such applications, and a platform for optimizing and executing the applications. We illustrate its applicability through two use cases.},
booktitle = {Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data},
pages = {1105–1110},
numpages = {6},
keywords = {information extraction, situational awareness, business intelligence, correlation, unstructured data, streaming data},
location = {Indianapolis, Indiana, USA},
series = {SIGMOD '10}
}

@inproceedings{10.1145/1807167.1807194,
author = {Tsirogiannis, Dimitris and Harizopoulos, Stavros and Shah, Mehul A.},
title = {Analyzing the Energy Efficiency of a Database Server},
year = {2010},
isbn = {9781450300322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807167.1807194},
doi = {10.1145/1807167.1807194},
abstract = {Rising energy costs in large data centers are driving an agenda for energy-efficient computing. In this paper, we focus on the role of database software in affecting, and, ultimately, improving the energy efficiency of a server. We first characterize the power-use profiles of database operators under different configuration parameters. We find that common database operations can exercise the full dynamic power range of a server, and that the CPU power consumption of different operators, for the same CPU utilization, can differ by as much as 60%. We also find that for these operations CPU power does not vary linearly with CPU utilization.We then experiment with several classes of database systems and storage managers, varying parameters that span from different query plans to compression algorithms and from physical layout to CPU frequency and operating system scheduling. Contrary to what recent work has suggested, we find that within a single node intended for use in scale-out (shared-nothing) architectures, the most energy-efficient configuration is typically the highest performing one. We explain under which circumstances this is not the case, and argue that these circumstances do not warrant a retargeting of database system optimization goals. Further, our results reveal opportunities for cross-node energy optimizations and point out directions for new scale-out architectures.},
booktitle = {Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data},
pages = {231–242},
numpages = {12},
keywords = {ssd, database server, power consumption, cpu power, energy efficiency},
location = {Indianapolis, Indiana, USA},
series = {SIGMOD '10}
}

@inproceedings{10.1145/1807167.1807269,
author = {Karvounarakis, Grigoris and Ives, Zachary G. and Tannen, Val},
title = {Querying Data Provenance},
year = {2010},
isbn = {9781450300322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807167.1807269},
doi = {10.1145/1807167.1807269},
abstract = {Many advanced data management operations (e.g., incremental maintenance, trust assessment, debugging schema mappings, keyword search over databases, or query answering in probabilistic databases), involve computations that look at how a tuple was produced, e.g., to determine its score or existence. This requires answers to queries such as, "Is this data derivable from trusted tuples?"; "What tuples are derived from this relation?"; or "What score should this answer receive, given initial scores of the base tuples?". Such questions can be answered by consulting the provenance of query results.In recent years there has been significant progress on formal models for provenance. However, the issues of provenance storage, maintenance, and querying have not yet been addressed in an application-independent way. In this paper, we adopt the most general formalism for tuple-based provenance, semiring provenance. We develop a query language for provenance, which can express all of the aforementioned types of queries, as well as many more; we propose storage, processing and indexing schemes for data provenance in support of these queries; and we experimentally validate the feasibility of provenance querying and the benefits of our indexing techniques across a variety of application classes and queries.},
booktitle = {Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data},
pages = {951–962},
numpages = {12},
keywords = {query processing, query language, annotation, data provenance},
location = {Indianapolis, Indiana, USA},
series = {SIGMOD '10}
}

@inproceedings{10.1145/1809049.1809079,
author = {Eastep, Jonathan and Wingate, David and Santambrogio, Marco D. and Agarwal, Anant},
title = {Smartlocks: Lock Acquisition Scheduling for Self-Aware Synchronization},
year = {2010},
isbn = {9781450300742},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1809049.1809079},
doi = {10.1145/1809049.1809079},
abstract = {As multicore processors become increasingly prevalent, system complexity is skyrocketing. The advent of the asymmetric multicore compounds this - it is no longer practical for an average programmer to balance the system constraints associated with today's multicores and worry about new problems like asymmetric partitioning and thread interference. Adaptive, or self-aware, computing has been proposed as one method to help application and system programmers confront this complexity. These systems take some of the burden off of programmers by monitoring themselves and optimizing or adapting to meet their goals.This paper introduces a self-aware synchronization library for multicores and asymmetric multicores called Smartlocks. Smartlocks is a spin-lock library that adapts its internal implementation during execution using heuristics and machine learning to optimize toward a user-defined goal, which may relate to performance or problem-specific criteria. Smartlocks builds upon adaptation techniques from prior work like reactive locks [1], but introduces a novel form of adaptation that we term lock acquisition scheduling designed specifically to address asymmetries in multicores. Lock acquisition scheduling is optimizing which waiter will get the lock next for the best long-term effect when multiple threads (or processes) are spinning for a lock.This work demonstrates that lock scheduling is important for addressing asymmetries in multicores. We study scenarios where core speeds vary both dynamically and intrinsically under thermal throttling and manufacturing variability, respectively, and we show that Smartlocks significantly outperforms conventional spin-locks and reactive locks. Based on our findings, we provide guidelines for application scenarios where Smartlocks works best versus less optimally.},
booktitle = {Proceedings of the 7th International Conference on Autonomic Computing},
pages = {215–224},
numpages = {10},
keywords = {heterogeneous multicore, self-aware, asymmetric multicore, performance optimization, synchronization, self-tuning},
location = {Washington, DC, USA},
series = {ICAC '10}
}

@inproceedings{10.1145/1809049.1809065,
author = {Hoffmann, Henry and Eastep, Jonathan and Santambrogio, Marco D. and Miller, Jason E. and Agarwal, Anant},
title = {Application Heartbeats: A Generic Interface for Specifying Program Performance and Goals in Autonomous Computing Environments},
year = {2010},
isbn = {9781450300742},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1809049.1809065},
doi = {10.1145/1809049.1809065},
abstract = {The rise of multicore computing has greatly increased system complexity and created an additional burden for software developers. This burden is especially troublesome when it comes to optimizing software on modern computing systems. Autonomic or adaptive computing has been proposed as one method to help application programmers handle this complexity. In an autonomic computing environment, system services monitor applications and automatically adapt their behavior to increase the performance of the applications they support. Unfortunately, applications often run as performance black-boxes and adaptive services must infer application performance from low-level information or rely on system-specific ad hoc methods. This paper proposes a standard framework, Application Heartbeats, which applications can use to communicate both their current and target performance and which autonomic services can use to query these values.The Application Heartbeats framework is designed around the well-known idea of a heartbeat. At important points in the program, the application registers a heartbeat. In addition, the interface allows applications to express their performance in terms of a desired heart rate and/or a desired latency between specially tagged heartbeats. Thus, the interface provides a standard method for an application to directly communicate its performance and goals while allowing autonomic services access to this information. Thus, Heartbeat-enabled applications are no longer performance black-boxes. This paper presents the Applications Heartbeats interface, characterizes two reference implementations (one suitable for clusters and one for multicore), and illustrates the use of Heartbeats with several examples of systems adapting behavior based on feedback from heartbeats.},
booktitle = {Proceedings of the 7th International Conference on Autonomic Computing},
pages = {79–88},
numpages = {10},
keywords = {adaptive computing, self-tuning systems},
location = {Washington, DC, USA},
series = {ICAC '10}
}

@inproceedings{10.1145/1809029.1809033,
author = {Collet, Philippe and K\v{r}ikava, Filip and Montagnat, Johan and Blay-Fornarino, Mireille and Manset, David},
title = {Issues and Scenarios for Self-Managing Grid Middleware},
year = {2010},
isbn = {9781450301008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1809029.1809033},
doi = {10.1145/1809029.1809033},
abstract = {Despite significant efforts to achieve reliable grid middlewares, grid infrastructures still encounter important difficulties to implement the promise of ubiquitous, seamless and transparent computing. Identified causes are numerous, such as the complexity of middleware stacks, dependence to many distributed resources, heterogeneity of hardware and software operated or incompatibilities between software components declared as interoperable. Based on failures that occurred during a large data challenge run on a grid dedicated to neuroscience, we identify scenarios that can be handled through autonomic management associated to the grid middleware. We also outline a flexible self-adaptive framework that aims at using model-driven development to facilitate the engineering, integration and reuse of MAPE-K loops in large scale distributed systems.},
booktitle = {Proceedings of the 2nd Workshop on Grids Meets Autonomic Computing},
pages = {1–10},
numpages = {10},
keywords = {grid computing, SCA, neuGRID, medical image analysis, self-adaptive systems, autonomic computing, model driven engineering, SALTY},
location = {Washington, DC, USA},
series = {GMAC '10}
}

@inproceedings{10.1145/1809939.1809960,
author = {DeCarlo, Doug and Stone, Matthew},
title = {Visual Explanations},
year = {2010},
isbn = {9781450301251},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1809939.1809960},
doi = {10.1145/1809939.1809960},
abstract = {Human perceptual processes organize visual input to make the structure of the world explicit. Successful techniques for automatic depiction, meanwhile, create images whose structure clearly matches the visual information to be conveyed. We discuss how analyzing these structures and realizing them in formal representations can allow computer graphics to engage with perceptual science, to mutual benefit. We call these representations visual explanations: their job is to account for patterns in two dimensions as evidence of a visual world.},
booktitle = {Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering},
pages = {173–178},
numpages = {6},
keywords = {non-photorealism, depiction, perception},
location = {Annecy, France},
series = {NPAR '10}
}

@inproceedings{10.1145/1810543.1810609,
author = {Toscos, Tammy},
title = {Using Data to Promote Healthy Behavior in Children},
year = {2010},
isbn = {9781605589510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1810543.1810609},
doi = {10.1145/1810543.1810609},
abstract = {Childhood offers a number of opportunities for parents to shape the health related attitudes and behaviors of their children. The proposed research described in this paper aims to better understand the ways in which a child's personal health data can be leveraged to educate and provide a transition to healthy adult behaviors. The target population for this project is children with Type 1 Diabetes and their parents but many of the design issues may be relevant to the management of other chronic diseases as well as general health in childhood.},
booktitle = {Proceedings of the 9th International Conference on Interaction Design and Children},
pages = {344–347},
numpages = {4},
location = {Barcelona, Spain},
series = {IDC '10}
}

@article{10.1145/1754393.1754394,
author = {Chen, Teh-Chung and Dick, Scott and Miller, James},
title = {Detecting Visually Similar Web Pages: Application to Phishing Detection},
year = {2010},
issue_date = {May 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/1754393.1754394},
doi = {10.1145/1754393.1754394},
abstract = {We propose a novel approach for detecting visual similarity between two Web pages. The proposed approach applies Gestalt theory and considers a Web page as a single indivisible entity. The concept of supersignals, as a realization of Gestalt principles, supports our contention that Web pages must be treated as indivisible entities. We objectify, and directly compare, these indivisible supersignals using algorithmic complexity theory. We illustrate our approach by applying it to the problem of detecting phishing scams. Via a large-scale, real-world case study, we demonstrate that 1) our approach effectively detects similar Web pages; and 2) it accuractely distinguishes legitimate and phishing pages.},
journal = {ACM Trans. Internet Technol.},
month = jun,
articleno = {5},
numpages = {38},
keywords = {Web page similarity, Gestalt theory, Algorithmic complexity theory, anti-phishing technologies}
}

@inproceedings{10.1145/1810617.1810637,
author = {Cartledge, Charles L. and Nelson, Michael L.},
title = {Analysis of Graphs for Digital Preservation Suitability},
year = {2010},
isbn = {9781450300414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1810617.1810637},
doi = {10.1145/1810617.1810637},
abstract = {We investigate the use of autonomically created small-world graphs as a framework for the long term storage of digital objects on the Web in a potentially hostile environment. We attack the classic Erdos --- Renyi random, Barab\'{a}si and Albert power law, Watts --- Strogatz small world and our Unsupervise. Small World (USW) graphs using different attacker strategies and report their respective robustness. Using different attacker profiles, we construct a game where the attacker is allowed to use a strategy of his choice to remove a percentage of each graph's elements. The graph is then allowed to repair some portion of its self. We report on the number of alternating attack and repair turns until either the graph is disconnected, or the game exceeds the number of permitted turns. Based on our analysis, an attack strategy that focuses on removing the vertices with the highest betweenness value is most advantageous to the attacker. Power law graphs can become disconnected with the removal of a single edge; random graphs with the removal of as few as 1% of their vertices, small-world graphs with the removal of 14% vertices, and USW with the removal of 17% vertices. Watts --- Strogatz small-world graphs are more robust and resilient than random or power law graphs. USW graphs are more robust and resilient than small world graphs. A graph of USW connected WOs filled with date could outlive the individuals and institutions that created the data in an environment where WOs are lost due to random failures or directed attacks.},
booktitle = {Proceedings of the 21st ACM Conference on Hypertext and Hypermedia},
pages = {109–118},
numpages = {10},
keywords = {small world, resilience, robustness},
location = {Toronto, Ontario, Canada},
series = {HT '10}
}

@inproceedings{10.1145/1811039.1811068,
author = {Casale, Giuliano and Mi, Ningfang and Smirni, Evgenia},
title = {CWS: A Model-Driven Scheduling Policy for Correlated Workloads},
year = {2010},
isbn = {9781450300384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1811039.1811068},
doi = {10.1145/1811039.1811068},
abstract = {We define CWS, a non-preemptive scheduling policy for workloads with correlated job sizes. CWS tackles the scheduling problem by inferring the expected sizes of upcoming jobs based on the structure of correlations and on the outcome of past scheduling decisions. Size prediction is achieved using a class of Hidden Markov Models (HMM) with continuous observation densities that describe job sizes. We show how the forward-backward algorithm of HMMs applies effectively in scheduling applications and how it can be used to derive closed-form expressions for size prediction. This is particularly simple to implement in the case of observation densities that are phase-type (PH-type) distributed, where existing fitting methods for Markovian point processes may also simplify the parameterization of the HMM workload model.Based on the job size predictions, CWS emulates size-based policies which favor short jobs, with accuracy depending mainly on the HMM used to parametrize the scheduling algorithm. Extensive simulation and analysis illustrate that CWS is competitive with policies that assume exact information about the workload.},
booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {251–262},
numpages = {12},
keywords = {correlated workload, response time, stochastic sheduling, model-driven scheduling},
location = {New York, New York, USA},
series = {SIGMETRICS '10}
}

@article{10.1145/1811099.1811068,
author = {Casale, Giuliano and Mi, Ningfang and Smirni, Evgenia},
title = {CWS: A Model-Driven Scheduling Policy for Correlated Workloads},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/1811099.1811068},
doi = {10.1145/1811099.1811068},
abstract = {We define CWS, a non-preemptive scheduling policy for workloads with correlated job sizes. CWS tackles the scheduling problem by inferring the expected sizes of upcoming jobs based on the structure of correlations and on the outcome of past scheduling decisions. Size prediction is achieved using a class of Hidden Markov Models (HMM) with continuous observation densities that describe job sizes. We show how the forward-backward algorithm of HMMs applies effectively in scheduling applications and how it can be used to derive closed-form expressions for size prediction. This is particularly simple to implement in the case of observation densities that are phase-type (PH-type) distributed, where existing fitting methods for Markovian point processes may also simplify the parameterization of the HMM workload model.Based on the job size predictions, CWS emulates size-based policies which favor short jobs, with accuracy depending mainly on the HMM used to parametrize the scheduling algorithm. Extensive simulation and analysis illustrate that CWS is competitive with policies that assume exact information about the workload.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = jun,
pages = {251–262},
numpages = {12},
keywords = {correlated workload, stochastic sheduling, model-driven scheduling, response time}
}

@inproceedings{10.1145/1874590.1874616,
author = {Al-Jedaiah, Mohamad and Masadeh, Shadi R. and Abu-Errub, Aymen M. and Areiqat, Ahmad Y.},
title = {The Impact of Web Applications on Decision-Making Process in the Public Sector},
year = {2010},
isbn = {9781450304757},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1874590.1874616},
doi = {10.1145/1874590.1874616},
abstract = {This paper aims to identify the impact of Web Applications on the decision-making process in the public sector. By citing international experiences (The Taxation System in Europe Union) and the Solid Waste Association of North America as case studies. The most important findings were firstly that the public sector has to gather complex information through using technological equipments and software. Secondly, public sector organizations can build their own web applications. And finally, Web applications provide a significant help to the decision maker, and enable to exchange information with other governments.},
booktitle = {Proceedings of the 1st International Conference on Intelligent Semantic Web-Services and Applications},
articleno = {26},
numpages = {5},
keywords = {e-government, web applications, public sector, information technology},
location = {Amman, Jordan},
series = {ISWSA '10}
}

@inproceedings{10.1145/1814433.1814450,
author = {Ganti, Raghu K. and Pham, Nam and Ahmadi, Hossein and Nangia, Saurabh and Abdelzaher, Tarek F.},
title = {GreenGPS: A Participatory Sensing Fuel-Efficient Maps Application},
year = {2010},
isbn = {9781605589855},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1814433.1814450},
doi = {10.1145/1814433.1814450},
abstract = {This paper develops a navigation service, called GreenGPS, that uses participatory sensing data to map fuel consumption on city streets, allowing drivers to find the most fuel efficient routes for their vehicles between arbitrary end-points. The service exploits measurements of vehicular fuel consumption sensors, available via the OBD-II interface standardized in all vehicles sold in the US since 1996. The interface gives access to most gauges and engine instrumentation. The most fuel-efficient route does not always coincide with the shortest or fastest routes, and may be a function of vehicle type. Our experimental study shows that a participatory sensing system can influence routing decisions of individual users and also answers two questions related to the viability of the new service. First, can it survive conditions of sparse deployment? Second, how much fuel can it save? A challenge in participatory sensing is to generalize from sparse sampling of high-dimensional spaces to produce compact descriptions of complex phenomena. We illustrate this by developing models that can predict fuel consumption of a set of sixteen different cars on the streets of the city of Urbana-Champaign. We provide experimental results from data collection suggesting that a 1% average prediction error is attainable and that an average 10% savings in fuel can be achieved by choosing the right route.},
booktitle = {Proceedings of the 8th International Conference on Mobile Systems, Applications, and Services},
pages = {151–164},
numpages = {14},
keywords = {green navigation, participatory sensing, green GPS, model clustering},
location = {San Francisco, California, USA},
series = {MobiSys '10}
}

@inproceedings{10.1145/1839379.1839430,
author = {Lefter, Iulia and Wiggers, Pascal and Rothkrantz, Leon J. M.},
title = {EmoReSp: An Online Emotion Recognizer Based on Speech},
year = {2010},
isbn = {9781450302432},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839379.1839430},
doi = {10.1145/1839379.1839430},
abstract = {The paper describes the development of an online real-time system able to recognize emotions from speech. A prosodic feature set was extracted from four databases of emotional speech (three with acted emotions and one with spontaneous ones). Two models were trained using support vector machines (SVM) or merged databases, for the purpose of providing a larger range of examples to the classifier and making it more general. The system outputs probabilities of a closed set of emotions and provides a time track of the emotions recognized in the valence and arousal continuum.},
booktitle = {Proceedings of the 11th International Conference on Computer Systems and Technologies and Workshop for PhD Students in Computing on International Conference on Computer Systems and Technologies},
pages = {287–292},
numpages = {6},
keywords = {machine learning, speech, emotional speech databases, real-time emotion recognition},
location = {Sofia, Bulgaria},
series = {CompSysTech '10}
}

@inproceedings{10.1145/1822348.1822365,
author = {McGee, Kevin and Abraham, Aswin Thomas},
title = {Real-Time Team-Mate AI in Games: A Definition, Survey, &amp; Critique},
year = {2010},
isbn = {9781605589374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1822348.1822365},
doi = {10.1145/1822348.1822365},
abstract = {Many contemporary games are team-based and there is a growing interest in, and need for, advances in team-mate AI for games. However, although there have been surveys of agent AI in games, to date there has been no survey of work on team-mate AI. Furthermore, the concept of "team-mate AI" is not currently well delineated to distinguish between work on independently-acting agents that happen to be on the same side from work on agents the coordinate their behaviors and decision-making in terms of their teammates behaviors, intentions, and the like. Also, it is important to distinguish between game AI that is used as an optimization technique from real-time game AI, so this paper proposes a definition for real-time team-mate AI (highlighted with examples by game genre), reviews work to date to implement real-time team-mate AI for games in terms of a number of AI research areas (e.g., coordinated action, prediction, learning), and concludes with a brief discussion of significant issues about the state of the art.},
booktitle = {Proceedings of the Fifth International Conference on the Foundations of Digital Games},
pages = {124–131},
numpages = {8},
location = {Monterey, California},
series = {FDG '10}
}

@inproceedings{10.1145/1822348.1822370,
author = {Rossoff, Sam and Tzanetakis, George and Gooch, Bruce},
title = {Adapting Personal Music for Synesthetic Game Play},
year = {2010},
isbn = {9781605589374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1822348.1822370},
doi = {10.1145/1822348.1822370},
abstract = {Music can significantly effect game play and help players understand underlying patterns in the game, or the effects of their actions on the characters. Conversely, inappropriate music can have a negative effect on players by creating additional difficulties. While game makers recognize the effects of music on game play, solutions that provide users with a choice in personal music are not forthcoming. We design, implement and evaluate an algorithm for automatically adapting an arbitrary music track from a personal library and synchronizing play back to the user, without requiring any access to the video game source code.},
booktitle = {Proceedings of the Fifth International Conference on the Foundations of Digital Games},
pages = {163–170},
numpages = {8},
location = {Monterey, California},
series = {FDG '10}
}

@inproceedings{10.1145/1822018.1822057,
author = {Schmidt, Benedikt and Stoitsev, Todor and M\"{u}hlh\"{a}user, Max},
title = {Activity-Centric Support for Weakly-Structured Business Processes},
year = {2010},
isbn = {9781450300834},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1822018.1822057},
doi = {10.1145/1822018.1822057},
abstract = {Knowledge-intensive tasks are a blind spot for business process management systems, as these tasks are executed in an unsupervised, highly individual manner. Hence, individual experience is not disseminated and task execution largely depends on implicit knowledge.In this paper we present a framework, realizing situation-specific and personalized task execution support for knowledge-intensive tasks in business processes. As a core concept we suggest activity scheme: a structure capturing a probabilistic task execution model. Activity schemes seamlessly integrate the organizational business process with the individual task execution process based on personalization and generalization of user interactions in the working applications.},
booktitle = {Proceedings of the 2nd ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
pages = {251–260},
numpages = {10},
keywords = {knowledge work support, human-computer interaction, task execution support},
location = {Berlin, Germany},
series = {EICS '10}
}

@inproceedings{10.1145/1815961.1816002,
author = {Janapa Reddi, Vijay and Lee, Benjamin C. and Chilimbi, Trishul and Vaid, Kushagra},
title = {Web Search Using Mobile Cores: Quantifying and Mitigating the Price of Efficiency},
year = {2010},
isbn = {9781450300537},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1815961.1816002},
doi = {10.1145/1815961.1816002},
abstract = {The commoditization of hardware, data center economies of scale, and Internet-scale workload growth all demand greater power efficiency to sustain scalability. Traditional enterprise workloads, which are typically memory and I/O bound, have been well served by chip multiprocessors com- prising of small, power-efficient cores. Recent advances in mobile computing have led to modern small cores capable of delivering even better power efficiency. While these cores can deliver performance-per-Watt efficiency for data center workloads, small cores impact application quality-of-service robustness, and flexibility, as these workloads increasingly invoke computationally intensive kernels. These challenges constitute the price of efficiency. We quantify efficiency for an industry-strength online web search engine in production at both the microarchitecture- and system-level, evaluating search on server and mobile-class architectures using Xeon and Atom processors.},
booktitle = {Proceedings of the 37th Annual International Symposium on Computer Architecture},
pages = {314–325},
numpages = {12},
keywords = {energy efficiency, mobile cores, web search, bing},
location = {Saint-Malo, France},
series = {ISCA '10}
}

@article{10.1145/1816038.1816002,
author = {Janapa Reddi, Vijay and Lee, Benjamin C. and Chilimbi, Trishul and Vaid, Kushagra},
title = {Web Search Using Mobile Cores: Quantifying and Mitigating the Price of Efficiency},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {3},
issn = {0163-5964},
url = {https://doi.org/10.1145/1816038.1816002},
doi = {10.1145/1816038.1816002},
abstract = {The commoditization of hardware, data center economies of scale, and Internet-scale workload growth all demand greater power efficiency to sustain scalability. Traditional enterprise workloads, which are typically memory and I/O bound, have been well served by chip multiprocessors com- prising of small, power-efficient cores. Recent advances in mobile computing have led to modern small cores capable of delivering even better power efficiency. While these cores can deliver performance-per-Watt efficiency for data center workloads, small cores impact application quality-of-service robustness, and flexibility, as these workloads increasingly invoke computationally intensive kernels. These challenges constitute the price of efficiency. We quantify efficiency for an industry-strength online web search engine in production at both the microarchitecture- and system-level, evaluating search on server and mobile-class architectures using Xeon and Atom processors.},
journal = {SIGARCH Comput. Archit. News},
month = jun,
pages = {314–325},
numpages = {12},
keywords = {mobile cores, energy efficiency, bing, web search}
}

@inproceedings{10.1145/1851476.1851572,
author = {Bhagawaty, Harsha and Jiang, Lei and Pothanis, Sreekanth and Allen, Gabrielle and Brener, Nathan and Kosar, Tevfik},
title = {Design, Implementation and Use of a Simulation Data Archive for Coastal Science},
year = {2010},
isbn = {9781605589428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851476.1851572},
doi = {10.1145/1851476.1851572},
abstract = {With many researchers now having easy access to supercomputers, coastal scientists are able to develop and run simulations that model the physical and ecological processes in ocean or nearshore areas in a distributed and collaborative environment. However, the increase in capacity of computational resources does not lead directly to a rapid improvement of the simulations themselves. Instead, it brings a new challenge that motivates scientists to fully utilize the huge amount of simulation data created in supercomputers, thus fostering advanced scientific research. Driven by the urgent need for in-depth investigations in Louisiana coastal areas, especially during hurricane seasons, a data center, which provides research communities with scientific data resources on demand, is imperative. In this paper, we present the design, implementation and use of such a simulation data archive for coastal science. The simulation data archive is capable of providing interfaces based on the requirements of user groups and its application incorporates multiple use cases. The enabling technology, as well as the challenges in the development of this simulation data archive, are also described in this paper.},
booktitle = {Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing},
pages = {651–657},
numpages = {7},
location = {Chicago, Illinois},
series = {HPDC '10}
}

@inproceedings{10.1145/1851476.1851593,
author = {Ekanayake, Jaliya and Li, Hui and Zhang, Bingjing and Gunarathne, Thilina and Bae, Seung-Hee and Qiu, Judy and Fox, Geoffrey},
title = {Twister: A Runtime for Iterative MapReduce},
year = {2010},
isbn = {9781605589428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851476.1851593},
doi = {10.1145/1851476.1851593},
abstract = {MapReduce programming model has simplified the implementation of many data parallel applications. The simplicity of the programming model and the quality of services provided by many implementations of MapReduce attract a lot of enthusiasm among distributed computing communities. From the years of experience in applying MapReduce to various scientific applications we identified a set of extensions to the programming model and improvements to its architecture that will expand the applicability of MapReduce to more classes of applications. In this paper, we present the programming model and the architecture of Twister an enhanced MapReduce runtime that supports iterative MapReduce computations efficiently. We also show performance comparisons of Twister with other similar runtimes such as Hadoop and DryadLINQ for large scale data parallel applications.},
booktitle = {Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing},
pages = {810–818},
numpages = {9},
keywords = {iterative algorithms, cloud technologies, MapReduce},
location = {Chicago, Illinois},
series = {HPDC '10}
}

@inproceedings{10.1145/1851476.1851487,
author = {Du, Juan and Gu, Xiaohui and Reeves, Douglas S.},
title = {Highly Available Component Sharing in Large-Scale Multi-Tenant Cloud Systems},
year = {2010},
isbn = {9781605589428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851476.1851487},
doi = {10.1145/1851476.1851487},
abstract = {A multi-tenant cloud system allows multiple users to share a common physical computing infrastructure in a cost-effective way. Component sharing is highly desired in such a shared computing infrastructure, where different tenants can leverage each other's information and expertise to fulfill their own tasks. However, it is challenging to maintain the availability of sharable component resources in a large-scale cloud infrastructure, as cloud tenants are fully autonomous and highly dynamic. In this paper, we present a novel highly available component sharing system for large-scale multi-tenant cloud systems. We describe a component availability prediction scheme to identify endangered components (i.e., components at risk of extinction) within the infrastructure. The system then performs predictive replication based on the availability prediction results to preserve those endangered components. Thus, our system can preserve the availability of all component resources with low cost. Theoretical analysis and large-scale simulation are used to quantify the accuracy of our component availability prediction, and the efficiency of predictive replication. Experimental results show that our scheme can predict endangered components with high accuracy, and achieve up to 99% availability with about 15% of the full replication cost.},
booktitle = {Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing},
pages = {85–94},
numpages = {10},
keywords = {component sharing, high availability, cloud computing},
location = {Chicago, Illinois},
series = {HPDC '10}
}

@inproceedings{10.1145/1851476.1851562,
author = {Wojciechowski, Maciej and Capot\u{a}, Mihai and Pouwelse, Johan and Iosup, Alexandru},
title = {BTWorld: Towards Observing the Global BitTorrent File-Sharing Network},
year = {2010},
isbn = {9781605589428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851476.1851562},
doi = {10.1145/1851476.1851562},
abstract = {Today, the BitTorrent Peer-to-Peer file-sharing network is one of the largest Internet applications---it generates massive traffic volumes, it is deployed in thousands of independent communities, and it serves millions of unique users worldwide. Despite a large number of empirical and theoretical studies, observing the state of the global BitTorrent network remains a grand challenge for the BitTorrent community. To address this challenge, in this work we introduce BT-World, an architecture for observing the global BitTorrent network without help from the ISPs. We design BTWorld around three main features specific to BitTorrent measurements. First, our architecture is able to find public trackers, that is, the BitTorrent components that offer unrestricted service to peers around the world. Second, by observing the state of these trackers, BTWorld obtains information about the performance, scalability, and reliability of BitTorrent. Third, BTWorld is designed to pre-process the large volumes of recorded data for later analysis. We demonstrate the viability of our architecture by deploying it in practice, to observe and analyze one week of operation of a large part of the global BitTorrent network--over 10 million swarms and tens of millions of concurrent users. We also show that BT-World can shed light on BitTorrent phenomena, such as the presence of spam trackers and giant swarms.},
booktitle = {Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing},
pages = {581–588},
numpages = {8},
location = {Chicago, Illinois},
series = {HPDC '10}
}

@inproceedings{10.1145/1851476.1851506,
author = {Rajanna, Vijay Shankar and Shah, Smit and Jahagirdar, Anand and Lemoine, Christopher and Gopalan, Kartik},
title = {XCo: Explicit Coordination to Prevent Network Fabric Congestion in Cloud Computing Cluster Platforms},
year = {2010},
isbn = {9781605589428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851476.1851506},
doi = {10.1145/1851476.1851506},
abstract = {Large cluster-based cloud computing platforms increasingly use commodity Ethernet technologies, such as Gigabit Ethernet, 10GigE, and Fibre Channel over Ethernet (FCoE), for intra-cluster communication. Traffic congestion can become a performance concern in the Ethernet due to consolidation of data, storage, and control traffic over a common layer-2 fabric, as well as consolidation of multiple virtual machines (VMs) over less physical hardware. Even as networking vendors race to develop switch-level hardware support for congestion management, we make the case that virtualization has opened up a complementary set of opportunities to reduce or even eliminate network congestion in cloud computing clusters. We present the design, implementation, and evaluation of a system called XCo, that performs explicit coordination of network transmissions over a shared Ethernet fabric to proactively prevent network congestion. XCo is a software-only distributed solution executing only in the end-nodes. A central controller uses explicit permissions to temporally separate (at millisecond granularity) the transmissions from competing senders through congested links. XCo is fully transparent to applications, presently deployable, and independent of any switch-level hardware support. We present a detailed evaluation of our XCo prototype across a number of network congestion scenarios, and demonstrate that XCo significantly improves network performance during periods of congestion.},
booktitle = {Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing},
pages = {252–263},
numpages = {12},
keywords = {congestion, ethernet, virtualization},
location = {Chicago, Illinois},
series = {HPDC '10}
}

@inproceedings{10.1145/1816123.1816168,
author = {Angrosh, M. A. and Cranefield, Stephen and Stanger, Nigel},
title = {Context Identification of Sentences in Related Work Sections Using a Conditional Random Field: Towards Intelligent Digital Libraries},
year = {2010},
isbn = {9781450300858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1816123.1816168},
doi = {10.1145/1816123.1816168},
abstract = {Identification of contexts associated with sentences is becoming increasingly necessary for developing intelligent information retrieval systems. This article describes a supervised learning mechanism employing a conditional random field (CRF) for context identification and sentence classification. Specifically, we focus on sentences in related work sections in research articles. Based on a generic rhetorical pattern, a framework for modelling the sequential flow in these sections is proposed. Adopting a generalization strategy, each of these sentences is transformed into a set of features, which forms our dataset. We distinguish between two kinds of features for each of these sentences viz., citation features and sentence features. While an overall accuracy of 96.51% is achieved by using a combination of both citation and sentence features, the use of sentence features alone yields an accuracy of 93.22%. The results also show F-Scores ranging from 0.99 to 0.90 for various classes indicating the robustness of our application.},
booktitle = {Proceedings of the 10th Annual Joint Conference on Digital Libraries},
pages = {293–302},
numpages = {10},
keywords = {conditional random fields, linear chain CRFs, citation classification, sentence classification},
location = {Gold Coast, Queensland, Australia},
series = {JCDL '10}
}

@inproceedings{10.1145/1816123.1816150,
author = {Bae, Soonil and Kim, DoHyoung and Meintanis, Konstantinos and Moore, J. Michael and Zacchi, Anna and Shipman, Frank and Hsieh, Haowei and Marshall, Catherine C.},
title = {Supporting Document Triage via Annotation-Based Multi-Application Visualizations},
year = {2010},
isbn = {9781450300858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1816123.1816150},
doi = {10.1145/1816123.1816150},
abstract = {For open-ended information tasks, users must sift through many potentially relevant documents, a practice we refer to as document triage. Normally, people perform triage using multiple applications in concert: a search engine interface presents lists of potentially relevant documents; a document reader displays their contents; and a third tool--a text editor or personal information management application--is used to record notes and assessments. To support document triage, we have developed an extensible multi-application architecture that initially includes an information workspace and a document reader. An Interest Profile Manager infers users' interests from their interactions with the triage applications, coupled with the characteristics of the documents they are interacting with. The resulting interest profile is used to generate visualizations that direct users' attention to documents or parts of documents that match their inferred interests. The novelty of our approach lies in the aggregation of activity records across applications to generate fine-grained models of user interest.},
booktitle = {Proceedings of the 10th Annual Joint Conference on Digital Libraries},
pages = {177–186},
numpages = {10},
keywords = {multi-application user modeling, document triage, visualization},
location = {Gold Coast, Queensland, Australia},
series = {JCDL '10}
}

@inproceedings{10.1145/1839294.1839317,
author = {Byrne, Richard and Eslambolchilar, Parisa and Crossan, Andrew},
title = {Health Monitoring Using Gait Phase Effects},
year = {2010},
isbn = {9781450300711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839294.1839317},
doi = {10.1145/1839294.1839317},
abstract = {The need to monitor patients after they leave the hospital or clinics is of growing concern and doctors may need the facility to monitor certain patients more than others. For example patients with high blood pressure are sometimes fitted with a mobile monitor which can be used to track the patients blood pressure over time. Patients suffering from depression, however, may also need to be monitored to ensure that they are in a happy emotional state. In this paper we introduce an alternative approach to mood detection and tracking based on built-in accelerometer sensors found in common mobile phones. Our method can be seen to compliment the need to monitor such patients allowing for doctors to get in touch with them when their mood has altered. We build a system based on neural networks which takes the gait information and learns the associated mood of the user. This trained model is then used to detect the mood of the individuals. We demonstrate preliminary results on mood detection using a mobile prototype system.},
booktitle = {Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {19},
numpages = {7},
keywords = {gait phase effects, tracking, gait phase, health monitoring, mood tracking, gait, mood detection},
location = {Samos, Greece},
series = {PETRA '10}
}

@inproceedings{10.1145/1839294.1839346,
author = {Liolios, Charalampos and Doukas, Charalampos and Fourlas, George and Maglogiannis, Ilias},
title = {An Overview of Body Sensor Networks in Enabling Pervasive Healthcare and Assistive Environments},
year = {2010},
isbn = {9781450300711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839294.1839346},
doi = {10.1145/1839294.1839346},
abstract = {The use of sensor networks for healthcare, well-being, and working in extreme environments has long roots in the engineering sector in medicine and biology community. With the growing needs in ubiquitous communications and recent advances in very-low-power wireless technologies, there has been considerable interest in the development and application of wireless networks around humans. With the maturity of wireless sensor networks, body area networks (BANs), and wireless BANs (WBANs), recent efforts in promoting the concept of body sensor networks (BSNs) aim to move beyond sensor connectivity to adopt a system-level approach to address issues related to biosensor design, interfacing, and embodiment, as well as ultra low-power processing / communication, power scavenging, autonomic sensing, data mining, inferencing, and integrated wireless sensor microsystems. As a result, the system architecture based on WBAN and BSN is becoming a widely accepted method of organization for ambulatory and ubiquitous monitoring systems. This review paper presents an up-to-date report of the current research and enabling applications and addresses some of the challenges and implementation issues.},
booktitle = {Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {43},
numpages = {10},
keywords = {ubiquitous computing, healthcare applications, wireless body area networks, body sensor networks},
location = {Samos, Greece},
series = {PETRA '10}
}

@inproceedings{10.1145/1839294.1839356,
author = {Xefteris, Stefanos and Haritou, Maria and Tserpes, Konstantinos and Serretti, Alessandro and Llopart, Josep Ramon and Calati, Raffaella and Varvarigou, Theodora},
title = {Analysis of Requirements and Specifications for a Monitoring System to Support the Self-Management of Dementia Patients at Home},
year = {2010},
isbn = {9781450300711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839294.1839356},
doi = {10.1145/1839294.1839356},
abstract = {Telemedicine systems are nowadays making significant advances in healthcare by decentralising it, offering innovative services to patients and doctors worldwide, and making medical practice more efficient and cost-effective in a plethora of its subfields. There is although a field that has not yet been successfully coped with, even though it induces a significant burden, both socially and financially. This field includes patients suffering from dementia, as well as their carers, who run the risk of developing depression symptoms themselves and often face social withdrawal and heavy additional private costs. ALADDIN is a technology platform that intends to progress "state-of-the-art" in integration of existing technological solutions. In order to develop and validate an innovative monitoring system for health promotion, risk assessment, prevention and sustainable impact of self management tools and education for patients suffering from dementia and their care-givers. In this paper the authors present the envisaged services of the ALADDIN platform, the user requirements and ALADDIN's functional specifications.},
booktitle = {Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {52},
numpages = {8},
keywords = {non-obtrusive monitoring, assisted living, quality of life, cognitive states, risk analysis, e-health and assistive infrastructures, Dementia},
location = {Samos, Greece},
series = {PETRA '10}
}

@inproceedings{10.1145/1839294.1839336,
author = {Makedon, Fillia and Zhang, Rong and Alexandrakis, Georgios and Owen, Charles B. and Huang, Heng and Saykin, Andrew J.},
title = {An Interactive User Interface System for Alzheimer's Intervention},
year = {2010},
isbn = {9781450300711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839294.1839336},
doi = {10.1145/1839294.1839336},
abstract = {Alzheimer's Disease (AD) is a neurological affliction that impacts primarily the aged due to brain tissue deterioration. It has been shown that this deterioration can be slowed down by engaging the person with daily interactive activities that include gaming, social interaction, memory exercises and physical activity. In this paper, we describe ZPLAY, a game-based user interface system which is designed to be web-based and to provide intervention therapy for AD. ZPLAY has two versions: the @lab version which is designed for diagnosis and used to measure different brain activation responses of AD and the @home version which is used to promote subject engagement and rehabilitation in a home environment in-between visits to the clinic.},
booktitle = {Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {35},
numpages = {5},
keywords = {functional near infrared (fNIR) imaging, physical therapy, motion capture, data stream synchronization, machine learning, human computer interaction, Dementia, game design, Alzheimer's, rehabilitation},
location = {Samos, Greece},
series = {PETRA '10}
}

@inproceedings{10.1145/1839294.1839337,
author = {Qudah, Islam and Leijdekkers, Peter and Gay, Valerie},
title = {Using Mobile Phones to Improve Medication Compliance and Awareness for Cardiac Patients},
year = {2010},
isbn = {9781450300711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839294.1839337},
doi = {10.1145/1839294.1839337},
abstract = {Improving cardiac patients' medication compliance is a major factor in reducing mortality rate and reducing hospitalization rate. This paper describes a novel medication compliance management system. Its novelty lies in the combination of functionalities that helps the patient to comply with their medication regimen, together with a personal health monitoring system that monitors their health and collects vital signs data using a mobile phone and wireless bio sensors. The system is designed to collect and analyse medication compliance, side effects and symptom responses and transfers the collected data in real time to a web based system for remote monitoring by caregivers and health professionals. Health professionals can use the system to assess the effect of the medication regimen on their patients' health and adapt it to reduce side effects and maximise the patient's wellbeing.},
booktitle = {Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {36},
numpages = {7},
keywords = {medication compliance, cardiac rehabilitation, tele-monitoring, ambulatory monitoring},
location = {Samos, Greece},
series = {PETRA '10}
}

@inproceedings{10.1145/1839294.1839300,
author = {Lin, Yong (Yates) and Le, Zhengyi and Becker, Eric and Makedon, Fillia},
title = {Acoustical Implicit Communication in Human-Robot Interaction},
year = {2010},
isbn = {9781450300711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839294.1839300},
doi = {10.1145/1839294.1839300},
abstract = {Explicit communication addresses the use of distinct language or protocol to convey the idea. Implicit communication helps to compensate many hidden meanings omitted from the explicit language. In some situations, implicit communication may even take the place of explicit communication. For the autonomous robot, implicit communication provides an alternative way to interact with people. This paper introduces the acoustic techniques for implicit communication in human-robot interaction, and the design of acoustical implicit communication based robot games.},
booktitle = {Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {5},
numpages = {5},
keywords = {human-robot interface, acoustic communication, implicit communication},
location = {Samos, Greece},
series = {PETRA '10}
}

@inproceedings{10.1145/1839294.1839313,
author = {Oliveira, Francisco and Cowan, Heidi and Fang, Bing and Quek, Francis},
title = {Fun to Develop Embodied Skill: How Games Help the Blind to Understand Pointing},
year = {2010},
isbn = {9781450300711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839294.1839313},
doi = {10.1145/1839294.1839313},
abstract = {We discuss how gaming can be used as a training strategy for students who are blind or visually impaired (SBVI) to develop embodied skill in use of haptic assistive technology. The technology takes the form of a haptic glove that is designed to give SBVI access to the pointing behavior of teachers in mathematics/science instruction that is performed in conjunction with speech and the use of instructional graphics. Our initial studies show that significant 'embodied skill' was required to afford fluent multimodal communication between the instructor and student. We developed a gaming strategy, employing flow theory to enhance the fun and engagement of the SBVI to promote extensive perceptual training. Our results showed significant improvement and interaction gains as the game-play progressed over multiple sessions. Results also indicate that skills developed through game play were persistent, and transferable to complex multimodal situated discourse conditions.},
booktitle = {Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {16},
numpages = {8},
keywords = {ACM proceedings, embodied skill, gaming, assistive technology, multimodal discourse},
location = {Samos, Greece},
series = {PETRA '10}
}

@article{10.1145/1823838.1823840,
author = {Thomasian, Alexander},
title = {Storage Research in Industry and Universities},
year = {2010},
issue_date = {May 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/1823838.1823840},
doi = {10.1145/1823838.1823840},
abstract = {We review activities at universities and industrial research centers in the storage area, but also briefly mention topics such as processor design, operating systems, databases, and performance analysis. Our starting point is the Berkeley RAID proposal and the associated taxonomy two decades ago. Important research groups are listed and key researchers are identified. We pay special attention to faculty/student relationships, listing PhD theses and articles related to storage. We also describe innovative storage products and the companies behind them. This paper complements author's "Publications in Storage and Systems", ACM CAN, Sept. 2009.},
journal = {SIGARCH Comput. Archit. News},
month = jun,
pages = {1–48},
numpages = {48}
}

@article{10.1145/1754414.1754415,
author = {Ko, Teresa and Ahmadian, Shaun and Hicks, John and Rahimi, Mohammad and Estrin, Deborah and Soatto, Stefano and Coe, Sharon and Hamilton, Michael P.},
title = {Heartbeat of a Nest: Using Imagers as Biological Sensors},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
issn = {1550-4859},
url = {https://doi.org/10.1145/1754414.1754415},
doi = {10.1145/1754414.1754415},
abstract = {We present a scalable end-to-end system for vision-based monitoring of natural environments, and illustrate its use for the analysis of avian nesting cycles. Our system enables automated analysis of thousands of images, where manual processing would be infeasible. We automate the analysis of raw imaging data using statistics that are tailored to the task of interest. These “features” are a representation to be fed to classifiers that exploit spatial and temporal consistencies. Our testbed can detect the presence or absence of a bird with an accuracy of 82%, count eggs with an accuracy of 84%, and detect the inception of the nesting stage within a day. Our results demonstrate the challenges and potential benefits of using imagers as biological sensors. An exploration of system performance under varying image resolution and frame rate suggest that an in situ adaptive vision system is technically feasible.},
journal = {ACM Trans. Sen. Netw.},
month = jun,
articleno = {19},
numpages = {31},
keywords = {system deployment, Image network, sensor network, computer vision}
}

@inproceedings{10.1145/1822090.1822104,
author = {Dee, Hannah M. and Boyle, Roger D.},
title = {Inspiring Women Undergraduates},
year = {2010},
isbn = {9781605588209},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1822090.1822104},
doi = {10.1145/1822090.1822104},
abstract = {This paper describes the conception, motivation, organization, and evaluation of a national, one-day event for women students of computing: the BCSWomen Lovelace Colloquium. The aim of this paper is to demonstrate that such events have value for women students of computing. We hope to show that through introducing these undergraduate women to high profile role models we can inspire them, and that through providing the students with a forum for presenting their own work, we can be inspired by them ourselves. We believe this is a successful and economical model for an event which could be re-used in other countries or regions.},
booktitle = {Proceedings of the Fifteenth Annual Conference on Innovation and Technology in Computer Science Education},
pages = {43–47},
numpages = {5},
keywords = {gender issues, women in computing, motivation},
location = {Bilkent, Ankara, Turkey},
series = {ITiCSE '10}
}

@inproceedings{10.1145/1822090.1822151,
author = {Simon, Beth and Kinnunen, P\"{a}ivi and Porter, Leo and Zazkis, Dov},
title = {Experience Report: CS1 for Majors with Media Computation},
year = {2010},
isbn = {9781605588209},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1822090.1822151},
doi = {10.1145/1822090.1822151},
abstract = {Previous reports of a media computation approach to teaching programming have either focused on pre-CS1 courses or courses for non-majors. We report the adoption of a media computation context in a majors' CS1 course at a large, selective R1 institution in the U.S. The main goal was to increase retention of majors, but do so by replacing the traditional CS1 course directly (fully preparing students for the subsequent course). In this paper we provide an experience report for instructors interested in this approach. We compare a traditional CS1 with a media computation CS1 in terms of desired student competencies (analyzed via programming assignments and exams) and find the media computation approach to focus more on problem solving and less on language issues. In comparing student success (analyzed via pass rates and retention rates one year later) we find pass rates to be statistically significantly higher with media computation both for majors and for the class as a whole. We give examples of media computation exam questions and programming assignments and share student and instructor experiences including advice for the new instructor.},
booktitle = {Proceedings of the Fifteenth Annual Conference on Innovation and Technology in Computer Science Education},
pages = {214–218},
numpages = {5},
keywords = {media computation, retention, CS1},
location = {Bilkent, Ankara, Turkey},
series = {ITiCSE '10}
}

@inproceedings{10.1145/1815396.1815523,
author = {Ouanaim, Mariam and Harroud, Hamid and Berrado, Aziz and Boulmalf, Mohammed},
title = {Dynamic User Profiling Approach for Services Discovery in Mobile Environments},
year = {2010},
isbn = {9781450300629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1815396.1815523},
doi = {10.1145/1815396.1815523},
abstract = {User profiling is commonly used to support personalization as well as to enhance usability of software systems by automatically adapting to the needs and preferences of their users. This paper presents an approach to dynamically update mobile users' profiles so that they can be provided with appropriate services while moving from one location to another. We propose an XML generic user profile structure that is dynamically updatable as the user experiences new services and that can be used by different software systems and applications. The proposed profile learning mechanism makes use of clustering users with a subset of similar attributes to predict appropriate services to a new user, and segmenting services with a subset of similar usage to discover and recommend new services that might be of interests to a mobile user. We demonstrated the feasibility of our approach by presenting a case study in tourism where tourists are assisted during their travels by providing them with services and information of interest. The tourist preferences and her/his current location are incorporated in the proactive formulation of suggestions on the tourist mobile devices about nearby points of interests (e.g. museums, restaurants...).},
booktitle = {Proceedings of the 6th International Wireless Communications and Mobile Computing Conference},
pages = {550–554},
numpages = {5},
keywords = {prediction, segmentation, user profiling, user interactions, behavior learning},
location = {Caen, France},
series = {IWCMC '10}
}

@inproceedings{10.5555/1854360.1854433,
author = {Levrini, Olivia and Fantini, Paola and Pecori, Barbara and Gagliardi, Marta and Scarongella, Mariateresa and Tasquier, Giulia},
title = {A Longitudinal Approach to Appropriation of Science Ideas: A Study of Students' Trajectories in Thermodynamics},
year = {2010},
publisher = {International Society of the Learning Sciences},
abstract = {This article provides an empirical analysis of data collected during the implementation of a teaching proposal on thermodynamics in a class of 20 students (17 year-olds) of a scientifically-oriented secondary school in Italy. During the activities, each student made evident progress in gaining intellectual autonomy as they took part in the teaching/learning dynamics of the classroom. Although the research had, up to now, an empirical orientation, this paper aims to provide a contribution for advancing theory development in physics education research. The study gives an example of the application of a specific model of teaching/learning (the Model of Longitudinal Development) that acted as "framework for action" in the design of the learning environment as "properly complex territory." The data analysis gives indications for how to develop a theoretical understanding of the concept of "personal learning trajectory" and it provides a basis for exploring the factors that can trigger intellectual autonomy.},
booktitle = {Proceedings of the 9th International Conference of the Learning Sciences - Volume 1},
pages = {572–579},
numpages = {8},
location = {Chicago, Illinois},
series = {ICLS '10}
}

@inproceedings{10.5555/1854360.1854427,
author = {Siewiorek, Anna and Gegenfurtner, Andreas},
title = {Leading to Win: The Influence of Leadership Styles on Team Performance during a Computer Game Training},
year = {2010},
publisher = {International Society of the Learning Sciences},
abstract = {The purpose of this study is to examine how leadership styles will influence the team performance during a computer game training In order to get a better understanding what leadership styles are going to be distinguished, researchers observed students' interactions while they played a strategic computer game. In the study, a group of Stanford University graduate students participated in the training with a 'real esate' computer game. The participants' task during the game was to manage an estate company in small teams. Students developed goals, discussed problems and tracked progress in order to win the game. The results showed that the teams had different leadership styles which affected their performance. The leadership styles that participants used and how they affected the teams' performance are described in the paper.},
booktitle = {Proceedings of the 9th International Conference of the Learning Sciences - Volume 1},
pages = {524–531},
numpages = {8},
location = {Chicago, Illinois},
series = {ICLS '10}
}

@inproceedings{10.5555/1854360.1854507,
author = {Magnifico, Alecia Marie},
title = {"Getting Others' Perspectives": A Case Study of Creative Writing Environments and Mentorship},
year = {2010},
publisher = {International Society of the Learning Sciences},
abstract = {Giving students opportunities to interact with real readers of their work may not only motivate them to write, but also to take on new literacies and see themselves as writers in new ways. I detail two case studies of successful writing communities---a high school classroom and an extracurricular arts program---and describe adolescent writing practices in the active (and often interactive) presence of the two different collaborative audiences. I discuss structural implications for the structure of authentic writing and writing workshop environments, the role of mentors in such instructional spaces, and the importance of teaching students how to be effective, collaborative audience members and readers of each others' writing.},
booktitle = {Proceedings of the 9th International Conference of the Learning Sciences - Volume 1},
pages = {1151–1157},
numpages = {7},
location = {Chicago, Illinois},
series = {ICLS '10}
}

@inproceedings{10.5555/1854360.1854371,
author = {Bagley, Elizabeth and Shaffer, David Williamson},
title = {The Epistemography of Urban and Regional Planning 912: Appropriation in the Face of Resistance},
year = {2010},
publisher = {International Society of the Learning Sciences},
abstract = {Preparing citizens to address the complex problems inherent in cities requires our changing society to embrace a new kind of education. One way to train people to think about complex problems is to identify and study how professionals who think in those ways develop their epistemic frame. In this paper, we examine one of the ways urban planners master and appropriate relevant expertise through an ethnographic study of an urban planning practicum. Specifically, we use a new method called epistemic network analysis to look at presentation feedback sessions during two weeks of the practicum to explore emergent relationships between the teacher's planning expertise and the students' expertise. The results of this study indicate that epistemic network analysis offers a technique for analyzing the kinds of situated understanding that result from sociocultural learning and for observing the translation of pedagogy into practice in various types of learning environments.},
booktitle = {Proceedings of the 9th International Conference of the Learning Sciences - Volume 1},
pages = {81–88},
numpages = {8},
location = {Chicago, Illinois},
series = {ICLS '10}
}

@inproceedings{10.5555/1854360.1854469,
author = {Martinez, Mara V. and Li, Wenjuan},
title = {Fostering Mathematical Inquiry: Focus on Teacher's Interventions},
year = {2010},
publisher = {International Society of the Learning Sciences},
abstract = {Previous research has emphasized the need to better understand and articulate the demands in the work of teaching mathematics entailed by an inquiry-based approach. It is in this context that, first, we describe an inquiry task intended to provide high school students the opportunity to construct algebraic proofs. Second, as students work on the problem, we map students' inquiry process. More, we identify elements common to students' inquiry process and current views of how mathematics knowledge is constructed. Last, we illustrate the teacher's interventions intended to sustain students' inquiry. Among these, we identified: (1) helping students re-focus their inquiry, (2) helping students select mathematical tools, (3) accepting students' provisory ideas, (4) recognizing the potential in students' ideas and promoting the student to showcase the idea, and (5) reviewing a property using an additional example to preserve the original challenge for students.},
booktitle = {Proceedings of the 9th International Conference of the Learning Sciences - Volume 1},
pages = {849–856},
numpages = {8},
location = {Chicago, Illinois},
series = {ICLS '10}
}

@inproceedings{10.5555/1854360.1854505,
author = {Clegg, Tamara L. and Gardner, Christina M. and Kolodner, Janet L.},
title = {Playing with Food: Moving from Interests and Goals into Scientifically Meaningful Experiences},
year = {2010},
publisher = {International Society of the Learning Sciences},
abstract = {As science educators, we want all learners to see the relevance of science to their lives and the world in which they live. Achieving this goal, however, has proven to be a difficult endeavor. Many learners see science as useful only in school, and they face difficulties connecting science to the real world and to their own interests and goals. In our research project, Kitchen Science Investigators, we aim to start with learners' interests and goals in cooking. We then help them connect cooking to science, using play to help them see food as an object of investigation. We then transition learners into engaging in authentic scientific practices. In this paper we present three cases that highlight scientifically meaningful experiences for KSI learners and the ways play, facilitation, and artifacts bridge the gap between their interests and scientific practices.},
booktitle = {Proceedings of the 9th International Conference of the Learning Sciences - Volume 1},
pages = {1135–1142},
numpages = {8},
location = {Chicago, Illinois},
series = {ICLS '10}
}

@inproceedings{10.5555/1854360.1854465,
author = {Turns, Jennifer and Sattler, Brook and Kilgore, Deborah},
title = {Disciplinary Knowledge, Identity, and Navigation: The Contributions of Portfolio Construction},
year = {2010},
publisher = {International Society of the Learning Sciences},
abstract = {In this paper, we look at how the construction of two types of professional portfolios supports engineering student learning. To frame "engineering learning," we use the dimensions brought together by Stevens and his colleagues: disciplinary knowledge, identity, and navigation. We present data from a comparative study in which students constructed one of two types of professional portfolios and provided data through extensive questionnaires. In this analysis, we look at their answers to the first question on the questionnaire ("What did you take away from this experience") in terms of the extent to which the students reported insights about disciplinary knowledge, identity, and navigation as a result of portfolio construction activities and the nature of the insights reported.},
booktitle = {Proceedings of the 9th International Conference of the Learning Sciences - Volume 1},
pages = {818–825},
numpages = {8},
location = {Chicago, Illinois},
series = {ICLS '10}
}

@inproceedings{10.5555/1854360.1854487,
author = {Dugan, Th\'{e}r\`{e}se E. and Stevens, Reed and Mehus, Siri},
title = {From Show, to Room, to World: A Cross-Context Investigation of How Children Learn from Media Programming},
year = {2010},
publisher = {International Society of the Learning Sciences},
abstract = {We conducted a year-long, naturalistic study that investigated what actually happens when children watch television. We video-recorded children's actions and interactions while watching television and simultaneously recorded the video stream from the television screen; these data were supported with parent diaries and interviews with parents and children. This paper describes two case studies, in which we consider children's interactions with others while watching television and the ways in which their television viewing influences other parts of their everyday lives. We find that both children actively applied knowledge they obtained from visual media to other contexts. In addition, they both shared their media viewing experiences with others, either by directly teaching others about what they had viewed or by creating new content based on what they had viewed.},
booktitle = {Proceedings of the 9th International Conference of the Learning Sciences - Volume 1},
pages = {992–999},
numpages = {8},
location = {Chicago, Illinois},
series = {ICLS '10}
}

@inproceedings{10.5555/1854360.1854440,
author = {Hatfield, David and Shaffer, David Williamson},
title = {The Epistemography of Journalism 335: Complexity in Developing Journalistic Expertise},
year = {2010},
publisher = {International Society of the Learning Sciences},
abstract = {As bloggers and mobile phone eye-witnesses increasingly supplement the 'news,' it is more important than ever to understand how professional journalists develop their expertise. In this paper, we examine an intermediate level reporting practicum course to explore the learning processes therein. Using a new method called Epistemic Network Analysis, we also explore emergent relationships within developing journalistic expertise. Understanding these relationships should be useful for journalism education as well as the design of research on learning environments.},
booktitle = {Proceedings of the 9th International Conference of the Learning Sciences - Volume 1},
pages = {628–635},
numpages = {8},
location = {Chicago, Illinois},
series = {ICLS '10}
}

@inproceedings{10.5555/1854509.1854548,
author = {Barab, Sasha A. and Gresalfi, Melissa and Arici, Anna and Pettyjohn, Patrick and Ingram-Goble, Adam},
title = {Transformative Play: Games as 21<sup>st</sup> Century Curriculum},
year = {2010},
publisher = {International Society of the Learning Sciences},
abstract = {In this presentation, we will discuss the design history, comparison studies, and scaling research focused on four units we have designed based on our theory of transformational play. The goal is to both discuss the power of these designs, but also the challenges of scaling such innovative learning experiences internationally. These four units (one focused on mathematics, science, language arts, and social studies) are situated in an online, multiplayer videogame called Quest Atlantis, supporting over 25,000 children worldwide. Each presented unit has gone through multiple iterations of implementation, analysis, and redesign, informed by empirical data and our evolving theoretical framework. In reviewing both results from comparison studies and differences in international engagement with the units, our accounts will illuminate the theory transformational play, how the theory has shaped design and interpretations of findings.},
booktitle = {Proceedings of the 9th International Conference of the Learning Sciences - Volume 2},
pages = {93–100},
numpages = {8},
location = {Chicago, Illinois},
series = {ICLS '10}
}

@article{10.1145/1785414.1785451,
author = {Talia, Domenico and Trunfio, Paolo},
title = {How Distributed Data Mining Tasks Can Thrive as Knowledge Services},
year = {2010},
issue_date = {July 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/1785414.1785451},
doi = {10.1145/1785414.1785451},
abstract = {IntroductionComputer science applications are becoming more and more network centric, ubiquitous, knowledge intensive, and computing demanding. This trend will result soon in an ecosystem of pervasive applications and services that professionals and end-users can exploit everywhere. Recently, collections of IT services and applications, such as Web services and Cloud computing services, became available opening the way for accessing computing services as public utilities, like water, gas and electricity.Key technologies for implementing that perspective are Cloud computing and Web services, semantic Web and ontologies, pervasive computing, P2P systems, Grid computing, ambient intelligence architectures, data mining and knowledge discovery tools, Web 2.0 facilities, mashup tools, and decentralized programming models. In fact, it is mandatory to develop solutions that integrate some or many of those technologies to provide future knowledge-intensive software utilities. The Grid paradigm can represent a key component of the future Internet, a cyber infrastructure for efficiently supporting that scenario.Grid and Cloud computing are evolved models of distributed computing and parallel processing technologies. The Grid is a distributed computing infrastructure that enables coordinated resource sharing within dynamic organizations consisting of individuals, institutions, and resources. In the area of Grid computing a proposed approach in accordance with the trend outlined above is the Service-Oriented Knowledge Utilities (SOKU) model that envisions the integrated use of a set of technologies that are considered as a solution to information, knowledge and communication needs of many knowledge-based industrial and business applications. The SOKU approach stems from the necessity of providing knowledge and processing capabilities to everybody, thus supporting the advent of a competitive knowledge-based economy. Although the SOKU model is not yet implemented, Grids are increasingly equipped with data management tools, semantic technologies, complex work-flows, data mining features and other Web intelligence approaches. Similar efforts are currently devoted to develop knowledge and intelligent Clouds. These technologies can facilitate the process of having Grids and Clouds as strategic components for supporting pervasive knowledge intensive applications and utilities.Grids were originally designed for dealing with problems involving large amounts of data and/or compute-intensive applications. Today, however, Grids enlarged their horizon as they are going to run business applications supporting consumers and end-users. To face those new challenges, Grid environments must support adaptive knowledge management and data analysis applications by offering resources, services, and decentralized data access mechanisms. In particular, according to the service-oriented architecture (SOA) model, data mining tasks and knowledge discovery processes can be delivered as services in Grid-based infrastructures.Through a service-based approach we can define integrated services for supporting distributed business intelligence tasks in Grids. Those services can address all the aspects that must be considered in data mining and in knowledge discovery processes such as data selection and transport, data analysis, knowledge models representation and visualization. We worked in this direction for providing Grid-based architectures and services for distributed knowledge discovery such as the Knowledge Grid the Weka4WS toolkit, and mobile Grid services for data mining.Here we describe a strategy and a model based on the use of services for the design of distributed knowledge discovery services and discuss how Grid frameworks, such those mentioned above, can be developed as a collection of services and how they can be used to develop distributed data analysis tasks and knowledge discovery processes using the SOA model.},
journal = {Commun. ACM},
month = jul,
pages = {132–137},
numpages = {6}
}

@article{10.1145/1806491.1806507,
author = {Churchill, Elizabeth F.},
title = {Today's <i>Fl\^{a}Neur</i>: From HCI to Place-Based Interaction and Human-Place Interaction},
year = {2010},
issue_date = {July + August 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1072-5520},
url = {https://doi.org/10.1145/1806491.1806507},
doi = {10.1145/1806491.1806507},
journal = {Interactions},
month = jul,
pages = {62–66},
numpages = {5}
}

@article{10.1145/1767751.1767753,
author = {Conboy, Kieran and Fitzgerald, Brian},
title = {Method and Developer Characteristics for Effective Agile Method Tailoring: A Study of XP Expert Opinion},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/1767751.1767753},
doi = {10.1145/1767751.1767753},
abstract = {It has long been acknowledged that software methods should be tailored if they are to achieve optimum effect. However comparatively little research has been carried out to date on this topic in general, and more notably, on agile methods in particular. This dearth of evidence in the case of agile methods is especially significant in that it is reasonable to expect that such methods would particularly lend themselves to tailoring. In this research, we present a framework based on interviews with 20 senior software development researchers and a review of the extant literature. The framework is comprised of two sets of factors—characteristics of the method, and developer practices—that can improve method tailoring effectiveness. Drawing on the framework, we then interviewed 16 expert XP practitioners to examine the current state and effectiveness of XP tailoring efforts, and to shed light on issues the framework identified as being important. The article concludes with a set of recommendations for research and practice that would advance our understanding of the method tailoring area.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jul,
articleno = {2},
numpages = {30},
keywords = {software development, contingency, tailoring, engineering, Extreme programming, XP, agile method, expert opinion}
}

@inproceedings{10.5555/1873738.1873755,
author = {Siddharthan, Advaith},
title = {Complex Lexico-Syntactic Reformulation of Sentences Using Typed Dependency Representations},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {We present a framework for reformulating sentences by applying transfer rules on a typed dependency representation. We specify a list of operations that the framework needs to support and argue that typed dependency structures are currently the most suitable formalism for complex lexico-syntactic paraphrasing. We demonstrate our approach by reformulating sentences expressing the discourse relation of causation using four lexico-syntactic discourse markers -- "cause" as a verb and as a noun, "because" as a conjunction and "because of" as a preposition.},
booktitle = {Proceedings of the 6th International Natural Language Generation Conference},
pages = {125–133},
numpages = {9},
location = {Trim, Co. Meath, Ireland},
series = {INLG '10}
}

@inproceedings{10.5555/1858681.1858799,
author = {Tomanek, Katrin and Hahn, Udo and Lohmann, Steffen and Ziegler, J\"{u}rgen},
title = {A Cognitive Cost Model of Annotations Based on Eye-Tracking Data},
year = {2010},
abstract = {We report on an experiment to track complex decision points in linguistic metadata annotation where the decision behavior of annotators is observed with an eye-tracking device. As experimental conditions we investigate different forms of textual context and linguistic complexity classes relative to syntax and semantics. Our data renders evidence that annotation performance depends on the semantic and syntactic complexity of the decision points and, more interestingly, indicates that full-scale context is mostly negligible - with the exception of semantic high-complexity cases. We then induce from this observational data a cognitively grounded cost model of linguistic meta-data annotations and compare it with existing non-cognitive models. Our data reveals that the cognitively founded model explains annotation costs (expressed in annotation time) more adequately than non-cognitive ones.},
booktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
pages = {1158–1167},
numpages = {10},
location = {Uppsala, Sweden},
series = {ACL '10}
}

@inproceedings{10.5555/1858842.1858889,
author = {Klebanov, Beata Beigman and Beigman, Eyal and Diermeier, Daniel},
title = {Vocabulary Choice as an Indicator of Perspective},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {We establish the following characteristics of the task of perspective classification: (a) using term frequencies in a document does not improve classification achieved with absence/presence features; (b) for datasets allowing the relevant comparisons, a small number of top features is found to be as effective as the full feature set and indispensable for the best achieved performance, testifying to the existence of perspective-specific keywords. We relate our findings to research on word frequency distributions and to discourse analytic studies of perspective.},
booktitle = {Proceedings of the ACL 2010 Conference Short Papers},
pages = {253–257},
numpages = {5},
location = {Uppsala, Sweden},
series = {ACLShort '10}
}

@inproceedings{10.5555/1858681.1858753,
author = {Klebanov, Beata Beigman and Beigman, Eyal},
title = {A Game-Theoretic Model of Metaphorical Bargaining},
year = {2010},
abstract = {We present a game-theoretic model of bargaining over a metaphor in the context of political communication, find its equilibrium, and use it to rationalize observed linguistic behavior. We argue that game theory is well suited for modeling discourse as a dynamic resulting from a number of conflicting pressures, and suggest applications of interest to computational linguists.},
booktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
pages = {698–709},
numpages = {12},
location = {Uppsala, Sweden},
series = {ACL '10}
}

@inproceedings{10.5555/1858681.1858759,
author = {Tomasoni, Mattia and Huang, Minlie},
title = {Metadata-Aware Measures for Answer Summarization in Community Question Answering},
year = {2010},
abstract = {This paper presents a framework for automatically processing information coming from community Question Answering (cQA) portals with the purpose of generating a trustful, complete, relevant and succinct summary in response to a question. We exploit the metadata intrinsically present in User Generated Content (UGC) to bias automatic multi-document summarization techniques toward high quality information. We adopt a representation of concepts alternative to n-grams and propose two concept-scoring functions based on semantic overlap. Experimental results on data drawn from Yahoo! Answers demonstrate the effectiveness of our method in terms of ROUGE scores. We show that the information contained in the best answers voted by users of cQA portals can be successfully complemented by our method.},
booktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
pages = {760–769},
numpages = {10},
location = {Uppsala, Sweden},
series = {ACL '10}
}

@inproceedings{10.5555/1858681.1858733,
author = {Lavergne, Thomas and Capp\'{e}, Olivier and Yvon, Fran\c{c}ois},
title = {Practical Very Large Scale CRFs},
year = {2010},
abstract = {Conditional Random Fields (CRFs) are a widely-used approach for supervised sequence labelling, notably due to their ability to handle large description spaces and to integrate structural dependency between labels. Even for the simple linear-chain model, taking structure into account implies a number of parameters and a computational effort that grows quadratically with the cardinality of the label set. In this paper, we address the issue of training very large CRFs, containing up to hundreds output labels and several billion features. Efficiency stems here from the sparsity induced by the use of a l penalty term. Based on our own implementation, we compare three recent proposals for implementing this regularization strategy. Our experiments demonstrate that very large CRFs can be trained efficiently and that very large models are able to improve the accuracy, while delivering compact parameter sets.},
booktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
pages = {504–513},
numpages = {10},
location = {Uppsala, Sweden},
series = {ACL '10}
}

@inproceedings{10.5555/1999416.1999485,
author = {McCourt, Richard and Ng, Kevin},
title = {Enhanced Network Modeling in ABSNEC},
year = {2010},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {In this paper we demonstrate new features added to an agent-based combat simulator developed in-house. ABSNEC is an agent-based system for networked capabilities/operations. It is being developed to study the effects of quality and timeliness of C4ISR on battle operations. Recently, the networking backbone of the model was added, allowing users to quickly configure any network topology and create flexible extensions in Delphi that will allow the user to dynamically alter link capacities and packet routing. Moreover, software extensions can be used to control tracked quantities within each agent. We demonstrate these capabilities with two scenarios.},
booktitle = {Proceedings of the 2010 Summer Computer Simulation Conference},
pages = {537–544},
numpages = {8},
keywords = {logistics modeling, agent-based model, military operations research, network-enabled capabilities/operations},
location = {Ottawa, Ontario, Canada},
series = {SCSC '10}
}

@inproceedings{10.5555/1999416.1999438,
author = {Durand, Audrey and Gagn\'{e}, Christian and Gardner, Marc-Andr\'{e} and Rousseau, Fran\c{c}ois and Gigu\`{e}re, Yves and Reinharz, Daniel},
title = {SCHNAPS: A Generic Population-Based Simulator for Public Health Purposes},
year = {2010},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {In this paper, we present SCHNAPS, a generic simulator designed for health care modelling and simulations, parametrizable by configuration files and usable by non-programmers such as public health specialists. SCHNAPS is a population-based simulator, using hybrid-state agents to simulate time-driven models. Its software architecture integrates some fundamental object oriented concepts to facilitate further developments and extensions. The proposed approach aims at narrowing the gap between the simulation model and the conceptual modelling made by public health specialists. Current work on osteoporosis, under evaluation by health care specialists, is also presented as a real use case.},
booktitle = {Proceedings of the 2010 Summer Computer Simulation Conference},
pages = {182–189},
numpages = {8},
location = {Ottawa, Ontario, Canada},
series = {SCSC '10}
}

@inproceedings{10.5555/1858681.1858811,
author = {Spitkovsky, Valentin I. and Jurafsky, Daniel and Alshawi, Hiyan},
title = {Profiting from Mark-up: Hyper-Text Annotations for Guided Parsing},
year = {2010},
abstract = {We show how web mark-up can be used to improve unsupervised dependency parsing. Starting from raw bracketings of four common HTML tags (anchors, bold, italics and underlines), we refine approximate partial phrase boundaries to yield accurate parsing constraints. Conversion procedures fall out of our linguistic analysis of a newly available million-word hyper-text corpus. We demonstrate that derived constraints aid grammar induction by training Klein and Manning's Dependency Model with Valence (DMV) on this data set: parsing accuracy on Section 23 (all sentences) of the Wall Street Journal corpus jumps to 50.4%, beating previous state-of-the-art by more than 5%. Web-scale experiments show that the DMV, perhaps because it is unlexicalized, does not benefit from orders of magnitude more annotated but noisier data. Our model, trained on a single blog, generalizes to 53.3% accuracy out-of-domain, against the Brown corpus --- nearly 10% higher than the previous published best. The fact that web mark-up strongly correlates with syntactic structure may have broad applicability in NLP.},
booktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
pages = {1278–1287},
numpages = {10},
location = {Uppsala, Sweden},
series = {ACL '10}
}

@inproceedings{10.1145/1831708.1831737,
author = {Kettunen, Vesa and Kasurinen, Jussi and Taipale, Ossi and Smolander, Kari},
title = {A Study on Agility and Testing Processes in Software Organizations},
year = {2010},
isbn = {9781605588230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1831708.1831737},
doi = {10.1145/1831708.1831737},
abstract = {In this paper, we studied the differences in testing activities between software organizations which apply agile development methods and organizations which take the traditional plan-driven approach. Our focus was on the concepts which allow the software organization to successfully apply agile development methods or plan-driven methods. We also observed the test process enhancements and hindrances, which originate in the selected development method. We interviewed 12 organizations, which were selected to represent different polar types of software production. The interviews were tape-recorded and transcribed for further analysis. The study yielded hypotheses which were derived by applying the qualitative grounded theory method. The results indicated that in practice, agile methods can improve the position of testing through the early involvement of testing activities in development, and also have a positive influence on end-product satisfaction. By applying these results, organizations can improve their processes and avoid pitfalls when transitioning to agile methods.},
booktitle = {Proceedings of the 19th International Symposium on Software Testing and Analysis},
pages = {231–240},
numpages = {10},
keywords = {empirical study, test process, agile development, case study},
location = {Trento, Italy},
series = {ISSTA '10}
}

@inproceedings{10.5555/1858913.1858915,
author = {Lison, Pierre},
title = {Towards Relational POMDPs for Adaptive Dialogue Management},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Open-ended spoken interactions are typically characterised by both structural complexity and high levels of uncertainty, making dialogue management in such settings a particularly challenging problem. Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously. This paper describes ongoing work on a new approach to dialogue management which attempts to fill this gap. We represent the interaction as a Partially Observable Markov Decision Process (POMDP) over a rich state space incorporating both dialogue, user, and environment models. The tractability of the resulting POMDP can be preserved using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures. These constraints are encoded in a small set of general rules expressed as a Markov Logic network. The first-order expressivity of Markov Logic enables us to leverage the rich relational structure of the problem and efficiently abstract over large regions of the state and action spaces.},
booktitle = {Proceedings of the ACL 2010 Student Research Workshop},
pages = {7–12},
numpages = {6},
location = {Uppsala, Sweden},
series = {ACLstudent '10}
}

@article{10.1145/1777406.1777414,
author = {Zhang, Lei and Liu, Ligang and Gotsman, Craig and Gortler, Steven J.},
title = {An As-Rigid-as-Possible Approach to Sensor Network Localization},
year = {2010},
issue_date = {July 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
issn = {1550-4859},
url = {https://doi.org/10.1145/1777406.1777414},
doi = {10.1145/1777406.1777414},
abstract = {We present a novel approach to localization of sensors in a network given a subset of noisy inter-sensor distances. The algorithm is based on “stitching” together local structures by solving an optimization problem requiring the structures to fit together in an “As-Rigid-As-Possible” manner, hence the name ARAP. The local structures consist of reference “patches” and reference triangles, both obtained from inter-sensor distances. We elaborate on the relationship between the ARAP algorithm and other state-of-the-art algorithms, and provide experimental results demonstrating that ARAP is significantly less sensitive to sparse connectivity and measurement noise. We also show how ARAP may be distributed.},
journal = {ACM Trans. Sen. Netw.},
month = jul,
articleno = {35},
numpages = {21},
keywords = {localization, as-rigid-as-possible, Sensor networks, embedding}
}

@inproceedings{10.1145/1866210.1866215,
author = {K\v{r}ena, Bohuslav and Letko, Zden\v{e}k and Vojnar, Tom\'{a}\v{s} and Ur, Shmuel},
title = {A Platform for Search-Based Testing of Concurrent Software},
year = {2010},
isbn = {9781450301367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1866210.1866215},
doi = {10.1145/1866210.1866215},
abstract = {The paper describes a generic, open-source infrastructure called SearchBestie (or S'Bestie for short) that we propose as a platform for experimenting with search-based techniques and for applying them in the area of software testing. Further, motivated by a lack of work on search-based testing targeted at identifying concurrency-related problems, we instantiate S'Bestie for search-based testing of concurrent programs using the IBM's concurrency testing infrastructure called ConTest. We demonstrate on series of experiments the capabilities of S'Bestie and (despite we have just made our first experiments with S'Bestie) also the fact that using search-based testing in the context of testing concurrent programs can be useful.},
booktitle = {Proceedings of the 8th Workshop on Parallel and Distributed Systems: Testing, Analysis, and Debugging},
pages = {48–58},
numpages = {11},
keywords = {searching, testing},
location = {Trento, Italy},
series = {PADTAD '10}
}

@inproceedings{10.1145/1837110.1837130,
author = {Czeskis, Alexei and Dermendjieva, Ivayla and Yapit, Hussein and Borning, Alan and Friedman, Batya and Gill, Brian and Kohno, Tadayoshi},
title = {Parenting from the Pocket: Value Tensions and Technical Directions for Secure and Private Parent-Teen Mobile Safety},
year = {2010},
isbn = {9781450302647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1837110.1837130},
doi = {10.1145/1837110.1837130},
abstract = {An increasing number of high-tech devices, such as driver monitoring systems and Internet usage monitoring tools, are advertised as useful or even necessary for good parenting of teens. Simultaneously, there is a growing market for mobile "personal safety" devices. As these trends merge, there will be significant implications for parent-teen relationships, affecting domains such as privacy, trust, and maturation. Not only the teen and his or her parents are affected; other important stakeholders include the teen's friends who may be unwittingly monitored. This problem space, with less clear-cut assets, risks, and affected parties, thus lies well outside of more typical computer security applications.To help understand this problem domain and what, if anything, should be built, we turn to the theory and methods of Value Sensitive Design, a systematic approach to designing for human values in technology. We first develop value scenarios that highlight potential issues, benefits, harms, and challenges. We then conducted semi-structured interviews with 18 participants (9 teens and their parents). Results show significant differences with respect to information about: 1) internal state (e.g., mood) versus external environment (e.g., location) state; 2) situation (e.g., emergency vs. non-emergency); and 3) awareness (e.g., notification vs. non-notification). The value scenario and interview results positioned us to identify key technical challenges -- such as strongly protecting the privacy of a teen's contextual information during ordinary situations but immediately exposing that information to others as appropriate in an emergency -- and corresponding architectural levers for these technologies.In addition to laying a foundation for future work in this area, this research serves as a prototypical example of using Value Sensitive Design to explicate the underlying human values in complex security domains.},
booktitle = {Proceedings of the Sixth Symposium on Usable Privacy and Security},
articleno = {15},
numpages = {15},
keywords = {safety, maturation, teenagers, privacy, value sensitive design, security, value dams and flows, mobile phones, value tensions, direct and indirect stakeholders, parenting technologies},
location = {Redmond, Washington, USA},
series = {SOUPS '10}
}

@inproceedings{10.1145/1837110.1837118,
author = {Ion, Iulia and Langheinrich, Marc and Kumaraguru, Ponnurangam and \v{C}apkun, Srdjan},
title = {Influence of User Perception, Security Needs, and Social Factors on Device Pairing Method Choices},
year = {2010},
isbn = {9781450302647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1837110.1837118},
doi = {10.1145/1837110.1837118},
abstract = {Recent years have seen a proliferation of secure device pairing methods that try to improve both the usability and security of today's de-facto standard -- PIN-based authentication. Evaluating such improvements is difficult. Most comparative laboratory studies have so far mainly focused on completeness, trying to find the single best method among the dozens of proposed approaches -- one that is both rated the most usable by test subjects, and which provides the most robust security guarantees. This search for the "best" pairing method, however, fails to take into account the variety of situations in which such pairing protocols may be used in real life. The comparative study reported here, therefore, explicitly situates pairing tasks in a number of more realistic situations. Our results indicate that people do not always use the easiest or most popular method -- they instead prefer different methods in different situations, based on the sensitivity of data involved, their time constraints, and the social conventions appropriate for a particular place and setting. Our study also provides qualitative data on factors influencing the perceived security of a particular method, the users' mental models surrounding security of a method, and their security needs.},
booktitle = {Proceedings of the Sixth Symposium on Usable Privacy and Security},
articleno = {6},
numpages = {13},
keywords = {device pairing, authentication, security, social factors, user studies, usability},
location = {Redmond, Washington, USA},
series = {SOUPS '10}
}

@inproceedings{10.1145/1837110.1837125,
author = {Wash, Rick},
title = {Folk Models of Home Computer Security},
year = {2010},
isbn = {9781450302647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1837110.1837125},
doi = {10.1145/1837110.1837125},
abstract = {Home computer systems are insecure because they are administered by untrained users. The rise of botnets has amplified this problem; attackers compromise these computers, aggregate them, and use the resulting network to attack third parties. Despite a large security industry that provides software and advice, home computer users remain vulnerable. I identify eight 'folk models' of security threats that are used by home computer users to decide what security software to use, and which expert security advice to follow: four conceptualizations of 'viruses' and other malware, and four conceptualizations of 'hackers' that break into computers. I illustrate how these models are used to justify ignoring expert security advice. Finally, I describe one reason why botnets are so difficult to eliminate: they cleverly take advantage of gaps in these models so that many home computer users do not take steps to protect against them.},
booktitle = {Proceedings of the Sixth Symposium on Usable Privacy and Security},
articleno = {11},
numpages = {16},
keywords = {home security, folk models, mental models},
location = {Redmond, Washington, USA},
series = {SOUPS '10}
}

@inproceedings{10.5555/1870065.1870073,
author = {Nilsson, Mattias and Nivre, Joakim},
title = {Towards a Data-Driven Model of Eye Movement Control in Reading},
year = {2010},
isbn = {9781932432749},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {This paper presents a data-driven model of eye movement control in reading that builds on earlier work using machine learning methods to model saccade behavior. We extend previous work by modeling the time course of eye movements, in addition to where the eyes move. In this model, the initiation of eye movements is delayed as a function of on-line processing difficulty, and the decision of where to move the eyes is guided by past reading experience, approximated using machine learning methods. In benchmarking the model against held-out previously unseen data, we show that it can predict gaze durations and skipping probabilities with good accuracy.},
booktitle = {Proceedings of the 2010 Workshop on Cognitive Modeling and Computational Linguistics},
pages = {63–71},
numpages = {9},
location = {Uppsala, Sweden},
series = {CMCL '10}
}

@inproceedings{10.5555/1870478.1870479,
author = {Mailhot, Fr\'{e}d\'{e}ric},
title = {Instance-Based Acquisition of Vowel Harmony},
year = {2010},
isbn = {9781932432763},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {I present LIbPhon, a nonparametric regression-based model of phonologi cal acquisition that induces a generalised and productive pattern of vowel harmony---including opaque and transparent neutrality---on the basis of simplified formant data. The model quickly learns to generate harmonically correct morphologically complex forms to which it has not been exposed.},
booktitle = {Proceedings of the 11th Meeting of the ACL Special Interest Group on Computational Morphology and Phonology},
pages = {1–8},
numpages = {8},
location = {Uppsala, Sweden},
series = {SIGMORPHON '10}
}

@inproceedings{10.5555/1869961.1869969,
author = {Jha, Mukund and Elhadad, No\'{e}mie},
title = {Cancer Stage Prediction Based on Patient Online Discourse},
year = {2010},
isbn = {9781932432732},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Forums and mailing lists dedicated to particular diseases are increasingly popular online. Automatically inferring the health status of a patient can be useful for both forum users and health researchers who study patients' online behaviors. In this paper, we focus on breast cancer forums and present a method to predict the stage of patients' cancers from their online discourse. We show that what the patients talk about (content-based features) and whom they interact with (social network-based features) provide complementary cues to predicting cancer stage and can be leveraged for better prediction. Our methods are extendable and can be applied to other tasks of acquiring contextual information about online health forum participants.},
booktitle = {Proceedings of the 2010 Workshop on Biomedical Natural Language Processing},
pages = {64–71},
numpages = {8},
location = {Uppsala, Sweden},
series = {BioNLP '10}
}

@inproceedings{10.1145/1835449.1835512,
author = {Arapakis, Ioannis and Athanasakos, Konstantinos and Jose, Joemon M.},
title = {A Comparison of General vs Personalised Affective Models for the Prediction of Topical Relevance},
year = {2010},
isbn = {9781450301534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1835449.1835512},
doi = {10.1145/1835449.1835512},
abstract = {Information retrieval systems face a number of challenges, originating mainly from the semantic gap problem. Implicit feedback techniques have been employed in the past to address many of these issues. Although this was a step towards the right direction, a need to personalise and tailor the search experience to the user-specific needs has become evident. In this study we examine ways of personalising affective models trained on facial expression data. Using personalised data we adapt these models to individual users and compare their performance to a general model. The main goal is to determine whether the behavioural differences of users have an impact on the models' ability to determine topical relevance and if, by personalising them, we can improve their accuracy. For modelling relevance we extract a set of features from the facial expression data and classify them using Support Vector Machines. Our initial evaluation indicates that accounting for individual differences and applying personalisation introduces, in most cases, a noticeable improvement in the models' performance.},
booktitle = {Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {371–378},
numpages = {8},
keywords = {personalisation, support vector machines, affective feedback, facial expression analysis, classification},
location = {Geneva, Switzerland},
series = {SIGIR '10}
}

@inproceedings{10.1145/1835449.1835537,
author = {Weber, Ingmar and Castillo, Carlos},
title = {The Demographics of Web Search},
year = {2010},
isbn = {9781450301534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1835449.1835537},
doi = {10.1145/1835449.1835537},
abstract = {How does the web search behavior of "rich" and "poor" people differ? Do men and women tend to click on difffferent results for the same query? What are some queries almost exclusively issued by African Americans? These are some of the questions we address in this study.Our research combines three data sources: the query log of a major US-based web search engine, profile information provided by 28 million of its users (birth year, gender and ZIP code), and US-census information including detailed demographic information aggregated at the level of ZIP code. Through this combination we can annotate each query with, e.g. the average per-capita income in the ZIP code it originated from. Though conceptually simple, this combination immediately creates a powerful user modeling tool.The main contributions of this work are the following. First, we provide a demographic description of a large sample of search engine users in the US and show that it agrees well with the distribution of the US population. Second, we describe how different segments of the population differ in their search behavior, e.g. with respect to the queries they formulate or the URLs they click. Third, we explore applications of our methodology to improve web search relevance and to provide better query suggestions.These results enable a wide range of applications including improving web search and advertising where, for instance, targeted advertisements for "family vacations" could be adapted to the (expected) income.},
booktitle = {Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {523–530},
numpages = {8},
keywords = {web search, demographic factors},
location = {Geneva, Switzerland},
series = {SIGIR '10}
}

@article{10.1145/1806916.1806919,
author = {Poblete, Barbara and Spiliopoulou, Myra and Baeza-Yates, Ricardo},
title = {Privacy-Preserving Query Log Mining for Business Confidentiality Protection},
year = {2010},
issue_date = {July 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
issn = {1559-1131},
url = {https://doi.org/10.1145/1806916.1806919},
doi = {10.1145/1806916.1806919},
abstract = {We introduce the concern of confidentiality protection of business information for the publication of search engine query logs and derived data. We study business confidentiality, as the protection of nonpublic data from institutions, such as companies and people in the public eye. In particular, we relate this concern to the involuntary exposure of confidential Web site information, and we transfer this problem into the field of privacy-preserving data mining. We characterize the possible adversaries interested in disclosing Web site confidential data and the attack strategies that they could use. These attacks are based on different vulnerabilities found in query log for which we present several anonymization heuristics to prevent them. We perform an experimental evaluation to estimate the remaining utility of the log after the application of our anonymization techniques. Our experimental results show that a query log can be anonymized against these specific attacks while retaining a significant volume of useful data.},
journal = {ACM Trans. Web},
month = jul,
articleno = {10},
numpages = {26},
keywords = {queries, Privacy preservation, query log publication, Web sites}
}

@inproceedings{10.1145/1836049.1836063,
author = {Bacim, Felipe and Polys, Nicholas and Chen, Jian and Setareh, Mehdi and Li, Ji and Ma, Lee},
title = {Cognitive Scaffolding in Web3D Learning Systems: A Case Study for Form and Structure},
year = {2010},
isbn = {9781450302098},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1836049.1836063},
doi = {10.1145/1836049.1836063},
abstract = {In this paper, we describe a case study in usability engineering for Web3D learning systems and introduce a new step to the typical methods of the usability design. Pedagogical applications present a challenge to the usual usability engineering process in that the end-users of the system (students) cannot describe the requirements of the system. For this situation, we engage the latest evidence and principles of cognition to help map requirements to information design for an interactive learning system.Our system seeks to improve the structural understanding of architects and to teach relationships between form and structure in long-span systems. We provide both explanatory multimedia resources and interactive resources including a Web-based modeling and simulation tool that aids architecture students with better understanding of the relationship between structure and form in design. We describe our design process and the system and examine the qualitative impact of the cognitive ergonomic process. This extra step in the usability design process of mapping expert knowledge to human perception and cognition can increase awareness of the requirements of a learning system and improve the effectiveness of the subsequent design.},
booktitle = {Proceedings of the 15th International Conference on Web 3D Technology},
pages = {93–100},
numpages = {8},
keywords = {Web3D learning tools, usability engineering},
location = {Los Angeles, California},
series = {Web3D '10}
}

@inproceedings{10.1145/1835804.1835823,
author = {Zheng, Li and Shen, Chao and Tang, Liang and Li, Tao and Luis, Steve and Chen, Shu-Ching and Hristidis, Vagelis},
title = {Using Data Mining Techniques to Address Critical Information Exchange Needs in Disaster Affected Public-Private Networks},
year = {2010},
isbn = {9781450300551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1835804.1835823},
doi = {10.1145/1835804.1835823},
abstract = {Crisis Management and Disaster Recovery have gained immense importance in the wake of recent man and nature inflicted calamities. A critical problem in a crisis situation is how to efficiently discover, collect, organize, search and disseminate real-time disaster information. In this paper, we address several key problems which inhibit better information sharing and collaboration between both private and public sector participants for disaster management and recovery. We design and implement a web based prototype implementation of a Business Continuity Information Network (BCIN) system utilizing the latest advances in data mining technologies to create a user-friendly, Internet-based, information-rich service and acting as a vital part of a company's business continuity process. Specifically, information extraction is used to integrate the input data from different sources; the content recommendation engine and the report summarization module provide users personalized and brief views of the disaster information; the community generation module develops spatial clustering techniques to help users build dynamic community in disasters. Currently, BCIN has been exercised at Miami-Dade County Emergency Management.},
booktitle = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {125–134},
numpages = {10},
keywords = {multi-document summarization, spatial clustering, data mining, disaster management, dynamic dashboard, critical information, information extraction},
location = {Washington, DC, USA},
series = {KDD '10}
}

@inproceedings{10.1145/1835804.1835826,
author = {Bennett, Collin and Grossman, Robert L. and Locke, David and Seidman, Jonathan and Vejcik, Steve},
title = {Malstone: Towards a Benchmark for Analytics on Large Data Clouds},
year = {2010},
isbn = {9781450300551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1835804.1835826},
doi = {10.1145/1835804.1835826},
abstract = {Developing data mining algorithms that are suitable for cloud computing platforms is currently an active area of research, as is developing cloud computing platforms appropriate for data mining. Currently, the most common benchmark for cloud computing is the Terasort (and related) benchmarks. Although the Terasort Benchmark is quite useful, it was not designed for data mining per se. In this paper, we introduce a benchmark called MalStone that is specifically designed to measure the performance of cloud computing middleware that supports the type of data intensive computing common when building data mining models. We also introduce MalGen, which is a utility for generating data on clouds that can be used with MalStone.},
booktitle = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {145–152},
numpages = {8},
keywords = {data mining benchmarks, benchmarks, cloud computing benchmarks},
location = {Washington, DC, USA},
series = {KDD '10}
}

@inproceedings{10.1145/1835804.1835863,
author = {Sundaravaradan, Naren and Hossain, K.S.M. Tozammel and Sreedharan, Vandana and Slotta, Douglas J. and Vergara, John Paul C. and Heath, Lenwood S. and Ramakrishnan, Naren},
title = {Extracting Temporal Signatures for Comprehending Systems Biology Models},
year = {2010},
isbn = {9781450300551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1835804.1835863},
doi = {10.1145/1835804.1835863},
abstract = {Systems biology has made massive strides in recent years, with capabilities to model complex systems including cell division, stress response, energy metabolism, and signaling pathways. Concomitant with their improved modeling capabilities, however, such biochemical network models have also become notoriously complex for humans to comprehend. We propose network comprehension as a key problem for the KDD community, where the goal is to create explainable representations of complex biological networks. We formulate this problem as one of extracting temporal signatures from multi-variate time series data, where the signatures are composed of ordinal comparisons between time series components. We show how such signatures can be inferred by formulating the data mining problem as one of feature selection in rank-order space. We propose five new feature selection strategies for rank-order space and assess their selective superiorities. Experimental results on budding yeast cell cycle models demonstrate compelling results comparable to human interpretations of the cell cycle.},
booktitle = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {453–462},
numpages = {10},
keywords = {feature selection, rank-order spaces, biological networks, systems biology, temporal signatures},
location = {Washington, DC, USA},
series = {KDD '10}
}

@inproceedings{10.1145/1835804.1835880,
author = {Hossain, M. Shahriar and Tadepalli, Satish and Watson, Layne T. and Davidson, Ian and Helm, Richard F. and Ramakrishnan, Naren},
title = {Unifying Dependent Clustering and Disparate Clustering for Non-Homogeneous Data},
year = {2010},
isbn = {9781450300551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1835804.1835880},
doi = {10.1145/1835804.1835880},
abstract = {Modern data mining settings involve a combination of attribute-valued descriptors over entities as well as specified relationships between these entities. We present an approach to cluster such non-homogeneous datasets by using the relationships to impose either dependent clustering or disparate clustering constraints. Unlike prior work that views constraints as boolean criteria, we present a formulation that allows constraints to be satisfied or violated in a smooth manner. This enables us to achieve dependent clustering and disparate clustering using the same optimization framework by merely maximizing versus minimizing the objective function. We present results on both synthetic data as well as several real-world datasets.},
booktitle = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {593–602},
numpages = {10},
keywords = {clustering, contingency tables, relational clustering, multi-criteria optimization.},
location = {Washington, DC, USA},
series = {KDD '10}
}

@inproceedings{10.1145/1835804.1835922,
author = {Lin, Cindy Xide and Zhao, Bo and Mei, Qiaozhu and Han, Jiawei},
title = {PET: A Statistical Model for Popular Events Tracking in Social Communities},
year = {2010},
isbn = {9781450300551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1835804.1835922},
doi = {10.1145/1835804.1835922},
abstract = {User generated information in online communities has been characterized with the mixture of a text stream and a network structure both changing over time. A good example is a web-blogging community with the daily blog posts and a social network of bloggers.An important task of analyzing an online community is to observe and track the popular events, or topics that evolve over time in the community. Existing approaches usually focus on either the burstiness of topics or the evolution of networks, but ignoring the interplay between textual topics and network structures.In this paper, we formally define the problem of popular event tracking in online communities (PET), focusing on the interplay between texts and networks. We propose a novel statistical method that models the the popularity of events over time, taking into consideration the burstiness of user interest, information diffusion on the network structure, and the evolution of textual topics. Specifically, a Gibbs Random Field is defined to model the influence of historic status and the dependency relationships in the graph; thereafter a topic model generates the words in text content of the event, regularized by the Gibbs Random Field. We prove that two classic models in information diffusion and text burstiness are special cases of our model under certain situations. Empirical experiments with two different communities and datasets (i.e., Twitter and DBLP) show that our approach is effective and outperforms existing approaches.},
booktitle = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {929–938},
numpages = {10},
keywords = {topic modeling, social communities, popular events tracking, PET},
location = {Washington, DC, USA},
series = {KDD '10}
}

@inproceedings{10.1145/1814245.1814249,
author = {Cataldi, Mario and Di Caro, Luigi and Schifanella, Claudio},
title = {Emerging Topic Detection on Twitter Based on Temporal and Social Terms Evaluation},
year = {2010},
isbn = {9781450302203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1814245.1814249},
doi = {10.1145/1814245.1814249},
abstract = {Twitter is a user-generated content system that allows its users to share short text messages, called tweets, for a variety of purposes, including daily conversations, URLs sharing and information news. Considering its world-wide distributed network of users of any age and social condition, it represents a low level news flashes portal that, in its impressive short response time, has the principal advantage.In this paper we recognize this primary role of Twitter and we propose a novel topic detection technique that permits to retrieve in real-time the most emergent topics expressed by the community. First, we extract the contents (set of terms) of the tweets and model the term life cycle according to a novel aging theory intended to mine the emerging ones. A term can be defined as emerging if it frequently occurs in the specified time interval and it was relatively rare in the past. Moreover, considering that the importance of a content also depends on its source, we analyze the social relationships in the network with the well-known Page Rank algorithm in order to determine the authority of the users. Finally, we leverage a navigable topic graph which connects the emerging terms with other semantically related keywords, allowing the detection of the emerging topics, under user-specified time constraints. We provide different case studies which show the validity of the proposed approach.},
booktitle = {Proceedings of the Tenth International Workshop on Multimedia Data Mining},
articleno = {4},
numpages = {10},
keywords = {aging theory, topic detection, text analysis},
location = {Washington, D.C.},
series = {MDMKDD '10}
}

@inproceedings{10.1145/1964858.1964867,
author = {Akcora, Cuneyt Gurcan and Bayir, Murat Ali and Demirbas, Murat and Ferhatosmanoglu, Hakan},
title = {Identifying Breakpoints in Public Opinion},
year = {2010},
isbn = {9781450302173},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1964858.1964867},
doi = {10.1145/1964858.1964867},
abstract = {While polls are traditionally used for observing public opinion, they provide a point snapshot, not a continuum. We consider the problem of identifying breakpoints in public opinion, and propose using micro-blogging sites to capture trends in public opinion. We develop methods to detect changes in public opinion, and find events that cause these changes.Our experiments show that the proposed methods are able to determine changes in public opinion and extract the major news about the events effectively. We also deploy an application where users can view the important news stories for a continuing event and find the related articles on web.},
booktitle = {Proceedings of the First Workshop on Social Media Analytics},
pages = {62–66},
numpages = {5},
keywords = {opinion mining, emotion corpus, microblogging, sentiment analysis},
location = {Washington D.C., District of Columbia},
series = {SOMA '10}
}

@inproceedings{10.1145/1836135.1836140,
author = {Yun, Chang and Trevino, Philip and Holtkamp, William and Deng, Zhigang},
title = {PADS: Enhancing Gaming Experience Using Profile-Based Adaptive Difficulty System},
year = {2010},
isbn = {9781450300971},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1836135.1836140},
doi = {10.1145/1836135.1836140},
abstract = {In this paper, we present a novel methodology to improve gaming experiences by automatically adjusting the game difficulty throughout the game play using a Profile-based Adaptive Difficulty System (PADS). We utilize a player's gaming experience and objective to create a player profile. Utilizing this profile and a performance-based algorithm, the PADS customizes the game's difficulty levels to accommodate each individual. Our experimental results successfully demonstrate improvements in both perceptual and actual gaming experiences. With our approach, traditional program-centered video games can be transformed to provide individualized, player-centered gaming experiences.},
booktitle = {Proceedings of the 5th ACM SIGGRAPH Symposium on Video Games},
pages = {31–36},
numpages = {6},
keywords = {player profile, player-centric gaming, difficulty adjustment, gaming experience, game difficulty},
location = {Los Angeles, California},
series = {Sandbox '10}
}

