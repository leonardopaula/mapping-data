@article{10.1145/1805974.1805983,
author = {Vaidya, Jaideep and Atluri, Vijayalakshmi and Guo, Qi},
title = {The Role Mining Problem: A Formal Perspective},
year = {2010},
issue_date = {July 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {1094-9224},
url = {https://doi.org/10.1145/1805974.1805983},
doi = {10.1145/1805974.1805983},
abstract = {Devising a complete and correct set of roles has been recognized as one of the most important and challenging tasks in implementing role-based access control. A key problem related to this is the notion of goodness/interestingness—when is a role good/interesting? In this article, we define the Role Mining Problem (RMP) as the problem of discovering an optimal set of roles from existing user permissions. The main contribution of this article is to formally define RMP and analyze its theoretical bounds. In addition to the above basic RMP, we introduce two different variations of the RMP, called the δ-Approx RMP and the minimal-noise RMP that have pragmatic implications. We reduce the known “Set Basis Problem” to RMP to show that RMP is an NP-complete problem. An important contribution of this article is also to show the relation of the RMP to several problems already identified in the data mining and data analysis literature. By showing that the RMP is in essence reducible to these known problems, we can directly borrow the existing implementation solutions and guide further research in this direction. We also develop a heuristic solution based on the previously proposed FastMiner algorithm, which is very accurate and efficient.},
journal = {ACM Trans. Inf. Syst. Secur.},
month = jul,
articleno = {27},
numpages = {31},
keywords = {RBAC, role mining, role engineering}
}

@inproceedings{10.1145/1838574.1838598,
author = {Zhao, Lan and Lee, Wonjun and Song, Carol X. and Huber, Matthew and Goldner, Aaron},
title = {Bringing High Performance Climate Modeling into the Classroom},
year = {2010},
isbn = {9781605588186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1838574.1838598},
doi = {10.1145/1838574.1838598},
abstract = {Climate science educators face great challenges on combining theory with hands-on practices in teaching climate modeling. Typical model runs require large computation and storage resources that may not be available on a campus. Additionally, the training and support required to bring novices up to speed would consume significant class time. The same challenges also exist across many other science and engineering disciplines. The TeraGrid science gateway program is leading the way of a new paradigm in addressing such challenges. As part of the TeraGrid science gateway initiative, The Purdue CCSM portal aims at assisting both research and education users to run Community Climate System Model (CCSM) simulations using the TeraGrid high performance computing resources. It provides a one-stop shop for creating, configuring, running CCSM simulations as well as managing jobs and processing output data. The CCSM portal was used in a Purdue graduate class for students to get hands-on experience with running world class climate simulations and use the results to study climate change impact on political policies. The CCSM portal is based on a service-oriented architecture with multiple interfaces to facilitate training. This paper describes the design of the CCSM portal with the goal of supporting classroom users, the challenges of utilizing the portal in a classroom setting, and the solutions implemented. We present two student projects from the fall 2009 class that successfully used the CCSM portal.},
booktitle = {Proceedings of the 2010 TeraGrid Conference},
articleno = {24},
numpages = {7},
keywords = {user interfaces, TeraGrid, education users, community climate system model (CCSM), science gateway},
location = {Pittsburgh, Pennsylvania},
series = {TG '10}
}

@inproceedings{10.1145/1839594.1839607,
author = {Meerbaum-Salant, Orni and Armoni, Michal and Ben-Ari, Mordechai (Moti)},
title = {Learning Computer Science Concepts with Scratch},
year = {2010},
isbn = {9781450302579},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839594.1839607},
doi = {10.1145/1839594.1839607},
abstract = {Scratch is a visual programming environment that is widely used by young people. We investigated if Scratch can be used to teach concepts of computer science. We developed new learning materials for middle-school students that were designed according to the constructionist philosophy of Scratch and evaluated them in two schools. The classes were normal classes, not extracurricular activities whose participants are self-selected. Questionnaires and a test were constructed based upon a novel combination of the Revised Bloom Taxonomy and the SOLO taxonomy. These quantitative instruments were augmented with a qualitative analysis of observations within the classes. The results showed that in general students could successfully learn important concepts of computer science, although there were some problems with initialization, variables and concurrency; these problems can be overcome by modifications to the teaching process.},
booktitle = {Proceedings of the Sixth International Workshop on Computing Education Research},
pages = {69–76},
numpages = {8},
keywords = {middle schools, concurrency, solo taxonomy, scratch, bloom's taxonomy},
location = {Aarhus, Denmark},
series = {ICER '10}
}

@inproceedings{10.1145/1839594.1839609,
author = {Kinnunen, Paivi and Simon, Beth},
title = {Experiencing Programming Assignments in CS1: The Emotional Toll},
year = {2010},
isbn = {9781450302579},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839594.1839609},
doi = {10.1145/1839594.1839609},
abstract = {The constant comparative method was used to explicate the experience computing majors have with programming assignments in a CS1 course. Findings from a series of four interviews conducted with a purposeful sample of nine students revealed that the primary reflective experience with programming assignments was emotional. That is, the way students remembered and discussed their experiences with programming assignments was dominated by emotional experiences and reactions. We identified six stages whose dimensions capture the variation in students' emotional experiences with programming assignments. This paper reports the beginnings of analysis geared at developing a theory of students' programming assignment experience, rich in detail and grounded in student experience. When completed such a theory may lead to curricular supports, interventions, or tools, to help steer student experience away from the most harmful of emotional tolls.},
booktitle = {Proceedings of the Sixth International Workshop on Computing Education Research},
pages = {77–86},
numpages = {10},
keywords = {emotion, novice programmers, cs1, retention},
location = {Aarhus, Denmark},
series = {ICER '10}
}

@inproceedings{10.1145/1858171.1858218,
author = {Chen, Yunan},
title = {Take It Personally: Accounting for Individual Difference in Designing Diabetes Management Systems},
year = {2010},
isbn = {9781450301039},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1858171.1858218},
doi = {10.1145/1858171.1858218},
abstract = {The goal of this study was to investigate how diabetes patients use health information to support their daily disease management. A qualitative interview study was conducted with type-2 diabetes patients and healthcare providers. The analysis suggests that individual diabetes patients have a unique way of managing their care through the interpretation of personal health experiences. The ways in which patients learn to interact with their diabetes are detailed in this paper in four themes: understanding typical life routine, accommodating atypical activities, disproving &amp; discovering healthy tips and reevaluating personal expectations. The findings of this study call for a diabetes management system that addresses a patient's physiological, social and psychological activities within the process of individual disease management. The finding opens up new opportunities for designing interactive systems to account for individual differences, encouraging positive patient involvement and sustaining long-term health outcomes.},
booktitle = {Proceedings of the 8th ACM Conference on Designing Interactive Systems},
pages = {252–261},
numpages = {10},
keywords = {personal health experience, diabetes management, individual experience},
location = {Aarhus, Denmark},
series = {DIS '10}
}

@inproceedings{10.1145/1858171.1858239,
author = {Burmester, Michael and Mast, Marcus and J\"{a}ger, Kilian and Homans, Hendrik},
title = {Valence Method for Formative Evaluation of User Experience},
year = {2010},
isbn = {9781450301039},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1858171.1858239},
doi = {10.1145/1858171.1858239},
abstract = {This paper describes a method for formative evaluation of the user experience based on the user experience model of Hassenzahl [11]. It captures positive and negative feelings during the exploration of an interactive product. In a subsequent retrospective interview phase users indicate for each instance of a positive or negative feeling the product design aspects inducing it. This phase further employs the laddering interview technique [24] to reveal the meaning of product design aspects to the user and the underlying fulfilled or frustrated needs. The generated information helps designers to understand and optimize the user experience potential of a product.},
booktitle = {Proceedings of the 8th ACM Conference on Designing Interactive Systems},
pages = {364–367},
numpages = {4},
keywords = {user experience, formative evaluation},
location = {Aarhus, Denmark},
series = {DIS '10}
}

@inproceedings{10.1145/1858171.1858192,
author = {Kim, Tanyoung and Hong, Hwajung and Magerko, Brian},
title = {Design Requirements for Ambient Display That Supports Sustainable Lifestyle},
year = {2010},
isbn = {9781450301039},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1858171.1858192},
doi = {10.1145/1858171.1858192},
abstract = {People are ready to change themselves to adopt more eco-friendly habits such as conserving electricity when they are aware of the possible problems of their lifestyle. In this sense, ambient display, which users experience occasionally without its interfering with their primary tasks, is well suited to provide the feedback of their personal activities in a more subtle manner than direct information presentation. We present the results of user studies with two ambient displays in different visualization styles. Participants showed diverse usage behaviors of ambient displays according to their motivational level of sustainable lifestyle. In addition, iconic metaphor of eco-visualization can trigger more emotional attachment while indexical representation helps retrospective functions. Finally, we suggest design requirements for ambient displays that support different stages of persuasion from raising awareness to motivating to change behaviors and to maintaining desired habits.},
booktitle = {Proceedings of the 8th ACM Conference on Designing Interactive Systems},
pages = {103–112},
numpages = {10},
keywords = {eco-visualization, behavior change, sustainable design, ambient display, persuasive technology},
location = {Aarhus, Denmark},
series = {DIS '10}
}

@inproceedings{10.1145/1840784.1840802,
author = {Frommholz, Ingo and Larsen, Birger and Piwowarski, Benjamin and Lalmas, Mounia and Ingwersen, Peter and van Rijsbergen, Keith},
title = {Supporting Polyrepresentation in a Quantum-Inspired Geometrical Retrieval Framework},
year = {2010},
isbn = {9781450302470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1840784.1840802},
doi = {10.1145/1840784.1840802},
abstract = {The relevance of a document has many facets, going beyond the usual topical one, which have to be considered to satisfy a user's information need. Multiple representations of documents, like user-given reviews or the actual document content, can give evidence towards certain facets of relevance. In this respect polyrepresentation of documents, where such evidence is combined, is a crucial concept to estimate the relevance of a document. In this paper, we discuss how a geometrical retrieval framework inspired by quantum mechanics can be extended to support polyrepresentation. We show by example how different representations of a document can be modelled in a Hilbert space, similar to physical systems known from quantum mechanics. We further illustrate how these representations are combined by means of the tensor product to support polyrepresentation, and discuss the case that representations of documents are not independent from a user point of view. Besides giving a principled framework for polyrepresentation, the potential of this approach is to capture and formalise the complex interdependent relationships that the different representations can have between each other.},
booktitle = {Proceedings of the Third Symposium on Information Interaction in Context},
pages = {115–124},
numpages = {10},
keywords = {polyrepresentation, quantum-inspired model},
location = {New Brunswick, New Jersey, USA},
series = {IIiX '10}
}

@inproceedings{10.5555/1873781.1873788,
author = {Bergsma, Shane and Cherry, Colin},
title = {Fast and Accurate Arc Filtering for Dependency Parsing},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {We propose a series of learned arc filters to speed up graph-based dependency parsing. A cascade of filters identify implausible head-modifier pairs, with time complexity that is first linear, and then quadratic in the length of the sentence. The linear filters reliably predict, in context, words that are roots or leaves of dependency trees, and words that are likely to have heads on their left or right. We use this information to quickly prune arcs from the dependency graph. More than 78% of total arcs are pruned while retaining 99.5% of the true dependencies. These filters improve the speed of two state-of-the-art dependency parsers, with low overhead and negligible loss in accuracy.},
booktitle = {Proceedings of the 23rd International Conference on Computational Linguistics},
pages = {53–61},
numpages = {9},
location = {Beijing, China},
series = {COLING '10}
}

@article{10.1145/1851175.1851178,
author = {Garrison, Gary and Wakefield, Robin L. and Xu, Xiaobo and `Kim, Sang Hyun},
title = {Globally Distributed Teams: The Effect of Diversity on Trust, Cohesion and Individual Performance},
year = {2010},
issue_date = {August 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {3},
issn = {0095-0033},
url = {https://doi.org/10.1145/1851175.1851178},
doi = {10.1145/1851175.1851178},
abstract = {Globally distributed teams are becoming more common among organizations that seek to maximize knowledge creation and innovation for competitive advantage. Although they are becoming widely used among global organizations, distributed teams are creating an environment replete in cultural and functional diversity. Whereas synergy among members is desired, diversity is likely to hinder team cohesion and individual performance. Our study models and empirically tests the effect of perceptions of diversity on trust, cohesion, and individual performance in actual globally distributed teams. The results indicate that individual productivity is negatively influenced by the extent of diversity within a team; however, this liability may be restrained if an environment of trust is encouraged and team cohesion develops.},
journal = {SIGMIS Database},
month = aug,
pages = {27–48},
numpages = {22},
keywords = {performance, cohesion, trust, diversity, globally distributed teams}
}

@inproceedings{10.5555/1944566.1944570,
author = {Balahur, Alexandra and Boldrini, Ester and Montoyo, Andr\'{e}s and Mart\'{\i}nez-Barco, Patricio},
title = {Going beyond Traditional QA Systems: Challenges and Keys in Opinion Question Answering},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {The treatment of factual data has been widely studied in different areas of Natural Language Processing (NLP). However, processing subjective information still poses important challenges. This paper presents research aimed at assessing techniques that have been suggested as appropriate in the context of subjective - Opinion Question Answering (OQA). We evaluate the performance of an OQA with these new components and propose methods to optimally tackle the issues encountered. We assess the impact of including additional resources and processes with the purpose of improving the system performance on two distinct blog datasets. The improvements obtained for the different combination of tools are statistically significant. We thus conclude that the proposed approach is adequate for the OQA task, offering a good strategy to deal with opinionated questions.},
booktitle = {Proceedings of the 23rd International Conference on Computational Linguistics: Posters},
pages = {27–35},
numpages = {9},
location = {Beijing, China},
series = {COLING '10}
}

@inproceedings{10.5555/1944566.1944624,
author = {Ji, Heng},
title = {Challenges from Information Extraction to Information Fusion},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Information Extraction (IE) technology is facing new challenges of dealing with large-scale heterogeneous data sources from different documents, languages and modalities. Information fusion, a new emerging area derived from IE, aims to address these challenges. We specify the requirements and possible solutions to perform information fusion. The issues include redundancy removal, contradiction resolution and uncertainty reduction. We believe this is a critical step to advance IE to a higher level of performance and portability.},
booktitle = {Proceedings of the 23rd International Conference on Computational Linguistics: Posters},
pages = {507–515},
numpages = {9},
location = {Beijing, China},
series = {COLING '10}
}

@article{10.1145/1851175.1851179,
author = {Heart, Tsipi},
title = {Who is out There? Exploring the Effects of Trust and Perceived Risk on Saas Adoption Intentions},
year = {2010},
issue_date = {August 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {3},
issn = {0095-0033},
url = {https://doi.org/10.1145/1851175.1851179},
doi = {10.1145/1851175.1851179},
abstract = {Software as a Service (SaaS) is a relatively new organizational application sourcing alternative, offering organizations the option to access applications--via the Internet--that are remotely hosted on offsite servers instead of installing equivalent applications in-house, thus presumably saving costs. Although SaaS has been offered since the late 1990s, so far it has not become a dominant sourcing alternative for organizational core applications, in spite of the fact that most leading IT companies now offer remotely-hosted organization-wide applications. This study conceptualized and empirically tested a model of the effects of the perceived risk of SaaS and trust in the SaaS vendor community on the organizational intention to adopt SaaS at this early stage of the SaaS market. Three novel, risk-related constructs were developed: perceived risk of SaaS, perceived risk of systems unavailability, and perceived risk of data insecurity. Likewise, three new trust-related constructs were also conceived: trust in the SaaS vendor community, perceived capabilities and perceived reputation of the SaaS vendor community. An empirical test of the model demonstrated the negative effect of perceived risk and the positive effects of trust in, and the reputation of, the SaaS vendor community, on the intention to adopt SaaS. Trust in the SaaS vendor community was also found to strongly affect all three risk concepts.},
journal = {SIGMIS Database},
month = aug,
pages = {49–68},
numpages = {20},
keywords = {trust, intention to adopt, perceived reputation, perceived capabilities, software as a service, perceived risk}
}

@inproceedings{10.1145/1931344.1931359,
author = {Millonig, Alexandra and Maierbrugger, Gudrun},
title = {Using Semi-Automated Shadowing for Analysing Stress-Inducedspatio-Temporal Behaviour Patterns of Passengers in Public Transport Infrastructures},
year = {2010},
isbn = {9781605589268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1931344.1931359},
doi = {10.1145/1931344.1931359},
abstract = {In the course of the scientific project IANUS, we examined the impacts of stress on the physical and psychological condition of passengers in train stations in order to identify relevant determinants and to develop recommendations for reducing stress-inducing factors in public transport infrastructures. We used a combination of biometric measuring of heart rate, semi-automated observation of spatio-temporal behaviour, psychological interviews, eye-tracking and visual field analyses during laboratory and field tests. In this contribution, we focus on the methodology of observing the spatio-temporal behaviour patterns of 35 individuals participating in field tests conducted in Vienna, Austria. The observation datasets have been analysed concerning velocities, route choice, stopping behaviour and related activities in order to identify noticeable patterns and events that can indicate stress-related behaviour. The outcomes were subsequently consolidated with the results of the complementary methods in order to identify stress-inducing factors in transport infrastructures.},
booktitle = {Proceedings of the 7th International Conference on Methods and Techniques in Behavioral Research},
articleno = {15},
numpages = {5},
keywords = {pedestrian spatio-temporal behaviour, shadowing, across-method triangulation},
location = {Eindhoven, The Netherlands},
series = {MB '10}
}

@inproceedings{10.1145/1931344.1931376,
author = {Voynarovskaya, Natalia and Gorbunov, Roman and Barakova, Emilia and Rauterberg, Matthias},
title = {Automatic Mental Heath Assistant: Monitoring and Measuring Nonverbal Behavior of the Crew during Long-Term Missions},
year = {2010},
isbn = {9781605589268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1931344.1931376},
doi = {10.1145/1931344.1931376},
abstract = {This paper presents a method for monitoring the mental state of small isolated crews during long-term missions (such as space mission, polar expeditions, submarine crews, meteorological stations, and etc.) The research is done as a part of Automatic Mental Health Assistant (AMHA) project which aims to develop set of techniques for automatic measuring of intra- and inter- personal states in working groups. The method is focused on those aspects of psychological and sociological states that are crucial for the performance of the crew. In particular, we focus on measuring of emotional stress, initial signs of conflicts, trust, and ability to collaborate. The present research is performed in collaboration with MARS-500 experiment in which a small group of people is isolated for a long period of time. The MARS-500 experiment, in this way, provides a unique platform for study of human-human interaction. The confinement study will imitate all key peculiarities expected to be present during future missions to Mars (i.e. ultra long duration flight, need for autonomy, complicated communication with a digital communication center due to signal delay, and limited stock of expendables). The developed method is also currently tested by usage of a web-based platform.},
booktitle = {Proceedings of the 7th International Conference on Methods and Techniques in Behavioral Research},
articleno = {32},
numpages = {5},
keywords = {long-term missions, nonverbal communication, social network analysis, colored trails, emotions, evolutionary game theory},
location = {Eindhoven, The Netherlands},
series = {MB '10}
}

@inproceedings{10.1145/1931344.1931350,
author = {van den Broek, Egon L. and Nijholt, Anton and Westerink, Joyce H. D. M.},
title = {Unveiling Affective Signals},
year = {2010},
isbn = {9781605589268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1931344.1931350},
doi = {10.1145/1931344.1931350},
abstract = {The ability to process and, subsequently, understand affective signals is the core of emotional intelligence and empathy. However, more than a decade of research in affective computing has shown that it is hard to develop computational models of this process. We pose that the solution for this problem lays in a better understanding of how to process these affective signals. This article introduces a symposium that brought together various approaches towards unveiling affective signals. As such, it is envisioned to be a springboard for affective computing.},
booktitle = {Proceedings of the 7th International Conference on Methods and Techniques in Behavioral Research},
articleno = {6},
numpages = {4},
keywords = {methods, affective computing, signal processing, emotion, affect, pattern recognition},
location = {Eindhoven, The Netherlands},
series = {MB '10}
}

@inproceedings{10.1145/1962300.1962346,
author = {van der Sar, Manon and Mulder, Ingrid},
title = {Human-Camera Interaction: An Exploratory Study on People's Emotions and Attitude towards Cameras},
year = {2010},
isbn = {9781605589466},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1962300.1962346},
doi = {10.1145/1962300.1962346},
abstract = {Motivation -- Cameras are increasingly dominating our life, but do these influence our behaviour as well? What are people's emotions and attitude towards camera surveillance?Research approach -- In an exploratory study (n=23) people's emotional reactions to (visible and hidden) cameras were observed. Next, a survey studied people's attitude towards camera surveillance at different places (n=102).Findings/Design -- Results suggest that people are conditioned by cameras, as they react both consciously and unconsciously to cameras. People like to spy other people, while they do not like to be observed.Research limitations/Implications -- The current study is exploratory, which limited generalisation of our findings.Originality/Value -- The research contributes to the public debate on camera surveillance and how people (un)consciously react to cameras.Take away message -- Cameras evoke emotions.},
booktitle = {Proceedings of the 28th Annual European Conference on Cognitive Ergonomics},
pages = {223–226},
numpages = {4},
keywords = {camera surveillance, emotion, exploratory study, public safety},
location = {Delft, Netherlands},
series = {ECCE '10}
}

@inproceedings{10.1145/1962300.1962342,
author = {Chauvin, Christine and Coppin, Gilles and Ch\'{e}n\'{e}, H\'{e}l\'{e}na},
title = {Analysis of the Dynamics of Common Ground: A Methodological Proposal},
year = {2010},
isbn = {9781605589466},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1962300.1962342},
doi = {10.1145/1962300.1962342},
abstract = {The elaboration and maintenance of a common ground between team members are crucial aspects for the efficiency and safety of complex systems.A method has been designed to analyze communication between members of a bridge team of a merchant ship, that was recorded during training sessions on a bridge simulator. This method aims to pointing out the positive or negative dynamics of their common ground. It relies on Hoc coding schemes, as well as on the Bales Interaction Process Analysis.Using a transposition of computer science parsing tools, we try to qualify the different levels and the dynamics of the common ground, expressed in terms of left-open requests or average time of closure.This research is in progress. Its main interest is to combine existing coding schemes (coming from cognitive ergonomics and from social psychology) to formalize functional communications and to use computer science tools to point out and qualify the dynamics of a common ground.},
booktitle = {Proceedings of the 28th Annual European Conference on Cognitive Ergonomics},
pages = {209–212},
numpages = {4},
keywords = {cooperation, team management, dynamic systems, ship handling},
location = {Delft, Netherlands},
series = {ECCE '10}
}

@inproceedings{10.1145/1851182.1851219,
author = {Mahimkar, Ajay Anil and Song, Han Hee and Ge, Zihui and Shaikh, Aman and Wang, Jia and Yates, Jennifer and Zhang, Yin and Emmons, Joanne},
title = {Detecting the Performance Impact of Upgrades in Large Operational Networks},
year = {2010},
isbn = {9781450302012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851182.1851219},
doi = {10.1145/1851182.1851219},
abstract = {Networks continue to change to support new applications, improve reliability and performance and reduce the operational cost. The changes are made to the network in the form of upgrades such as software or hardware upgrades, new network or service features and network configuration changes. It is crucial to monitor the network when upgrades are made because they can have a significant impact on network performance and if not monitored may lead to unexpected consequences in operational networks. This can be achieved manually for a small number of devices, but does not scale to large networks with hundreds or thousands of routers and extremely large number of different upgrades made on a regular basis.In this paper, we design and implement a novel infrastructure MERCURY for detecting the impact of network upgrades (or triggers) on performance. MERCURY extracts interesting triggers from a large number of network maintenance activities. It then identifies behavior changes in network performance caused by the triggers. It uses statistical rule mining and network configuration to identify commonality across the behavior changes. We systematically evaluate MERCURY using data collected at a large tier-1 ISP network. By comparing to operational practice, we show that MERCURY is able to capture the interesting triggers and behavior changes induced by the triggers. In some cases, MERCURY also discovers previously unknown network behaviors demonstrating the effectiveness in identifying network conditions flying under the radar.},
booktitle = {Proceedings of the ACM SIGCOMM 2010 Conference},
pages = {303–314},
numpages = {12},
keywords = {network upgrades, change detection, performance impact, statistical data mining},
location = {New Delhi, India},
series = {SIGCOMM '10}
}

@article{10.1145/1851275.1851219,
author = {Mahimkar, Ajay Anil and Song, Han Hee and Ge, Zihui and Shaikh, Aman and Wang, Jia and Yates, Jennifer and Zhang, Yin and Emmons, Joanne},
title = {Detecting the Performance Impact of Upgrades in Large Operational Networks},
year = {2010},
issue_date = {October 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/1851275.1851219},
doi = {10.1145/1851275.1851219},
abstract = {Networks continue to change to support new applications, improve reliability and performance and reduce the operational cost. The changes are made to the network in the form of upgrades such as software or hardware upgrades, new network or service features and network configuration changes. It is crucial to monitor the network when upgrades are made because they can have a significant impact on network performance and if not monitored may lead to unexpected consequences in operational networks. This can be achieved manually for a small number of devices, but does not scale to large networks with hundreds or thousands of routers and extremely large number of different upgrades made on a regular basis.In this paper, we design and implement a novel infrastructure MERCURY for detecting the impact of network upgrades (or triggers) on performance. MERCURY extracts interesting triggers from a large number of network maintenance activities. It then identifies behavior changes in network performance caused by the triggers. It uses statistical rule mining and network configuration to identify commonality across the behavior changes. We systematically evaluate MERCURY using data collected at a large tier-1 ISP network. By comparing to operational practice, we show that MERCURY is able to capture the interesting triggers and behavior changes induced by the triggers. In some cases, MERCURY also discovers previously unknown network behaviors demonstrating the effectiveness in identifying network conditions flying under the radar.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = aug,
pages = {303–314},
numpages = {12},
keywords = {change detection, network upgrades, statistical data mining, performance impact}
}

@inproceedings{10.1145/1851290.1851298,
author = {Keshav, Srinivasan and Rosenberg, Catherine},
title = {How Internet Concepts and Technologies Can Help Green and Smarten the Electrical Grid},
year = {2010},
isbn = {9781450301961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851290.1851298},
doi = {10.1145/1851290.1851298},
abstract = {Several powerful forces are gathering to make fundamental and irrevocable changes to the century-old grid. The next-generation grid, often called the 'smart grid,' will feature distributed energy production, vastly more storage, tens of millions of stochastic renewable-energy sources, and the use of communication technologies both to allow precise matching of supply to demand and to incentivize appropriate consumer behaviour. These changes will have the effect of reducing energy waste and reducing the carbon footprint of the grid, making it 'smarter' and 'greener.' In this position paper, we discuss how the concepts and techniques pioneered by the Internet, the fruit of four decades of research in this area, are directly applicable to the design of a smart, green grid. This is because both the Internet and the electrical grid are designed to meet fundamental needs, for information and for energy, respectively, by connecting geographically dispersed suppliers with geographically dispersed consumers. Keeping this and other similarities (and fundamental differences, as well) in mind, we propose several specific areas where Internet concepts and technologies can contribute to the development of a smart, green grid. We also describe some areas where the Internet operations can be improved based on the experience gained in the electrical grid. We hope that our work will initiate a dialogue between the Internet and the smart grid communities.},
booktitle = {Proceedings of the First ACM SIGCOMM Workshop on Green Networking},
pages = {35–40},
numpages = {6},
keywords = {electrical grid, green networking},
location = {New Delhi, India},
series = {Green Networking '10}
}

@inproceedings{10.1145/1851182.1851199,
author = {McSherry, Frank and Mahajan, Ratul},
title = {Differentially-Private Network Trace Analysis},
year = {2010},
isbn = {9781450302012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851182.1851199},
doi = {10.1145/1851182.1851199},
abstract = {We consider the potential for network trace analysis while providing the guarantees of "differential privacy." While differential privacy provably obscures the presence or absence of individual records in a dataset, it has two major limitations: analyses must (presently) be expressed in a higher level declarative language; and the analysis results are randomized before returning to the analyst.We report on our experiences conducting a diverse set of analyses in a differentially private manner. We are able to express all of our target analyses, though for some of them an approximate expression is required to keep the error-level low. By running these analyses on real datasets, we find that the error introduced for the sake of privacy is often (but not always) low even at high levels of privacy. We factor our learning into a toolkit that will be likely useful for other analyses. Overall, we conclude that differential privacy shows promise for a broad class of network analyses.},
booktitle = {Proceedings of the ACM SIGCOMM 2010 Conference},
pages = {123–134},
numpages = {12},
keywords = {differential privacy, trace analysis},
location = {New Delhi, India},
series = {SIGCOMM '10}
}

@article{10.1145/1851275.1851199,
author = {McSherry, Frank and Mahajan, Ratul},
title = {Differentially-Private Network Trace Analysis},
year = {2010},
issue_date = {October 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/1851275.1851199},
doi = {10.1145/1851275.1851199},
abstract = {We consider the potential for network trace analysis while providing the guarantees of "differential privacy." While differential privacy provably obscures the presence or absence of individual records in a dataset, it has two major limitations: analyses must (presently) be expressed in a higher level declarative language; and the analysis results are randomized before returning to the analyst.We report on our experiences conducting a diverse set of analyses in a differentially private manner. We are able to express all of our target analyses, though for some of them an approximate expression is required to keep the error-level low. By running these analyses on real datasets, we find that the error introduced for the sake of privacy is often (but not always) low even at high levels of privacy. We factor our learning into a toolkit that will be likely useful for other analyses. Overall, we conclude that differential privacy shows promise for a broad class of network analyses.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = aug,
pages = {123–134},
numpages = {12},
keywords = {differential privacy, trace analysis}
}

@inproceedings{10.1145/1851290.1851294,
author = {Krioukov, Andrew and Mohan, Prashanth and Alspaugh, Sara and Keys, Laura and Culler, David and Katz, Randy H.},
title = {NapSAC: Design and Implementation of a Power-Proportional Web Cluster},
year = {2010},
isbn = {9781450301961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851290.1851294},
doi = {10.1145/1851290.1851294},
abstract = {Energy consumption is a major and costly problem in data centers. A large fraction of this energy goes to powering idle machines that are not doing any useful work. We identify two causes of this inefficiency: low server utilization and a lack of power-proportionality. To address this problem we present a design for an power-proportional cluster consisting of a power-aware cluster manager and a set of heterogeneous machines. Our design makes use of currently available energy-efficient hardware, mechanisms for transitioning in and out of low-power sleep states, and dynamic provisioning and scheduling to continually adjust to workload and minimize power consumption. With our design we are able to reduce energy consumption while maintaining acceptable response times for a web service workload based on Wikipedia. With our dynamic provisioning algorithms we demonstrate via simulation a 63% savings in power usage in a typically provisioned datacenter where all machines are left on and awake at all times. Our results show that we are able to achieve close to 90% of the savings a theoretically optimal provisioning scheme would achieve. We have also built a prototype cluster which runs Wikipedia to demonstrate the use of our design in a real environment.},
booktitle = {Proceedings of the First ACM SIGCOMM Workshop on Green Networking},
pages = {15–22},
numpages = {8},
keywords = {heterogenous hardware, energy, web server, data center, web application, cluster, power proportional, power management},
location = {New Delhi, India},
series = {Green Networking '10}
}

@inproceedings{10.1145/1851182.1851227,
author = {Pujol, Josep M. and Erramilli, Vijay and Siganos, Georgos and Yang, Xiaoyuan and Laoutaris, Nikos and Chhabra, Parminder and Rodriguez, Pablo},
title = {The Little Engine(s) That Could: Scaling Online Social Networks},
year = {2010},
isbn = {9781450302012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851182.1851227},
doi = {10.1145/1851182.1851227},
abstract = {The difficulty of scaling Online Social Networks (OSNs) has introduced new system design challenges that has often caused costly re-architecting for services like Twitter and Facebook. The complexity of interconnection of users in social networks has introduced new scalability challenges. Conventional vertical scaling by resorting to full replication can be a costly proposition. Horizontal scaling by partitioning and distributing data among multiples servers - e.g. using DHTs - can lead to costly inter-server communication.We design, implement, and evaluate SPAR, a social partitioning and replication middle-ware that transparently leverages the social graph structure to achieve data locality while minimizing replication. SPAR guarantees that for all users in an OSN, their direct neighbor's data is co-located in the same server. The gains from this approach are multi-fold: application developers can assume local semantics, i.e., develop as they would for a single server; scalability is achieved by adding commodity servers with low memory and network I/O requirements; and redundancy is achieved at a fraction of the cost.We detail our system design and an evaluation based on datasets from Twitter, Orkut, and Facebook, with a working implementation. We show that SPAR incurs minimum overhead, and can help a well-known open-source Twitter clone reach Twitter's scale without changing a line of its application logic and achieves higher throughput than Cassandra, Facebook's DHT based key-value store database.},
booktitle = {Proceedings of the ACM SIGCOMM 2010 Conference},
pages = {375–386},
numpages = {12},
keywords = {partition, replication, scalability, social networks},
location = {New Delhi, India},
series = {SIGCOMM '10}
}

@article{10.1145/1851275.1851227,
author = {Pujol, Josep M. and Erramilli, Vijay and Siganos, Georgos and Yang, Xiaoyuan and Laoutaris, Nikos and Chhabra, Parminder and Rodriguez, Pablo},
title = {The Little Engine(s) That Could: Scaling Online Social Networks},
year = {2010},
issue_date = {October 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/1851275.1851227},
doi = {10.1145/1851275.1851227},
abstract = {The difficulty of scaling Online Social Networks (OSNs) has introduced new system design challenges that has often caused costly re-architecting for services like Twitter and Facebook. The complexity of interconnection of users in social networks has introduced new scalability challenges. Conventional vertical scaling by resorting to full replication can be a costly proposition. Horizontal scaling by partitioning and distributing data among multiples servers - e.g. using DHTs - can lead to costly inter-server communication.We design, implement, and evaluate SPAR, a social partitioning and replication middle-ware that transparently leverages the social graph structure to achieve data locality while minimizing replication. SPAR guarantees that for all users in an OSN, their direct neighbor's data is co-located in the same server. The gains from this approach are multi-fold: application developers can assume local semantics, i.e., develop as they would for a single server; scalability is achieved by adding commodity servers with low memory and network I/O requirements; and redundancy is achieved at a fraction of the cost.We detail our system design and an evaluation based on datasets from Twitter, Orkut, and Facebook, with a working implementation. We show that SPAR incurs minimum overhead, and can help a well-known open-source Twitter clone reach Twitter's scale without changing a line of its application logic and achieves higher throughput than Cassandra, Facebook's DHT based key-value store database.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = aug,
pages = {375–386},
numpages = {12},
keywords = {scalability, social networks, replication, partition}
}

@article{10.1145/1810891.1810916,
author = {McSherry, Frank},
title = {Privacy Integrated Queries: An Extensible Platform for Privacy-Preserving Data Analysis},
year = {2010},
issue_date = {September 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {9},
issn = {0001-0782},
url = {https://doi.org/10.1145/1810891.1810916},
doi = {10.1145/1810891.1810916},
abstract = {Privacy Integrated Queries (PINQ) is an extensible data analysis platform designed to provide unconditional privacy guarantees for the records of the underlying data sets. PINQ provides analysts with access to records through an SQL-like declarative language (LINQ) amidst otherwise arbitrary C# code. At the same time, the design of PINQ's analysis language and its careful implementation provide formal guarantees of differential privacy for any and all uses of the platform. PINQ's guarantees require no trust placed in the expertise or diligence of the analysts, broadening the scope for design and deployment of privacy-preserving data analyses, especially by privacy nonexperts.},
journal = {Commun. ACM},
month = sep,
pages = {89–97},
numpages = {9}
}

@article{10.1145/1836216.1836223,
author = {Blevis, Eli and Blevis, Shunying},
title = {Hope for the Best and Prepare for the Worst: Interaction Design and the Tipping Point},
year = {2010},
issue_date = {September + October 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {5},
issn = {1072-5520},
url = {https://doi.org/10.1145/1836216.1836223},
doi = {10.1145/1836216.1836223},
journal = {Interactions},
month = sep,
pages = {26–30},
numpages = {5}
}

@article{10.14778/1920841.1920908,
author = {Dittrich, Jens and Quian\'{e}-Ruiz, Jorge-Arnulfo and Jindal, Alekh and Kargin, Yagiz and Setty, Vinay and Schad, J\"{o}rg},
title = {Hadoop++: Making a Yellow Elephant Run like a Cheetah (without It Even Noticing)},
year = {2010},
issue_date = {September 2010},
publisher = {VLDB Endowment},
volume = {3},
number = {1–2},
issn = {2150-8097},
url = {https://doi.org/10.14778/1920841.1920908},
doi = {10.14778/1920841.1920908},
abstract = {MapReduce is a computing paradigm that has gained a lot of attention in recent years from industry and research. Unlike parallel DBMSs, MapReduce allows non-expert users to run complex analytical tasks over very large data sets on very large clusters and clouds. However, this comes at a price: MapReduce processes tasks in a scan-oriented fashion. Hence, the performance of Hadoop --- an open-source implementation of MapReduce --- often does not match the one of a well-configured parallel DBMS. In this paper we propose a new type of system named Hadoop++: it boosts task performance without changing the Hadoop framework at all (Hadoop does not even 'notice it'). To reach this goal, rather than changing a working system (Hadoop), we inject our technology at the right places through UDFs only and affect Hadoop from inside. This has three important consequences: First, Hadoop++ significantly outperforms Hadoop. Second, any future changes of Hadoop may directly be used with Hadoop++ without rewriting any glue code. Third, Hadoop++ does not need to change the Hadoop interface. Our experiments show the superiority of Hadoop++ over both Hadoop and HadoopDB for tasks related to indexing and join processing.},
journal = {Proc. VLDB Endow.},
month = sep,
pages = {515–529},
numpages = {15}
}

@article{10.1145/1824777.1824787,
author = {Oudot, Steve Y. and Guibas, Leonidas J. and Gao, Jie and Wang, Yue},
title = {Geodesic Delaunay Triangulations in Bounded Planar Domains},
year = {2010},
issue_date = {August 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
issn = {1549-6325},
url = {https://doi.org/10.1145/1824777.1824787},
doi = {10.1145/1824777.1824787},
abstract = {We introduce a new feature size for bounded domains in the plane endowed with an intrinsic metric. Given a point x in a domain X, the systolic feature size of X at x measures half the length of the shortest loop through x that is not null-homotopic in X. The resort to an intrinsic metric makes the systolic feature size rather insensitive to the local geometry of the domain, in contrast with its predecessors (local feature size, weak feature size, homology feature size). This reduces the number of samples required to capture the topology of X, provided that a reliable approximation to the intrinsic metric of X is available. Under sufficient sampling conditions involving the systolic feature size, we show that the geodesic Delaunay triangulation Dx(L) of a finite sampling L is homotopy equivalent to X. Under similar conditions, Dx(L) is sandwiched between the geodesic witness complex CWX(L) and a relaxed version CWX,ν(L). In the conference version of the article, we took advantage of this fact and proved that the homology of Dx(L) (and hence the one of X) can be retrieved by computing the persistent homology between CWX(L) and CWX,ν(L). Here, we investigate further and show that the homology of X can also be recovered from the persistent homology associated with inclusions of type CWX,ν(L)↪CWX,ν′(L), under some conditions on the parameters ν≤ν′. Similar results are obtained for Vietoris-Rips complexes in the intrinsic metric. The proofs draw some connections with recent advances on the front of homology inference from point cloud data, but also with several well-known concepts of Riemannian (and even metric) geometry. On the algorithmic front, we propose algorithms for estimating the systolic feature size of a bounded planar domain X, selecting a landmark set of sufficient density, and computing the homology of X using geodesic witness complexes or Rips complexes.},
journal = {ACM Trans. Algorithms},
month = sep,
articleno = {67},
numpages = {47},
keywords = {witness complex, feature size, Alexandrov space, intrinsic metric, systole, Delaunay triangulation}
}

@inproceedings{10.1145/1854229.1854238,
author = {Levett, Chris P. and Jhumka, Arshad and Anand, Sarabjot Singh},
title = {Towards Event Ordering in Digital Forensics},
year = {2010},
isbn = {9781450302869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1854229.1854238},
doi = {10.1145/1854229.1854238},
abstract = {In criminal investigation and criminal justice, investigators are usually faced with several reports, which contain a set of events of interest. Often, it is important to be able to order these events so that relevant queries can be posed on this ordering, such as "was X at location Y when the murder took place?". However, ordering of these events is very difficult, especially if very few events are anchored in time, i.e., few events are associated with an explicit time. Manual extraction of all the events of interest from these reports is tedious. On the other hand, automated extraction is inaccurate at best, in the sense that either several events that may not be important could be included. This ultimately gives a large set of events to consider, and imposing an ordering on this set can yield a large tree structure, where nodes represent an event of interest, and an edge (i, j) indicates that event i occurred before or at the same time as event j, and the root node represents a special "start" event. In this paper, we investigate two techniques for automating extraction of events, and then ordering these. We compare the efficiency of the techniques through the size of the tree structure obtained},
booktitle = {Proceedings of the 12th ACM Workshop on Multimedia and Security},
pages = {35–42},
numpages = {8},
keywords = {machine learning, timestamps, forensics, ordering},
location = {Roma, Italy},
series = {MM&amp;Sec '10}
}

@inproceedings{10.1145/1854273.1854282,
author = {Ganesan, Karthik and Jo, Jungho and Bircher, W. Lloyd and Kaseridis, Dimitris and Yu, Zhibin and John, Lizy K.},
title = {System-Level Max Power (SYMPO): A Systematic Approach for Escalating System-Level Power Consumption Using Synthetic Benchmarks},
year = {2010},
isbn = {9781450301787},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1854273.1854282},
doi = {10.1145/1854273.1854282},
abstract = {To effectively design a computer system for the worst case power consumption scenario, system architects often use hand-crafted maximum power consuming benchmarks at the assembly language level. These stressmarks, also called power viruses, are very tedious to generate and require significant domain knowledge. In this paper, we propose SYMPO, an automatic SYstem level Max POwer virus generation framework, which maximizes the power consumption of the CPU and the memory system using genetic algorithm and an abstract workload generation framework. For a set of three ISAs, we show the efficacy of the power viruses generated using SYMPO by comparing the power consumption with that of MPrime torture test, which is widely used by industry to test system stability. Our results show that the usage of SYMPO results in the generation of power viruses that consume 14-41% more power compared to MPrime on SPARC ISA. The genetic algorithm achieved this result in about 70 to 90 generations in 11 to 15 hours when using a full system simulator. We also show that the power viruses generated in the Alpha ISA consume 9-24% more power compared to the previous approach of stressmark generation. We measure and provide the power consumption of these benchmarks on hardware by instrumenting a quad-core AMD Phenom II X4 system. The SYMPO power virus consumes more power compared to various industry grade power viruses on x86 hardware. We also provide a microarchitecture independent characterization of various industry standard power viruses.},
booktitle = {Proceedings of the 19th International Conference on Parallel Architectures and Compilation Techniques},
pages = {19–28},
numpages = {10},
keywords = {thermal design point, synthetic benchmark, system-level power virus},
location = {Vienna, Austria},
series = {PACT '10}
}

@inproceedings{10.1145/1854273.1854321,
author = {Tournavitis, Georgios and Franke, Bj\"{o}rn},
title = {Semi-Automatic Extraction and Exploitation of Hierarchical Pipeline Parallelism Using Profiling Information},
year = {2010},
isbn = {9781450301787},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1854273.1854321},
doi = {10.1145/1854273.1854321},
abstract = {In recent years multi-core computer systems have left the realm of high-performance computing and virtually all of today's desktop computers and embedded computing systems are equipped with several processing cores. Still, no single parallel programming model has found widespread support and parallel programming remains an art for the majority of application programmers. In addition, there exists a plethora of sequential legacy applications for which automatic parallelization is the only hope to benefit from the increased processing power of modern multi-core systems. In the past automatic parallelization largely focused on data parallelism. In this paper we present a novel approach to extracting and exploiting pipeline parallelism from sequential applications. We use profiling to overcome the limitations of static data and control flow analysis enabling more aggressive parallelization. Our approach is orthogonal to existing automatic parallelization approaches and additional data parallelism may be exploited in the individual pipeline stages. The key contribution of this paper is a whole-program representation that supports profiling, parallelism extraction and exploitation. We demonstrate how this enhances conventional pipeline parallelization by incorporating support for multi-level loops and pipeline stage replication in a uniform and automatic way. We have evaluated our methodology on a set of multimedia and stream processing benchmarks and demonstrate speedups of up to 4.7 on a eight-core Intel Xeon machine.},
booktitle = {Proceedings of the 19th International Conference on Parallel Architectures and Compilation Techniques},
pages = {377–388},
numpages = {12},
keywords = {parallelization, streaming applications, program dependence graph, pipeline parallelism},
location = {Vienna, Austria},
series = {PACT '10}
}

@inproceedings{10.1145/1868328.1868338,
author = {Lavazza, Luigi and Robiolo, Gabriela},
title = {The Role of the Measure of Functional Complexity in Effort Estimation},
year = {2010},
isbn = {9781450304047},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868328.1868338},
doi = {10.1145/1868328.1868338},
abstract = {Background. Currently there are several definitions of measures that should represent the size of software functional requirements. These measures have gained a quite relevant role, since they are one of the few basis upon which effort estimation can be based. However, traditional Functional Size Measures do not take into account the amount and complexity of the elaboration required, concentrating instead on the amount of data accessed or moved. This is a problem, when it comes to effort estimation, since the amount and complexity of the required data elaborations affect the implementation effort, but are not adequately represented by the current measures (including the standardized ones).Objective. The paper evaluates different types of functional size measures as effort estimators. Moreover, the consequences of taking into consideration also the amount and complexity of required elaboration in the effort estimation models are evaluated.Methods. In this paper we take into consideration a representative set of functional size measures (namely, function points, COSMIC function points and use case points) and a recently proposed elaboration complexity measure (Paths) and evaluate how well these measures are correlated with the development effort. To this end, we measured a set of 17 projects and analyzed the resulting data.Results. We found that it is possible to build statistically valid models of the development effort that use the functional size and complexity measures as independent variables. In fact, we discovered that using the measure of elaboration complexity in addition to the functional size substantially improves the precision of the fitting.Conclusions. The analysis reported here suggests that a measure of the amount and complexity of elaboration required from a software system should be used, in conjunction with traditional functional size measures, in the estimation of software development effort. Further investigations, involving a greater number of projects, are however needed to confirm these findings.},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
articleno = {6},
numpages = {10},
keywords = {use case points, functional size measurement, use case-based measurement, effort estimation, COSMIC function points, functional complexity measurement, function points},
location = {Timi\c{s}oara, Romania},
series = {PROMISE '10}
}

@inproceedings{10.1145/1852786.1852794,
author = {Murgia, Alessandro and Concas, Giulio and Marchesi, Michele and Tonelli, Roberto},
title = {A Machine Learning Approach for Text Categorization of Fixing-Issue Commits on CVS},
year = {2010},
isbn = {9781450300391},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1852786.1852794},
doi = {10.1145/1852786.1852794},
abstract = {We studied data mining from CVS repositories of two large OO projects, Eclipse and Netbeans, focusing on "fixing-issue" commits.We highlight common characteristics of issue reporting, and problems related to the identification of these messages, and compare static traditional approaches, like Knowledge Engineering, to dynamic approaches based on Machine Learning techniques. We compare for the first time performances of Machine Learning (ML) techniques to automatic classify "fixing-issues" among message commits. Our study calculates precision and recall of different Machine Learning Classifiers for the correct classification of issue-reporting commits. Our results show that some ML classifiers can correctly classify up to 99.9% of such commits.},
booktitle = {Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {6},
numpages = {10},
keywords = {classifier, data mining, machine learning},
location = {Bolzano-Bozen, Italy},
series = {ESEM '10}
}

@inproceedings{10.1145/1852786.1852804,
author = {Li, Jingyue and Moe, Nils B. and Dyb\r{a}, Tore},
title = {Transition from a Plan-Driven Process to Scrum: A Longitudinal Case Study on Software Quality},
year = {2010},
isbn = {9781450300391},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1852786.1852804},
doi = {10.1145/1852786.1852804},
abstract = {Although Scrum is an important topic in software engineering and information systems, few longitudinal industrial studies have investigated the effects of Scrum on software quality, in terms of defects and defect density, and the quality assurance process. In this paper we report on a longitudinal study in which we have followed a project over a three-year period. We compared software quality assurance processes and software defects of the project between a 17-month phase with a plan-driven process, followed by a 20-month phase with Scrum. The results of the study did not show a significant reduction of defect densities or changes of defect profiles after Scrum was used. However, the iterative nature of Scrum resulted in constant system and acceptance testing and related defect fixing, which made the development process more efficient in terms of fewer surprises and better control of software quality and release date. In addition, software quality and knowledge sharing got more focus when using Scrum. However, Scrum put more stress and time pressure on the developers, and made them reluctant to perform certain tasks for later maintenance, such as refactoring.},
booktitle = {Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {13},
numpages = {10},
keywords = {empirical software engineering, agile software development, software quality},
location = {Bolzano-Bozen, Italy},
series = {ESEM '10}
}

@inproceedings{10.1145/1852786.1852817,
author = {Jalali, Samireh and Gencel, Cigdem and \v{S}mite, Darja},
title = {Trust Dynamics in Global Software Engineering},
year = {2010},
isbn = {9781450300391},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1852786.1852817},
doi = {10.1145/1852786.1852817},
abstract = {Trust is one of the key factors that determines success or failure of any software project. However, achieving and maintaining trust in distributed software projects, when team members are geographically, temporally and culturally distant from each other, is a remarkable challenge. This paper explores the dynamics of trust and best practices performed in software organizations to address trust-related issues in global software engineering. Semi-structured interviews were conducted in six different distributed software development organizations and a resulting trust dynamics model is presented. Based on the findings, the paper also provides suggestions for the industry to achieve trust in distributed collaborations.},
booktitle = {Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {23},
numpages = {9},
keywords = {trust building, global software engineering, trust maintenance, trust},
location = {Bolzano-Bozen, Italy},
series = {ESEM '10}
}

@inproceedings{10.1145/1852786.1852808,
author = {Qattous, Hazem and Gray, Philip and Welland, Ray},
title = {An Empirical Study of Specification by Example in a Software Engineering Tool},
year = {2010},
isbn = {9781450300391},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1852786.1852808},
doi = {10.1145/1852786.1852808},
abstract = {Meta-CASE tools offer CASE tool specialisation by enabling a designer to specify a tool which is then generated automatically. Constraints are often used in such meta-CASE tools for governing the syntax and semantics of model elements and the values of their attributes. However, the constraint definition process is complex, time-consuming and error-prone. This paper presents an empirical study of the use of Specification by Example (SBE), based on the well-known notion of Programming by Example (PBE), as a user-computer interactive technique for such constraint specification. Two constraint specification techniques have been implemented in a meta-CASE tool a wizard that represents a conventional form-filling technique and an SBE technique that depends on the user providing one or more examples and the system inferring a list of possible intended constraints. The empirical study compared the wizard and SBE with respect to constraint definition correctness, task completion time, and user satisfaction. Two common modelling diagrams have been used, a State Transition Diagram and a Use Case Diagram. Results suggest that SBE is superior to the wizard in terms of measured criteria described above. Observations on the interaction of users with the system and opinions of participants are also presented.},
booktitle = {Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {16},
numpages = {10},
keywords = {meta-CASE tools, programming by example, specification by example, user study, domain specific language, example-based interface},
location = {Bolzano-Bozen, Italy},
series = {ESEM '10}
}

@inproceedings{10.1145/1941007.1941009,
author = {Dufresne, Aude and Courtemanche, Fran\c{c}ois and Tep, Sandrine Prom},
title = {Analyse Des Interactions En Utilisant Le Suivi Oculaire, Le Suivi Physiologique et Les Structures d'actions},
year = {2010},
isbn = {9781450304108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1941007.1941009},
doi = {10.1145/1941007.1941009},
abstract = {In order to improve human-computer interaction, eye-tracking measures and physiological reactions are combined to the context of navigation and the structure of actions to analyze emotional state of users. Understanding affective reactions is essential to improve the human-computer interaction and the design of systems. In the domain of e-commerce those techniques are being used informally to observe interactions during the design of systems or for research, more systematic methods are necessary to efficiently highlight important aspects of the interaction and the emotional reactions. More so to help interpret measures it is necessary to complete measures with the recognition of structures of actions, so that reactions could be interpreted in context.},
booktitle = {Proceedings of the 22nd Conference on l'Interaction Homme-Machine},
pages = {1–8},
numpages = {8},
keywords = {UGC, physiological measures, emotions, machine learning, e-commerce, task models, eye-tracking, interaction evaluation},
location = {Luxembourg, Luxembourg},
series = {IHM '10}
}

@inproceedings{10.1145/1863482.1863489,
author = {Lobachev, Oleg and Loogen, Rita},
title = {Estimating Parallel Performance, a Skeleton-Based Approach},
year = {2010},
isbn = {9781450302548},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1863482.1863489},
doi = {10.1145/1863482.1863489},
abstract = {In this paper we estimate parallel execution times, based on identifying separate "parts" of the work done by parallel programs. We assume that programs are described using algorithmic skeletons. Therefore our runtime analysis works without any source code inspection. The time of parallel program execution is expressed in terms of the sequential work and the parallel penalty. We measure these values for different problem sizes and numbers of processors and estimate them for unknown values in both dimensions. This allows us to predict parallel execution time for unknown inputs and non-available processor numbers.Another useful application of our formalism is a measure of parallel program quality. We analyse the values for parallel penalty both for growing input size and for increasing numbers of processing elements. From these data, conclusions on parallel performance and scalability are drawn.},
booktitle = {Proceedings of the Fourth International Workshop on High-Level Parallel Programming and Applications},
pages = {25–34},
numpages = {10},
keywords = {serial fraction, algorithmic skeletons, scalability measure, amdahl's law, parallel runtime, forecasting, polynomial regression, runtime estimation},
location = {Baltimore, Maryland, USA},
series = {HLPP '10}
}

@inproceedings{10.1145/1864349.1864394,
author = {Madan, Anmol and Cebrian, Manuel and Lazer, David and Pentland, Alex},
title = {Social Sensing for Epidemiological Behavior Change},
year = {2010},
isbn = {9781605588438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1864349.1864394},
doi = {10.1145/1864349.1864394},
abstract = {An important question in behavioral epidemiology and public health is to understand how individual behavior is affected by illness and stress. Although changes in individual behavior are intertwined with contagion, epidemiologists today do not have sensing or modeling tools to quantitatively measure its effects in real-world conditions. In this paper, we propose a novel application of ubiquitous computing. We use mobile phone based co-location and communication sensing to measure characteristic behavior changes in symptomatic individuals, reflected in their total communication, interactions with respect to time of day (e.g., late night, early morning), diversity and entropy of face-to-face interactions and movement. Using these extracted mobile features, it is possible to predict the health status of an individual, without having actual health measurements from the subject. Finally, we estimate the temporal information flux and implied causality between physical symptoms, behavior and mental health.},
booktitle = {Proceedings of the 12th ACM International Conference on Ubiquitous Computing},
pages = {291–300},
numpages = {10},
keywords = {mobile sensing, spatial epidemiology, social computing},
location = {Copenhagen, Denmark},
series = {UbiComp '10}
}

@inproceedings{10.1145/1864349.1864393,
author = {Rachuri, Kiran K. and Musolesi, Mirco and Mascolo, Cecilia and Rentfrow, Peter J. and Longworth, Chris and Aucinas, Andrius},
title = {EmotionSense: A Mobile Phones Based Adaptive Platform for Experimental Social Psychology Research},
year = {2010},
isbn = {9781605588438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1864349.1864393},
doi = {10.1145/1864349.1864393},
abstract = {Today's mobile phones represent a rich and powerful computing platform, given their sensing, processing and communication capabilities. Phones are also part of the everyday life of billions of people, and therefore represent an exceptionally suitable tool for conducting social and psychological experiments in an unobtrusive way.de the ability of sensing individual emotions as well as activities, verbal and proximity interactions among members of social groups. Moreover, the system is programmable by means of a declarative language that can be used to express adaptive rules to improve power saving. We evaluate a system prototype on Nokia Symbian phones by means of several small-scale experiments aimed at testing performance in terms of accuracy and power consumption. Finally, we present the results of real deployment where we study participants emotions and interactions. We cross-validate our measurements with the results obtained through questionnaires filled by the users, and the results presented in social psychological studies using traditional methods. In particular, we show how speakers and participants' emotions can be automatically detected by means of classifiers running locally on off-the-shelf mobile phones, and how speaking and interactions can be correlated with activity and location measures.},
booktitle = {Proceedings of the 12th ACM International Conference on Ubiquitous Computing},
pages = {281–290},
numpages = {10},
keywords = {speaker recognition, mobile phones, social psychology, emotion recognition, energy efficiency},
location = {Copenhagen, Denmark},
series = {UbiComp '10}
}

@inproceedings{10.1145/1864349.1864376,
author = {Dillahunt, Tawanna and Mankoff, Jennifer and Paulos, Eric},
title = {Understanding Conflict between Landlords and Tenants: Implications for Energy Sensing and Feedback},
year = {2010},
isbn = {9781605588438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1864349.1864376},
doi = {10.1145/1864349.1864376},
abstract = {Energy use in the home is a topic of increasing interest and concern, and one on which technology can have a significant impact. However, existing work typically focuses on moderately affluent homeowners who have relative autonomy with respect to their home, or does not address socio-economic status, class, and other related issues. For the 30% of the U.S. population who rent their homes, many key decisions regarding energy use must be negotiated with a landlord. Because energy use impacts the bottom line of both landlords and tenants, this can be a source of conflict in the landlord/tenant relationship. Ubicomp technologies for reducing energy use in rental units must engage with landlord/tenant conflicts to be successful. Unfortunately, little detailed knowledge is available about the impact of landlord/tenant conflicts on energy use. We present an analysis of a series of qualitative studies with landlords and tenants. We argue that a consideration of multiple stakeholders, and the power imbalances among them, will drive important new research questions and lead to more widely applicable solutions. The main contribution of our work is a set of open research questions and design recommendations for technologies that may affect and be affected by the conflict between stakeholders around energy use.},
booktitle = {Proceedings of the 12th ACM International Conference on Ubiquitous Computing},
pages = {149–158},
numpages = {10},
keywords = {energy, domestic computing, inequality, sustainability},
location = {Copenhagen, Denmark},
series = {UbiComp '10}
}

@inproceedings{10.1145/1864349.1864359,
author = {Tentori, Monica and Hayes, Gillian R.},
title = {Designing for Interaction Immediacy to Enhance Social Skills of Children with Autism},
year = {2010},
isbn = {9781605588438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1864349.1864359},
doi = {10.1145/1864349.1864359},
abstract = {Children with Autism Spectrum Disorder often require therapeutic interventions to support engagement in effective social interactions. In this paper, we present the results of a study conducted in three public schools that use an educational and behavioral intervention for the instruction of social skills in changing situational contexts. The results of this study led to the concept of interaction immediacy to help children maintain appropriate spatial boundaries, reply to conversation initiators, disengage appropriately at the end of an interaction, and identify potential communication partners. We describe design principles for Ubicomp technologies to support interaction immediacy and present an example design. The contribution of this work is twofold. First, we present an understanding of social skills in mobile and dynamic contexts. Second, we introduce the concept of interaction immediacy and show its effectiveness as a guiding principle for the design of Ubicomp applications.},
booktitle = {Proceedings of the 12th ACM International Conference on Ubiquitous Computing},
pages = {51–60},
numpages = {10},
keywords = {interaction immediacy, social skills, autism, social compass},
location = {Copenhagen, Denmark},
series = {UbiComp '10}
}

@inproceedings{10.1145/1864349.1864358,
author = {Whittle, Jon and Simm, William and Ferrario, Maria-Angela and Frankova, Katerina and Garton, Laurence and Woodcock, Andr\'{e}e and Nasa, Baseerit and Binner, Jane and Ariyatum, Aom},
title = {VoiceYourView: Collecting Real-Time Feedback on the Design of Public Spaces},
year = {2010},
isbn = {9781605588438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1864349.1864358},
doi = {10.1145/1864349.1864358},
abstract = {This paper reports on VoiceYourView, a kind of intelligent kiosk, which uses speech recognition and natural language processing to gather the public's creative input on the public space designs. Over a six week period, VoiceYourView was deployed in a public space and 2000 design critiques were collected from 600 people. The paper shows that people are capable of providing creative input on their environment using unstructured speech or text and that a good proportion of these comments are actionable. The paper also investigates the use of public displays to auto-summarize comments left by the public so far. Although there is anecdotal evidence that this encourages participation, an experiment found that filtering comments (e.g., to display only positive responses) had no effect on what people had to say.},
booktitle = {Proceedings of the 12th ACM International Conference on Ubiquitous Computing},
pages = {41–50},
numpages = {10},
keywords = {public reporting, civic engagement, intelligent kiosk},
location = {Copenhagen, Denmark},
series = {UbiComp '10}
}

@inproceedings{10.1145/1863543.1863576,
author = {Crestani, Marcus and Sperber, Michael},
title = {Experience Report: Growing Programming Languages for Beginning Students},
year = {2010},
isbn = {9781605587943},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1863543.1863576},
doi = {10.1145/1863543.1863576},
abstract = {A student learning how to program learns best when the programming language and programming environment cater to her specific needs. These needs are different from the requirements of a professional programmer. Consequently, the design of teaching languages poses challenges different from the design of professional languages. Using a functional language by itself gives advantages over more popular, professional languages, but fully exploiting these advantages requires careful adaptation to the needs of the students' as-is, these languages do not support the students nearly as well as they could. This paper describes our experience adopting the didactic approach of How to Design Programs, focussing on the design process for our own set of teaching languages. We have observed students as they try to program as part of our introductory course, and used these observations to significantly improve the design of these languages. This paper describes the changes we have made, and the journey we took to get there.},
booktitle = {Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
pages = {229–234},
numpages = {6},
keywords = {introductory programming},
location = {Baltimore, Maryland, USA},
series = {ICFP '10}
}

@article{10.1145/1932681.1863576,
author = {Crestani, Marcus and Sperber, Michael},
title = {Experience Report: Growing Programming Languages for Beginning Students},
year = {2010},
issue_date = {September 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {9},
issn = {0362-1340},
url = {https://doi.org/10.1145/1932681.1863576},
doi = {10.1145/1932681.1863576},
abstract = {A student learning how to program learns best when the programming language and programming environment cater to her specific needs. These needs are different from the requirements of a professional programmer. Consequently, the design of teaching languages poses challenges different from the design of professional languages. Using a functional language by itself gives advantages over more popular, professional languages, but fully exploiting these advantages requires careful adaptation to the needs of the students' as-is, these languages do not support the students nearly as well as they could. This paper describes our experience adopting the didactic approach of How to Design Programs, focussing on the design process for our own set of teaching languages. We have observed students as they try to program as part of our introductory course, and used these observations to significantly improve the design of these languages. This paper describes the changes we have made, and the journey we took to get there.},
journal = {SIGPLAN Not.},
month = sep,
pages = {229–234},
numpages = {6},
keywords = {introductory programming}
}

@inproceedings{10.1145/2377576.2377580,
author = {Donmez, Birsen and Cummings, M. L.},
title = {Metric Selection for Evaluating Human Supervisory Control of Unmanned Vehicles},
year = {2010},
isbn = {9781450302906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2377576.2377580},
doi = {10.1145/2377576.2377580},
abstract = {Broad metric classes were proposed in the literature in order to facilitate metric selection for evaluating human-autonomous vehicle interaction. However, there still lacks a systematic method for selecting an efficient set of metrics from the many metrics available. We previously identified a list of evaluation criteria that can help determine the quality of a metric, and generated a list of potential metric costs and benefits. Depending on research objectives and limitations, these costs and benefits can have different weights of importance. Through an experiment with subject matter experts, we investigated which metric characteristics human factors practitioners consider to be important in evaluating human supervisory control of unmanned vehicles. We also tested two different multi-criteria decision making methods to help practitioners assign subjective weights to the cost/benefit criteria. The majority of participants rated the evaluation criteria used in both tools as very useful. However, the majority of participants' metric selections before using the methods were the same as the suggestions provided by the methods. Since determining weights of metric importance is an inherently subjective process, even with objective computational tools, the real value of using such a tool may be reminding human factors practitioners of the important experimental criteria and relationships between these criteria that should be considered when designing an experiment.},
booktitle = {Proceedings of the 10th Performance Metrics for Intelligent Systems Workshop},
pages = {14–21},
numpages = {8},
keywords = {metrics, metric quality, analytic hierarchy process, experiments, AHP, human supervisory control},
location = {Baltimore, Maryland},
series = {PerMIS '10}
}

@inproceedings{10.1145/1869652.1869660,
author = {D\'{\i}ez, Fernando and Chavarriaga, J. Enrique and Campos, Pedro G. and Bellog\'{\i}n, Alejandro},
title = {Movie Recommendations Based in Explicit and Implicit Features Extracted from the <i>Filmtipset</i> Dataset},
year = {2010},
isbn = {9781450302586},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1869652.1869660},
doi = {10.1145/1869652.1869660},
abstract = {In this paper, we describe the experiments conducted by the Information Retrieval Group at the Universidad Aut\'{o}noma de Madrid (Spain) in order to better recommend movies for the 2010 CAMRa Challenge edition. Experiments were carried out on the dataset corresponding to social Filmtipset track. To obtain the movies recommendations we have used different algorithms based on Random Walks, which are well documented in the literature of collaborative recommendation. We have also included a new proposal in one of the algorithms in order to get better results. The results obtained have been computed by means of the trec_eval standard NIST evaluation procedure.},
booktitle = {Proceedings of the Workshop on Context-Aware Movie Recommendation},
pages = {45–52},
numpages = {8},
keywords = {challenge, social networks, random walk, movie recommendations, recommender systems},
location = {Barcelona, Spain},
series = {CAMRa '10}
}

@inproceedings{10.1145/1863509.1863515,
author = {Fritchie, Scott Lystig},
title = {Chain Replication in Theory and in Practice},
year = {2010},
isbn = {9781450302531},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1863509.1863515},
doi = {10.1145/1863509.1863515},
abstract = {When implementing a distributed storage system, using an algorithm with a formal definition and proof is a wise idea. However, translating any algorithm into effective code can be difficult because the implementation must be both correct and fast.This paper is a case study of the implementation of the chain replication protocol in a distributed key-value store called Hibari. In theory, the chain replication algorithm is quite simple and should be straightforward to implement correctly. In practice, however, there were many implementation details that had effects both profound and subtle. The Erlang community, as well as distributed systems implementors in general, can use the lessons learned with Hibari (specifically in areas of performance enhancements and failure detection) to avoid many dangers that lurk at the interface between theory and real-world computing.},
booktitle = {Proceedings of the 9th ACM SIGPLAN Workshop on Erlang},
pages = {33–44},
numpages = {12},
keywords = {key-value store, chain replication, hibari, erlang},
location = {Baltimore, Maryland, USA},
series = {Erlang '10}
}

@inproceedings{10.1145/1940941.1940975,
author = {Lamis, Trevor},
title = {A Forensic Approach to Incident Response},
year = {2010},
isbn = {9781450302029},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1940941.1940975},
doi = {10.1145/1940941.1940975},
abstract = {An incident response plan is critical for the detection and removal of information security threats. Incident response involves many aspects other than technical issues. There are management, legal, and social issues that an incident response team needs to consider. An incident response identifies, contains, and eliminates the incident. Then, the compromised system is fully recovered and restored. To hold the intruder accountable, a forensic investigation is needed. Documentation of all activities and evidence gathering is crucial when during the entire response and investigation. The paper proposes and discusses interconnected methodological frameworks for both incident response and network forensics.},
booktitle = {2010 Information Security Curriculum Development Conference},
pages = {177–185},
numpages = {9},
keywords = {network traces, evidence, incident response, network forensics},
location = {Kennesaw, Georgia},
series = {InfoSecCD '10}
}

@inproceedings{10.1145/1866029.1866062,
author = {Mueller, Florian and Vetere, Frank and Gibbs, Martin R. and Edge, Darren and Agamanolis, Stefan and Sheridan, Jennifer G.},
title = {Jogging over a Distance between Europe and Australia},
year = {2010},
isbn = {9781450302715},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1866029.1866062},
doi = {10.1145/1866029.1866062},
abstract = {Exertion activities, such as jogging, require users to invest intense physical effort and are associated with physical and social health benefits. Despite the benefits, our understanding of exertion activities is limited, especially when it comes to social experiences. In order to begin understanding how to design for technologically augmented social exertion experiences, we present "Jogging over a Distance", a system in which spatialized audio based on heart rate allowed runners as far apart as Europe and Australia to run together. Our analysis revealed how certain aspects of the design facilitated a social experience, and consequently we describe a framework for designing augmented exertion activities. We make recommendations as to how designers could use this framework to aid the development of future social systems that aim to utilize the benefits of exertion.},
booktitle = {Proceedings of the 23nd Annual ACM Symposium on User Interface Software and Technology},
pages = {189–198},
numpages = {10},
keywords = {mobile phone, heart rate, spatialization, exergaming, physiological data, running, exergame, whole-body interaction, sports, exertion interface, audio},
location = {New York, New York, USA},
series = {UIST '10}
}

@inproceedings{10.1145/1866307.1866346,
author = {Corrigan-Gibbs, Henry and Ford, Bryan},
title = {Dissent: Accountable Anonymous Group Messaging},
year = {2010},
isbn = {9781450302456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1866307.1866346},
doi = {10.1145/1866307.1866346},
abstract = {Users often wish to participate in online groups anonymously, but misbehaving users may abuse this anonymity to disrupt the group's communication. Existing messaging protocols such as DC-nets leave groups vulnerable to denial-of-service and Sybil attacks, Mix-nets are difficult to protect against traffic analysis, and accountable voting protocols are unsuited to general anonymous messaging.We present the first general messaging protocol that offers provable anonymity with accountability for moderate-size groups, and efficiently handles unbalanced loads where few members wish to transmit in a given round. The N group members first cooperatively shuffle an N x N matrix of pseudorandom seeds, then use these seeds in N "pre-planned" DC-nets protocol runs. Each DC-nets run transmits the variable-length bulk data comprising one member's message, using the minimum number of bits required for anonymity under our attack model. The protocol preserves message integrity and one-to-one correspondence between members and messages, makes denial-of-service attacks by members traceable to the culprit, and efficiently handles large, unbalanced message loads. A working prototype demonstrates the protocol's practicality for anonymous messaging in groups of 40+ members.},
booktitle = {Proceedings of the 17th ACM Conference on Computer and Communications Security},
pages = {340–350},
numpages = {11},
keywords = {denial of service, peer-to-peer networks, anonymity, accountability, group communication, verifiable anonymous shuffle},
location = {Chicago, Illinois, USA},
series = {CCS '10}
}

@inproceedings{10.1145/1866919.1866923,
author = {Asuncion, Arthur U. and Goodrich, Michael T.},
title = {Turning Privacy Leaks into Floods: Surreptitious Discovery of Social Network Friendships and Other Sensitive Binary Attribute Vectors},
year = {2010},
isbn = {9781450300964},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1866919.1866923},
doi = {10.1145/1866919.1866923},
abstract = {We study methods for attacking the privacy of social networking sites, collaborative filtering sites, databases of genetic signatures, and other data sets that can be represented as vectors of binary relationships. Our methods are based on reductions to nonadaptive group testing, which implies that our methods can exploit a minimal amount of privacy leakage, such as contained in a single bit that indicates if two people in a social network have a friend in common or not. We analyze our methods for turning such privacy leaks into floods using theoretical characterizations as well as experimental tests. Our empirical analyses are based on experiments involving privacy attacks on the social networking sites Facebook and LiveJournal, a database of mitochondrial DNA, a power grid network, and the movie-rating database released as a part of the Netflix Prize contest. For instance, with respect to Facebook, our analysis shows that it is effectively possible to break the privacy of members who restrict their friends lists to friends-of-friends.},
booktitle = {Proceedings of the 9th Annual ACM Workshop on Privacy in the Electronic Society},
pages = {21–30},
numpages = {10},
keywords = {binary attribute vectors, combinatorial group testing, social networks, genetic signatures, privacy leaks},
location = {Chicago, Illinois, USA},
series = {WPES '10}
}

@inproceedings{10.1145/1866307.1866310,
author = {Christin, Nicolas and Yanagihara, Sally S. and Kamataki, Keisuke},
title = {Dissecting One Click Frauds},
year = {2010},
isbn = {9781450302456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1866307.1866310},
doi = {10.1145/1866307.1866310},
abstract = {"One Click Fraud" is an online confidence scam that has been plaguing an increasing number of Japanese Internet users, in spite of new laws and the mobilization of police task forces. In this scam, the victim clicks on a link presented to them, only to be informed that they just entered a binding contract and are required to pay a registration fee for a service. Even though no money is legally owed, a large number of users prefer to pay up, because of potential embarrassment due to the type of service "requested" (e.g., pornographic goods).Using public reports of fraudulent websites as a source of data, we analyze over 2,000 reported One Click Frauds incidents. By correlating several attributes (WHOIS data, bank accounts, phone numbers, malware installed...), we discover that a few fraudsters are seemingly responsible for a majority of the scams, and evidence a number of loopholes these miscreants exploit. We further show that, while some of these sites may also be engaging in other illicit activities such as spamming, the connection between different types of scams is not as obvious as we initially expected. Last, we show that the rise in the number of these frauds is fueled by high expected monetary gains in return for very little risk. The quantitative data obtained gives us an interesting window on the economic dynamics of some online criminal syndicates.},
booktitle = {Proceedings of the 17th ACM Conference on Computer and Communications Security},
pages = {15–26},
numpages = {12},
keywords = {online crime, web frauds},
location = {Chicago, Illinois, USA},
series = {CCS '10}
}

@inproceedings{10.1145/1921081.1921086,
author = {Ganapathy, Priya and Joshi, Shantanu H. and Yadegar, Jacob and Kamat, Niranjan and Caluser, Calin},
title = {An Intelligent and Portable Ambulatory Medical Toolkit for Automatic Detection and Assessment of Traumatic Brain Injuries},
year = {2010},
isbn = {9781605589893},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1921081.1921086},
doi = {10.1145/1921081.1921086},
abstract = {We propose to develop a portable, handheld, noninvasive solution for accurate screening and real-time monitoring of traumatic brain injury (BI) in ambulatory/emergency response scenarios. A layered sensing concept that unifies alternate modalities such as a) ultrasound (US), b) near infrared spectroscopy (NIRS), c) tonometry (IOP), to predict BI, their severity and mode of recommendations for emergency medical service (EMS) personnel is offered. Specifically, we aim to determine i) novel 3D morphometric parameters of optic nerve sheath that can predict elevated intracranial pressure from US data, ii) incidence of intracranial hematomas using NIRS, iii) intraocular pressure using a tonometer, iv) cerebral blood flow and blood oxygen content using other auxiliary non-invasive sensing modes and v) finally provide a sensor fused outcome of all i)-iv) combined. This decision-support system (DSS) will improve BI detection by incorporating accurate on-site measurements that accounts for individual baseline variations and monitors temporal manifestation of the injury. The data collected and the preliminary analysis performed by the DSS will be sent to an emergency department (ED) physician stationed at a nearby trauma center via a wireless 3G network. Based on the available bandwidth, either all the data including the preliminary analysis (US video, images, 1D measurements, etc) or only the refined signals (feature vector extracted during screening) along with the DSS diagnosis will be sent to the physician. If the DSS determined output is agreeable to the physician then the screening can be terminated and the physician/ED staff can prepare to perform advanced interventions (intubation, cerebralspinal fluid (CSF) drainage, etc). If not, the on-call physician can inform the medic to repeat the scans/take additional measurements to obtain a more concrete outcome via the DSS. In summary, such a knowledge-driven system will equip a novice or a trained medic with an easy-to-use tool to detect traumatic BI and reduce the diagnosis time involved (i.e., computed tomography (CT) scan, clinical evaluation) in ED before performing advanced interventions and thereby improve the prognosis.},
booktitle = {Wireless Health 2010},
pages = {24–33},
numpages = {10},
location = {San Diego, California},
series = {WH '10}
}

@inproceedings{10.1145/1921081.1921092,
author = {Lockhart, Thurmon E. and Barth, Adam T. and Zhang, Xiaoyue and Songra, Rahul and Abdel-Rahman, Emaad and Lach, John},
title = {Portable, Non-Invasive Fall Risk Assessment in End Stage Renal Disease Patients on Hemodialysis},
year = {2010},
isbn = {9781605589893},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1921081.1921092},
doi = {10.1145/1921081.1921092},
abstract = {Patients with end stage renal diseases (ESRD) on hemodialysis (HD) have high morbidity and mortality due to multiple causes, one of which is dramatically higher fall rates than the general population. The mobility mechanisms that contribute to falls in this population must be understood if adequate interventions for fall prevention are to be achieved. This study utilizes emerging non-invasive, portable gait, posture, strength, and stability assessment technologies to extract various mobility parameters that research has shown to be predictive of fall risk in the general population. As part of an ongoing human subjects study, mobility measures such as postural and locomotion profiles were obtained from five (5) ESRD patients undergoing HD treatments. To assess the effects of post-HD-fatigue on fall risk, both the pre- and post-HD measurements were obtained. Additionally, the effects of inter-HD periods (two days vs. three days) were investigated using the non-invasive, wireless, body-worn motion capture technology and novel signal processing algorithms. The results indicated that HD treatment influenced strength and mobility (i.e., weaker and slower after the dialysis, increasing the susceptibility to falls while returning home) and inter-dialysis period influenced pre-HD profiles (increasing the susceptibility to falls before they come in for a HD treatment). Methodology for early detection of increased fall risk -- before a fall event occurs -- using the portable mobility assessment technology for out-patient monitoring is further explored, including targeting interventions to identified individuals for fall prevention.},
booktitle = {Wireless Health 2010},
pages = {84–93},
numpages = {10},
location = {San Diego, California},
series = {WH '10}
}

@inproceedings{10.1145/1921081.1921102,
author = {Zhang, Lei and Tamminedi, Tejaswi and Ganguli, Anurag and Yosiphon, Guy and Yadegar, Jacob},
title = {Hierarchical Multiple Sensor Fusion Using Structurally Learned Bayesian Network},
year = {2010},
isbn = {9781605589893},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1921081.1921102},
doi = {10.1145/1921081.1921102},
abstract = {Multiple sensor fusion is very important for wireless health monitoring since a single type of sensor usually can only provide limited aspects of the health condition while multiple sensors of different types hopefully can complement each other and yield more comprehensive aspects of the health condition. Many existing sensor fusion approaches are based on a flat structure, where multiple sensor features are treated as in the same layer and are fused by the feature-level fusion. In this paper we present a systematic approach using a structurally learned Bayesian Network (BN) for sensor fusion. The BN serves as a powerful framework that can integrate multiple sensor features in a hierarchy that is automatically learned via supervised learning. We present a hybrid structure learning approach that includes four steps and consists of both systematic global and local structure learning, as well as random perturbation for structure learning. Subsequent to the feature selection, we first learn an Augmented Bayesian Classifier (ABC) and it is followed by an extended K2 structure learning to search for a better structure in another structure subspace. Random structure learning is then performed to perturb the structure learning so as to avoid getting stuck in a local optimum. Finally, we perform local structure learning with hill-climbing by reversing or removing each link between features. The proposed hierarchical sensor fusion solution outperformed some conventional approaches such as Na\"{\i}ve Bayesian Classifier and Support Vector Machine classifier that integrate multiple sensor features by a flat feature-level fusion.},
booktitle = {Wireless Health 2010},
pages = {174–183},
numpages = {10},
keywords = {hierarchical sensor fusion, structure learning, wireless networking, classification, feature extraction, Bayesian network},
location = {San Diego, California},
series = {WH '10}
}

@inproceedings{10.1145/1921081.1921101,
author = {Wouhaybi, Rita H. and Yarvis, Mark D. and Muse, Philip and Wan, Chieh-Yih and Sharma, Sangita and Prasad, Sai and Durham, Lenitra and Sahni, Ritu and Norton, Robert and Curry, Merlin and Jimison, Holly and Harper, Richard and Lowe, Robert},
title = {A Context-Management Framework for Telemedicine: An Emergency Medicine Case Study},
year = {2010},
isbn = {9781605589893},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1921081.1921101},
doi = {10.1145/1921081.1921101},
abstract = {Patient care can be intense and stressful, especially in emergency care situations. Emergency care has two parts, field care by a paramedic and in-hospital care. Paramedics often consult with physicians before the patient reaches the hospital. To do this effectively, they must convey the patient's condition rapidly and effectively. Upon hospital arrival they must also transfer as much patient data as possible to ensure continuation of care. In this paper, we present a context-management framework for telemedicine that is designed to capture sensor data for transfer to a remote location. We further describe an application developed on top of the framework for emergency medicine. We examine design considerations for the application based on collaboration with medical personnel. Finally, we present technical results obtained from use of the technology in simulated emergency scenarios.},
booktitle = {Wireless Health 2010},
pages = {164–173},
numpages = {10},
keywords = {emergency medicine application, open platform, context-aware systems, telemedicine, sensor networks},
location = {San Diego, California},
series = {WH '10}
}

@inproceedings{10.1145/1930488.1930496,
author = {Foth, Marcus and Schroeter, Ronald},
title = {Enhancing the Experience of Public Transport Users with Urban Screens and Mobile Applications},
year = {2010},
isbn = {9781450300117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1930488.1930496},
doi = {10.1145/1930488.1930496},
abstract = {Public transportation is an environment with great potential for applying location-based services through mobile devices. This paper provides the underpinning rationale for research that will be looking at how the real-time passenger information system deployed by the Translink Transit Authority across all of South East Queensland in Australia can provide a core platform to improve commuters' user experiences. This system relies on mobile computing and GPS technology to provide accurate information on transport vehicle locations. The proposal builds on this platform to inform the design and development of innovative social media, mobile computing and geospatial information applications. The core aim is to digitally augment the public transport environment to enhance the user experience of commuters for a more enjoyable journey.},
booktitle = {Proceedings of the 14th International Academic MindTrek Conference: Envisioning Future Media Environments},
pages = {33–40},
numpages = {8},
keywords = {mobile technologies, passenger movements, public transport, ubiquitous computing, social media, interaction design, urban informatics},
location = {Tampere, Finland},
series = {MindTrek '10}
}

@inproceedings{10.1145/1866886.1866897,
author = {Nellikar, Suraj and Nicol, David M. and Choi, Jai J.},
title = {Role-Based Differentiation for Insider Detection Algorithms},
year = {2010},
isbn = {9781450300926},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1866886.1866897},
doi = {10.1145/1866886.1866897},
abstract = {Insider threat problems are widespread in industry today, resulting in large losses of intellectual property. Reputable reports assert that attacks from within an organization are on the rise, making detection of insider-based attacks a top priority. This paper evaluates the effectiveness of using role-based differentiation of user behavior as a tool in detecting insider attack behavior. This differentiation is natural in contexts where role-based access control (RBAC) mechanisms are in place. Using synthetically generated traffic (which puts placement and intensity of insider behavior under experimental control), we train five different algorithms on "normal" behavior with and without RBAC differentiation, and measure the accuracy of detecting malicious behavior with, and without RBAC, as a function of insider behavior. We find that in some contexts RBAC differentiation significantly reduces these errors. However, in our experiments two of the five algorithms had statistically significant increases in false positives under RBAC as opposed to non-RBAC. However, these increases are small compared to the very large gain in detection capability that RBAC brings, and we conclude that RBAC is very much worth considering as a tool for insider threat detection.},
booktitle = {Proceedings of the 2010 ACM Workshop on Insider Threats},
pages = {55–62},
numpages = {8},
keywords = {insider threat, role based access, insider detection algorithms, data mining algorithms},
location = {Chicago, Illinois, USA},
series = {Insider Threats '10}
}

@inproceedings{10.1145/1866835.1866837,
author = {Chow, Richard and Jakobsson, Markus and Masuoka, Ryusuke and Molina, Jesus and Niu, Yuan and Shi, Elaine and Song, Zhexuan},
title = {Authentication in the Clouds: A Framework and Its Application to Mobile Users},
year = {2010},
isbn = {9781450300896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1866835.1866837},
doi = {10.1145/1866835.1866837},
abstract = {Cloud computing is a natural fit for mobile security. Typical handsets have input constraints and practical computational and power limitations, which must be respected by mobile security technologies in order to be effective. We describe how cloud computing can address these issues. Our approach is based on a flexible framework for supporting authentication decisions we call TrustCube (to manage the authentication infrastructure) and on a behavioral authentication approach referred to as implicit authentication (to translate user behavior into authentication scores). The combination results in a new authentication paradigm for users of mobile technologies, one where an appropriate balance between usability and trust can be managed through flexible policies and dynamic tuning.},
booktitle = {Proceedings of the 2010 ACM Workshop on Cloud Computing Security Workshop},
pages = {1–6},
numpages = {6},
keywords = {authentication, mobile computing, cloud computing},
location = {Chicago, Illinois, USA},
series = {CCSW '10}
}

@inproceedings{10.5555/1870658.1870679,
author = {Mukherjee, Arjun and Liu, Bing},
title = {Improving Gender Classification of Blog Authors},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {The problem of automatically classifying the gender of a blog author has important applications in many commercial domains. Existing systems mainly use features such as words, word classes, and POS (part-of-speech) n-grams, for classification learning. In this paper, we propose two new techniques to improve the current result. The first technique introduces a new class of features which are variable length POS sequence patterns mined from the training data using a sequence pattern mining algorithm. The second technique is a new feature selection method which is based on an ensemble of several feature selection criteria and approaches. Empirical evaluation using a real-life blog data set shows that these two techniques improve the classification accuracy of the current state-of-the-art methods significantly.},
booktitle = {Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing},
pages = {207–217},
numpages = {11},
location = {Cambridge, Massachusetts},
series = {EMNLP '10}
}

@inproceedings{10.5555/1870658.1870756,
author = {Chiticariu, Laura and Krishnamurthy, Rajasekar and Li, Yunyao and Reiss, Frederick and Vaithyanathan, Shivakumar},
title = {Domain Adaptation of Rule-Based Annotators for Named-Entity Recognition Tasks},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Named-entity recognition (NER) is an important task required in a wide variety of applications. While rule-based systems are appealing due to their well-known "explainability," most, if not all, state-of-the-art results for NER tasks are based on machine learning techniques. Motivated by these results, we explore the following natural question in this paper: Are rule-based systems still a viable approach to named-entity recognition? Specifically, we have designed and implemented a high-level language NERL on top of SystemT, a general-purpose algebraic information extraction system. NERL is tuned to the needs of NER tasks and simplifies the process of building, understanding, and customizing complex rule-based named-entity annotators. We show that these customized annotators match or outperform the best published results achieved with machine learning techniques. These results confirm that we can reap the benefits of rule-based extractors' explainability without sacrificing accuracy. We conclude by discussing lessons learned while building and customizing complex rule-based annotators and outlining several research directions towards facilitating rule development.},
booktitle = {Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing},
pages = {1002–1012},
numpages = {11},
location = {Cambridge, Massachusetts},
series = {EMNLP '10}
}

@inproceedings{10.5555/1870658.1870714,
author = {Christodoulopoulos, Christos and Goldwater, Sharon and Steedman, Mark},
title = {Two Decades of Unsupervised POS Induction: How Far Have We Come?},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Part-of-speech (POS) induction is one of the most popular tasks in research on unsupervised NLP. Many different methods have been proposed, yet comparisons are difficult to make since there is little consensus on evaluation framework, and many papers evaluate against only one or two competitor systems. Here we evaluate seven different POS induction systems spanning nearly 20 years of work, using a variety of measures. We show that some of the oldest (and simplest) systems stand up surprisingly well against more recent approaches. Since most of these systems were developed and tested using data from the WSJ corpus, we compare their generalization abilities by testing on both WSJ and the multilingual Multext-East corpus. Finally, we introduce the idea of evaluating systems based on their ability to produce cluster prototypes that are useful as input to a prototype-driven learner. In most cases, the prototype-driven learner outperforms the unsupervised system used to initialize it, yielding state-of-the-art results on WSJ and improvements on non-English corpora.},
booktitle = {Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing},
pages = {575–584},
numpages = {10},
location = {Cambridge, Massachusetts},
series = {EMNLP '10}
}

@inproceedings{10.5555/1870658.1870769,
author = {Ahmed, Amr and Xing, Eric P.},
title = {Staying Informed: Supervised and Semi-Supervised Multi-View Topical Analysis of Ideological Perspective},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {With the proliferation of user-generated articles over the web, it becomes imperative to develop automated methods that are aware of the ideological-bias implicit in a document collection. While there exist methods that can classify the ideological bias of a given document, little has been done toward understanding the nature of this bias on a topical-level. In this paper we address the problem of modeling ideological perspective on a topical level using a factored topic model. We develop efficient inference algorithms using Collapsed Gibbs sampling for posterior inference, and give various evaluations and illustrations of the utility of our model on various document collections with promising results. Finally we give a Metropolis-Hasting inference algorithm for a semi-supervised extension with decent results.},
booktitle = {Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing},
pages = {1140–1150},
numpages = {11},
location = {Cambridge, Massachusetts},
series = {EMNLP '10}
}

@inproceedings{10.1145/1899503.1899508,
author = {Clough, Duncan and Rivera, Stefano and Kuttel, Michelle and Geddes, Vincent and Marais, Patrick},
title = {Panopticon: A Scalable Monitoring System},
year = {2010},
isbn = {9781605589503},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1899503.1899508},
doi = {10.1145/1899503.1899508},
abstract = {Monitoring systems are necessary for the management of anything beyond the smallest networks of computers. While specialised monitoring systems can be deployed to detect specific problems, more general systems are required to detect unexpected issues, and track performance trends.While large fleets of computers are becoming more common, few existing, general monitoring systems have the capability to scale to monitor these very large networks. There is also an absence of systems in the literature that cater for visualisation of monitoring information on a large scale.Scale is an issue in both the design and presentation of large-scale monitoring systems. We discuss Panopticon, a monitoring system that we have developed, which can scale to monitor tens of thousands of nodes, using only commodity equipment. In addition, we propose a novel method for visualising monitoring information on a large scale, based on general techniques for visualising massive multi-dimensional datasets.The monitoring system is shown to be able to collect information from up to 100 000 nodes. The storage system is able to record and output information from up to 25 000 nodes, and the visualisation is able to simultaneously display all this information for up to 20 000 nodes. Optimisations to our storage system could allow it to scale a little further, but a distributed storage approach combined with intelligent filtering algorithms would be necessary for significant improvements in scalability.},
booktitle = {Proceedings of the 2010 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists},
pages = {39–47},
numpages = {9},
keywords = {monitoring system, visualisation, scalability},
location = {Bela Bela, South Africa},
series = {SAICSIT '10}
}

@inproceedings{10.1145/1899503.1899510,
author = {Emmanuel, Edim Azom and Muyingi, Hippolyte N.},
title = {A Mobile Commerce Application for Rural Economy Development: A Case Study for Dwesa},
year = {2010},
isbn = {9781605589503},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1899503.1899510},
doi = {10.1145/1899503.1899510},
abstract = {Economic activities in rural areas of developing countries are usually not strong enough to impact significantly in poverty alleviation and improve rural life. These communities are often marginalized in terms of basic infrastructures; low economic activities and limited markets. However, they possess market potentials in agriculture and micro-enterprises. Information and communication technologies can be use to develop these potentials by opening these markets beyond the local borders. Our objective is to explore the potentials of information technologies for rural economy development by bringing mobile added value to potential users. Our aim is to design a mobile user interface that will be easy to use by rural micro-entrepreneurs who have little or no previous experience of the mobile commerce technology. In order to design the application and user interface, we conducted a case study in Dwesa community and applied user-centered design methods in the design process. Qualitative and quantitative methods were used to gather user data. This paper presents the design process, and user evaluation of the prototype mobile user interface. The user evaluation of the prototype was conducted and the descriptive statistics of users' performance is presented. The result shows that the evaluators who had no prior experience with this technology recorded minimum tasks completion time and with few errors, and an increasing level of precision in task performance as they continue to use the interface; which is a positive indication on the usability of the user-interface.},
booktitle = {Proceedings of the 2010 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists},
pages = {58–66},
numpages = {9},
keywords = {user interface, ICT4D, rural micro-entrepreneur, mobile commerce, usability},
location = {Bela Bela, South Africa},
series = {SAICSIT '10}
}

@inproceedings{10.1145/1868914.1868938,
author = {Foster, Derek and Lawson, Shaun and Blythe, Mark and Cairns, Paul},
title = {Wattsup? Motivating Reductions in Domestic Energy Consumption Using Social Networks},
year = {2010},
isbn = {9781605589343},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868914.1868938},
doi = {10.1145/1868914.1868938},
abstract = {This paper reports on the design, deployment and evaluation of "Wattsup", an innovative application which displays live autonomously logged data from the Wattson energy monitor, allowing users to compare domestic energy consumption on Facebook. Discussions and sketches from a workshop with Facebook users were used to develop a final design implemented using the Facebook API. Wattson energy monitors and the Wattsup app were deployed and trialled in eight homes over an eighteen day period in two conditions. In the first condition participants could only access their personal energy data, whilst in the second they could access each others' data to make comparisons. A significant reduction in energy was observed in the socially enabled condition. Comments on discussion boards and semi-structured interviews with the participants indicated that the element of competition helped motivate energy savings. The paper argues that socially-mediated banter and competition made for a more enjoyable user experience.},
booktitle = {Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries},
pages = {178–187},
numpages = {10},
keywords = {social networking, persuasive technology, user experience, sustainability, competitive energy saving},
location = {Reykjavik, Iceland},
series = {NordiCHI '10}
}

@inproceedings{10.1145/1868914.1868944,
author = {Ikonen, Heli and Iivari, Netta and Hedberg, Henrik},
title = {Controlling the Use of Collaboration Tools in Open Source Software Development},
year = {2010},
isbn = {9781605589343},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868914.1868944},
doi = {10.1145/1868914.1868944},
abstract = {This paper analyses control in the open source software (OSS) development context, focusing specifically on how the use of collaboration tools, such as bug trackers and mailing lists, are controlled in OSS projects. The tools are vital for the functioning of distributed OSS projects. One OSS case project was analysed in the paper. The findings show a surprising amount of control in the OSS project. In addition, when compared to traditional information systems (IS) development projects, different control modes and mechanism were found. Strong evidence for informal 'clan' and 'self-control' were found, but also a lot of formal control was in use. The results are discussed in connection to OSS literature and critical IS literature.},
booktitle = {Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries},
pages = {236–245},
numpages = {10},
keywords = {open source software, collaboration tools, control},
location = {Reykjavik, Iceland},
series = {NordiCHI '10}
}

@inproceedings{10.1145/1868914.1868941,
author = {Holleis, Paul and Wagner, Matthias and B\"{o}hm, Sebastian and Koolwaaij, Johan},
title = {Studying Mobile Context-Aware Social Services in the Wild},
year = {2010},
isbn = {9781605589343},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868914.1868941},
doi = {10.1145/1868914.1868941},
abstract = {We have implemented and evaluated IYOUIT, a context-aware application for the mobile phone that promotes a digital lifestyle, sharing, and life-logging approach for people on the go. The service incorporates context management technology to abstract data about and around the user into meaningful interpretations of the user's digital trace in the real world. Complementary to the public release of our service, we have conducted a longitudinal field study with 19 users for a period of one month. In this paper, we present findings from this coordinated user trial and provide researchers with advice on the design and implementation of similar systems.},
booktitle = {Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries},
pages = {207–216},
numpages = {10},
keywords = {mobile services, social networking, context awareness},
location = {Reykjavik, Iceland},
series = {NordiCHI '10}
}

@inproceedings{10.5555/1920331.1920394,
author = {Eschenfelder, Kristin R. and Caswell, Michelle},
title = {Digital Cultural Collections in an Age of Reuse and Remixes},
year = {2010},
publisher = {American Society for Information Science},
address = {USA},
abstract = {This paper reports the results of a survey of U.S. cultural institution (CI) professionals about whether CI should seek to control access to and use of digital cultural collections. It describes motivations that encourage institutions to control access to or use of collections and factors that discourage institutions from controlling access and use. The paper describes the results in terms of three general themes: "Object descriptions, representations and control," "Legal risks and complexities" and "Getting credit: fiscal and social costs and revenue."},
booktitle = {Proceedings of the 73rd ASIS&amp;T Annual Meeting on Navigating Streams in an Information Ecosystem - Volume 47},
articleno = {44},
numpages = {10},
keywords = {museums, licensing, archives, digital collections, privacy, copyright, open access},
location = {Pittsburgh, Pennsylvania},
series = {ASIS&amp;T '10}
}

@inproceedings{10.5555/1920331.1920333,
author = {Ingwersen, Peter and Larsen, Birger and Kelly, Diane and Wang, Peiling and Lykke, Marianne},
title = {Perspectives on Adaptivity in Information Retrieval Interaction (PAIRI): Panel},
year = {2010},
publisher = {American Society for Information Science},
address = {USA},
abstract = {Adaptivity in IR interactions requires the IR systems adapting to users' situations and the users adapting to the systems. System adaption entails dynamic user modeling, effective information architecture and enhanced search features such as search integration and relevance feedback; user adaptation through interactions entails mental model building and modification towards a coherent state of knowledge and learning.The panel is structured as follows. Initially we provide an overview of the panel contents, consisting of four central dimensions of adaptivity in IR interaction. These are adaption 1) through integration of information objects; 2) of information system to searcher; 3) of searcher to information system; and 4) to context and practice. The sequence follows the order of the panellists, i.e., each panellist is the prime mover of a particular dimension.},
booktitle = {Proceedings of the 73rd ASIS&amp;T Annual Meeting on Navigating Streams in an Information Ecosystem - Volume 47},
articleno = {1},
numpages = {5},
keywords = {information retrieval interaction, digital libraries, human-computer interaction, information architecture},
location = {Pittsburgh, Pennsylvania},
series = {ASIS&amp;T '10}
}

@inproceedings{10.5555/1920331.1920426,
author = {Agosto, Denise E. and Abbas, June},
title = {High School Seniors' Social Network and Other ICT Use Preferences and Concerns},
year = {2010},
publisher = {American Society for Information Science},
address = {USA},
abstract = {The study develops an in-depth picture of teens' thoughts and opinions related to social networks and ICT's, particularly preferences towards, and concerns related to, their use. Using a series of six semi-structured focus group interviews, data were gathered from 45 high school seniors attending a highly technological public high school. Focus group questions included 1) preferred methods for communicating with friends and family; 2) reasons for engaging or not engaging in online social networking; 3) how ICT's for social networking and other communication purposes were selected; and 4) decisions related to accepting online "friends."Findings contradicted earlier "digital natives" literature, which suggests that teens are avid users of technology for technology's sake. Instead, the teens viewed ICTs and social networks from a more pragmatic view, using them as tools for quick and easy communication and for relationship building and maintenance.General findings indicated that 1) communication media were selected based on the closeness of the relationship with the message receiver(s) and the number of intended receivers; 2) social networks, such as Facebook, were used for less frequent contact with wider range of friends and relatives; 3) teens used ICTs differently for communication with adults than with peers; and 4) teens preferred to use email for interactions with teachers.An eight-category typology of four ICT capability preferences (Simplicity of interface design/Ease of use, Speed of use, Constant contact/Ubiquitous communication, and Multitasking) and four ICT use concerns (Information privacy, Information security, Communication overload; and Reduced face-to-face communication and interaction) is proposed.},
booktitle = {Proceedings of the 73rd ASIS&amp;T Annual Meeting on Navigating Streams in an Information Ecosystem - Volume 47},
articleno = {65},
numpages = {10},
keywords = {social networking, teens, facebook, ICTs, MySpace},
location = {Pittsburgh, Pennsylvania},
series = {ASIS&amp;T '10}
}

@inproceedings{10.5555/1920331.1920469,
author = {Detlor, Brian and Julien, Heidi and Serenko, Alexander and Booker, Lorne},
title = {Factors Affecting Student Learning Outcomes of Information Literacy Instruction},
year = {2010},
publisher = {American Society for Information Science},
address = {USA},
abstract = {This poster reports results of a survey conducted recently at a Canadian business school concerning factors affecting student learning outcomes of information literacy instruction (ILI). Specifically, the effects of demographics, learning environment factors, and information literacy components on behavioral, psychological, and benefit outcomes of ILI are examined. Results test qualitative findings reported in a paper by the authors at last year's ASIST Annual Meeting (Julien et al., 2009), and identify the salient factors surrounding the delivery of ILI that affect student learning outcomes. Specifically, results show that greater amounts of active instruction, more senior students, and more positive perceptions of the quality of and satisfaction with ILI, all yield improved student learning outcomes.},
booktitle = {Proceedings of the 73rd ASIS&amp;T Annual Meeting on Navigating Streams in an Information Ecosystem - Volume 47},
articleno = {97},
numpages = {2},
keywords = {student learning outcomes, information literacy instruction, information literacy},
location = {Pittsburgh, Pennsylvania},
series = {ASIS&amp;T '10}
}

@inproceedings{10.5555/1920331.1920359,
author = {Zhang, Hong and Smith, Linda C. and Twidale, Michael},
title = {Four Epistemological Views of Information Organization Behavior on Personal Computers of Information Workers},
year = {2010},
publisher = {American Society for Information Science},
address = {USA},
abstract = {Hj\o{}rland proposes a typology of four epistemological views in analyzing professional knowledge organization systems. In this study, we identified all four views as components of personal information organization in the current hierarchical folder structures on personal computers. The typology enabled us to synthesize the varieties and commonalities within the large number of particular information organizational practices observed both within and between individuals over time. The study demonstrated that the typology is a promising analytic descriptive framework and can help illuminate problems in current folder systems.},
booktitle = {Proceedings of the 73rd ASIS&amp;T Annual Meeting on Navigating Streams in an Information Ecosystem - Volume 47},
articleno = {19},
numpages = {7},
keywords = {Hj\o{}rland's typology, information organization behavior, personal information management, folders, empiricism, rationalism, pragmatism, historicism, tags},
location = {Pittsburgh, Pennsylvania},
series = {ASIS&amp;T '10}
}

@inproceedings{10.5555/1920331.1920419,
author = {Fleming-May, Rachel A. and Miller, Laura E.},
title = {I'm Scared to Look but I'm Dying to Know: Information Seeking and Sharing on Pro-Ana Weblogs},
year = {2010},
publisher = {American Society for Information Science},
address = {USA},
abstract = {As individuals' access to the Internet has grown, so has the diversity of lifestyles and interests represented on the web. On the Internet, members of any subculture can communicate and share information anonymously and directly on a variety of platforms. Although researchers from many disciplinary backgrounds have devoted considerable attention to the nature of information practices in online communities, there has been little investigation into the information practices of adherents to lifestyles that could be considered perilous or harmful. The members of such a group, referred to as Pro-Anorexia, or Pro-Ana, characterize themselves as believing that Anorexia is not a disease, but a lifestyle choice.This paper presents findings from a textual analysis of posts and comments on three Pro-Anorexia (Pro-Ana) weblogs. Using a Grounded Theory approach, we found that both bloggers and commenters share a diverse array of types of information in a variety of formats. Because much of the information sought and shared on Pro-Ana blogs would be considered dangerous in another venue, Pro-Ana blogs present an interesting forum for considering how the context in which information is solicited, encountered, or presented actively shapes both the information itself and the information practices of community members.},
booktitle = {Proceedings of the 73rd ASIS&amp;T Annual Meeting on Navigating Streams in an Information Ecosystem - Volume 47},
articleno = {61},
numpages = {9},
keywords = {online communities, pro-anorexia, information seeking and sharing, peer information sharing, sharing harmful information, information practice},
location = {Pittsburgh, Pennsylvania},
series = {ASIS&amp;T '10}
}

@inproceedings{10.1145/1878961.1879002,
author = {Ebi, Thomas and Al Faruque, Mohammad Abdullah and Henkel, J\"{o}rg},
title = {NeuroNoC: Neural Network Inspired Runtime Adaptation for an on-Chip Communication Architecture},
year = {2010},
isbn = {9781605589053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1878961.1879002},
doi = {10.1145/1878961.1879002},
abstract = {The on-chip communication architecture presented in this paper, NeuroNoC, addresses the problems arising in large multi-core systems where global or local routing strategies do not work efficiently anymore since they either do not scale or lack information on the network state. Our communication architecture is runtime adaptive and it deploys a distributed artificial neural network to aid routing decisions. It thereby provides a light-weight mechanism for local routing information to propagate through the communication architecture and is capable of self-organizing efficiently (since scalable) to varying communication workload scenarios. The underlying basic concepts are borrowed from spiking neural networks, a special case of artificial neural networks. Our experiments show that already with low hardware overhead, a significant improvement of the runtime routing behavior compared to current state-of-the-art approaches is possible. We report an improvement of 23% in routing quality compared to wXY [9] routing in terms of failed transactions.},
booktitle = {Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},
pages = {223–230},
numpages = {8},
keywords = {spiking neural networks, adaptive system, network-on-chip},
location = {Scottsdale, Arizona, USA},
series = {CODES/ISSS '10}
}

@inproceedings{10.1145/1873951.1874196,
author = {Jin, Xin and Gallagher, Andrew and Cao, Liangliang and Luo, Jiebo and Han, Jiawei},
title = {The Wisdom of Social Multimedia: Using Flickr for Prediction and Forecast},
year = {2010},
isbn = {9781605589336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1873951.1874196},
doi = {10.1145/1873951.1874196},
abstract = {Social multimedia hosting and sharing websites, such as Flickr, Facebook, Youtube, Picasa, ImageShack and Photobucket, are increasingly popular around the globe. A major trend in the current studies on social multimedia is using the social media sites as a source of huge amount of labeled data for solving large scale computer science problems in computer vision, data mining and multimedia. In this paper, we take a new path to explore the global trends and sentiments that can be drawn by analyzing the sharing patterns of uploaded and downloaded social multimedia. In a sense, each time an image or video is uploaded or viewed, it constitutes an implicit vote for (or against) the subject of the image. This vote carries along with it a rich set of associated data including time and (often) location information. By aggregating such votes across millions of Internet users, we reveal the wisdom that is embedded in social multimedia sites for social science applications such as politics, economics, and marketing. We believe that our work opens a brand new arena for the multimedia research community with a potentially big impact on society and social sciences.},
booktitle = {Proceedings of the 18th ACM International Conference on Multimedia},
pages = {1235–1244},
numpages = {10},
keywords = {economics, prediction, politics, social multimedia, marketing},
location = {Firenze, Italy},
series = {MM '10}
}

@inproceedings{10.1145/1878803.1878817,
author = {Nazneen, Fnu and Boujarwah, Fatima A. and Sadler, Shone and Mogus, Amha and Abowd, Gregory D. and Arriaga, Rosa I.},
title = {Understanding the Challenges and Opportunities for Richer Descriptions of Stereotypical Behaviors of Children with Asd: A Concept Exploration and Validation},
year = {2010},
isbn = {9781605588810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1878803.1878817},
doi = {10.1145/1878803.1878817},
abstract = {Individuals with Autism Spectrum Disorder (ASD) often engage in stereotypical behaviors. In some individuals these behaviors occur with very high frequency and can be disruptive and at times self-injurious. We propose a system that can tacitly collect contextual data related to the individual's physiological state and their external environment, and map it to occurrences of stereotypies. A user study was conducted with children with ASD, parents, and caregivers to explore and validate this concept. A prototype of the system, developed through participatory design, was used in the study as a probe to elicit the information needs of these stakeholders, and provide a better understanding of the nuances involved in supporting those needs. Here we present the findings of this study, and four design recommendations; promoting ecological integration, addressing privacy concerns, supporting inference, and enabling customization.},
booktitle = {Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility},
pages = {67–74},
numpages = {8},
keywords = {autism spectrum disorder, stereotypical repetitive behavior},
location = {Orlando, Florida, USA},
series = {ASSETS '10}
}

@inproceedings{10.1145/1878803.1878820,
author = {Ferres, Leo and Lindgaard, Gitte and Sumegi, Livia},
title = {Evaluating a Tool for Improving Accessibility to Charts and Graphs},
year = {2010},
isbn = {9781605588810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1878803.1878820},
doi = {10.1145/1878803.1878820},
abstract = {We discuss factors in the design and evaluation of natural language-driven assistive technologies that generate descriptions of, and allow interaction with, graphical representations of numerical data. In particular, we provide data in favor of 1) screen-reading technologies as a usable, useful, and cost-effective means of interacting with graphs. The data also show that by carrying out evaluation of Assistive Technologies on populations other than the target communities, certain subtleties of navigation and interaction may be lost or distorted.},
booktitle = {Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility},
pages = {83–90},
numpages = {8},
keywords = {statistical graphs and diagrams, natural language generation and interaction, accessibility (blind and visually-impaired)},
location = {Orlando, Florida, USA},
series = {ASSETS '10}
}

@inproceedings{10.1145/1871437.1871537,
author = {Bamis, Athanasios and Fang, Jia and Savvides, Andreas},
title = {A Method for Discovering Components of Human Rituals from Streams of Sensor Data},
year = {2010},
isbn = {9781450300995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1871437.1871537},
doi = {10.1145/1871437.1871537},
abstract = {This paper describes an algorithm for determining if an event occurs persistently within an interval where the interval is periodic but the event is not. The goal of the algorithm is to identify events with this property and also determine the minimum interval in which they occur. This solution is geared towards discovering human routines by considering the triggering of simple sensors over a diverse set of spatial and temporal scales. After describing the problem and the proposed solution, in this paper we demonstrate using testbed data and simulations that this approach uncovers components of routines by identifying which events are parts of the same routine through their temporal properties.},
booktitle = {Proceedings of the 19th ACM International Conference on Information and Knowledge Management},
pages = {779–788},
numpages = {10},
keywords = {periodic events recognition, assisted living, human routine discovery, macroscopic sensing composition},
location = {Toronto, ON, Canada},
series = {CIKM '10}
}

@inproceedings{10.1145/1871437.1871588,
author = {Godbole, Shantanu and Bhattacharya, Indrajit and Gupta, Ajay and Verma, Ashish},
title = {Building Re-Usable Dictionary Repositories for Real-World Text Mining},
year = {2010},
isbn = {9781450300995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1871437.1871588},
doi = {10.1145/1871437.1871588},
abstract = {Text mining, though still a nascent industry, has been growing quickly along with the awareness of the importance of unstructured data in business analytics, customer retention and extension, social media, and legal applications. There has been a recent increase in the number of commercial text mining product and service offerings, but successful or wide-spread deployments are rare, mainly due to a dependence on the expertise and skill of practitioners. Accordingly, there is a growing need for re-usable repositories for text mining. In this paper, we focus on dictionary-based text mining and its role in enabling practitioners in understanding and analyzing large text datasets. We motivate and define the problem of exploratory dictionary construction for capturing concepts of interest, and propose a framework for efficient construction, tuning, and re-use of these dictionaries across datasets. The construction framework offers a range of interaction modes to the user to quickly build concept dictionaries over large datasets. We also show how to adapt one or more dictionaries across domains and tasks, thereby enabling reuse of knowledge and effort in industrial practice. We present results and case studies on real-life CRM analytics datasets, where such repositories and tooling significantly cut down practitioner time and effort for dictionary-based text mining.},
booktitle = {Proceedings of the 19th ACM International Conference on Information and Knowledge Management},
pages = {1189–1198},
numpages = {10},
keywords = {text mining},
location = {Toronto, ON, Canada},
series = {CIKM '10}
}

@inproceedings{10.1145/1936254.1936283,
author = {Kundu, Anirban and Guha, Sutirtha Kr. and Mitra, Arnab and Mukherjee, Tapas},
title = {A New Approach in Dynamic Prediction for User Based Web Page Crawling},
year = {2010},
isbn = {9781450300476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1936254.1936283},
doi = {10.1145/1936254.1936283},
abstract = {Maximum available Web prediction techniques typically follow Markov model for Web based prediction. Everybody knows that there are lots of Web links or URLs on any Web page. So, it is very hard to predict the next Web page from the huge number of Web links. Existing approaches predict successfully on the private (personal) computer using different Markov models. In case of public (like cyber cafe) computers, prediction can not be done at all, since many people use the same machine in this type of scenario. In this paper, we propose a new policy on Web prediction using the dynamic behavior of users. We demonstrate four procedures for Web based prediction to make it faster. Our technique does not require any Web-log or usage history at client machine. We are going to use the mouse movement and its direction for the prediction of next Web page. We track the mouse position and its respective direction instead of using Markov model. In this research work, we introduce a fully dynamic Web prediction scheme, since Web-log or any type of static or previous information has not been utilized in our approach. In this paper, we try to minimize the number of Web links to be considered of any Web page in runtime for achieving better accuracy in dynamic Web prediction. Our approach shows the step-wise build-up of a solid Web prediction program which is appropriate in both the private as well as public scenario. Overall, this method shows a new way for prediction using dynamic nature of the respective users.},
booktitle = {Proceedings of the International Conference on Management of Emergent Digital EcoSystems},
pages = {166–173},
numpages = {8},
keywords = {predictive crawling, user based prediction, dynamic prediction},
location = {Bangkok, Thailand},
series = {MEDES '10}
}

@inproceedings{10.1145/1871437.1871567,
author = {Raghavan, Hema and Iyer, Rukmini},
title = {Probabilistic First Pass Retrieval for Search Advertising: From Theory to Practice},
year = {2010},
isbn = {9781450300995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1871437.1871567},
doi = {10.1145/1871437.1871567},
abstract = {Information retrieval in search advertising, as in other ad-hoc retrieval tasks, aims to find the most appropriate ranking of the ad documents of a corpus for a given query. In addition to ranking the ad documents, we also need to filter or threshold irrelevant ads from participating in the auction to be displayed alongside search results. In this work, we describe our experience in implementing a successful ad retrieval system for a commercial search engine based on the Language Modeling (LM) framework for retrieval. The LM demonstrates significant performance improvements over the baseline vector space model (TF-IDF) system that was in production at the time. From a modeling perspective, we propose a novel approach to incorporate query segmentation and phrases in the LM framework, discuss impact of score normalization for relevance filtering, and present preliminary results of incorporating query expansions using query rewriting techniques. From an implementation perspective, we also discuss real-time latency constraints of a production search engine and how we overcome them by adapting the WAND algorithm to work with language models. In sum, our LM formulation is considerably better in terms of accuracy metrics such as Precision-Recall (10% improvement in AUC) and nDCG (8% improvement in nDCG@5) on editorial data and also demonstrates significant improvements in clicks in live user tests (0.787% improvement in Click Yield, with 8% coverage increase). Finally, we hope that this paper provides the reader with adequate insights into the challenges of building a system that serves millions of users every day.},
booktitle = {Proceedings of the 19th ACM International Conference on Information and Knowledge Management},
pages = {1019–1028},
numpages = {10},
keywords = {sponsored search, language models, advertising},
location = {Toronto, ON, Canada},
series = {CIKM '10}
}

@inproceedings{10.1145/1871437.1871474,
author = {Zhao, Le and Callan, Jamie},
title = {Term Necessity Prediction},
year = {2010},
isbn = {9781450300995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1871437.1871474},
doi = {10.1145/1871437.1871474},
abstract = {The probability that a term appears in relevant documents (P(t | R)) is a fundamental quantity in several probabilistic retrieval models, however it is difficult to estimate without relevance judgments or a relevance model. We call this value term necessity because it measures the percentage of relevant documents retrieved by the term - how necessary a term's occurrence is to document relevance. Prior research typically either set this probability to a constant, or estimated it based on the term's inverse document frequency, neither of which was very effective.This paper identifies several factors that affect term necessity, for example, a term's topic centrality, synonymy and abstractness. It develops term- and query-dependent features for each factor that enable supervised learning of a predictive model of term necessity from training data. Experiments with two popular retrieval models and 6 standard datasets demonstrate that using predicted term necessity estimates as user term weights of the original query terms leads to significant improvements in retrieval accuracy.},
booktitle = {Proceedings of the 19th ACM International Conference on Information and Knowledge Management},
pages = {259–268},
numpages = {10},
keywords = {term weighting, mismatch, ad-hoc retrieval models, necessity},
location = {Toronto, ON, Canada},
series = {CIKM '10}
}

@inproceedings{10.1145/1877826.1877835,
author = {Baltru\v{s}aitis, Tadas and Riek, Laurel D. and Robinson, Peter},
title = {Synthesizing Expressions Using Facial Feature Point Tracking: How Emotion is Conveyed},
year = {2010},
isbn = {9781450301701},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1877826.1877835},
doi = {10.1145/1877826.1877835},
abstract = {Many approaches to the analysis and synthesis of facial expressions rely on automatically tracking landmark points on human faces. However, this approach is usually chosen because of ease of tracking rather than its ability to convey affect. We have conducted an experiment that evaluated the perceptual importance of 22 such automatically tracked feature points in a mental state recognition task. The experiment compared mental state recognition rates of participants who viewed videos of human actors and synthetic characters (physical android robot, virtual avatar, and virtual stick figure drawings) enacting various facial expressions. All expressions made by the synthetic characters were automatically generated using the 22 tracked facial feature points on the videos of the human actors. Our results show no difference in accuracy across the three synthetic representations, however, all three were less accurate than the original human actor videos that generated them. Overall, facial expressions showing surprise were more easily identifiable than other mental states, suggesting that a geometric approach to synthesis may be better suited toward some mental states than others.},
booktitle = {Proceedings of the 3rd International Workshop on Affective Interaction in Natural Environments},
pages = {27–32},
numpages = {6},
keywords = {facial expression analysis, facial expressions synthesis, affective computing, emotion},
location = {Firenze, Italy},
series = {AFFINE '10}
}

@inproceedings{10.1145/1877826.1877842,
author = {Evers, Vanessa and Wildvuur, Sabine and Kr\"{o}se, Ben},
title = {A Motivational Health Companion in the Home as Part of an Intelligent Health Monitoring Sensor Network},
year = {2010},
isbn = {9781450301701},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1877826.1877842},
doi = {10.1145/1877826.1877842},
abstract = {This paper describes our work in progress to develop a personal monitoring system that can monitor the physical and emotional condition of a patient by using contextual information from a sensor network, provide the patient with feedback concerning their health status and motivate the patient to adopt behavior with a positive health impact (such as exercising or taking medication at the right moment). We will extend the capabilities of an existing robotic health buddy with a (DBN based) sensor network. Then we will carry out a series of controlled, long-term field experiments where we identify and evaluate the effects of various agent social communicative behaviors on the user's adoption of health improving lifestyle patterns. The findings of the experiments will inform the final design of the health buddy and its behaviors. We will also realize system adaptivity of the data processing and data fusion methods as well as the health buddy adaptivity to the user's emotional state. The project will limit itself to monitoring and motivating people who suffer from cardiovascular chronic conditions and to the home environment.},
booktitle = {Proceedings of the 3rd International Workshop on Affective Interaction in Natural Environments},
pages = {61–64},
numpages = {4},
keywords = {ambient intelligence, health and well-being, intelligent sensor network, human robot interaction, social robots},
location = {Firenze, Italy},
series = {AFFINE '10}
}

@inproceedings{10.1145/1877826.1877830,
author = {Tognetti, Simone and Garbarino, Maurizio and Bonanno, Andrea Tommaso and Matteucci, Matteo and Bonarini, Andrea},
title = {Enjoyment Recognition from Physiological Data in a Car Racing Game},
year = {2010},
isbn = {9781450301701},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1877826.1877830},
doi = {10.1145/1877826.1877830},
abstract = {In this paper we present a case study on The Open Racing Car Simulator (TORCS) video game with the aim of developing a classifier to recognize user enjoyment from physiological signals. Three classes of enjoyment, derived from pairwise comparison of different races, are considered for classification; impact of artifact reduction, normalization and feature selection is studied; results from a protocol involving 75 gamers are discussed. The best model, obtained by taking into account a subset of features derived from physiological signals (selected by a genetic algorithm), is able to correctly classify 3 levels of enjoyment with a correct classification rate of 57%.},
booktitle = {Proceedings of the 3rd International Workshop on Affective Interaction in Natural Environments},
pages = {3–8},
numpages = {6},
keywords = {data normalization, torcs, cross validation, pairwise preference, SFS, enjoyment classification, physiological signals, artifact removals, genetic algorithms, feature selection, k-nn},
location = {Firenze, Italy},
series = {AFFINE '10}
}

@inproceedings{10.1145/1877826.1877833,
author = {Broekens, Joost and Pronker, Anne and Neuteboom, Marian},
title = {Real Time Labeling of Affect in Music Using the Affectbutton},
year = {2010},
isbn = {9781450301701},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1877826.1877833},
doi = {10.1145/1877826.1877833},
abstract = {Valid, reliable and quick measurement of emotion and affect is an important challenge for the use of emotion and affect in human-technology interaction. Emotion and affect can be measured in two different ways: explicit, the user is asked for feedback, and implicit, signals from the users are automatically translated to affective and emotional meaning (affect recognition). Here we focus on explicit affective feedback. More specifically, we focus on the evaluation of an affect measurement tool called the AffectButton. Previous evaluation studies [2] showed that the AffectButton enables users to give affective feedback in a low-effort, reliable and valid way. In this paper we report a study involving real-time affective labeling of movie music by primarily high school students, i.e., a realistic domain with mainstream users. Our results show that (a) users (n=21) are able to use the AffectButton in real time while listening to the music; (b) the labeling very-well follows the changes in the music and gives insight into the different affective dimensions of the music, and; (c) objective music properties correlate to these affective dimensions replicating findings of others. This provides evidence that the AffectButton is a viable affect measurement tool usable by non-expert users in real-time realistic domains.},
booktitle = {Proceedings of the 3rd International Workshop on Affective Interaction in Natural Environments},
pages = {21–26},
numpages = {6},
keywords = {affectbutton, music, affective feedback, user study},
location = {Firenze, Italy},
series = {AFFINE '10}
}

@inproceedings{10.1145/1877826.1877846,
author = {Delaborde, Agnes and Devillers, Laurence},
title = {Use of Nonverbal Speech Cues in Social Interaction between Human and Robot: Emotional and Interactional Markers},
year = {2010},
isbn = {9781450301701},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1877826.1877846},
doi = {10.1145/1877826.1877846},
abstract = {We focus on audio cues required for the interaction between a human and a robot. We argue that a multi-level use of different paralinguistic cues is needed to pilot the decisions of the robot. Our challenge is to know how to use them to pilot the human-robot interaction. We offer in this paper a protocol for a study on the way paralinguistic cues can impact the human-robot interaction, by interpreting the low-level cues computed from speech into an emotional and interactional profile of the user. This study will be carried out through a game between two children and a robot.},
booktitle = {Proceedings of the 3rd International Workshop on Affective Interaction in Natural Environments},
pages = {75–80},
numpages = {6},
keywords = {social robot, affective interaction, human-robot interaction, real-time emotion detection},
location = {Firenze, Italy},
series = {AFFINE '10}
}

@inproceedings{10.1145/1877826.1877848,
author = {Wu, Peggy and Miller, Christopher},
title = {Can Polite Computers Produce Better Human Performance},
year = {2010},
isbn = {9781450301701},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1877826.1877848},
doi = {10.1145/1877826.1877848},
abstract = {We claim that the concept from human-human social interactions can be expanded and utilized to facilitate, inform, and predict human-computer interaction and perceptions. By expanding on a qualitative model of politeness proposed by Brown and Levinson we created a quantitative, computational model of etiquette that allows a machine to interpret and display politeness. The results from a human subject study show that the variables included in our model have important effects on subjects' decision making and performance in our experimental tasks. The results also demonstrate that variations in etiquette can result in objective, measurable consequences in human performance.},
booktitle = {Proceedings of the 3rd International Workshop on Affective Interaction in Natural Environments},
pages = {87–92},
numpages = {6},
location = {Firenze, Italy},
series = {AFFINE '10}
}

@inproceedings{10.1145/1878083.1878096,
author = {Moussa, Maher Ben and Kasap, Zerrin and Magnenat-Thalmann, Nadia and Chandramouli, Krishna and Haji Mirza, Seyed Navid and Zhang, Qianni and Izquierdo, Ebroul and Biperis, Iordanis and Daras, Petros},
title = {Towards an Expressive Virtual Tutor: An Implementation of a Virtual Tutor Based on an Empirical Study of Non-Verbal Behaviour},
year = {2010},
isbn = {9781450301756},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1878083.1878096},
doi = {10.1145/1878083.1878096},
abstract = {In this paper we investigate the non-verbal behaviour of a tutor and propose a model for ECAs (Embodied Conversational Agents) acting as virtual tutors. We have conducted an empirical study where we focused on the distribution of gaze, head and eyebrowns behaviour of the tutors in a teaching scenario and on the co-occurrences of these behaviours with certain teaching activities or conversational events. Further, we built an ECA with conversational capabilities, episodic memory, emotions and expressive behaviour based on the result from the empirical study.},
booktitle = {Proceedings of the 2010 ACM Workshop on Surreal Media and Virtual Cloning},
pages = {39–44},
numpages = {6},
keywords = {eca, gaze, iapd, non-verbal behaviour, tutor},
location = {Firenze, Italy},
series = {SMVC '10}
}

@inproceedings{10.1145/1877850.1877854,
author = {Friedland, Gerald and Gottlieb, Luke and Janin, Adam},
title = {Narrative Theme Navigation for Sitcoms Supported by Fan-Generated Scripts},
year = {2010},
isbn = {9781450301640},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1877850.1877854},
doi = {10.1145/1877850.1877854},
abstract = {The following article presents a novel method to generate indexing information for the navigation of TV content and presents an implementation that extends the Joke-O-Mat sitcom navigation system, presented in [1]. The extended system enhances Joke-o-mat's capability to browse a sitcom by scene, punchline, dialog segment, and actor with word-level keyword search. The indexing is performed based on the alignment of the multimedia content with closed captions and "found" fan-generated scripts processed with speech and speaker recognition systems. This significantly reduces the amount of manual intervention required for training new episodes, and the final narrative-theme segmentation has proven indistinguishable from expert annotation. This article describes the new Joke-o-mat system, discusses problems with using fan-generated data, and presents results on episodes from the sitcom Seinfeld, showing segmentation accuracy and user satisfaction as determined by a human-subject study.},
booktitle = {Proceedings of the 3rd International Workshop on Automated Information Extraction in Media Production},
pages = {3–8},
numpages = {6},
keywords = {acoustic video segmentation, broadcast tv, narrative-themes, crowd sourcing},
location = {Firenze, Italy},
series = {AIEMPro '10}
}

@inproceedings{10.1145/1877850.1877862,
author = {Broilo, Mattia and Zavesky, Eric and Basso, Andrea and De Natale, Francesco G. B.},
title = {Unsupervised Event Segmentation of News Content with Multimodal Cues},
year = {2010},
isbn = {9781450301640},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1877850.1877862},
doi = {10.1145/1877850.1877862},
abstract = {In the age of content snacking and mobisodes (mobile episodes) the paradigm of media consumption is radically changing. Media consumption is moving from monolithic, prepackaged, well-edited, and elaborate content presentation to a continuous feed of brief segments as singleton episodes and few-minutes videos, that are often supported by or initiated via tweets and status updates. In these updates, attention spans are small and the content packaging is less relevant with respect to the dynamic, 'streaming' aspect of information. This trend has a profound influence on the segmentation requirements that are needed to make this stream of possible information. In this paper, we present a novel method to automatically extract structured content, events, where events include major cast interviews, dialogs, background segments, etc. from news video in an unsupervised fashion. Two key ideas differentiate this unsupervised method from the others: the type of information that we use to find events and the method utilized to combine this information for coherent multimedia events. The proposed system exploits audio, visual appearance, detected faces, and mid-level semantic concepts from every video shot, but instead of combining everything together, the framework clusters them independently and by applying coherence rules assembles the multimedia events. Additionally, we discuss the effect of segmentation errors in practical retrieval and content consumption tasks.},
booktitle = {Proceedings of the 3rd International Workshop on Automated Information Extraction in Media Production},
pages = {39–44},
numpages = {6},
keywords = {unsupervised clustering, content-based multimedia indexing, video events},
location = {Firenze, Italy},
series = {AIEMPro '10}
}

@inproceedings{10.1145/1871902.1871912,
author = {Pawlish, Michael J. and Varde, Aparna S.},
title = {A Decision Support System for Green Data Centers},
year = {2010},
isbn = {9781450303859},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1871902.1871912},
doi = {10.1145/1871902.1871912},
abstract = {In this paper, we propose a decision support system for green computing in data centers on campuses. Green computing aims at the development of technologies for a greener and more sustainable planet. In this work we focus on the greening of data centers that house servers on campuses. It is known that servers consume a huge amount of power and incur other costs in cooling and related operations. It is challenging to meet the demands of efficiency and accuracy in data centers while yet promoting a greener environment along with cost cutting. Our work proposes a decision support system based on decision trees and case-based reasoning that mines existing data in order to assist decision-making for better management in data centers. We consider various aspects of the data from an environmental management perspective such as carbon footprint, thermal profiles and virtualization. Issues such as efficiency and accuracy are taken into account here, In this proposal paper, we outline the need for our work, the challenges involved, the proposed approach for building the system, preliminary evaluation and future plans. This work would be of interest to the data and knowledge management community as well as environmental scientists and researchers in related areas.},
booktitle = {Proceedings of the 3rd Workshop on Ph.D. Students in Information and Knowledge Management},
pages = {47–56},
numpages = {10},
keywords = {data centers, decision support systems, decision trees, green information technology},
location = {Toronto, ON, Canada},
series = {PIKM '10}
}

@inproceedings{10.1145/1879141.1879201,
author = {Carter, Kevin M. and Lippmann, Richard P. and Boyer, Stephen W.},
title = {Temporally Oblivious Anomaly Detection on Large Networks Using Functional Peers},
year = {2010},
isbn = {9781450304832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1879141.1879201},
doi = {10.1145/1879141.1879201},
abstract = {Abstract Previous methods of network anomaly detection have focused on defining a temporal model of what is "normal," and flagging the "abnormal" activity that does not fit into this pre-trained construct. When monitoring traffic to and from IP addresses on a large network, this problem can become computationally complex, and potentially intractable, as a state model must be maintained for each address. In this paper, we present a method of detecting anomalous network activity without providing any historical context. By exploiting the size of the network along with the minimal overhead of NetFlow data, we are able to model groups of hosts performing similar functions to discover anomalous behavior. As a collection, these anomalies can be further described with a few high-level characterizations and we provide a means for creating and labeling these categories. We demonstrate our method on a very large-scale network consisting of 30 million unique addresses, focusing specifically on traffic related to web servers.},
booktitle = {Proceedings of the 10th ACM SIGCOMM Conference on Internet Measurement},
pages = {465–471},
numpages = {7},
keywords = {network security, anomaly detection, machine learning},
location = {Melbourne, Australia},
series = {IMC '10}
}

@inproceedings{10.1145/1879141.1879175,
author = {Benson, Theophilus and Akella, Aditya and Maltz, David A.},
title = {Network Traffic Characteristics of Data Centers in the Wild},
year = {2010},
isbn = {9781450304832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1879141.1879175},
doi = {10.1145/1879141.1879175},
abstract = {Although there is tremendous interest in designing improved networks for data centers, very little is known about the network-level traffic characteristics of data centers today. In this paper, we conduct an empirical study of the network traffic in 10 data centers belonging to three different categories, including university, enterprise campus, and cloud data centers. Our definition of cloud data centers includes not only data centers employed by large online service providers offering Internet-facing applications but also data centers used to host data-intensive (MapReduce style) applications). We collect and analyze SNMP statistics, topology and packet-level traces. We examine the range of applications deployed in these data centers and their placement, the flow-level and packet-level transmission properties of these applications, and their impact on network and link utilizations, congestion and packet drops. We describe the implications of the observed traffic patterns for data center internal traffic engineering as well as for recently proposed architectures for data center networks.},
booktitle = {Proceedings of the 10th ACM SIGCOMM Conference on Internet Measurement},
pages = {267–280},
numpages = {14},
keywords = {characterization, data center traffic},
location = {Melbourne, Australia},
series = {IMC '10}
}

@inproceedings{10.1145/1879141.1879173,
author = {Kreibich, Christian and Weaver, Nicholas and Nechaev, Boris and Paxson, Vern},
title = {Netalyzr: Illuminating the Edge Network},
year = {2010},
isbn = {9781450304832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1879141.1879173},
doi = {10.1145/1879141.1879173},
abstract = {In this paper we present Netalyzr, a network measurement and debugging service that evaluates the functionality provided by people's Internet connectivity. The design aims to prove both comprehensive in terms of the properties we measure and easy to employ and understand for users with little technical background. We structure Netalyzr as a signed Java applet (which users access via their Web browser) that communicates with a suite of measurement-specific servers. Traffic between the two then probes for a diverse set of network properties, including outbound port filtering, hidden in-network HTTP caches, DNS manipulations, NAT behavior, path MTU issues, IPv6 support, and access-modem buffer capacity. In addition to reporting results to the user, Netalyzr also forms the foundation for an extensive measurement of edge-network properties. To this end, along with describing Netalyzr 's architecture and system implementation, we present a detailed study of 130,000 measurement sessions that the service has recorded since we made it publicly available in June 2009.},
booktitle = {Proceedings of the 10th ACM SIGCOMM Conference on Internet Measurement},
pages = {246–259},
numpages = {14},
keywords = {network troubleshooting, network measurement, network performance, network neutrality},
location = {Melbourne, Australia},
series = {IMC '10}
}

@inproceedings{10.1145/1878500.1878505,
author = {Geisler, Sandra and Quix, Christoph and Schiffer, Stefan},
title = {A Data Stream-Based Evaluation Framework for Traffic Information Systems},
year = {2010},
isbn = {9781450304313},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1878500.1878505},
doi = {10.1145/1878500.1878505},
abstract = {Traffic information systems based on mobile, in-car sensor technology are a challenge for data management systems as a huge amount of data has to be processed in real-time. Data mining methods must be adapted to cope with these challenges in handling streaming data. Although several data stream mining methods have been proposed, an evaluation of such methods in the context of traffic applications is yet missing. In this paper, we present an evaluation framework for data stream mining for traffic applications. We apply a traffic simulation software to emulate the generation of traffic data by mobile probes. The framework is evaluated in a first case study, namely queue-end detection. We show first results of the evaluation of a data stream mining method, varying multiple parameters for the traffic simulation. The goal of our work is to identify parameter settings for which the data stream mining methods produce useful results for the traffic application at hand.},
booktitle = {Proceedings of the ACM SIGSPATIAL International Workshop on GeoStreaming},
pages = {11–18},
numpages = {8},
keywords = {data streams, data mining, traffic information systems},
location = {San Jose, California},
series = {IWGS '10}
}

@inproceedings{10.1145/1867699.1867703,
author = {Ying, Josh Jia-Ching and Lu, Eric Hsueh-Chan and Lee, Wang-Chien and Weng, Tz-Chiao and Tseng, Vincent S.},
title = {Mining User Similarity from Semantic Trajectories},
year = {2010},
isbn = {9781450304344},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1867699.1867703},
doi = {10.1145/1867699.1867703},
abstract = {In recent years, research on measuring trajectory similarity has attracted a lot of attentions. Most of similarities are defined based on the geographic features of mobile users' trajectories. However, trajectories geographically close may not necessarily be similar because the activities implied by nearby landmarks they pass through may be different. In this paper, we argue that a better similarity measurement should have taken into account the semantics of trajectories. In this paper, we propose a novel approach for recommending potential friends based on users' semantic trajectories for location-based social networks. The core of our proposal is a novel trajectory similarity measurement, namely, Maximal Semantic Trajectory Pattern Similarity (MSTP-Similarity), which measures the semantic similarity between trajectories. Accordingly, we propose a user similarity measurement based on MSTP-Similarity of user trajectories and use it as the basis for recommending potential friends to a user. Through experimental evaluation, the proposed friend recommendation approach is shown to deliver excellent performance.},
booktitle = {Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Location Based Social Networks},
pages = {19–26},
numpages = {8},
keywords = {trajectory database, semantic, global positioning system},
location = {San Jose, California},
series = {LBSN '10}
}

@inproceedings{10.1145/1865885.1865895,
author = {Schultz, Carl and Bhatt, Mehul},
title = {A Multi-Modal Data Access Framework for Spatial Assistance Systems: Use-Cases with the Building Information Model (BIM/IFC)},
year = {2010},
isbn = {9781450304337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1865885.1865895},
doi = {10.1145/1865885.1865895},
abstract = {Spatial assistance systems are computational embodiments of spatial decision-making and other forms of analytical abilities that otherwise typically require extensive domain-specific training, knowledge, and expertise. Broadly, such systems are essentially instruments of assistance, assurance and empowerment. Whereas these systems may vary in the domain of application and the precise manner of intelligent assistance, there exist several fundamental similarities from a systemic and information-theoretic viewpoint with regard to the ontological and computational foundations that underlie their practical design and implementation.We present a multi-modal spatial data access framework designed to serve the informational and computational requirements of the class of spatial assistance systems that are intended to provide intelligent spatial decision-making capabilities. The framework focuses on multi-perspective semantics, qualitative and artefactual abstractions, and industrial conformance and interoperability. We position the framework, and also provide use-cases with distinct application domains.},
booktitle = {Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Indoor Spatial Awareness},
pages = {39–46},
numpages = {8},
keywords = {interoperability, spatial assistance, spatial computing, ontology, semantics, decision-support systems, spatial data models, indoor environments},
location = {San Jose, California},
series = {ISA '10}
}

@inproceedings{10.1145/1869983.1870001,
author = {Sundaram, Vinaitheerthan and Eugster, Patrick and Zhang, Xiangyu},
title = {Efficient Diagnostic Tracing for Wireless Sensor Networks},
year = {2010},
isbn = {9781450303446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1869983.1870001},
doi = {10.1145/1869983.1870001},
abstract = {Wireless sensor networks (WSNs) are hard to program due to unconventional programming models used to satisfy stringent resource constraints. The common event-driven concurrent programming model and lack of kernel protection in these systems introduce the possibility of several subtle faults such as race conditions. These faults are often triggered by unexpected interleavings of events in the real world, and can occur long after their causes. Reproducing a fault from the trace of the past events can play a crucial role in debugging such faults. The same tight constraints that motivate the specific programming model however make tracing challenging. This paper proposes an efficient intra-procedural and inter-procedural control-flow tracing algorithm that generates the traces of all interleaving concurrent events. Our approach enables reproducing faults at a later stage, allowing the programmer to identify them effectively. We argue for the accuracy of our approach through case studies, and illustrate its low overhead through measurements and simulations.},
booktitle = {Proceedings of the 8th ACM Conference on Embedded Networked Sensor Systems},
pages = {169–182},
numpages = {14},
keywords = {diagnosis, wireless sensor networks, tracing, embedded debugging},
location = {Z\"{u}rich, Switzerland},
series = {SenSys '10}
}

@article{10.1145/1842722.1842725,
author = {Zhou, Suiping and Chen, Dan and Cai, Wentong and Luo, Linbo and Low, Malcolm Yoke Hean and Tian, Feng and Tay, Victor Su-Han and Ong, Darren Wee Sze and Hamilton, Benjamin D.},
title = {Crowd Modeling and Simulation Technologies},
year = {2010},
issue_date = {October 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {4},
issn = {1049-3301},
url = {https://doi.org/10.1145/1842722.1842725},
doi = {10.1145/1842722.1842725},
abstract = {As a collective and highly dynamic social group, the human crowd is a fascinating phenomenon that has been frequently studied by experts from various areas. Recently, computer-based modeling and simulation technologies have emerged to support investigation of the dynamics of crowds, such as a crowd's behaviors under normal and emergent situations. This article assesses the major existing technologies for crowd modeling and simulation. We first propose a two-dimensional categorization mechanism to classify existing work depending on the size of crowds and the time-scale of the crowd phenomena of interest. Four evaluation criteria have also been introduced to evaluate existing crowd simulation systems from the point of view of both a modeler and an end-user.We have discussed some influential existing work in crowd modeling and simulation regarding their major features, performance as well as the technologies used in this work. We have also discussed some open problems in the area. This article will provide the researchers with useful information and insights on the state of the art of the technologies in crowd modeling and simulation as well as future research directions.},
journal = {ACM Trans. Model. Comput. Simul.},
month = nov,
articleno = {20},
numpages = {35},
keywords = {crowd dynamics, Crowd simulation, multi-agent system, human behavior}
}

