@inproceedings{10.1145/2389176.2389205,
author = {Wen, Miaomiao and Rose, Carolyn Penstein},
title = {Understanding Participant Behavior Trajectories in Online Health Support Groups Using Automatic Extraction Methods},
year = {2012},
isbn = {9781450314862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389176.2389205},
doi = {10.1145/2389176.2389205},
abstract = {This paper presents an automatic analysis method that enables efficient examination of participant behavior trajectories in online communities, which offers the opportunity to examine behavior over time at a level of granularity that has previously only been possible in small scale case study analyses. We provide an empirical validation of its performance. We then illustrate how this method offers insights into behavior patterns that enable avoiding faulty oversimplified assumptions about participation, such as that it follows a consistent trend over time. In particular, we use this method to investigate the connection between user behavior and distressful cancer events and demonstrate how this tool could assist in cancer story summarization.},
booktitle = {Proceedings of the 17th ACM International Conference on Supporting Group Work},
pages = {179–188},
numpages = {10},
keywords = {natural language analysis, cancer trajectory, online support groups, disease event},
location = {Sanibel Island, Florida, USA},
series = {GROUP '12}
}

@inproceedings{10.1145/2389176.2389212,
author = {Mayer, Julia M. and Schuler, Richard P. and Jones, Quentin},
title = {Towards an Understanding of Social Inference Opportunities in Social Computing},
year = {2012},
isbn = {9781450314862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389176.2389212},
doi = {10.1145/2389176.2389212},
abstract = {Social computing applications are transforming the way we make new social ties, work, learn and play, thus becoming an essential part our social fabric. As a result, people and systems routinely make inferences about people's personal information based on their disclosed personal information. Despite the significance of this phenomenon the opportunity to make social inferences about users and how this process can be managed is poorly understood. In this paper we 1) outline why social inferences are important to study in the context of social computing applications, 2) how we can model, understand and predict social inference opportunities 3) highlight the need for social inference management systems, and 4) discuss the design space and associated research challenges. Collectively, this paper provides the first systematic overview for social inference research in the area of social computing.},
booktitle = {Proceedings of the 17th ACM International Conference on Supporting Group Work},
pages = {239–248},
numpages = {10},
keywords = {privacy, impression management, social inference, personalization, social computing},
location = {Sanibel Island, Florida, USA},
series = {GROUP '12}
}

@inproceedings{10.1145/2389176.2389183,
author = {Barkhuus, Louise and Brown, Barry},
title = {The Sociality of Fieldwork: Designing for Social Science Research Practice and Collaboration},
year = {2012},
isbn = {9781450314862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389176.2389183},
doi = {10.1145/2389176.2389183},
abstract = {Supporting scientific practice has been a longstanding goal of CSCW research. This paper explores how we might design for social science research practices and collaboration. Drawing on sixteen interviews with fieldwork-based social scientists we document the importance of small-scale long-term collaborative arrangements for research and intellectual work - pairs of researchers who work together in-depth over their careers, developing a common yet distinctive view of their research field. This contrasts with the large-scale short-lived collaborations that have classically been the target of cyber-infrastructure work. We describe technology practices among social scientists and how these can inform technology design for fieldwork practices.},
booktitle = {Proceedings of the 17th ACM International Conference on Supporting Group Work},
pages = {35–44},
numpages = {10},
keywords = {cyber-infrastructure e-social science fieldwork},
location = {Sanibel Island, Florida, USA},
series = {GROUP '12}
}

@inproceedings{10.1145/2457276.2457292,
author = {Mequanint, Dessalegn and Brunie, Lionel and Libsie, Mulugeta and Coquil, David},
title = {A Latency Hiding Framework for Enhanced Ubiquitous Access to Big Data in a Constrained Digital Ecosystem: Application to Digital Medical Archives},
year = {2012},
isbn = {9781450317559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2457276.2457292},
doi = {10.1145/2457276.2457292},
abstract = {This paper presents our latency hiding framework for access to big data in a constrained digital ecosystem with application to digital medical archives. Aiming to enhance ubiquitous access of big data such as patient-oriented access of medical archives, we apply complex/multi-context prefetching to reduce latency thereby improving response time. We propose a formal model for prefetch requests rate and network workload or stress bound that takes into account a diverse set of constraints a digital ecosystem could be in. In addition to that, components of our latency hiding framework such as a generic multi-context functional architecture, use case model, medical database model with emphasis on API (abstracted patient information) and a high-level system architecture have been designed. The development of a complex or multi-context prefetch algorithm that uses a patient's chief complaints, slackness sensitivity, popular content tag, user specified contexts and constraints is underway. A prototype system will also be developed to validate the proposed solutions. Moreover, input and output metrics will be developed to gauge the efficiency and effectiveness of the prefetch algorithm under development.},
booktitle = {Proceedings of the International Conference on Management of Emergent Digital EcoSystems},
pages = {80–87},
numpages = {8},
keywords = {ubiquitous access to big data, digital medical archives, multi-context prefetching, latency hiding},
location = {Addis Ababa, Ethiopia},
series = {MEDES '12}
}

@inproceedings{10.1145/2396761.2396776,
author = {Riondato, Matteo and DeBrabant, Justin A. and Fonseca, Rodrigo and Upfal, Eli},
title = {PARMA: A Parallel Randomized Algorithm for Approximate Association Rules Mining in MapReduce},
year = {2012},
isbn = {9781450311564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2396761.2396776},
doi = {10.1145/2396761.2396776},
abstract = {Frequent Itemsets and Association Rules Mining (FIM) is a key task in knowledge discovery from data. As the dataset grows, the cost of solving this task is dominated by the component that depends on the number of transactions in the dataset. We address this issue by proposing PARMA, a parallel algorithm for the MapReduce framework, which scales well with the size of the dataset (as number of transactions) while minimizing data replication and communication cost. PARMA cuts down the dataset-size-dependent part of the cost by using a random sampling approach to FIM. Each machine mines a small random sample of the dataset, of size independent from the dataset size. The results from each machine are then filtered and aggregated to produce a single output collection. The output will be a very close approximation of the collection of Frequent Itemsets (FI's) or Association Rules (AR's) with their frequencies and confidence levels. The quality of the output is probabilistically guaranteed by our analysis to be within the user-specified accuracy and error probability parameters. The sizes of the random samples are independent from the size of the dataset, as is the number of samples. They depend on the user-chosen accuracy and error probability parameters and on the parallel computational model. We implemented PARMA in Hadoop MapReduce and show experimentally that it runs faster than previously introduced FIM algorithms for the same platform, while 1) scaling almost linearly, and 2) offering even higher accuracy and confidence than what is guaranteed by the analysis.},
booktitle = {Proceedings of the 21st ACM International Conference on Information and Knowledge Management},
pages = {85–94},
numpages = {10},
keywords = {sampling, frequent itemsets, association rules, MapReduce},
location = {Maui, Hawaii, USA},
series = {CIKM '12}
}

@inproceedings{10.1145/2390131.2390145,
author = {Mogadala, Aditya and Varma, Vasudeva},
title = {Twitter User Behavior Understanding with Mood Transition Prediction},
year = {2012},
isbn = {9781450317078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2390131.2390145},
doi = {10.1145/2390131.2390145},
abstract = {Human moods continuously change over time. Tracking moods can provide important information about psychological and health behavior of an individual. Also, history of mood information can be used to predict the future moods of individuals. In this paper, we try to predict the mood transition of a Twitter user by regression analysis on the tweets posted over twitter time line. Initially, user tweets are automatically labeled with mood labels from time 0 to t-1. It is then used to predict user mood transition information at time t. Experiments show that SVM regression attained less root-mean-square error compared to other regression approaches for mood transition prediction.},
booktitle = {Proceedings of the 2012 Workshop on Data-Driven User Behavioral Modelling and Mining from Social Media},
pages = {31–34},
numpages = {4},
keywords = {twitter user mood prediction, mood analysis, regression on tweets},
location = {Maui, Hawaii, USA},
series = {DUBMMSM '12}
}

@inproceedings{10.1145/2396761.2398434,
author = {Liu, Jingjing and Liu, Chang and Cole, Michael and Belkin, Nicholas J. and Zhang, Xiangmin},
title = {Exploring and Predicting Search Task Difficulty},
year = {2012},
isbn = {9781450311564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2396761.2398434},
doi = {10.1145/2396761.2398434},
abstract = {We report on an investigation of behavioral differences between users in difficult and easy search tasks. Behavioral factors that can be used in real-time to predict task difficulty are identified. User data was collected in a controlled lab experiment (n=38) where each participant completed four search tasks in the genomics domain. We looked at user behaviors that can be obtained by systems at three levels, distinguished by the time point when the measurements can be done. They are: 1) first-round level at the beginning of the search, 2) accumulated level during the search, and 3) whole-session level by the end of the search. Results show that a number of user behaviors at all three levels differed between easy and difficult tasks. Models predicting task difficulty at all three levels were developed and evaluated. A real-time model incorporating first-round and accumulated levels of behaviors (FA) had fairly good prediction performance (accuracy 83%; precision 88%), which is comparable with the model using the whole-session level behaviors which are not real-time (accuracy 75%; precision 92%). We also found that for efficiency purpose, using only a limited number of significant variables (FC_FA) can obtain a prediction accuracy of 75%, with a precision of 88%. Our findings can help search systems predict task difficulty and adapt search results to users.},
booktitle = {Proceedings of the 21st ACM International Conference on Information and Knowledge Management},
pages = {1313–1322},
numpages = {10},
keywords = {user behavior, user modeling, first-round level, whole-session level, task difficulty, accumulated level, difficulty prediction},
location = {Maui, Hawaii, USA},
series = {CIKM '12}
}

@inproceedings{10.1145/2396761.2396850,
author = {Agarwal, Deepak and Chen, Bee-Chung and Wang, Xuanhui},
title = {Multi-Faceted Ranking of News Articles Using Post-Read Actions},
year = {2012},
isbn = {9781450311564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2396761.2396850},
doi = {10.1145/2396761.2396850},
abstract = {Personalized article recommendation is important for news portals to improve user engagement. Existing work quantifies engagement primarily through click rates. We suggest that quality of recommendations may be improved by exploiting different types of "post-read" engagement signals like sharing, commenting, printing and e-mailing article links. Specifically, we propose a multi-faceted ranking problem for recommending articles, where each facet corresponds to a ranking task that seeks to maximize actions of a particular post-read type (e.g., ranking articles to maximize sharing actions). Our approach is to predict the probability that a user would take a post-read action on an article, so that articles can be ranked according to such probabilities. However, post-read actions are rare events --- enormous data sparsity makes the problem challenging. We meet the challenge by exploiting correlations across different post-read action types through a novel locally augmented tensor (LAT) model, so that the ranking performance of a particular action type can be improved by leveraging data from all other action types. Through extensive experiments, we show that our LAT model significantly outperforms a variety of state-of-the-art factor models, logistic regression and IR models.},
booktitle = {Proceedings of the 21st ACM International Conference on Information and Knowledge Management},
pages = {694–703},
numpages = {10},
keywords = {post-read, multi-faceted, tensor model},
location = {Maui, Hawaii, USA},
series = {CIKM '12}
}

@article{10.1145/2382553.2382555,
author = {Erlingsson, \'{U}lfar and Peinado, Marcus and Peter, Simon and Budiu, Mihai and Mainar-Ruiz, Gloria},
title = {Fay: Extensible Distributed Tracing from Kernels to Clusters},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0734-2071},
url = {https://doi.org/10.1145/2382553.2382555},
doi = {10.1145/2382553.2382555},
abstract = {Fay is a flexible platform for the efficient collection, processing, and analysis of software execution traces. Fay provides dynamic tracing through use of runtime instrumentation and distributed aggregation within machines and across clusters. At the lowest level, Fay can be safely extended with new tracing primitives, including even untrusted, fully optimized machine code, and Fay can be applied to running user-mode or kernel-mode software without compromising system stability. At the highest level, Fay provides a unified, declarative means of specifying what events to trace, as well as the aggregation, processing, and analysis of those events.We have implemented the Fay tracing platform for Windows and integrated it with two powerful, expressive systems for distributed programming. Our implementation is easy to use, can be applied to unmodified production systems, and provides primitives that allow the overhead of tracing to be greatly reduced, compared to previous dynamic tracing platforms. To show the generality of Fay tracing, we reimplement, in experiments, a range of tracing strategies and several custom mechanisms from existing tracing frameworks.Fay shows that modern techniques for high-level querying and data-parallel processing of disagreggated data streams are well suited to comprehensive monitoring of software execution in distributed systems. Revisiting a lesson from the late 1960s [Deutsch and Grant 1971], Fay also demonstrates the efficiency and extensibility benefits of using safe, statically verified machine code as the basis for low-level execution tracing. Finally, Fay establishes that, by automatically deriving optimized query plans and code for safe extensions, the expressiveness and performance of high-level tracing queries can equal or even surpass that of specialized monitoring tools.},
journal = {ACM Trans. Comput. Syst.},
month = nov,
articleno = {13},
numpages = {35}
}

@article{10.1145/2366145.2366174,
author = {Ha, Sehoon and Ye, Yuting and Liu, C. Karen},
title = {Falling and Landing Motion Control for Character Animation},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/2366145.2366174},
doi = {10.1145/2366145.2366174},
abstract = {We introduce a new method to generate agile and natural human landing motions in real-time via physical simulation without using any mocap or pre-scripted sequences. We develop a general controller that allows the character to fall from a wide range of heights and initial speeds, continuously roll on the ground, and get back on its feet, without inducing large stress on joints at any moment. The character's motion is generated through a forward simulator and a control algorithm that consists of an airborne phase and a landing phase. During the airborne phase, the character optimizes its moment of inertia to meet the ideal relation between the landing velocity and the angle of attack, under the laws of conservation of momentum. The landing phase can be divided into three stages: impact, rolling, and getting-up. To reduce joint stress at landing, the character leverages contact forces to control linear momentum and angular momentum, resulting in a rolling motion which distributes impact over multiple body parts. We demonstrate that our control algorithm can be applied to a variety of initial conditions with different falling heights, orientations, and linear and angular velocities. Simulated results show that our algorithm can effectively create realistic action sequences comparable to real world footage of experienced freerunners.},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {155},
numpages = {9},
keywords = {optimal control, physics-based animation, character animation}
}

@article{10.1145/2382553.2382557,
author = {Ferdman, Michael and Adileh, Almutaz and Kocberber, Onur and Volos, Stavros and Alisafaee, Mohammad and Jevdjic, Djordje and Kaynak, Cansu and Popescu, Adrian Daniel and Ailamaki, Anastasia and Falsafi, Babak},
title = {Quantifying the Mismatch between Emerging Scale-Out Applications and Modern Processors},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0734-2071},
url = {https://doi.org/10.1145/2382553.2382557},
doi = {10.1145/2382553.2382557},
abstract = {Emerging scale-out workloads require extensive amounts of computational resources. However, data centers using modern server hardware face physical constraints in space and power, limiting further expansion and calling for improvements in the computational density per server and in the per-operation energy. Continuing to improve the computational resources of the cloud while staying within physical constraints mandates optimizing server efficiency to ensure that server hardware closely matches the needs of scale-out workloads.In this work, we introduce CloudSuite, a benchmark suite of emerging scale-out workloads. We use performance counters on modern servers to study scale-out workloads, finding that today’s predominant processor microarchitecture is inefficient for running these workloads. We find that inefficiency comes from the mismatch between the workload needs and modern processors, particularly in the organization of instruction and data memory systems and the processor core microarchitecture. Moreover, while today’s predominant microarchitecture is inefficient when executing scale-out workloads, we find that continuing the current trends will further exacerbate the inefficiency in the future. In this work, we identify the key microarchitectural needs of scale-out workloads, calling for a change in the trajectory of server processors that would lead to improved computational density and power efficiency in data centers.},
journal = {ACM Trans. Comput. Syst.},
month = nov,
articleno = {15},
numpages = {24}
}

@article{10.1145/2366316.2366335,
author = {Pfeifer, Rolf and Lungarella, Max and Iida, Fumiya},
title = {The Challenges Ahead for Bio-Inspired 'soft' Robotics},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/2366316.2366335},
doi = {10.1145/2366316.2366335},
abstract = {Soft materials may enable the automation of tasks beyond the capacities of current robotic technology.},
journal = {Commun. ACM},
month = nov,
pages = {76–87},
numpages = {12}
}

@article{10.1145/2366145.2366172,
author = {Min, Jianyuan and Chai, Jinxiang},
title = {Motion Graphs++: A Compact Generative Model for Semantic Motion Analysis and Synthesis},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/2366145.2366172},
doi = {10.1145/2366145.2366172},
abstract = {This paper introduces a new generative statistical model that allows for human motion analysis and synthesis at both semantic and kinematic levels. Our key idea is to decouple complex variations of human movements into finite structural variations and continuous style variations and encode them with a concatenation of morphable functional models. This allows us to model not only a rich repertoire of behaviors but also an infinite number of style variations within the same action. Our models are appealing for motion analysis and synthesis because they are highly structured, contact aware, and semantic embedding. We have constructed a compact generative motion model from a huge and heterogeneous motion database (about two hours mocap data and more than 15 different actions). We have demonstrated the power and effectiveness of our models by exploring a wide variety of applications, ranging from automatic motion segmentation, recognition, and annotation, and online/offline motion synthesis at both kinematics and behavior levels to semantic motion editing. We show the superiority of our model by comparing it with alternative methods.},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {153},
numpages = {12},
keywords = {semantic motion analysis and synthesis, generative motion models, motion planning, character animation}
}

@article{10.1145/2382564.2382567,
author = {Benda, Klara and Bruckman, Amy and Guzdial, Mark},
title = {When Life and Learning Do Not Fit: Challenges of Workload and Communication in Introductory Computer Science Online},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
url = {https://doi.org/10.1145/2382564.2382567},
doi = {10.1145/2382564.2382567},
abstract = {We present the results of an interview study investigating student experiences in two online introductory computer science courses. Our theoretical approach is situated at the intersection of two research traditions: distance and adult education research, which tends to be sociologically oriented, and computer science education research, which has strong connections with pedagogy and psychology. The article reviews contributions from both traditions on student failure in the context of higher education, distance and online education as well as introductory computer science. Our research relies on a combination of the two perspectives, which provides useful results for the field of computer science education in general, as well as its online or distance versions. The interviewed students exhibited great diversity in both socio-demographic and educational background. We identified no profiles that predicted student success or failure. At the same time, we found that expectations about programming resulted in challenges of time-management and communication. The time requirements of programming assignments were unpredictable, often disproportionate to expectations, and clashed with the external commitments of adult professionals. Too little communication was available to access adequate instructor help. On the basis of these findings, we suggest instructional design solutions for adult professionals studying introductory computer science education.},
journal = {ACM Trans. Comput. Educ.},
month = nov,
articleno = {15},
numpages = {38},
keywords = {programming instruction, Online education, workload, qualitative research, communication, student failure, introductory computer science}
}

@inproceedings{10.1145/2390045.2390062,
author = {B\"{a}r, Arian and Golab, Lukasz},
title = {Towards Benchmarking Stream Data Warehouses},
year = {2012},
isbn = {9781450317214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2390045.2390062},
doi = {10.1145/2390045.2390062},
abstract = {Data management systems are facing two challenges driven by the requirements of emerging data-intensive applications: more data and less time to process the data. Data volumes continue to increase as new sources and data collecting mechanisms appear. At the same time, these sources tend to be highly dynamic and generate data in the form of a stream, which requires quick reaction to newly arrived data. Traditional data warehouses enable scalable data storage and analytics, including the ability to define nested levels of materialized views. However, views are typically refreshed during downtimes---e.g., every night---which does not meet the latency requirements of many applications. Stream data warehousing is a new data management technology that allows nearly-continuous view refresh as new data arrive, which enables seamless integration of real-time monitoring and business intelligence with long-term data mining. In this paper, we argue that a new benchmark is required for stream warehouses, which should focus on measuring the property that determines the utility of these systems, namely how well they can keep up with the incoming data and guarantee the "freshness" of materialized views.},
booktitle = {Proceedings of the Fifteenth International Workshop on Data Warehousing and OLAP},
pages = {105–112},
numpages = {8},
keywords = {materialized view maintenance, stream data warehousing, data warehouse benchmarking},
location = {Maui, Hawaii, USA},
series = {DOLAP '12}
}

@inproceedings{10.1145/2389661.2389671,
author = {Barocas, Solon},
title = {The Price of Precision: Voter Microtargeting and Its Potential Harms to the Democratic Process},
year = {2012},
isbn = {9781450317139},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389661.2389671},
doi = {10.1145/2389661.2389671},
abstract = {This paper explores the potentially perverse effects of voter microtargeting, delineating how the very same techniques that empower political candidates to be more efficient and effective in their campaigning may also undermine the political and social fabric of the democracies in which those candidates seek office. The first part of the paper reviews the apparent attraction and stated goals of voter microtargeting and the technical processes upon which it relies. The second part draws out the ethical and political implications of the practice, pointing to some troubling empirical findings. The paper considers how microtargeting contributes to (1) an increased willingness and ability to deliver messages on wedge issues that would be extremely divisive in a more public forum; (2) voter discrimination and de facto disenfranchisement, (3) a chilling of political participation due to perceived violations of voters' privacy, and (4) a general trend toward single issue politics that leads to increased partisanship among voters and ambiguous political mandates for elected representatives. The final part of the paper introduces Soap Box: a project (initiated by the author) to develop a website that will act as a clearinghouse for targeted political advertising. The website aims to make these messages available to all-comers, forcing campaigns to account for and reconcile the different positions they present to different audiences. The paper concludes with a discussion of the limits of an approach that seeks to combat the more worrisome aspects of voter microtageting by exposing the tailored messages to greater public scrutiny.},
booktitle = {Proceedings of the First Edition Workshop on Politics, Elections and Data},
pages = {31–36},
numpages = {6},
keywords = {voting, elections, democracy, political campaigns, microtargeting},
location = {Maui, Hawaii, USA},
series = {PLEAD '12}
}

@inproceedings{10.1145/2389661.2389665,
author = {Garcia, David and Mendez, Fernando and Serd\"{u}lt, Uwe and Schweitzer, Frank},
title = {Political Polarization and Popularity in Online Participatory Media: An Integrated Approach},
year = {2012},
isbn = {9781450317139},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2389661.2389665},
doi = {10.1145/2389661.2389665},
abstract = {We present our approach to online popularity and its applications to political science, aiming at the creation of agent-based models that reproduce patterns of popularity in participatory media. We illustrate our approach analyzing a dataset from Youtube, composed of the view statistics and comments for the videos of the U.S. presidential campaigns of 2008 and 2012. Using sentiment analysis, we quantify the collective emotions expressed by the viewers, finding that democrat campaigns elicited more positive collective emotions than republican campaigns. Techniques from computational social science allow us to measure virality of the videos of each campaign, to find that democrat videos are shared faster but republican ones are remembered longer inside the community. Last we present our work in progress in voting advice applications, and our results analyzing the data from choose4greece.com. We show how we assess the policy differences between parties and their voters, and how voting advice applications can be extended to test our agent-based models.},
booktitle = {Proceedings of the First Edition Workshop on Politics, Elections and Data},
pages = {3–10},
numpages = {8},
keywords = {emotion, agent-based modelling, politics, popularity, internet},
location = {Maui, Hawaii, USA},
series = {PLEAD '12}
}

@inproceedings{10.1145/2398936.2398961,
author = {Kottege, Navinda and Kroon, Frederieke and Jurdak, Raja and Jones, Dean},
title = {Classification of Underwater Broadband Bio-Acoustics Using Spectro-Temporal Features},
year = {2012},
isbn = {9781450317733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2398936.2398961},
doi = {10.1145/2398936.2398961},
abstract = {Large scale freshwater monitoring networks can passively capture sound for species detection or classification. The sheer volume of acoustic recordings in such systems requires in-network classification. Most of the recent work on bio-acoustic in-network classification targets narrowband or short-durations signals, which renders it unsuitable for classifying species that emit broadband short-duration signals. This paper proposes a method for broadband sound based classification for large scale aquatic monitoring networks. The method is based on the extraction of a small set of spectral and temporal features. We collect empirical fish sounds, using the case study of the spotted tilapia (Tilapia mariae) which is an invasive freshwater fish species in Australia, and extract spectral and temporal features with our method. We then evaluate the classification accuracy and precision of these features for detecting tilapia sounds against the performance of existing narrowband sound features. The results show that using logistic regression with our limited feature set yields the best performance. Surprisingly, performance slightly improves when we downsample the signal from 44.1 to 16 kHz, indicating that our method is well-suited for classification on embedded devices. We quantify the computational benefits of our approach for enabling broader long-term in-situ species tracking in underwater environments.},
booktitle = {Proceedings of the Seventh ACM International Conference on Underwater Networks and Systems},
articleno = {19},
numpages = {8},
keywords = {freshwater fish, bio-acoustics, tilapia, detection, sound, classification, underwater},
location = {Los Angeles, California},
series = {WUWNet '12}
}

@inproceedings{10.5555/2400076.2400082,
author = {Romani, Luciana A. S. and Gon\c{c}alves, Renata R. V. and Chino, Daniel Y. T. and Traina, Agma J. M.},
title = {Challenges for Users and Designers in the Design Process of a Satellite Images Handling System},
year = {2012},
isbn = {9788576692621},
publisher = {Brazilian Computer Society},
address = {Porto Alegre, BRA},
abstract = {In this paper, we present the design process of a system to support agrometeorologists to improve a tiresome task of extracting data to generate time series from multiple satellite images. To understand the difficulty of dealing with thousands of images, one researcher in HCI has worked in a team of agrometeorologists for over 6 months. This case study describes the experience of this researcher using a manual and semi-automatic method developed by agrometeorologists. Moreover, we highlight the difficulties faced by specialists trying to learn how to develop scripts in order to make their tasks easier. Finally, we report the involvement of these experts in the design process of a new system that led to a more successful approach to deal with the challenge of handling enormous amount of satellite images.},
booktitle = {Companion Proceedings of the 11th Brazilian Symposium on Human Factors in Computing Systems},
pages = {13–16},
numpages = {4},
keywords = {user centered design, user experiences, remote sensing applications, participatory design},
location = {Cuiaba, Brazil},
series = {IHC '12}
}

@inproceedings{10.1145/2447481.2447482,
author = {Vatsavai, Ranga Raju and Ganguly, Auroop and Chandola, Varun and Stefanidis, Anthony and Klasky, Scott and Shekhar, Shashi},
title = {Spatiotemporal Data Mining in the Era of Big Spatial Data: Algorithms and Applications},
year = {2012},
isbn = {9781450316927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2447481.2447482},
doi = {10.1145/2447481.2447482},
abstract = {Spatial data mining is the process of discovering interesting and previously unknown, but potentially useful patterns from the spatial and spatiotemporal data. However, explosive growth in the spatial and spatiotemporal data, and the emergence of social media and location sensing technologies emphasize the need for developing new and computationally efficient methods tailored for analyzing big data. In this paper, we review major spatial data mining algorithms by closely looking at the computational and I/O requirements and allude to few applications dealing with big spatial data.},
booktitle = {Proceedings of the 1st ACM SIGSPATIAL International Workshop on Analytics for Big Geospatial Data},
pages = {1–10},
numpages = {10},
keywords = {computational and I/O challenges, large scale data mining, big data, spatiotemporal patterns},
location = {Redondo Beach, California},
series = {BigSpatial '12}
}

@inproceedings{10.1145/2422531.2422562,
author = {Beckel, Christian and Sadamori, Leyna and Santini, Silvia},
title = {Towards Automatic Classification of Private Households Using Electricity Consumption Data},
year = {2012},
isbn = {9781450311700},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2422531.2422562},
doi = {10.1145/2422531.2422562},
abstract = {The ongoing liberalization of the energy market makes energy providers increasingly look at premium services -- like personalized energy consulting -- as preferred methods to bind existing customers and attract new ones. Providing such services, however, requires knowledge of specific properties of the customer's household -- like its size and the number of persons living in it. In this paper, we investigate how such properties can be inferred from the fine-grained electricity consumption data provided by digital electricity meters. In particular, we focus on exploring which properties are both interesting and likely to be identified using well-known classification methods. To this end, we first elicit a set of interesting properties by performing in-depth interviews with employees of three different energy providers. We then explore a large set of electricity consumption traces using a self-organizing map. This analysis allows to identify a set of household properties that are likely to be inferable from electricity consumption data using standard classification methods. For instance, our results show that the size of a household and the income of its occupants are properties that are both highly useful to energy providers as well as likely to be detectable using an automatic classification system.},
booktitle = {Proceedings of the Fourth ACM Workshop on Embedded Sensing Systems for Energy-Efficiency in Buildings},
pages = {169–176},
numpages = {8},
keywords = {smart electricity meters, self-organizing maps, data mining, energy consumption analysis},
location = {Toronto, Ontario, Canada},
series = {BuildSys '12}
}

@inproceedings{10.1145/2447481.2447490,
author = {Assam, Roland and Seidl, Thomas},
title = {TMC-Pattern: Holistic Trajectory Extraction, Modeling and Mining},
year = {2012},
isbn = {9781450316927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2447481.2447490},
doi = {10.1145/2447481.2447490},
abstract = {Mobility data is Big Data. Modeling such raw big location data is quite challenging in terms of quality and runtime efficiency. Mobility data emanating from smart phones and other pervasive devices consists of a combination of spatio-temporal dimensions, as well as some additional contextual dimensions that may range from social network activities, diseases to telephone calls. However, most existing trajectory models focus only on the spatio-temporal dimensions of mobility data and their regions of interest depict only the popularity of a place. In this paper, we propose a novel trajectory model called Time Mobility Context Correlation Pattern (TMC-Pattern), which considers a wide variety of dimensions and utilizes subspace clustering to find contextual regions of interest. In addition, our proposed TMC-Pattern rigorously captures and embeds infrastructural, human, social and behavioral patterns into the trajectory model. We show theoretically and experimentally, how TMC-Pattern can be used for Frequent Location Sequence Mining and Location Prediction with real datasets.},
booktitle = {Proceedings of the 1st ACM SIGSPATIAL International Workshop on Analytics for Big Geospatial Data},
pages = {71–80},
numpages = {10},
keywords = {trajectory mining, context-aware location mining},
location = {Redondo Beach, California},
series = {BigSpatial '12}
}

@inproceedings{10.1145/2442968.2442975,
author = {Qi, Lin and Schneider, Markus},
title = {MONET: Modeling and Querying Moving Objects in Spatial Networks},
year = {2012},
isbn = {9781450316958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2442968.2442975},
doi = {10.1145/2442968.2442975},
abstract = {Data about moving objects is being collected in many different application domains with the help of sensor networks, and GPS-enabled devices. In most cases, the moving objects are not free to move, they are usually restricted by some spatial constraints such as Spatial Networks. Spatial networks are ubiquitous and have been widely used in transportation, traffic planning, navigation as well as in Geographical Information System (GIS) applications. In most scenarios, moving objects such as vehicles move along predefined spatial networks like transportation networks. Unfortunately, the concepts for modeling and querying objects in unconstrained spaces like an outdoor space cannot be transferred to constrained spaces like a road network due to the different features of the environments in which the spatial objects move. Further, modern positioning devices as well as mobile and sensor technology have led to large volumes of moving objects in spatial networks. Therefore, we need a database-friendly data model to explicitly model spatial networks and, more importantly, describe relative movements in these networks. In this paper, we propose a new two-layered data model called MONET (Moving Objects in NETworks) model. The lower layer is a data model for spatial networks. This data model is the prerequisite for the upper model that represents moving objects in these networks. This layered model fits well to formulate relationships between moving objects and a network in queries. A query language, called MONET QL (MONET Query Language), allows a clear description of and access to moving objects in spatial networks and to provides high-level operations on them.},
booktitle = {Proceedings of the 3rd ACM SIGSPATIAL International Workshop on GeoStreaming},
pages = {48–57},
numpages = {10},
keywords = {querying, spatial networks, modeling, moving objects},
location = {Redondo Beach, California},
series = {IWGS '12}
}

@inproceedings{10.1145/2442968.2442970,
author = {Masciari, Elio},
title = {Finding Homogeneous Groups in Trajectory Streams},
year = {2012},
isbn = {9781450316958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2442968.2442970},
doi = {10.1145/2442968.2442970},
abstract = {Trajectory data streams are huge amounts of data pertaining to time and position of moving objects. They are continuously generated by different sources exploiting a wide variety of technologies (e.g., RFID tags, GPS, GSM networks). Mining such amount of data is a challenging problem, since the possibility to extract useful information from this peculiar kind of data is crucial in many application scenarios such as vehicle traffic management, hand-off in cellular networks, supply chain management. Moreover, spatial data streams pose interesting challenges for their proper representation, thus making the mining process harder than for classical point data. In this paper, we address the problem of trajectory data streams clustering, that revealed really intriguing as we deal with a kind of data (trajectories) for which the order of elements is relevant. We propose a complete framework starting from data preparation task that allows us to make the mining step quite effective. Since the validation of data mining approaches has to be experimental we performed several tests on real world datasets that confirmed the efficiency and effectiveness of the proposed technique.},
booktitle = {Proceedings of the 3rd ACM SIGSPATIAL International Workshop on GeoStreaming},
pages = {11–18},
numpages = {8},
keywords = {spatial data, data warehousing},
location = {Redondo Beach, California},
series = {IWGS '12}
}

@inproceedings{10.1145/2426656.2426682,
author = {Liu, Tao and Cerpa, Alberto E.},
title = {TALENT: Temporal Adaptive Link Estimator with No Training},
year = {2012},
isbn = {9781450311694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2426656.2426682},
doi = {10.1145/2426656.2426682},
abstract = {Link quality estimation is a fundamental component of the low power wireless network protocols and is essential for routing protocols in Wireless Sensor Networks (WSNs). However, accurate link quality estimation remains a challenging task due to the notoriously dynamic and unpredictable wireless environment. In this paper, we argue that in addition to the estimation of current link quality, prediction of the future link quality is more important for the routing protocol to establish low cost delivery paths. We propose to apply machine learning methods to predict the link quality in the near future to facilitate the utilization of intermediate links with frequent quality changes. Moreover, we show that by using online learning methods, our adaptive link estimator (TALENT) adapts to network dynamics better than statically trained models without the need of a priori data collection for training the model before deployment. We implemented TALENT in TinyOS with Low-Power Listening (LPL) and conducted extensive experiments in three testbeds. Our experimental results show that the addition of TALENT increases the delivery efficiency 1.95 times on average compared with 4B, the state of the art link quality estimator, as well as improve the end-to-end delivery rate when tested on three different wireless testbeds.},
booktitle = {Proceedings of the 10th ACM Conference on Embedded Network Sensor Systems},
pages = {253–266},
numpages = {14},
keywords = {link quality prediction, link quality estimation},
location = {Toronto, Ontario, Canada},
series = {SenSys '12}
}

@inproceedings{10.1145/2426656.2426662,
author = {Nirjon, Shahriar and Dickerson, Robert F. and Li, Qiang and Asare, Philip and Stankovic, John A. and Hong, Dezhi and Zhang, Ben and Jiang, Xiaofan and Shen, Guobin and Zhao, Feng},
title = {MusicalHeart: A <i>Hearty</i> Way of Listening to Music},
year = {2012},
isbn = {9781450311694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2426656.2426662},
doi = {10.1145/2426656.2426662},
abstract = {MusicalHeart is a biofeedback-based, context-aware, automated music recommendation system for smartphones. We introduce a new wearable sensing platform, Septimu, which consists of a pair of sensor-equipped earphones that communicate to the smartphone via the audio jack. The Septimu platform enables the MusicalHeart application to continuously monitor the heart rate and activity level of the user while listening to music. The physiological information and contextual information are then sent to a remote server, which provides dynamic music suggestions to help the user maintain a target heart rate. We provide empirical evidence that the measured heart rate is 75% -- 85% correlated to the ground truth with an average error of 7.5 BPM. The accuracy of the person-specific, 3-class activity level detector is on average 96.8%, where these activity levels are separated based on their differing impacts on heart rate. We demonstrate the practicality of MusicalHeart by deploying it in two real world scenarios and show that MusicalHeart helps the user achieve a desired heart rate intensity with an average error of less than 12.2%, and its quality of recommendation improves over time.},
booktitle = {Proceedings of the 10th ACM Conference on Embedded Network Sensor Systems},
pages = {43–56},
numpages = {14},
keywords = {biofeedback, heart rate, music},
location = {Toronto, Ontario, Canada},
series = {SenSys '12}
}

@inproceedings{10.1145/2442968.2442977,
author = {Assam, Roland and Hassani, Marwan and Seidl, Thomas},
title = {Differential Private Trajectory Protection of Moving Objects},
year = {2012},
isbn = {9781450316958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2442968.2442977},
doi = {10.1145/2442968.2442977},
abstract = {Location privacy and security of spatio-temporal data has come under high scrutiny in the past years. This has rekindled enormous research interest. So far, most of the research studies that attempt to address location privacy are based on the k-Anonymity privacy paradigm. In this paper, we propose a novel technique to ensure location privacy in stream and non-stream mobility data using differential privacy. We portray incoming stream or non-stream mobility data emanating from GPS-enabled devices as a differential privacy problem and rigorously define a spatio-temporal sensitivity function for a trajectory metric space. Privacy is achieved through path perturbation in both the space and time domain. In addition, we introduce a new notion of Nearest Neighbor Anchor Resource to add more contextual meaning in the face of uncertainty to the perturbed trajectory path. Unlike k-Anonymity techniques that require more mobile objects to achieve strong anonymity; we show that our approach provides stronger privacy even for a single moving mobile object, outliers or mobile objects in sparsely populated regions.},
booktitle = {Proceedings of the 3rd ACM SIGSPATIAL International Workshop on GeoStreaming},
pages = {68–77},
numpages = {10},
keywords = {moving object privacy, location Privacy, differential privacy, stream privacy},
location = {Redondo Beach, California},
series = {IWGS '12}
}

@inproceedings{10.1145/2442985.2442989,
author = {Dos Santos, Raimundo F. and Boedihardjo, Arnold P. and Lu, Chang-Tien},
title = {Towards Ontological Similarity for Spatial Hierarchies},
year = {2012},
isbn = {9781450317009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2442985.2442989},
doi = {10.1145/2442985.2442989},
abstract = {Ontological structures provide a rich hierarchy of concepts and relationships that are helpful in exploratory analysis. Ontologies, however, are often categorical, which introduces ambiguity, and makes numerical analysis difficult. Adding to the problem is the fact that as the number of ontological concepts increases so does computational complexity for a variety of analytical tasks. In this paper, we propose both spatial and ontological co-occurrence as a means to derive similarity among categorical values. More specifically, we devise a method that combines entity location as well as categorical frequency into a numerical measure of similarity for any pair of categorical values. In addition, we show how different ontological levels can hide or uncover information content while influencing the number of processed categorical values. We provide experiments that demonstrate the effectiveness of our approach.},
booktitle = {Proceedings of the Third ACM SIGSPATIAL International Workshop on Querying and Mining Uncertain Spatio-Temporal Data},
pages = {26–33},
numpages = {8},
keywords = {categorical data, ontologies, spatial hierarchies},
location = {Redondo Beach, California},
series = {QUeST '12}
}

@inproceedings{10.1145/2442796.2442808,
author = {Gong, Zhaoya and Tang, Wenwu and Thill, Jean-Claude},
title = {Parallelization of Ensemble Neural Networks for Spatial Land-Use Modeling},
year = {2012},
isbn = {9781450316989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2442796.2442808},
doi = {10.1145/2442796.2442808},
abstract = {Artificial neural networks have been widely applied to spatial modeling and knowledge discovery because of their high-level intelligence and flexibility. Their highly parallel and distributed structure makes them inherently suitable for parallel computing. As the technology of parallel and high-performance computing evolves and computing resources become more widely available, new opportunities exist for spatial neural network models to benefit from this advancement in terms of better handling computational and data intensity associated with spatial problems. In this study, we present a hybrid parallel ensemble neural network approach for modeling spatial land-use change. Our approach combines the shared-memory paradigm and the embarrassingly parallel method by leveraging the power of multicore computer clusters. The efficacy of this approach is demonstrated by the parallelization of Fuzzy ARTMAP neural network models, which have been extensively used in land-use modeling applications. We adopt an ensemble structure of neural networks to train multiple models in parallel and make use of the entire dataset simultaneously. We evaluate the proposed parallelization approach by examining performance variation of training datasets with alternative sizes. Experimental results reveal great potential of higher performance achievement when our hybrid parallel computing approach is applied to large spatial modeling problems.},
booktitle = {Proceedings of the 5th ACM SIGSPATIAL International Workshop on Location-Based Social Networks},
pages = {48–54},
numpages = {7},
keywords = {artificial neural networks, parallel computing, shared-memory, spatial land-use modeling, multicore computing},
location = {Redondo Beach, California},
series = {LBSN '12}
}

@inproceedings{10.1145/2426656.2426671,
author = {Aslam, Javed and Lim, Sejoon and Pan, Xinghao and Rus, Daniela},
title = {City-Scale Traffic Estimation from a Roving Sensor Network},
year = {2012},
isbn = {9781450311694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2426656.2426671},
doi = {10.1145/2426656.2426671},
abstract = {Traffic congestion, volumes, origins, destinations, routes, and other road-network performance metrics are typically collected through survey data or via static sensors such as traffic cameras and loop detectors. This information is often out-of-date, difficult to collect and aggregate, difficult to analyze and quantify, or all of the above. In this paper we conduct a case study that demonstrates that it is possible to accurately infer traffic volume through data collected from a roving sensor network of taxi probes that log their locations and speeds at regular intervals. Our model and inference procedures can be used to analyze traffic patterns and conditions from historical data, as well as to infer current patterns and conditions from data collected in real-time. As such, our techniques provide a powerful new sensor network approach for traffic visualization, analysis, and urban planning.},
booktitle = {Proceedings of the 10th ACM Conference on Embedded Network Sensor Systems},
pages = {141–154},
numpages = {14},
keywords = {GPS, estimation, sensor network, inductor loop detector, prediction, taxi, traffic},
location = {Toronto, Ontario, Canada},
series = {SenSys '12}
}

@inproceedings{10.5555/2388996.2389101,
author = {Gainaru, Ana and Cappello, Franck and Snir, Marc and Kramer, William},
title = {Fault Prediction under the Microscope: A Closer Look into HPC Systems},
year = {2012},
isbn = {9781467308045},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
abstract = {A large percentage of computing capacity in today's large high-performance computing systems is wasted because of failures. Consequently current research is focusing on providing fault tolerance strategies that aim to minimize fault's effects on applications. By far the most popular technique is the checkpoint-restart strategy. A complement to this classical approach is failure avoidance, by which the occurrence of a fault is predicted and preventive measures are taken. This requires a reliable prediction system to anticipate failures and their locations. Thus far, research in this field has used ideal predictors that were not implemented in real HPC systems.In this paper, we merge signal analysis concepts with data mining techniques to extend the ELSA (Event Log Signal Analyzer) toolkit and offer an adaptive and more efficient prediction module. Our goal is to provide models that characterize the normal behavior of a system and the way faults affect it. Being able to detect deviations from normality quickly is the foundation of accurate fault prediction. However, this is challenging because component failure dynamics are heterogeneous in space and time. To this end, a large part of the paper is focused on a detailed analysis of the prediction method, by applying it to two large-scale systems and by investigating the characteristics and bottlenecks of each step of the prediction process. Furthermore, we analyze the prediction's precision and recall impact on current checkpointing strategies and highlight future improvements and directions for research in this field.},
booktitle = {Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
articleno = {77},
numpages = {11},
keywords = {fault tolerance, large-scale HPC systems, signal analysis, fault detection},
location = {Salt Lake City, Utah},
series = {SC '12}
}

@inproceedings{10.5555/2388996.2389078,
author = {Kanov, Kalin and Burns, Randal and Eyink, Greg and Meneveau, Charles and Szalay, Alexander},
title = {Data-Intensive Spatial Filtering in Large Numerical Simulation Datasets},
year = {2012},
isbn = {9781467308045},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
abstract = {We present a query processing framework for the efficient evaluation of spatial filters on large numerical simulation datasets stored in a data-intensive cluster. Previously, filtering of large numerical simulations stored in scientific databases has been impractical owing to the immense data requirements. Rather, filtering is done during simulation or by loading snapshots into the aggregate memory of an HPC cluster. Our system performs filtering within the database and supports large filter widths. We present two complementary methods of execution: I/O streaming computes a batch filter query in a single sequential pass using incremental evaluation of decomposable kernels, summed volumes generates an intermediate data set and evaluates each filtered value by accessing only eight points in this dataset. We dynamically choose between these methods depending upon workload characteristics. The system allows us to perform filters against large data sets with little overhead: query performance scales with the cluster's aggregate I/O throughput.},
booktitle = {Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
articleno = {60},
numpages = {9},
location = {Salt Lake City, Utah},
series = {SC '12}
}

@inproceedings{10.1145/2393596.2393624,
author = {Siegmund, Janet and Brechmann, Andr\'{e} and Apel, Sven and K\"{a}stner, Christian and Liebig, J\"{o}rg and Leich, Thomas and Saake, Gunter},
title = {Toward Measuring Program Comprehension with Functional Magnetic Resonance Imaging},
year = {2012},
isbn = {9781450316149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2393596.2393624},
doi = {10.1145/2393596.2393624},
abstract = {Program comprehension is an often evaluated, internal cognitive process. In neuroscience, functional magnetic resonance imaging (fMRI) is used to visualize such internal cognitive processes. We propose an experimental design to measure program comprehension based on fMRI. In the long run, we hope to answer questions like What distinguishes good programmers from bad programmers? or What makes a good programmer?},
booktitle = {Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
articleno = {24},
numpages = {4},
keywords = {controlled experiments, fMRI, program comprehension},
location = {Cary, North Carolina},
series = {FSE '12}
}

@inproceedings{10.1145/2393596.2393636,
author = {Park, Sangmin and Hossain, B. M. Mainul and Hussain, Ishtiaque and Csallner, Christoph and Grechanik, Mark and Taneja, Kunal and Fu, Chen and Xie, Qing},
title = {CarFast: Achieving Higher Statement Coverage Faster},
year = {2012},
isbn = {9781450316149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2393596.2393636},
doi = {10.1145/2393596.2393636},
abstract = {Test coverage is an important metric of software quality, since it indicates thoroughness of testing. In industry, test coverage is often measured as statement coverage. A fundamental problem of software testing is how to achieve higher statement coverage faster, and it is a difficult problem since it requires testers to cleverly find input data that can steer execution sooner toward sections of application code that contain more statements.We created a novel fully automatic approach for aChieving higher stAtement coveRage FASTer (CarFast), which we implemented and evaluated on twelve generated Java applications whose sizes range from 300 LOC to one million LOC. We compared CarFast with several popular test case generation techniques, including pure random, adaptive random, and Directed Automated Random Testing (DART). Our results indicate with strong statistical significance that when execution time is measured in terms of the number of runs of the application on different input test data, CarFast outperforms the evaluated competitive approaches on most subject applications.},
booktitle = {Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
articleno = {35},
numpages = {11},
keywords = {testing, statement coverage, experimentation},
location = {Cary, North Carolina},
series = {FSE '12}
}

@inproceedings{10.1145/2398776.2398784,
author = {Santiago del Rio, Pedro M. and Rossi, Dario and Gringoli, Francesco and Nava, Lorenzo and Salgarelli, Luca and Aracil, Javier},
title = {Wire-Speed Statistical Classification of Network Traffic on Commodity Hardware},
year = {2012},
isbn = {9781450317054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2398776.2398784},
doi = {10.1145/2398776.2398784},
abstract = {In this paper we present a software-based traffic classification engine running on commodity multi-core hardware, able to process in real-time aggregates of up to 14.2 Mpps over a single 10 Gbps interface -- i.e., the maximum possible packet rate over a 10 Gbps Ethernet links given the minimum frame size of 64 Bytes.This significant advance with respect to the current state of the art in terms of achieved classification rates are made possible by:(i) the use of an improved network driver, PacketShader, to efficiently move batches of packets from the NIC to the main CPU;(ii) the use of lightweight statistical classification techniques exploiting the size of the first few packets of every observed flow;(iii) a careful tuning of critical parameters of the hardware environment and the software application itself.},
booktitle = {Proceedings of the 2012 Internet Measurement Conference},
pages = {65–72},
numpages = {8},
keywords = {commodity hardware, statistical identification, traffic monitoring},
location = {Boston, Massachusetts, USA},
series = {IMC '12}
}

@article{10.1145/2390756.2398392,
author = {Helland, Pat},
title = {Condos and Clouds: Constraints in an Environment Empower the Services.},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {11},
issn = {1542-7730},
url = {https://doi.org/10.1145/2390756.2398392},
doi = {10.1145/2390756.2398392},
abstract = {Living in a condominium has its constraints and its services. By defining the lifestyle and limits on usage patterns, it is possible to pack many homes close together and to provide the residents with many conveniences. Condo living can offer a great value to those interested and willing to live within its constraints and enjoy the sharing of common services.},
journal = {Queue},
month = nov,
pages = {20–35},
numpages = {16}
}

@inproceedings{10.1145/2414536.2414563,
author = {Foth, Marcus and Fitz-Walter, Zachary and Ti, Jimmy and Russell-Bennett, Rebekah and Kuhn, Kerri-Ann},
title = {Please Take out Your Phones: On the Spot Solicitation of Student Feedback in Class},
year = {2012},
isbn = {9781450314381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2414536.2414563},
doi = {10.1145/2414536.2414563},
abstract = {The use of mobile devices such as smart phones and tablets in classrooms has been met with mixed sentiments. Some instructors and teachers see them as a distraction and regularly ban their usage. Others who see their potential to enhance learning have started to explore ways to integrate them into their teaching in an attempt to improve student engagement. In this paper we report on a pilot study that forms part of a university-wide project reconceptualising its approach to the student evaluation of learning and teaching. In a progressive decision to embrace mobile technology, the university decided to trial a smart phone app designed for students to check-in to class and leave feedback on the spot. Our preliminary findings from trialling the app indicate that the application establishes a more immediate feedback loop between students and teachers. However, the app's impact depends on how feedback is shared with students and how the teaching team responds.},
booktitle = {Proceedings of the 24th Australian Computer-Human Interaction Conference},
pages = {150–153},
numpages = {4},
keywords = {tertiary education, assessment, mobile applications, student feedback, technology-assisted learning},
location = {Melbourne, Australia},
series = {OzCHI '12}
}

@inproceedings{10.1145/2414536.2414602,
author = {Nourbakhsh, Nargess and Wang, Yang and Chen, Fang and Calvo, Rafael A.},
title = {Using Galvanic Skin Response for Cognitive Load Measurement in Arithmetic and Reading Tasks},
year = {2012},
isbn = {9781450314381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2414536.2414602},
doi = {10.1145/2414536.2414602},
abstract = {Galvanic Skin Response (GSR) has recently attracted researchers' attention as a prospective physiological indicator of cognitive load and emotions. However, it has commonly been investigated through single or few measures and in one experimental scenario. In this research, aiming to perform a comprehensive study, we have assessed GSR data captured from two different experiments, one including text reading tasks and the other using arithmetic tasks, each imposing multiple cognitive load levels. We have examined temporal and spectral features of GSR against different task difficulty levels. ANOVA test was applied for the statistical evaluation. Obtained results show the strong significance of the explored features, especially the spectral ones, in cognitive workload measurement in the two studied experiments.},
booktitle = {Proceedings of the 24th Australian Computer-Human Interaction Conference},
pages = {420–423},
numpages = {4},
keywords = {cognitive load, galvanic skin response, temporal analysis, physiological signals, spectral analysis},
location = {Melbourne, Australia},
series = {OzCHI '12}
}

@article{10.1145/2379799.2379800,
author = {Osborne, Michael A. and Roberts, Stephen J. and Rogers, Alex and Jennings, Nicholas R.},
title = {Real-Time Information Processing of Environmental Sensor Network Data Using Bayesian Gaussian Processes},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
issn = {1550-4859},
url = {https://doi.org/10.1145/2379799.2379800},
doi = {10.1145/2379799.2379800},
abstract = {In this article, we consider the problem faced by a sensor network operator who must infer, in real time, the value of some environmental parameter that is being monitored at discrete points in space and time by a sensor network. We describe a powerful and generic approach built upon an efficient multi-output Gaussian process that facilitates this information acquisition and processing. Our algorithm allows effective inference even with minimal domain knowledge, and we further introduce a formulation of Bayesian Monte Carlo to permit the principled management of the hyperparameters introduced by our flexible models. We demonstrate how our methods can be applied in cases where the data is delayed, intermittently missing, censored, and/or correlated. We validate our approach using data collected from three networks of weather sensors and show that it yields better inference performance than both conventional independent Gaussian processes and the Kalman filter. Finally, we show that our formalism efficiently reuses previous computations by following an online update procedure as new data sequentially arrives, and that this results in a four-fold increase in computational speed in the largest cases considered.},
journal = {ACM Trans. Sen. Netw.},
month = nov,
articleno = {1},
numpages = {32},
keywords = {adaptive sampling, information processing, Gaussian processes, Learning of models from data}
}

@article{10.5555/2382887.2382903,
author = {Carter, Thomas and Hauselt, Peggy and Martin, Melanie and Thomas, Megan},
title = {Building a Big Data Research Program at a Small University},
year = {2012},
issue_date = {December 2012},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {28},
number = {2},
issn = {1937-4771},
abstract = {In the 2010-2011 school year we received an Army High Performance Computing Research Center grant whose goal was increasing the number of Hispanic engineers with expertise in complex systems, simulations and large data sets. Our university is a medium-sized, public, Hispanic-serving institution; our department is small. Our goals were to improve the social support available to our Hispanic students, encourage them to complete their degrees, and give them a valid research experience to provide a basis for informed decisions about whether or not they want to go to graduate school. This paper will cover how we structured our program to accomplish our goals, including how we factored in results from prior research on minority student experiences. In the second year, we expanded our program to include geography and give a new cohort of students a multi-disciplinary experience. We will discuss how a small computer science department successfully built an undergraduate research program organized around the theme of large data sets, what we have accomplished so far and how we hope to continue.},
journal = {J. Comput. Sci. Coll.},
month = dec,
pages = {95–102},
numpages = {8}
}

@article{10.1145/2382570.2382572,
author = {Maggio, Martina and Hoffmann, Henry and Papadopoulos, Alessandro V. and Panerati, Jacopo and Santambrogio, Marco D. and Agarwal, Anant and Leva, Alberto},
title = {Comparison of Decision-Making Strategies for Self-Optimization in Autonomic Computing Systems},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
issn = {1556-4665},
url = {https://doi.org/10.1145/2382570.2382572},
doi = {10.1145/2382570.2382572},
abstract = {Autonomic computing systems are capable of adapting their behavior and resources thousands of times a second to automatically decide the best way to accomplish a given goal despite changing environmental conditions and demands. Different decision mechanisms are considered in the literature, but in the vast majority of the cases a single technique is applied to a given instance of the problem. This article proposes a comparison of some state of the art approaches for decision making, applied to a self-optimizing autonomic system that allocates resources to a software application. A variety of decision mechanisms, from heuristics to control-theory and machine learning, are investigated. The results obtained with these solutions are compared by means of case studies using standard benchmarks. Our results indicate that the most suitable decision mechanism can vary depending on the specific test case but adaptive and model predictive control systems tend to produce good performance and may work best in a priori unknown situations.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = dec,
articleno = {36},
numpages = {32},
keywords = {design approaches, comparison, Decision mechanisms}
}

@article{10.1145/2395131.2395138,
author = {Gao, Yuan and Bianchi-Berthouze, Nadia and Meng, Hongying},
title = {What Does Touch Tell Us about Emotions in Touchscreen-Based Gameplay?},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {4},
issn = {1073-0516},
url = {https://doi.org/10.1145/2395131.2395138},
doi = {10.1145/2395131.2395138},
abstract = {The increasing number of people playing games on touch-screen mobile phones raises the question of whether touch behaviors reflect players’ emotional states. This prospect would not only be a valuable evaluation indicator for game designers, but also for real-time personalization of the game experience. Psychology studies on acted touch behavior show the existence of discriminative affective profiles. In this article, finger-stroke features during gameplay on an iPod were extracted and their discriminative power analyzed. Machine learning algorithms were used to build systems for automatically discriminating between four emotional states (Excited, Relaxed, Frustrated, Bored), two levels of arousal and two levels of valence. Accuracy reached between 69% and 77% for the four emotional states, and higher results (~89%) were obtained for discriminating between two levels of arousal and two levels of valence. We conclude by discussing the factors relevant to the generalization of the results to applications other than games.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = dec,
articleno = {31},
numpages = {30},
keywords = {touch-based computer games, Automatic emotion recognition, touch behavior, affective touch}
}

@article{10.1145/2399193.2399195,
author = {Leung, Rock and Tang, Charlotte and Haddad, Shathel and Mcgrenere, Joanna and Graf, Peter and Ingriany, Vilia},
title = {How Older Adults Learn to Use Mobile Devices: Survey and Field Investigations},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
issn = {1936-7228},
url = {https://doi.org/10.1145/2399193.2399195},
doi = {10.1145/2399193.2399195},
abstract = {Mobile computing devices, such as smart phones, offer benefits that may be especially valuable to older adults (age 65+). Yet, older adults have been shown to have difficulty learning to use these devices. In the research presented in this article, we sought to better understand how older adults learn to use mobile devices, their preferences and barriers, in order to find new ways to support them in their learning process. We conducted two complementary studies: a survey study with 131 respondents from three age groups (20--49, 50--64, 65+) and an in-depth field study with 6 older adults aged 50+. The results showed, among other things, that the preference for trial-and-error decreases with age, and while over half of older respondents and participants preferred using the instruction manual, many reported difficulties using it. We discuss implications for design and illustrate these implications with an example help system, Help Kiosk, designed to support older adults’ learning to use mobile devices.},
journal = {ACM Trans. Access. Comput.},
month = dec,
articleno = {11},
numpages = {33},
keywords = {mobile device, Older adults, learning}
}

@inproceedings{10.1145/2428736.2428764,
author = {Hu, Bo and Carvalho, Nuno and Laera, Loredana and Matsutsuka, Takahide},
title = {Towards Big Linked Data: A Large-Scale, Distributed Semantic Data Storage},
year = {2012},
isbn = {9781450313063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2428736.2428764},
doi = {10.1145/2428736.2428764},
abstract = {In light of the challenges of effectively managing Big Data, we are witnessing a gradual shift towards the increasingly popular Linked Open Data (LOD) paradigm. LOD aims to impose a machine-readable semantic layer over structured as well as unstructured data and hence automate some data analysis tasks that are not designed for computers. The convergence of Big Data and LOD is, however, not straightforward: the semantic layer of LOD and the Big Data large scale storage do not get along easily. Meanwhile, the sheer data size envisioned by Big Data denies certain computationally expensive semantic technologies, rendering the latter much less efficient than their performance on relatively small data sets.In this paper, we propose a mechanism allowing LOD to take advantage of existing large-scale data stores while sustaining its "semantic" nature. We demonstrate how RDF-based semantic models can be distributed across multiple storage servers and we examine how a fundamental semantic operation can be tuned to meet the requirements on distributed and parallel data processing. Our future work will focus on stress test of the platform in the magnitude of tens of billions of triples, as well as comparative studies in usability and performance against similar offerings.},
booktitle = {Proceedings of the 14th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {167–176},
numpages = {10},
keywords = {distributed data reconciliation, graph storage, fault tolerance, key-value stores, RDF store},
location = {Bali, Indonesia},
series = {IIWAS '12}
}

@inproceedings{10.1145/2420950.2420975,
author = {Enev, Miro and Jung, Jaeyeon and Bo, Liefeng and Ren, Xiaofeng and Kohno, Tadayoshi},
title = {SensorSift: Balancing Sensor Data Privacy and Utility in Automated Face Understanding},
year = {2012},
isbn = {9781450313124},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2420950.2420975},
doi = {10.1145/2420950.2420975},
abstract = {We introduce SensorSift, a new theoretical scheme for balancing utility and privacy in smart sensor applications. At the heart of our contribution is an algorithm which transforms raw sensor data into a 'sifted' representation which minimizes exposure of user defined private attributes while maximally exposing application-requested public attributes. We envision multiple applications using the same platform, and requesting access to public attributes explicitly not known at the time of the platform creation. Support for future-defined public attributes, while still preserving the defined privacy of the private attributes, is a central challenge that we tackle.To evaluate our approach, we apply SensorSift to the PubFig dataset of celebrity face images, and study how well we can simultaneously hide and reveal various policy combinations of face attributes using machine classifiers.We find that as long as the public and private attributes are not significantly correlated, it is possible to generate a sifting transformation which reduces private attribute inferences to random guessing while maximally retaining classifier accuracy of public attributes relative to raw data (average PubLoss = .053 and PrivLoss = .075, see Figure 4). In addition, our sifting transformations led to consistent classification performance when evaluated using a set of five modern machine learning methods (linear SVM, kNearest Neighbors, Random Forests, kernel SVM, and Neural Nets).},
booktitle = {Proceedings of the 28th Annual Computer Security Applications Conference},
pages = {149–158},
numpages = {10},
location = {Orlando, Florida, USA},
series = {ACSAC '12}
}

@inproceedings{10.1145/2405186.2405188,
author = {Beernaert, Leander and Matos, Miguel and Vila\c{c}a, Ricardo and Oliveira, Rui},
title = {Automatic Elasticity in OpenStack},
year = {2012},
isbn = {9781450316156},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2405186.2405188},
doi = {10.1145/2405186.2405188},
abstract = {Cloud computing infrastructures are the most recent approach to the development and conception of computational systems. Cloud infrastructures are complex environments with various subsystems, each one with their own challenges. Cloud systems should be able to provide the following fundamental property: elasticity. Elasticity is the ability to automatically add and remove instances according to the needs of the system. This is a requirement for pay-per-use billing models.Various open source software solutions allow companies and institutions to build their own Cloud infrastructure. However, in most of these, the elasticity feature is quite immature. Monitoring and timely adapting the active resources of a Cloud computing infrastructure is key to provide the elasticity required by diverse, multi-tenant and pay-per-use business models.In this paper, we propose Elastack, an automated monitoring and adaptive system, generic enough to be applied to existing IaaS frameworks, and intended to enable the elasticity they currently lack. Our approach offers any Cloud infrastructure the mechanisms to implement automated monitoring and adaptation as well as the flexibility to go beyond these. We evaluate Elastack by integrating it with the OpenStack showing how easy it is to add these important features with a minimum, almost imperceptible, amount of modifications to the default installation.},
booktitle = {Proceedings of the Workshop on Secure and Dependable Middleware for Cloud Monitoring and Management},
articleno = {2},
numpages = {6},
keywords = {cloud computing, scalability, elasticity, automatization, adaptation, middleware},
location = {Montreal, Quebec, Canada},
series = {SDMCMM '12}
}

@inproceedings{10.1145/2420950.2420980,
author = {Willems, Carsten and Hund, Ralf and Fobian, Andreas and Felsch, Dennis and Holz, Thorsten and Vasudevan, Amit},
title = {Down to the Bare Metal: Using Processor Features for Binary Analysis},
year = {2012},
isbn = {9781450313124},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2420950.2420980},
doi = {10.1145/2420950.2420980},
abstract = {A detailed understanding of the behavior of exploits and malicious software is necessary to obtain a comprehensive overview of vulnerabilities in operating systems or client applications, and to develop protection techniques and tools. To this end, a lot of research has been done in the last few years on binary analysis techniques to efficiently and precisely analyze code. Most of the common analysis frameworks are based on software emulators since such tools offer a fine-grained control over the execution of a given program. Naturally, this leads to an arms race where the attackers are constantly searching for new methods to detect such analysis frameworks in order to successfully evade analysis.In this paper, we focus on two aspects. As a first contribution, we introduce several novel mechanisms by which an attacker can delude an emulator. In contrast to existing detection approaches that perform a dedicated test on the environment and combine the test with an explicit conditional branch, our detection mechanisms introduce code sequences that have an implicitly different behavior on a native machine when compared to an emulator. Such differences in behavior are caused by the side-effects of the particular operations and imperfections in the emulation process that cannot be mitigated easily. Motivated by these findings, we introduce a novel approach to generate execution traces. We propose to utilize the processor itself to generate such traces. Mores precisely, we propose to use a hardware feature called branch tracing available on commodity x86 processors in which the log of all branches taken during code execution is generated directly by the processor. Effectively, the logging is thus performed at the lowest level possible. We evaluate the practical viability of this approach.},
booktitle = {Proceedings of the 28th Annual Computer Security Applications Conference},
pages = {189–198},
numpages = {10},
location = {Orlando, Florida, USA},
series = {ACSAC '12}
}

@inproceedings{10.1145/2406367.2406410,
author = {Lehtiniemi, Arto and Ojala, Jarno},
title = {MyTerritory: Evaluation of Outdoor Gaming Prototype for Music Discovery},
year = {2012},
isbn = {9781450318150},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2406367.2406410},
doi = {10.1145/2406367.2406410},
abstract = {This paper presents an outdoor gaming prototype for music discovery and its field-trial evaluation by 15 Finnish users. The implemented mobile prototype enables users to conquer physical areas from a map view by circulating them and assigning songs to dominate the areas. Music can then be consumed from these areas by other users using three different methods. Based on the results, the concept adds novel experiences to outdoor gaming and music discovery. Populating the world with music by competing in the game was seen as a motivating way to discover and share music. Outdoor exercising combined to discovering places conquered with new music were seen as important and interesting by all the users in the interviews. Users found the different music consumption options to be novel and useful. This paper proposes a set of general design drivers for music discovery in outdoor gaming and further development ideas for the concept.},
booktitle = {Proceedings of the 11th International Conference on Mobile and Ubiquitous Multimedia},
articleno = {35},
numpages = {10},
keywords = {motivations, location based, user experience, mobile music services, personal content, music discovery, mobile content consumption, content creation, outdoor-gaming},
location = {Ulm, Germany},
series = {MUM '12}
}

@inproceedings{10.1145/2405146.2405151,
author = {Chen, Han and Kim, Minkyong and Zhang, Zhe and Lei, Hui},
title = {Empirical Study of Application Runtime Performance Using On-Demand Streaming Virtual Disks in the Cloud},
year = {2012},
isbn = {9781450316132},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2405146.2405151},
doi = {10.1145/2405146.2405151},
abstract = {As enterprises migrate more and more mission critical workloads to the cloud, the performance of a cloud computing system becomes increasingly important. The traditional method of pre-copying virtual machine images to hypervisors before VMs are booted results in long provisioning delays. On-demand streaming of virtual disks is used to speed up the provisioning but it may result in application runtime performance penalty. This paper seeks to quantify the runtime performance when using on-demand streaming through an empirical study. We have studied three representative application workloads: I/O micro-benchmarks, transactional application and Big Data. Two streaming protocols, NFS and iSCSI, are used in conjunction with two Copy-on-Write schemes, qcow2 from QEMU and dm-snapshot from Linux Device Mapper. We have also investigated the impact of page caching at hypervisor level on application runtime performance. The results show that I/O micro-benchmarks and transactional workload perform equally well with on-demand streaming as with pre-copied local virtual disks, while Big Data workload such as Hadoop sees a performance degradation up to 16%. We hope this study can provide insights into the performance aspect of various streaming technologies and offer guidelines to cloud operators and end users in implementing them.},
booktitle = {Proceedings of the Industrial Track of the 13th ACM/IFIP/USENIX International Middleware Conference},
articleno = {5},
numpages = {6},
keywords = {virtualization, virtual disk, cloud computing, virtual machine, caching},
location = {Montreal, Quebec, Canada},
series = {MIDDLEWARE '12}
}

@article{10.1145/2385603.2385607,
author = {Kim, Hyojun and Agrawal, Nitin and Ungureanu, Cristian},
title = {Revisiting Storage for Smartphones},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
issn = {1553-3077},
url = {https://doi.org/10.1145/2385603.2385607},
doi = {10.1145/2385603.2385607},
abstract = {Conventional wisdom holds that storage is not a big contributor to application performance on mobile devices. Flash storage (the type most commonly used today) draws little power, and its performance is thought to exceed that of the network subsystem. In this article, we present evidence that storage performance does indeed affect the performance of several common applications such as Web browsing, maps, application install, email, and Facebook. For several Android smartphones, we find that just by varying the underlying flash storage, performance over WiFi can typically vary between 100% and 300% across applications; in one extreme scenario, the variation jumped to over 2000%. With a faster network (set up over USB), the performance variation rose even further. We identify the reasons for the strong correlation between storage and application performance to be a combination of poor flash device performance, random I/O from application databases, and heavy-handed use of synchronous writes. Based on our findings, we implement and evaluate a set of pilot solutions to address the storage performance deficiencies in smartphones.},
journal = {ACM Trans. Storage},
month = dec,
articleno = {14},
numpages = {25},
keywords = {mobile, Android, smartphones, Storage systems, mobile storage}
}

@article{10.1145/2379776.2379784,
author = {Hawe, Glenn I. and Coates, Graham and Wilson, Duncan T. and Crouch, Roger S.},
title = {Agent-Based Simulation for Large-Scale Emergency Response: A Survey of Usage and Implementation},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2379776.2379784},
doi = {10.1145/2379776.2379784},
abstract = {When attempting to determine how to respond optimally to a large-scale emergency, the ability to predict the consequences of certain courses of action in silico is of great utility. Agent-based simulations (ABSs) have become the de facto tool for this purpose; however, they may be used and implemented in a variety of ways. This article reviews existing implementations of ABSs for large-scale emergency response, and presents a taxonomy classifying them by usage. Opportunities for improving ABS for large-scale emergency response are identified.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {8},
numpages = {51},
keywords = {emergency response, Agent-based simulation}
}

@article{10.1145/2379776.2379780,
author = {Zhuravlev, Sergey and Saez, Juan Carlos and Blagodurov, Sergey and Fedorova, Alexandra and Prieto, Manuel},
title = {Survey of Scheduling Techniques for Addressing Shared Resources in Multicore Processors},
year = {2012},
issue_date = {November 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/2379776.2379780},
doi = {10.1145/2379776.2379780},
abstract = {Chip multicore processors (CMPs) have emerged as the dominant architecture choice for modern computing platforms and will most likely continue to be dominant well into the foreseeable future. As with any system, CMPs offer a unique set of challenges. Chief among them is the shared resource contention that results because CMP cores are not independent processors but rather share common resources among cores such as the last level cache (LLC). Shared resource contention can lead to severe and unpredictable performance impact on the threads running on the CMP. Conversely, CMPs offer tremendous opportunities for mulithreaded applications, which can take advantage of simultaneous thread execution as well as fast inter thread data sharing. Many solutions have been proposed to deal with the negative aspects of CMPs and take advantage of the positive. This survey focuses on the subset of these solutions that exclusively make use of OS thread-level scheduling to achieve their goals. These solutions are particularly attractive as they require no changes to hardware and minimal or no changes to the OS. The OS scheduler has expanded well beyond its original role of time-multiplexing threads on a single core into a complex and effective resource manager. This article surveys a multitude of new and exciting work that explores the diverse new roles the OS scheduler can successfully take on.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {4},
numpages = {28},
keywords = {cooperative resource sharing, Survey, thread level scheduling, shared resource contention, thermal effects, power-aware scheduling}
}

@inproceedings{10.5555/2429759.2430280,
author = {Assun\c{c}\~{a}o, Marcos D. and Cavalcante, Victor F. and de C. Gatti, Maira A. and Netto, Marco A. S. and Pinhanez, Claudio S. and de Souza, Cleidson R. B.},
title = {Scheduling with Preemption for Incident Management: When Interrupting Tasks is Not Such a Bad Idea},
year = {2012},
publisher = {Winter Simulation Conference},
abstract = {Large IT service providers comprise hundreds or even thousands of system administrators to handle customers' IT infrastructure. As part of the Information Systems that support the decision making of this environment, Incident Management Systems are used and usually provide human resource assignment functionalities. However, the assignment poses several challenges, such as establishing priorities to tasks and defining when and how tasks are allocated to available system administrators. This paper describes a set of incident dispatching policies that can be used, and by using workloads from different departments of an IT service provider, this work evaluates the impact of task preemption on incident resolution and service level agreement attainment.},
booktitle = {Proceedings of the Winter Simulation Conference},
articleno = {403},
numpages = {12},
location = {Berlin, Germany},
series = {WSC '12}
}

@inproceedings{10.5555/2429759.2430001,
author = {Kohn, Robert and Rose, Oliver},
title = {Study on Optimization Potential Influencing Factors in Simulation Studies Focused on Parallel Batch Machine Scheduling Using Variable Neighbourhood Search},
year = {2012},
publisher = {Winter Simulation Conference},
abstract = {Studies on operational lot scheduling in semiconductor manufacturing show significantly varying optimization potentials, depending on a multitude of factors relating to methods and models in simulation. We present experiments examining Variable Neighbourhood Search (VNS) used to improve the objectives queuing time and tardiness for the parallel batch machine scheduling problem. The discussed results incorporate the effects of specific model characteristics and constraints, namely incompatible job families, process dedication schemes, critical time bounds, and minimal batch size constraints among others. With regard to methodical factors, we examine the effect of time window decomposition on simulation results, and we discuss fundamental VNS settings, respectively their influence on improvements measured for problem instances of size relevant for industrial applications. This study intends to identify important factors in scheduling studies and evaluates their influence on optimization potentials based on extensive experiments.},
booktitle = {Proceedings of the Winter Simulation Conference},
articleno = {181},
numpages = {13},
location = {Berlin, Germany},
series = {WSC '12}
}

@inproceedings{10.5555/2429759.2430242,
author = {Chauhan, Shalini and Devetsikiotis, Michael},
title = {Agent Based Framework for Avatar Interactions in an Adaptive Virtual World Game Environment},
year = {2012},
publisher = {Winter Simulation Conference},
abstract = {Technology has progressed by leaps and bounds by making a big footprint on society at large, but more than often we notice the basic infrastructure of social setup not progressing, in many cases quite stagnant-noticeably healthcare[2][3]. While acknowledging progress in healthcare technology- enabling us to perform surgeries and treatments which would seem nothing less than a miracle a decade ago, to the great advances in pharmacology and medicine, one thing which is still elusive and coping up is the healthcare delivery system.},
booktitle = {Proceedings of the Winter Simulation Conference},
articleno = {368},
numpages = {2},
location = {Berlin, Germany},
series = {WSC '12}
}

@inproceedings{10.5555/2429759.2429982,
author = {Fishwick, Paul A.},
title = {A Tutorial on Simulation Modeling in Six Dimensions},
year = {2012},
publisher = {Winter Simulation Conference},
abstract = {Simulation involves modeling and analysis of real-world systems. This tutorial will provide a broad overview of the modeling practice within simulation by introducing the reader to modeling choices found using six dimensions: abstraction, complexity, culture, engineering, environment, and process. Modeling can be a daunting task even for the seasoned modeling and simulation professional, and so my goal is to introduce modeling in two ways: 1) to use one specific type of model (Petri Net) as an anchor for cross-dimensional discussion, and 2) to provide a follow up discussion, with additional non Petri Net examples, to clarify the extent of each dimension. For example, in the abstraction dimension, one must think about scale, refinement, and hierarchy when modeling regardless of the type of modeling language. The reader will come away with a broad framework within which to understand the possibilities of models and of modeling within the practice of simulation.},
booktitle = {Proceedings of the Winter Simulation Conference},
articleno = {166},
numpages = {12},
location = {Berlin, Germany},
series = {WSC '12}
}

@inproceedings{10.5555/2429759.2429943,
author = {Skoogh, Anders and Johansson, Bj\"{o}rn and Williams, Edward J.},
title = {Constructive Alignment in Simulation Education},
year = {2012},
publisher = {Winter Simulation Conference},
abstract = {Recent and ongoing developments are significantly augmenting both the demand for and the expectations of university simulation education. These developments include increased use of simulation in industry, increased variety of economic segments in which simulation is used, broader variation in demographics of simulation students, and higher expectations of both those students and their eventual employers. To meet the challenges these developments impose, it is vital that simulation educators aggressively and innovatively improve the teaching of simulation. To this end, we explore the application of constructive alignment concepts in simulation education, and compare and contrast its application in the context of two university course offerings. These concepts suggest continuation of some practices and revision of others relative to the learning objectives, learning activities, and assessment tasks in these and other simulation courses.},
booktitle = {Proceedings of the Winter Simulation Conference},
articleno = {137},
numpages = {11},
location = {Berlin, Germany},
series = {WSC '12}
}

@inproceedings{10.5555/2429759.2429947,
author = {Cleophas, Catherine},
title = {Designing Serious Games for Revenue Management Training and Strategy Development},
year = {2012},
publisher = {Winter Simulation Conference},
abstract = {This paper proposes a framework for the design of serious games in the area of revenue management. At this time, there is little systematic consideration of simulation-based serious games and their set-up available in this field. The suggested framework regards games as structured in three layered stages and explicates decisions influencing their design and focus. These decisions are structured according to five aspects: concurrence, conditions, cognizance, cooperation and competition. Revenue management provides a particular challenge as its success depends not only on the customer choice, competition and sophisticated operations research algorithms, but also on analysts' understanding. Simulation systems are a well-known tool for the evaluation of revenue management approaches in research and practice and can easily be extended for use in serious games. The framework introduced here can be used for future evaluations of alternative designs of serious games aiming to improve revenue management understanding and strategy evaluation.},
booktitle = {Proceedings of the Winter Simulation Conference},
articleno = {140},
numpages = {12},
location = {Berlin, Germany},
series = {WSC '12}
}

@inproceedings{10.5555/2429759.2429921,
author = {Paz, Daniel Pablo and Racca, Pablo and Bustelo, C\'{e}sar},
title = {Simulation of Liquid Metal Logistics in Primary Aluminum Industry},
year = {2012},
publisher = {Winter Simulation Conference},
abstract = {Production planning in the primary aluminum industry is a critical task, due to heavy imbalances among the main processes. As liquid production (reduction) has a very continuous and stable output, solidification at different lines have different operational paths (batch/continuous), shutdowns and variations in rates. Due to material's nature (hot liquid metal), it is not possible to maintain a buffer to absorb those imbalances. An adequate logistics planning for distributing liquid metal has to accomplish the solidification plan with an adequate usage of resources. In this paper we present the application of a simulation model to identify the main bottlenecks in the process, analyze dynamic system behavior, apply heuristics balancing algorithms and validate possible solutions for increasing casting capacity. The simulation model was implemented at Aluar's plant.},
booktitle = {Proceedings of the Winter Simulation Conference},
articleno = {121},
numpages = {11},
location = {Berlin, Germany},
series = {WSC '12}
}

@inproceedings{10.1145/2413236.2413243,
author = {Aug\'{e}-Blum, Isabelle and Boussetta, Khaled and Rivano, Herv\'{e} and Stanica, Razvan and Valois, Fabrice},
title = {Capillary Networks: A Novel Networking Paradigm for Urban Environments},
year = {2012},
isbn = {9781450317818},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2413236.2413243},
doi = {10.1145/2413236.2413243},
abstract = {In this paper, we present our vision of the networking challenges that are yielded by the rise of Smart Cities. Smart Cities leverage massive data collected by sensors, connected devices, social applications,... for proving a whole set a new services to the citizens. However, there is a lack of reflexion on the networking solutions that enable these services, from the gathering of sensed data to the dissemination of digital services. We identify the emerging needs of Smart Cities, focus on the capillary networks paradigm which unify the wealth of wireless connectivity available in urban environment, and present the research issues it yields.},
booktitle = {Proceedings of the First Workshop on Urban Networking},
pages = {25–30},
numpages = {6},
keywords = {urban networks, real-time networking, capillary networks, digital cities, vehicular, sensor, smart cities, mesh},
location = {Nice, France},
series = {UrbaNe '12}
}

@inproceedings{10.1145/2413176.2413190,
author = {Tian, Guibin and Liu, Yong},
title = {Towards Agile and Smooth Video Adaptation in Dynamic HTTP Streaming},
year = {2012},
isbn = {9781450317757},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2413176.2413190},
doi = {10.1145/2413176.2413190},
abstract = {Dynamic Adaptive Streaming over HTTP (DASH) is widely deployed on the Internet for live and on-demand video streaming services. Video adaptation algorithms in existing DASH systems are either too sluggish to respond to congestion level shifts or too sensitive to short-term network bandwidth variations. Both degrade user video experience. In this paper, we formally study the responsiveness and smoothness trade-off in DASH through analysis and experiments. We show that client-side buffered video time is a good feedback signal to guide video adaptation. We then propose novel video rate control algorithms that balance the needs for video rate smoothness and high bandwidth utilization. We show that a small video rate margin can lead to much improved smoothness in video rate and buffer size. The proposed DASH designs are also extended to work with multiple CDN servers. We develop a fully-functional DASH system and evaluate its performance through extensive experiments on a network testbed and the Internet. We demonstrate that our DASH designs are highly efficient and robust in realistic network environment.},
booktitle = {Proceedings of the 8th International Conference on Emerging Networking Experiments and Technologies},
pages = {109–120},
numpages = {12},
keywords = {SVR, adaptation, multiple CDN, dash, emulab},
location = {Nice, France},
series = {CoNEXT '12}
}

@inproceedings{10.1145/2407336.2407360,
author = {Wang, Jia and Lindeman, Rob},
title = {Leaning-Based Travel Interfaces Revisited: Frontal versus Sidewise Stances for Flying in 3D Virtual Spaces},
year = {2012},
isbn = {9781450314695},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2407336.2407360},
doi = {10.1145/2407336.2407360},
abstract = {In this paper we revisit the design of leaning-based travel interfaces and propose a design space to categorize existing implementations. Within the design space, frontal and sidewise stances when using a flying surfboard interface were compared through a user study. The interfaces were adapted and improved from our previous designs using a body-mounted, multi-touch touchpad. Two different experiments were designed and conducted that focus on user performance and virtual world cognition, respectively. The results suggest better user performance and user experience when using the frontal stance, although no better spatial orientation or virtual world cognition was identified. Further, user interviews revealed that despite the realistic simulation of skateboarding/snowboarding, the sidewise stance suffers from poor usability due to inefficient and inaccurate turning control and confusion between the viewing and movement directions. Based on these results, several guidelines are proposed to aid the design of leaning-based travel interfaces for immersive virtual reality applications.},
booktitle = {Proceedings of the 18th ACM Symposium on Virtual Reality Software and Technology},
pages = {121–128},
numpages = {8},
keywords = {navigation, 3d virtual spaces., stance, leaning-based travel interface},
location = {Toronto, Ontario, Canada},
series = {VRST '12}
}

@article{10.1145/2382577.2382579,
author = {Kaufman, Shachar and Rosset, Saharon and Perlich, Claudia and Stitelman, Ori},
title = {Leakage in Data Mining: Formulation, Detection, and Avoidance},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
issn = {1556-4681},
url = {https://doi.org/10.1145/2382577.2382579},
doi = {10.1145/2382577.2382579},
abstract = {Deemed “one of the top ten data mining mistakes”, leakage is the introduction of information about the data mining target that should not be legitimately available to mine from. In addition to our own industry experience with real-life projects, controversies around several major public data mining competitions held recently such as the INFORMS 2010 Data Mining Challenge and the IJCNN 2011 Social Network Challenge are evidence that this issue is as relevant today as it has ever been. While acknowledging the importance and prevalence of leakage in both synthetic competitions and real-life data mining projects, existing literature has largely left this idea unexplored. What little has been said turns out not to be broad enough to cover more complex cases of leakage, such as those where the classical independently and identically distributed (i.i.d.) assumption is violated, that have been recently documented. In our new approach, these cases and others are explained by explicitly defining modeling goals and analyzing the broader framework of the data mining problem. The resulting definition enables us to derive general methodology for dealing with the issue. We show that it is possible to avoid leakage with a simple specific approach to data management followed by what we call a learn-predict separation, and present several ways of detecting leakage when the modeler has no control over how the data have been collected. We also offer an alternative point of view on leakage that is based on causal graph modeling concepts.},
journal = {ACM Trans. Knowl. Discov. Data},
month = dec,
articleno = {15},
numpages = {21},
keywords = {predictive modeling, leakage, Data mining}
}

@article{10.1145/2421648.2421653,
author = {Basak, Jayanta and Wadhwani, Kushal and Voruganti, Kaladhar and Narayanamurthy, Srinivasan and Mathur, Vipul and Nandi, Siddhartha},
title = {Model Building for Dynamic Multi-Tenant Provider Environments},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {3},
issn = {0163-5980},
url = {https://doi.org/10.1145/2421648.2421653},
doi = {10.1145/2421648.2421653},
abstract = {Increasingly, storage vendors are finding it difficult to leverage existing white-box and black-box modeling techniques to build robust system models that can predict system behavior in the emerging dynamic and multi-tenant data centers. White-box models are becoming brittle because the model builders are not able to keep up with the innovations in the storage system stack, and black-box models are becoming brittle because it is increasingly difficult to a priori train the model for the dynamic and multi-tenant data center environment. Thus, there is a need for innovation in system model building area.In this paper we present a machine learning based blackbox modeling algorithm called M-LISP that can predict system behavior in untrained region for these emerging multitenant and dynamic data center environments. We have implemented and analyzed M-LISP in real environments and the initial results look very promising. We also provide a survey of some common machine learning algorithms and how they fare with respect to satisfying the modeling needs of the new data center environments.},
journal = {SIGOPS Oper. Syst. Rev.},
month = dec,
pages = {20–31},
numpages = {12},
keywords = {resource modeling, storage management, black-box, machine learning}
}

@article{10.1145/2390176.2390189,
author = {Amir, Amihood and Eisenberg, Estrella and Levy, Avivit and Porat, Ely and Shapira, Natalie},
title = {Cycle Detection and Correction},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
issn = {1549-6325},
url = {https://doi.org/10.1145/2390176.2390189},
doi = {10.1145/2390176.2390189},
abstract = {Assume that a natural cyclic phenomenon has been measured, but the data is corrupted by errors. The type of corruption is application-dependent and may be caused by measurements errors, or natural features of the phenomenon. We assume that an appropriate metric exists, which measures the amount of corruption experienced. This article studies the problem of recovering the correct cycle from data corrupted by various error models, formally defined as the period recovery problem. Specifically, we define a metric property which we call pseudolocality and study the period recovery problem under pseudolocal metrics. Examples of pseudolocal metrics are the Hamming distance, the swap distance, and the interchange (or Cayley) distance. We show that for pseudolocal metrics, periodicity is a powerful property allowing detecting the original cycle and correcting the data, under suitable conditions. Some surprising features of our algorithm are that we can efficiently identify the period in the corrupted data, up to a number of possibilities logarithmic in the length of the data string, even for metrics whose calculation is NP-hard. For the Hamming metric, we can reconstruct the corrupted data in near-linear time even for unbounded alphabets. This result is achieved using the property of separation in the self-convolution vector and Reed-Solomon codes. Finally, we employ our techniques beyond the scope of pseudo-local metrics and give a recovery algorithm for the non-pseudolocal Levenshtein edit metric.},
journal = {ACM Trans. Algorithms},
month = dec,
articleno = {13},
numpages = {20},
keywords = {string metrics, Approximate periodicity, strings algorithms}
}

@article{10.1145/2398356.2398374,
author = {Helland, Pat},
title = {Condos and Clouds},
year = {2013},
issue_date = {January 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {1},
issn = {0001-0782},
url = {https://doi.org/10.1145/2398356.2398374},
doi = {10.1145/2398356.2398374},
abstract = {Constraints in an environment empower the services.},
journal = {Commun. ACM},
month = jan,
pages = {50–59},
numpages = {10}
}

@article{10.1145/2414782.2414784,
author = {Webber, William},
title = {Approximate Recall Confidence Intervals},
year = {2013},
issue_date = {January 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/2414782.2414784},
doi = {10.1145/2414782.2414784},
abstract = {Recall, the proportion of relevant documents retrieved, is an important measure of effectiveness in information retrieval, particularly in the legal, patent, and medical domains. Where document sets are too large for exhaustive relevance assessment, recall can be estimated by assessing a random sample of documents, but an indication of the reliability of this estimate is also required. In this article, we examine several methods for estimating two-tailed recall confidence intervals. We find that the normal approximation in current use provides poor coverage in many circumstances, even when adjusted to correct its inappropriate symmetry. Analytic and Bayesian methods based on the ratio of binomials are generally more accurate but are inaccurate on small populations. The method we recommend derives beta-binomial posteriors on retrieved and unretrieved yield, with fixed hyperparameters, and a Monte Carlo estimate of the posterior distribution of recall. We demonstrate that this method gives mean coverage at or near the nominal level, across several scenarios, while being balanced and stable. We offer advice on sampling design, including the allocation of assessments to the retrieved and unretrieved segments, and compare the proposed beta-binomial with the officially reported normal intervals for recent TREC Legal Track iterations.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
articleno = {2},
numpages = {33},
keywords = {Posterior distributions, probabilistic models}
}

@article{10.1145/2395123.2395129,
author = {Kay, Judy and Kummerfeld, Bob},
title = {Creating Personalized Systems That People Can Scrutinize and Control: Drivers, Principles and Experience},
year = {2013},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {2160-6455},
url = {https://doi.org/10.1145/2395123.2395129},
doi = {10.1145/2395123.2395129},
abstract = {Widespread personalized computing systems play an already important and fast-growing role in diverse contexts, such as location-based services, recommenders, commercial Web-based services, and teaching systems. The personalization in these systems is driven by information about the user, a user model. Moreover, as computers become both ubiquitous and pervasive, personalization operates across the many devices and information stores that constitute the user's personal digital ecosystem. This enables personalization, and the user models driving it, to play an increasing role in people's everyday lives. This makes it critical to establish ways to address key problems of personalization related to privacy, invisibility of personalization, errors in user models, wasted user models, and the broad issue of enabling people to control their user models and associated personalization. We offer scrutable user models as a foundation for tackling these problems.This article argues the importance of scrutable user modeling and personalization, illustrating key elements in case studies from our work. We then identify the broad roles for scrutable user models. The article describes how to tackle the technical and interface challenges of designing and building scrutable user modeling systems, presenting design principles and showing how they were established over our twenty years of work on the Personis software framework. Our contributions are the set of principles for scrutable personalization linked to our experience from creating and evaluating frameworks and associated applications built upon them. These constitute a general approach to tackling problems of personalization by enabling users to scrutinize their user models as a basis for understanding and controlling personalization.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = jan,
articleno = {24},
numpages = {42},
keywords = {scrutability, open learner modeling, Personalization, user modeling, understandability, augmented cognition, user control, reasoning under uncertainty, inconsistency, user model}
}

@article{10.1145/2398356.2398371,
author = {Grudin, Jonathan and Mark, Gloria and Riedl, John},
title = {Conference-Journal Hybrids},
year = {2013},
issue_date = {January 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {1},
issn = {0001-0782},
url = {https://doi.org/10.1145/2398356.2398371},
doi = {10.1145/2398356.2398371},
abstract = {Considering how to combine the best elements of conferences and journals.},
journal = {Commun. ACM},
month = jan,
pages = {44–49},
numpages = {6}
}

@article{10.1145/2395123.2395127,
author = {Chen, Fang and Ruiz, Natalie and Choi, Eric and Epps, Julien and Khawaja, M. Asif and Taib, Ronnie and Yin, Bo and Wang, Yang},
title = {Multimodal Behavior and Interaction as Indicators of Cognitive Load},
year = {2013},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {2160-6455},
url = {https://doi.org/10.1145/2395123.2395127},
doi = {10.1145/2395123.2395127},
abstract = {High cognitive load arises from complex time and safety-critical tasks, for example, mapping out flight paths, monitoring traffic, or even managing nuclear reactors, causing stress, errors, and lowered performance. Over the last five years, our research has focused on using the multimodal interaction paradigm to detect fluctuations in cognitive load in user behavior during system interaction. Cognitive load variations have been found to impact interactive behavior: by monitoring variations in specific modal input features executed in tasks of varying complexity, we gain an understanding of the communicative changes that occur when cognitive load is high. So far, we have identified specific changes in: speech, namely acoustic, prosodic, and linguistic changes; interactive gesture; and digital pen input, both interactive and freeform. As ground-truth measurements, galvanic skin response, subjective, and performance ratings have been used to verify task complexity.The data suggest that it is feasible to use features extracted from behavioral changes in multiple modal inputs as indices of cognitive load. The speech-based indicators of load, based on data collected from user studies in a variety of domains, have shown considerable promise. Scenarios include single-user and team-based tasks; think-aloud and interactive speech; and single-word, reading, and conversational speech, among others. Pen-based cognitive load indices have also been tested with some success, specifically with pen-gesture, handwriting, and freeform pen input, including diagraming. After examining some of the properties of these measurements, we present a multimodal fusion model, which is illustrated with quantitative examples from a case study.The feasibility of employing user input and behavior patterns as indices of cognitive load is supported by experimental evidence. Moreover, symptomatic cues of cognitive load derived from user behavior such as acoustic speech signals, transcribed text, digital pen trajectories of handwriting, and shapes pen, can be supported by well-established theoretical frameworks, including O'Donnell and Eggemeier's workload measurement [1986] Sweller's Cognitive Load Theory [Chandler and Sweller 1991], and Baddeley's model of modal working memory [1992] as well as McKinstry et al.'s [2008] and Rosenbaum's [2005] action dynamics work. The benefit of using this approach to determine the user's cognitive load in real time is that the data can be collected implicitly that is, during day-to-day use of intelligent interactive systems, thus overcomes problems of intrusiveness and increases applicability in real-world environments, while adapting information selection and presentation in a dynamic computer interface with reference to load.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = jan,
articleno = {22},
numpages = {36},
keywords = {assessment, multimodal, Cognitive load, pen input}
}

@article{10.1145/2395123.2395128,
author = {D'mello, Sidney and Graesser, Art},
title = {AutoTutor and Affective Autotutor: Learning by Talking with Cognitively and Emotionally Intelligent Computers That Talk Back},
year = {2013},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {2160-6455},
url = {https://doi.org/10.1145/2395123.2395128},
doi = {10.1145/2395123.2395128},
abstract = {We present AutoTutor and Affective AutoTutor as examples of innovative 21st century interactive intelligent systems that promote learning and engagement. AutoTutor is an intelligent tutoring system that helps students compose explanations of difficult concepts in Newtonian physics and enhances computer literacy and critical thinking by interacting with them in natural language with adaptive dialog moves similar to those of human tutors. AutoTutor constructs a cognitive model of students' knowledge levels by analyzing the text of their typed or spoken responses to its questions. The model is used to dynamically tailor the interaction toward individual students' zones of proximal development. Affective AutoTutor takes the individualized instruction and human-like interactivity to a new level by automatically detecting and responding to students' emotional states in addition to their cognitive states. Over 20 controlled experiments comparing AutoTutor with ecological and experimental controls such reading a textbook have consistently yielded learning improvements of approximately one letter grade after brief 30--60-minute interactions. Furthermore, Affective AutoTutor shows even more dramatic improvements in learning than the original AutoTutor system, particularly for struggling students with low domain knowledge. In addition to providing a detailed description of the implementation and evaluation of AutoTutor and Affective AutoTutor, we also discuss new and exciting technologies motivated by AutoTutor such as AutoTutor-Lite, Operation ARIES, GuruTutor, DeepTutor, MetaTutor, and AutoMentor. We conclude this article with our vision for future work on interactive and engaging intelligent tutoring systems.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = jan,
articleno = {23},
numpages = {39},
keywords = {user modeling, affect detection and synthesis, Intelligent tutoring systems, affective computing, constructivism, natural language understanding, deep learning, student modeling}
}

@inproceedings{10.5555/2627817.2627879,
author = {Navarro, Gonzalo and Nekrich, Yakov},
title = {Optimal Dynamic Sequence Representations},
year = {2013},
isbn = {9781611972511},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
abstract = {We describe a data structure that supports access, rank and select queries, as well as symbol insertions and deletions, on a string S[1, n] over alphabet [1..σ] in time O(lg n/lg lg n), which is optimal. The time is worst-case for the queries and amortized for the updates. This complexity is better than the best previous ones by a Θ(1 + lg σ/lg lg n) factor. Our structure uses nH0(S) + O(n + σ(lg σ + lg1+ε n)) bits, where H0(S) is the zero-order entropy of S and 0 &lt; ε &lt; 1 is any constant. This space redundancy over nH0(S) is also better, almost always, than that of the best previous dynamic structures, o(n lg σ) + O(σ(lg σ+lg n)). We can also handle general alphabets in optimal time, which has been an open problem in dynamic sequence representations.},
booktitle = {Proceedings of the Twenty-Fourth Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {865–876},
numpages = {12},
location = {New Orleans, Louisiana},
series = {SODA '13}
}

@inproceedings{10.1145/2459976.2460043,
author = {Kher, Shubhalaxmi and Nutt, Victor and Dasgupta, Dipankar and Ali, Hasan and Mixon, Paul},
title = {A Prediction Model for Anomalies in Smart Grid with Sensor Network},
year = {2013},
isbn = {9781450316873},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459976.2460043},
doi = {10.1145/2459976.2460043},
abstract = {A machine learning based model to monitor the smart grid for any suspicious activity or malicious attack is presented in this paper. The model is designed to detect and classify anomalies in the sensory data and is helpful in ensuring the security and stability of the smart grid. The model relies on the real time data collected using wireless sensor networks as an overlay network on the power distribution grid. The overlay network of wireless sensors/devices uses a cluster topology at each tower to collect local information about the tower, and is further augmented by the linear chain topology to connect each tower to the base station (usually at the substation). Preliminary results show that detection mechanism is promising and is able to detect the occurrence of any anomalous event that may cause threat to the smart grid.},
booktitle = {Proceedings of the Eighth Annual Cyber Security and Information Intelligence Research Workshop},
articleno = {60},
numpages = {4},
location = {Oak Ridge, Tennessee, USA},
series = {CSIIRW '13}
}

@inproceedings{10.1145/2459976.2460019,
author = {Carvalho, Marco M. and Eskridge, Thomas C. and Bunch, Larry and Bradshaw, Jeffrey M. and Dalton, Adam and Feltovich, Paul and Lott, James and Kidwell, Daniel},
title = {A Human-Agent Teamwork Command and Control Framework for Moving Target Defense (MTC2)},
year = {2013},
isbn = {9781450316873},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2459976.2460019},
doi = {10.1145/2459976.2460019},
abstract = {In this paper we discuss the need for a command and control (C2) capability for moving target (MT) defenses. We describe some of the requirements and constraints associated with such a capability, and propose a human-agent teamwork approach for MTC2. We further discuss some specific concepts and technologies that could play an important role in the development of this capability, and conclude by describing some implementation details of a prototype being developed to demonstrate and study the proposed concepts for MTC2.},
booktitle = {Proceedings of the Eighth Annual Cyber Security and Information Intelligence Research Workshop},
articleno = {38},
numpages = {4},
keywords = {moving target defense, coactive emergence, organic resilience, command and control, computer network defense, human-agent teamwork},
location = {Oak Ridge, Tennessee, USA},
series = {CSIIRW '13}
}

@inproceedings{10.1145/2442882.2442893,
author = {Underwood, Heather and Sterling, S. Revi and Bennett, John K.},
title = {The Design and Implementation of the PartoPen Maternal Health Monitoring System},
year = {2013},
isbn = {9781450318563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2442882.2442893},
doi = {10.1145/2442882.2442893},
abstract = {The World Health Organization advocates the paper partograph as the single most effective tool for monitoring labor and reducing labor complications in developing countries. Used correctly, the partograph can serve as a tool for early detection of serious maternal and fetal complications during labor, allowing sufficient time for an appropriate response. However, in order to be effective, the partograph must be used correctly. Recent studies in Kenya reported that less than one fourth of partographs were completed in accordance with WHO guidelines. In developing countries, lack of training and continuing education, exacerbated by limited resources, represents a serious barrier to effective partograph use. The goal of the PartoPen project is to increase the effectiveness of the partograph using an interactive digital pen with custom software, together with partograph forms printed with a background dot pattern that is recognized by the pen. This paper describes the design and implementation of the PartoPen system, and the technical evolution of the PartoPen system during studies that evaluated the PartoPen in use in Nairobi, Kenya from June 2012 -- August 2012.},
booktitle = {Proceedings of the 3rd ACM Symposium on Computing for Development},
articleno = {8},
numpages = {10},
keywords = {Kenya, partograph, digital pens, ICTD, maternal health},
location = {Bangalore, India},
series = {ACM DEV '13}
}

@inproceedings{10.1145/2429069.2429083,
author = {Benzaken, V\'{e}ronique and Castagna, Giuseppe and Nguyen, Kim and Sim\'{e}on, J\'{e}r\^{o}me},
title = {Static and Dynamic Semantics of NoSQL Languages},
year = {2013},
isbn = {9781450318327},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2429069.2429083},
doi = {10.1145/2429069.2429083},
abstract = {We present a calculus for processing semistructured data that spans differences of application area among several novel query languages, broadly categorized as "NoSQL". This calculus lets users define their own operators, capturing a wider range of data processing capabilities, whilst providing a typing precision so far typical only of primitive hard-coded operators. The type inference algorithm is based on semantic type checking, resulting in type information that is both precise, and flexible enough to handle structured and semistructured data. We illustrate the use of this calculus by encoding a large fragment of Jaql, including operations and iterators over JSON, embedded SQL expressions, and co-grouping, and show how the encoding directly yields a typing discipline for Jaql as it is, namely without the addition of any type definition or type annotation in the code.},
booktitle = {Proceedings of the 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {101–114},
numpages = {14},
keywords = {NoSQL, jaql, type inference, cloud computing, bigdata analytics},
location = {Rome, Italy},
series = {POPL '13}
}

@article{10.1145/2480359.2429083,
author = {Benzaken, V\'{e}ronique and Castagna, Giuseppe and Nguyen, Kim and Sim\'{e}on, J\'{e}r\^{o}me},
title = {Static and Dynamic Semantics of NoSQL Languages},
year = {2013},
issue_date = {January 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0362-1340},
url = {https://doi.org/10.1145/2480359.2429083},
doi = {10.1145/2480359.2429083},
abstract = {We present a calculus for processing semistructured data that spans differences of application area among several novel query languages, broadly categorized as "NoSQL". This calculus lets users define their own operators, capturing a wider range of data processing capabilities, whilst providing a typing precision so far typical only of primitive hard-coded operators. The type inference algorithm is based on semantic type checking, resulting in type information that is both precise, and flexible enough to handle structured and semistructured data. We illustrate the use of this calculus by encoding a large fragment of Jaql, including operations and iterators over JSON, embedded SQL expressions, and co-grouping, and show how the encoding directly yields a typing discipline for Jaql as it is, namely without the addition of any type definition or type annotation in the code.},
journal = {SIGPLAN Not.},
month = jan,
pages = {101–114},
numpages = {14},
keywords = {jaql, NoSQL, bigdata analytics, cloud computing, type inference}
}

@inproceedings{10.1145/2430553.2430554,
author = {Ghosh, Sudeep and Hiser, Jason and Davidson, Jack W.},
title = {Software Protection for Dynamically-Generated Code},
year = {2013},
isbn = {9781450318570},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2430553.2430554},
doi = {10.1145/2430553.2430554},
abstract = {Process-level Virtual machines (PVMs) often play a crucial role in program protection. In particular, virtualization-based tools like VMProtect and CodeVirtualizer have been shown to provide desirable obfuscation properties (i.e., resistance to disassembly and code analysis). To be efficient, many tools cache frequently-executed code in a code cache. This code is run directly on hardware and consequently may be susceptible to unintended, malicious modification after it has been generated.To thwart such modifications, this work presents a novel methodology that imparts tamper detection at run time to PVM-protected applications. Our scheme centers around the run-time creation of a network of software knots (an instruction sequence that checksums portions of the code) to detect tamper. These knots are used to check the integrity of cached code, although our techniques could be applied to check any software-protection properties. Used in conjunction with established static techniques, our solution provides a mechanism for protecting PVM-generated code from modification.We have implemented a PVM system that automatically inserts code into an application to dynamically generate polymorphic software knots. Our experiments show that PVMs do indeed provide a suitable platform for extending guard protection, without the addition of high overheads to run-time performance and memory. Our evaluations demonstrate that these knots add less than 10% overhead while providing frequent integrity checks.},
booktitle = {Proceedings of the 2nd ACM SIGPLAN Program Protection and Reverse Engineering Workshop},
articleno = {1},
numpages = {12},
keywords = {polymorphism, obfuscation, tamper detection, process-level virtual machines},
location = {Rome, Italy},
series = {PPREW '13}
}

@inproceedings{10.5555/2667199.2667216,
author = {Le Nguyen, Thanh Tri and Carbone, Angela and Sheard, Judy and Schuhmacher, Margot},
title = {Integrating Source Code Plagiarism into a Virtual Learning Environment: Benefits for Students and Staff},
year = {2013},
isbn = {9781921770210},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Source code plagiarism is a growing concern in computing related courses. There are a variety of tools to help academics detect suspicious similarity in computer programs. These are purpose-built and necessarily different from the more widely used text-matching tools for plagiarism detection in essays. However, not only is the adoption of these code plagiarism detection tools very modest, the lack of integration of these tools into learning environments means that they are, if used, just intended to identify offending students, rather than as an educational tool to raise their awareness of this sensitive problem. This paper describes the development of a plugin to integrate the two well-known code plagiarism detectors, JPlag and MOSS, into an open source virtual learning environment, Moodle, to address the needs of academics teaching computer programming at an Australian University. A study was carried out to evaluate the benefits offered by such integration for academics and students.},
booktitle = {Proceedings of the Fifteenth Australasian Computing Education Conference - Volume 136},
pages = {155–164},
numpages = {10},
keywords = {academic integrity, plagiarism, source code matching tools},
location = {Adelaide, Australia},
series = {ACE '13}
}

@inproceedings{10.5555/2525512.2525517,
author = {Sinnott, Richard O. and Bayliss, Christopher and Morandini, Luca and Tomko, Martin},
title = {Tools and Processes to Support the Development of a National Platform for Urban Research: Lessons (Being) Learnt from the AURIN Project},
year = {2013},
isbn = {9781921770258},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {The development of large-scale software systems remains a non-trivial endeavour. This is especially so when the software systems comprise services and resources coming from multiple distributed software groups, and where they are required to interoperate with heterogeneous, independent (and autonomous) distributed data providers. The use of software development and management tools to support this process is highly desirable. In this paper we focus on the software development and management systems that have been adopted within the national Australian Urban Research Infrastructure Network (AURIN - www.aurin.org.au) project. AURIN is tasked with developing a software platform to support research into the urban and built environment - a domain with many diverse software system and data needs. In particular, given that AURIN is tasked with integrating a large portfolio of sub-projects offering both software and data that needs to be integrated, deployed and managed by a core team at the University of Melbourne, we illustrate how tooling and support processes are used to manage the software development lifecycle and code/data integration from the distributed teams and data providers that are involved. Results from the project demonstrating the ongoing status are presented.},
booktitle = {Proceedings of the Eleventh Australasian Symposium on Parallel and Distributed Computing - Volume 140},
pages = {39–48},
numpages = {10},
keywords = {collaborative development environment, urban research, code management, software testing},
location = {Adelaide, Australia},
series = {AusPDC '13}
}

@inproceedings{10.5555/2527208.2527209,
author = {Quah, Audrey Mei Yi and R\"{o}hm, Uwe},
title = {User Awareness and Policy Compliance of Data Privacy in Cloud Computing},
year = {2013},
isbn = {9781921770296},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Cloud computing is promising many technical benefits such as enhanced scalability, computing elasticity, and cost efficiency. However, with the benefits of cloud-based, hosted software platforms also comes the responsibility to data privacy. This paper investigates the data privacy issues brought about by cloud computing from an Australian perspective with specific focus on two aspects: How does cloud computing affect organisations' compliance to Australian privacy and data protection regulations? And to what extent are end-users aware of how cloud computing technologies affect their privacy?We present the results of an online survey among cloud computing users and contrast these with the technological possibilities and the cloud provider positions. According to this survey, almost half of the end-users were unaware that they are in fact using one or more cloud services themselves already today. At the same time, the overwhelming majority of the participants (more than 90%) agreed that companies need to inform customers if they store and process personal customer information in the cloud. Cloud computing is playing an important role in the future of IT but the technology's privacy risks and the apparent user-unawareness necessitates the push for greater transparency of the technology.},
booktitle = {Proceedings of the First Australasian Web Conference - Volume 144},
pages = {3–12},
numpages = {10},
location = {Adelaide, Australia},
series = {AWC '13}
}

@article{10.1145/2414425.2414441,
author = {Shi, Yue and Larson, Martha and Hanjalic, Alan},
title = {Mining Contextual Movie Similarity with Matrix Factorization for Context-Aware Recommendation},
year = {2013},
issue_date = {January 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/2414425.2414441},
doi = {10.1145/2414425.2414441},
abstract = {Context-aware recommendation seeks to improve recommendation performance by exploiting various information sources in addition to the conventional user-item matrix used by recommender systems. We propose a novel context-aware movie recommendation algorithm based on joint matrix factorization (JMF). We jointly factorize the user-item matrix containing general movie ratings and other contextual movie similarity matrices to integrate contextual information into the recommendation process. The algorithm was developed within the scope of the mood-aware recommendation task that was offered by the Moviepilot mood track of the 2010 context-aware movie recommendation (CAMRa) challenge. Although the algorithm could generalize to other types of contextual information, in this work, we focus on two: movie mood tags and movie plot keywords. Since the objective in this challenge track is to recommend movies for a user given a specified mood, we devise a novel mood-specific movie similarity measure for this purpose. We enhance the recommendation based on this measure by also deploying the second movie similarity measure proposed in this article that takes into account the movie plot keywords. We validate the effectiveness of the proposed JMF algorithm with respect to the recommendation performance by carrying out experiments on the Moviepilot challenge dataset. We demonstrate that exploiting contextual information in JMF leads to significant improvement over several state-of-the-art approaches that generate movie recommendations without using contextual information. We also demonstrate that our proposed mood-specific movie similarity is better suited for the task than the conventional mood-based movie similarity measures. Finally, we show that the enhancement provided by the movie similarity capturing the plot keywords is particularly helpful in improving the recommendation to those users who are significantly more active in rating the movies than other users.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = feb,
articleno = {16},
numpages = {19},
keywords = {Collaborative filtering, matrix factorization, recommender systems, mood-specific movie similarity, context-aware recommendation}
}

@inproceedings{10.1145/2433396.2433476,
author = {Sadilek, Adam and Kautz, Henry},
title = {Modeling the Impact of Lifestyle on Health at Scale},
year = {2013},
isbn = {9781450318693},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2433396.2433476},
doi = {10.1145/2433396.2433476},
abstract = {Research in computational epidemiology to date has concentrated on estimating summary statistics of populations and simulated scenarios of disease outbreaks. Detailed studies have been limited to small domains, as scaling the methods involved poses considerable challenges. By contrast, we model the associations of a large collection of social and environmental factors with the health of particular individuals. Instead of relying on surveys, we apply scalable machine learning techniques to noisy data mined from online social media and infer the health state of any given person in an automated way. We show that the learned patterns can be subsequently leveraged in descriptive as well as predictive fine-grained models of human health. Using a unified statistical model, we quantify the impact of social status, exposure to pollution, interpersonal interactions, and other important lifestyle factors on one's health. Our model explains more than 54% of the variance in people's health (as estimated from their online communication), and predicts the future health status of individuals with 91% accuracy. Our methods complement traditional studies in life sciences, as they enable us to perform large-scale and timely measurement, inference, and prediction of previously elusive factors that affect our everyday lives.},
booktitle = {Proceedings of the Sixth ACM International Conference on Web Search and Data Mining},
pages = {637–646},
numpages = {10},
keywords = {machine learning, online social networks, computational epidemiology, geo-temporal modeling, ubiquitous computing},
location = {Rome, Italy},
series = {WSDM '13}
}

@inproceedings{10.1145/2433396.2433447,
author = {Ailon, Nir and Karnin, Zohar S. and Liberty, Edo and Maarek, Yoelle},
title = {Threading Machine Generated Email},
year = {2013},
isbn = {9781450318693},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2433396.2433447},
doi = {10.1145/2433396.2433447},
abstract = {Viewing email messages as parts of a sequence or a thread is a convenient way to quickly understand their context. Current threading techniques rely on purely syntactic methods, matching sender information, subject line, and reply/forward prefixes. As such, they are mostly limited to personal conversations. In contrast, machine-generated email, which amount, as per our experiments, to more than 60% of the overall email traffic, requires a different kind of threading that should reflect how a sequence of emails is caused by a few related user actions. For example, purchasing goods from an online store will result in a receipt or a confirmation message, which may be followed, possibly after a few days, by a shipment notification message from an express shipping service. In today's mail systems, they will not be a part of the same thread, while we believe they should. In this paper, we focus on this type of threading that we coin "causal threading". We demonstrate that, by analyzing recurring patterns over hundreds of millions of mail users, we can infer a causality relation between these two individual messages. In addition, by observing multiple causal relations over common messages, we can generate "causal threads" over a sequence of messages. The four key stages of our approach consist of: (1) identifying messages that are instances of the same email type or "template" (generated by the same machine process on the sender side) (2) building a causal graph, in which nodes correspond to email templates and edges indicate potential causal relations (3) learning a causal relation prediction function, and (4) automatically "threading" the incoming email stream. We present detailed experimental results obtained by analyzing the inboxes of 12.5 million Yahoo! Mail users, who voluntarily opted-in for such research. Supervised editorial judgments show that we can identify more than 70% (recall rate) of all "causal threads" at a precision level of 90%. In addition, for a search scenario we show that we achieve a precision close to 80% at 90% recall. We believe that supporting causal threads in email clients opens new grounds for improving both email search and browsing experiences.},
booktitle = {Proceedings of the Sixth ACM International Conference on Web Search and Data Mining},
pages = {405–414},
numpages = {10},
keywords = {email threading, frequent sets and patterns, emamodels, user experience, algorithms},
location = {Rome, Italy},
series = {WSDM '13}
}

@inproceedings{10.1145/2433396.2433483,
author = {Karande, Chinmay and Mehta, Aranyak and Srikant, Ramakrishnan},
title = {Optimizing Budget Constrained Spend in Search Advertising},
year = {2013},
isbn = {9781450318693},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2433396.2433483},
doi = {10.1145/2433396.2433483},
abstract = {Search engine ad auctions typically have a significant fraction of advertisers who are budget constrained, i.e., if allowed to participate in every auction that they bid on, they would spend more than their budget. This yields an important problem: selecting the ad auctions which these advertisers participate, in order to optimize different system objectives such as the return on investment for advertisers, and the quality of ads shown to users. We present a system and algorithms for optimizing budget constrained spend. The system is designed be deployed in a large search engine, with hundreds of thousands of advertisers, millions of searches per hour, and with the query stream being only partially predictable. We have validated the system design by implementing it in the Google ads serving system and running experiments on live traffic. We have also compared our algorithm to previous work that casts this problem as a large linear programming problem limited to popular queries, and show that our algorithms yield substantially better results.},
booktitle = {Proceedings of the Sixth ACM International Conference on Web Search and Data Mining},
pages = {697–706},
numpages = {10},
keywords = {online advertising, budget optimization},
location = {Rome, Italy},
series = {WSDM '13}
}

@inproceedings{10.1145/2460625.2460658,
author = {Juli\`{a}, Carles F. and Earnshaw, Nicolas and Jord\`{a}, Sergi},
title = {GestureAgents: An Agent-Based Framework for Concurrent Multi-Task Multi-User Interaction},
year = {2013},
isbn = {9781450318983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2460625.2460658},
doi = {10.1145/2460625.2460658},
abstract = {While the HCI community has been putting a lot of effort on creating physical interfaces for collaboration, studying multi-user interaction dynamics and creating specific applications to support (and test) this kind of phenomena, it has not addressed the problems implied in having multiple applications sharing the same interactive space. Having an ecology of rich interactive programs sharing the same interfaces poses questions on how to deal with interaction ambiguity in a cross-application way and still allow different programmers the freedom to program rich unconstrained interaction experiences.This paper describes GestureAgents, a framework demonstrating several techniques that can be used to coordinate different applications in order to have concurrent multi-user multi-tasking interaction and still dealing with gesture ambiguity across multiple applications.},
booktitle = {Proceedings of the 7th International Conference on Tangible, Embedded and Embodied Interaction},
pages = {207–214},
numpages = {8},
keywords = {agent-exclusivity, concurrent interaction, gesture framework, multi-user},
location = {Barcelona, Spain},
series = {TEI '13}
}

@inproceedings{10.1145/2442754.2442756,
author = {Kim, Sunghun and Zimmermann, Thomas and Premraj, Rahul and Bettenburg, Nicolas and Shivaji, Shivkumar},
title = {Predicting Method Crashes with Bytecode Operations},
year = {2013},
isbn = {9781450319874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2442754.2442756},
doi = {10.1145/2442754.2442756},
abstract = {Software monitoring systems have high performance overhead because they typically monitor all processes of the running program. For example, to capture and replay crashes, most current systems monitor all methods; thus yielding a significant performance overhead. Lowering the number of methods being monitored to a smaller subset can dramatically reduce this overhead. We present an approach that can help arrive at such a subset by reliably identifying methods that are the most likely candidates to crash in a future execution of the software. Our approach involves learning patterns from features of methods that previously crashed to classify new methods as crash-prone or non-crash-prone. An evaluation of our approach on two large open source projects, ASPECTJ and ECLIPSE, shows that we can correctly classify crash-prone methods with an accuracy of 80--86%. Notably, we found that the classification models can also be used for cross-project prediction with virtually no loss in classification accuracy. In a further experiment, we demonstrate how a monitoring tool, RECRASH could take advantage of only monitoring crash-prone methods and thereby, reduce its performance overhead and maintain its ability to perform its intended tasks.},
booktitle = {Proceedings of the 6th India Software Engineering Conference},
pages = {3–12},
numpages = {10},
location = {New Delhi, India},
series = {ISEC '13}
}

@article{10.1145/2423636.2423644,
author = {Nam, Yunyoung and Rho, Seungmin and Lee, Chulung},
title = {Physical Activity Recognition Using Multiple Sensors Embedded in a Wearable Device},
year = {2013},
issue_date = {February 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
issn = {1539-9087},
url = {https://doi.org/10.1145/2423636.2423644},
doi = {10.1145/2423636.2423644},
abstract = {In this article, we present a wearable intelligence device for activity monitoring applications. We developed and evaluated algorithms to recognize physical activities from data acquired using a 3-axis accelerometer with a single camera worn on a body. The recognition process is performed in two steps: at first the features for defining a human activity are measured by the 3-axis accelerometer sensor and the image sensor embedded in a wearable device. Then, the physical activity corresponding to the measured features is determined by applying the SVM classifier. The 3-axis accelerometer sensor computes the correlation between axes and the magnitude of the FFT for other features of an activity. Acceleration data is classified into nine activity labels. Through the image sensor, multiple optical flow vectors computed on each grid image patch are extracted as features for defining an activity. In the experiments, we showed that an overall accuracy rate of activity recognition based our method was 92.78%.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = feb,
articleno = {26},
numpages = {14},
keywords = {wearable computing, ubiquitous, human activity recognition, SVM, Accelerometer}
}

@article{10.1145/2423636.2423649,
author = {Waluyo, Agustinus Borgy and Taniar, David and Srinivasan, Bala and Rahayu, Wenny},
title = {Mobile Query Services in a Participatory Embedded Sensing Environment},
year = {2013},
issue_date = {February 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
issn = {1539-9087},
url = {https://doi.org/10.1145/2423636.2423649},
doi = {10.1145/2423636.2423649},
abstract = {A participatory mobile sensing system is designed to enable clients to voluntarily collect environmental data using embedded sensors and a mobile device while going about their daily activities. Due to the spatio-temporal nature of the data, and the significant benefits of the data to the general public, it is necessary to employ an efficient and effective query processing model for the mobile clients to access the data that can be visualized via an interactive multimedia interface. This article introduces a unified on-demand and data broadcast model to serve queries in the context of a mobile sensing system. The contributions of this article include the following: (i) it presents a novel data structure and indexing method to support the system; (ii) it provides flexibility for the client to issue query using on-demand or broadcast channel according to the server load and broadcast schedule; (iii) it enables new data access and processing for the mobile client; and (iv) it is designed for a multiple channels/receivers environment in a 4G wireless network. The proposed model uses a holistic query processing approach for the mobile sensing system that offers substantial efficiency and autonomy for mobile clients when retrieving data. The results of the experiments undertaken affirm the effectiveness of its performance.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = feb,
articleno = {31},
numpages = {24},
keywords = {energy-efficient query processing, participatory-based air-quality monitoring system, mobile query processing, Mobile sensing system, participatory embedded sensing}
}

@inproceedings{10.1145/2441776.2441836,
author = {Kusunoki, Diana S. and Sarcevic, Aleksandra and Zhang, Zhan and Burd, Randall S.},
title = {Understanding Visual Attention of Teams in Dynamic Medical Settings through Vital Signs Monitor Use},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441836},
doi = {10.1145/2441776.2441836},
abstract = {The purpose of this study was to understand how vital signs monitors support teamwork during trauma resuscitation -- the fast-paced and information-rich process of stabilizing critically injured patients. We analyzed 12 videos of simulated resuscitations to characterize trauma team monitor use. To structure our observations, we adopted the feedback loop concept. Our results showed that the monitor was used frequently, especially by team leaders and anesthesiologists. We identified three patterns of monitor use: (i) periods with a low frequency of short looks (glances) to maintain overall process awareness; (ii) periods with a medium frequency of long looks (scrutiny) to monitor trends in patient status; and (iii) peaks with a high frequency of glances to maintain attention on both the patient and monitor during critical tasks. Approximately 75% of looks were 3 seconds or shorter, but many looks (25%) ranged between 3 and 26 seconds. Our results have implications for improving displays by presenting the status of the patient's physiological systems and team activities.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {527–540},
numpages = {14},
keywords = {trauma resuscitation, video analysis, health informatics, information behavior, visual attention, feedback loop.},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2441776.2441852,
author = {Smith, Chris and Quercia, Daniele and Capra, Licia},
title = {Finger on the Pulse: Identifying Deprivation Using Transit Flow Analysis},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441852},
doi = {10.1145/2441776.2441852},
abstract = {A common metaphor to describe the movement of people within a city is that of blood flowing through the veins of a living organism. We often speak of the 'pulse of the city' when referring to flow patterns we observe. Here we extend this metaphor by hypothesising that by monitoring the flow of people through a city we can assess the city's health, as a nurse takes a patient's heart-rate and blood pressure during a routine health check. Using an automated fare collection dataset of journeys made on the London rail system, we build a classification model that identifies areas of high deprivation as measured by the Indices of Multiple Deprivation, and achieve a precision, sensitivity and specificity of 0.805, 0.733 and 0.810, respectively. We conclude with a discussion of the potential benefits this work provides to city planning, policymaking, and citizen engagement initiatives.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {683–692},
numpages = {10},
keywords = {data mining, well being, urban computing, public transport},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2442516.2442526,
author = {Morozov, Dmitriy and Weber, Gunther},
title = {Distributed Merge Trees},
year = {2013},
isbn = {9781450319225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2442516.2442526},
doi = {10.1145/2442516.2442526},
abstract = {Improved simulations and sensors are producing datasets whose increasing complexity exhausts our ability to visualize and comprehend them directly. To cope with this problem, we can detect and extract significant features in the data and use them as the basis for subsequent analysis. Topological methods are valuable in this context because they provide robust and general feature definitions.As the growth of serial computational power has stalled, data analysis is becoming increasingly dependent on massively parallel machines. To satisfy the computational demand created by complex datasets, algorithms need to effectively utilize these computer architectures. The main strength of topological methods, their emphasis on global information, turns into an obstacle during parallelization.We present two approaches to alleviate this problem. We develop a distributed representation of the merge tree that avoids computing the global tree on a single processor and lets us parallelize subsequent queries. To account for the increasing number of cores per processor, we develop a new data structure that lets us take advantage of multiple shared-memory cores to parallelize the work on a single node. Finally, we present experiments that illustrate the strengths of our approach as well as help identify future challenges.},
booktitle = {Proceedings of the 18th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
pages = {93–102},
numpages = {10},
keywords = {merge tree computation, topological data analysis, hybrid parallelization approaches, parallelization, feature extraction},
location = {Shenzhen, China},
series = {PPoPP '13}
}

@article{10.1145/2517327.2442526,
author = {Morozov, Dmitriy and Weber, Gunther},
title = {Distributed Merge Trees},
year = {2013},
issue_date = {August 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {8},
issn = {0362-1340},
url = {https://doi.org/10.1145/2517327.2442526},
doi = {10.1145/2517327.2442526},
abstract = {Improved simulations and sensors are producing datasets whose increasing complexity exhausts our ability to visualize and comprehend them directly. To cope with this problem, we can detect and extract significant features in the data and use them as the basis for subsequent analysis. Topological methods are valuable in this context because they provide robust and general feature definitions.As the growth of serial computational power has stalled, data analysis is becoming increasingly dependent on massively parallel machines. To satisfy the computational demand created by complex datasets, algorithms need to effectively utilize these computer architectures. The main strength of topological methods, their emphasis on global information, turns into an obstacle during parallelization.We present two approaches to alleviate this problem. We develop a distributed representation of the merge tree that avoids computing the global tree on a single processor and lets us parallelize subsequent queries. To account for the increasing number of cores per processor, we develop a new data structure that lets us take advantage of multiple shared-memory cores to parallelize the work on a single node. Finally, we present experiments that illustrate the strengths of our approach as well as help identify future challenges.},
journal = {SIGPLAN Not.},
month = feb,
pages = {93–102},
numpages = {10},
keywords = {hybrid parallelization approaches, topological data analysis, merge tree computation, feature extraction, parallelization}
}

@inproceedings{10.1145/2441776.2441811,
author = {Choi, Jinhyuk and Heo, Seongkook and Han, Jaehyun and Lee, Geehyuk and Song, Junehwa},
title = {Mining Social Relationship Types in an Organization Using Communication Patterns},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441811},
doi = {10.1145/2441776.2441811},
abstract = {Our goal is to show that it is possible to automatically infer social relationship types among people who stay together in an organization by analyzing communication patterns. We collected indoor co-location data and instant messenger data from 22 participants for one month. Based on the data, we designed and explored several indicators which are considered to be useful for mining social relationship types. We applied machine learning techniques using the indicators and found that it is possible to develop an intelligent method to infer social relationship types.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {295–302},
numpages = {8},
keywords = {social relationship, relationship mining},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2441776.2441789,
author = {Chen, Yunan and Ngo, Victor and Park, Sun Young},
title = {Caring for Caregivers: Designing for Integrality},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441789},
doi = {10.1145/2441776.2441789},
abstract = {Health and wellness have drawn significant attention in the HCI and CSCW communities. Many prior studies have focused on designing technologies that are patient-centric, allowing caregivers to take better care of patients. Less has been done in understanding and minimizing the burden of caregiving in caregivers' own lives. We conducted a qualitative interview study to understand their experiences in caregiving. The findings reveal a great magnitude of challenges in the caregivers' day-to-day lives, ranging from the physical and social, to the personal and emotional. Caregivers have to constantly balance their personal lives with work, family, and their caregiver roles, which can be overwhelmingly stressful. We discuss how caregivers attempt maintaining this balance through two concepts: first, giving-impact, and second, visibility-invisibility. Our study's findings call for system design that focuses not only on patients but also caregivers, addressing the burdens that often impair their health and wellness.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {91–102},
numpages = {12},
keywords = {healthcare technology, caregiving, integrality, health and wellness, caregiver, invisibility},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2441776.2441842,
author = {Liao, Qinying and Shi, Lei},
title = {She Gets a Sports Car from Our Donation: Rumor Transmission in a Chinese Microblogging Community},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441842},
doi = {10.1145/2441776.2441842},
abstract = {In this paper we report on a case study of rumor transmission during a nationwide scandal via China's most popular microblogging service, weibo.com. Specifically, we explore dynamics of the rumor discourse by characterizing different statement types and their evolution over time. We examine the roles that different user groups play in the rumor discussions. Through qualitative and statistical analyses, our results identify seven reaction patterns to rumors and their different development trends. We reveal a three-stage pattern of the change of leadership during the rumor discussions. By connecting social theories on rumor transmission to the large scale social platform, this paper offers insight into understanding rumor development in social media, as well as utilizing microblogging data for effectively detecting, analyzing and controlling public rumors.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {587–598},
numpages = {12},
keywords = {rumor transmission, microblogging, social media, china},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2441776.2441838,
author = {O'Kane, Aisling A. and Mentis, Helena M. and Thereska, Eno},
title = {Non-Static Nature of Patient Consent: Shifting Privacy Perspectives in Health Information Sharing},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441838},
doi = {10.1145/2441776.2441838},
abstract = {The purpose of the study is to explore how chronically ill patients and their specialized care network have viewed their personal medical information privacy and how it has impacted their perspectives of sharing their records with their network of healthcare providers and secondary use organizations. Diabetes patients and specialized diabetes medical care providers in Eastern England were interviewed about their sharing of medical information and their privacy concerns to inform a descriptive qualitative and exploratory thematic analysis. From the interview data, we see that diabetes patients shift their perceived privacy concerns and needs throughout their lifetime due to persistence of health data, changes in health, technology advances, and experience with technology that affect one's consent decisions. From these findings, we begin to take a translational research approach in critically examining current privacy enhancing technologies for secondary use consent management and motivate the further exploration of both temporally-sensitive privacy perspectives and new options in consent management that support shifting privacy concerns over one's lifetime.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {553–562},
numpages = {10},
keywords = {privacy, chronic illness, temporality, illness trajectory, medical records},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2441776.2441826,
author = {Rolland, Betsy and Lee, Charlotte P.},
title = {Beyond Trust and Reliability: Reusing Data in Collaborative Cancer Epidemiology Research},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441826},
doi = {10.1145/2441776.2441826},
abstract = {While previous CSCW research on data sharing and reuse has focused on how researchers assess the trust and reliability of the data of others, we know little about scientists' data use practices after that decision has been taken. This qualitative study of post-doctoral researchers' use of preexisting datasets investigates the practices of cancer-epidemiology post-docs working to understand their "Small Data" datasets. We report the ongoing and iterative nature of information seeking inherent in using unfamiliar data and the time-consuming and highly-collaborative process post-docs used to understand aspects of the dataset important to their scientific questions. Understanding data use practices can help inform the design of both Small Data projects and large cyberinfrastructure projects where multi-source data are collected and combined.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {435–444},
numpages = {10},
keywords = {information seeking, qualitative research, data reuse, data sharing, collaboration, data},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2441776.2441797,
author = {Harper, Richard and Mentis, Helena},
title = {The Mocking Gaze: The Social Organization of Kinect Use},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441797},
doi = {10.1145/2441776.2441797},
abstract = {As the Kinect sensor is being extended from gaming to other applications and contexts, we critically examine what is the nature of the experience garnered through its current use in gaming in the home setting. Through an exploratory study of family experiences with Kinect in gaming, we discuss the character of the experience as one that entails users reveling in absurdity of movement that is required by the Kinect sensor. Through this analysis, we liken the 'third-space' defined by Kinect-based gestural interaction to that of Bakhtin's mocking gaze in the contexts of carnivals. This is followed by remarks on the implications this re-specification of understanding Kinect-enabled interaction has for the term 'natural' and relatedly the emphasis on the 'user' as 'the 'controller' in HCI. Remarks will be made on the implications of this for the application of the Kinect sensor to distributed gaming and other non-gaming interaction spaces in the home.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {167–180},
numpages = {14},
keywords = {hci, cultural theory, kinect, family, natural user interfaces, gesture, body-based interaction, culture, home, games, sociology},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2441776.2441865,
author = {Sleeper, Manya and Balebako, Rebecca and Das, Sauvik and McConahy, Amber Lynn and Wiese, Jason and Cranor, Lorrie Faith},
title = {The Post That Wasn't: Exploring Self-Censorship on Facebook},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441865},
doi = {10.1145/2441776.2441865},
abstract = {Social networking site users must decide what content to share and with whom. Many social networks, including Facebook, provide tools that allow users to selectively share content or block people from viewing content. However, sometimes instead of targeting a particular audience, users will self-censor, or choose not to share. We report the results from an 18-participant user study designed to explore self-censorship behavior as well as the subset of unshared content participants would have potentially shared if they could have specifically targeted desired audiences. We asked participants to report all content they thought about sharing but decided not to share on Facebook and interviewed participants about why they made sharing decisions and with whom they would have liked to have shared or not shared. Participants reported that they would have shared approximately half the unshared content if they had been able to exactly target their desired audiences.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {793–802},
numpages = {10},
keywords = {self-censorship, social networking sites, privacy, usability},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2441776.2441954,
author = {Jung, Malte F. and Lee, Jin Joo and DePalma, Nick and Adalgeirsson, Sigurdur O. and Hinds, Pamela J. and Breazeal, Cynthia},
title = {Engaging Robots: Easing Complex Human-Robot Teamwork Using Backchanneling},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441954},
doi = {10.1145/2441776.2441954},
abstract = {People are increasingly working with robots in teams and recent research has focused on how human-robot teams function, but little attention has yet been paid to the role of social signaling behavior in human-robot teams. In a controlled experiment, we examined the role of backchanneling and task complexity on team functioning and perceptions of the robots' engagement and competence. Based on results from 73 participants interacting with autonomous humanoid robots as part of a human-robot team (one participant, one confederate, and three robots), we found that when robots used backchanneling team functioning improved and the robots were seen as more engaged. Ironically, the robots using backchanneling were perceived as less competent than those that did not. Our results suggest that backchanneling plays an important role in human-robot teams and that the design and implementation of robots for human-robot teams may be more effective if backchanneling capability is provided.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {1555–1566},
numpages = {12},
keywords = {team performance, affect, human-robot teams, urban search and rescue, human-robot interaction},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@inproceedings{10.1145/2441776.2441793,
author = {Fugelli, P\r{a}l and Lahn, Leif C. and M\o{}rch, Anders I.},
title = {Shared Prolepsis and Intersubjectivity in Open Source Development: Expansive Grounding in Distributed Work},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2441776.2441793},
doi = {10.1145/2441776.2441793},
abstract = {Intersubjectivity is a term used to conceptualize the psychological relationship between people during conversation, e.g. for building a shared understanding. Ragnar Rommetveit, a Norwegian social psychologist, developed a conceptual framework for intersubjectivity, treating it as a social phenomenon and a dynamic process. One technique for increasing intersubjectivity according to Rommetveit is to issue 'anticipatory cues,' i.e. referring to common knowledge and indicating future situations where the knowledge will be relevant. This framework was adapted for online communication and applied to an analysis of the mod_perl module of the Apache Web server (an open source development project). Based on observations of 215 participants' contributions to the project's mailing list over a 6-month period, we explore how processes of intersubjectivity evolve across the developer network. We conclude with a discussion of how so-called proleptic instances in post-and-reply messages may be significant and trigger the co-construction of shared understanding.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {129–144},
numpages = {16},
keywords = {collaboration, shared understanding, software development, empirical study, intersubjectivity, grounding, prolepsis},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

