@inproceedings{10.5555/2133429.2133465,
author = {Leem, Larkhoon and Cho, Hyungmin and Lee, Hsiao-Heng and Kim, Young Moon and Li, Yanjing and Mitra, Subhasish},
title = {Cross-Layer Error Resilience for Robust Systems},
year = {2010},
isbn = {9781424481927},
publisher = {IEEE Press},
abstract = {A large class of robust electronic systems of the future must be designed to perform correctly despite hardware failures. In contrast, today's mainstream systems typically assume error-free hardware. Classical fault-tolerant computing techniques are too expensive for this purpose. This paper presents an overview of new techniques that can enable a sea change in the design of cost-effective robust systems. These techniques utilize globally-optimized cross-layer approaches, i.e., across device, circuit, architecture, runtime, and application layers, to overcome hardware failures.},
booktitle = {Proceedings of the International Conference on Computer-Aided Design},
pages = {177–180},
numpages = {4},
keywords = {ERSA, soft error, on-line self-test, circuit failure prediction, CASP, robust system design, error resilient system architecture, LEAP, reliability, diagnostics},
location = {San Jose, California},
series = {ICCAD '10}
}

@inproceedings{10.1145/1882362.1882383,
author = {Easterbrook, Steve M.},
title = {Climate Change: A Grand Software Challenge},
year = {2010},
isbn = {9781450304276},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1882362.1882383},
doi = {10.1145/1882362.1882383},
abstract = {Software is a critical enabling technology in nearly all aspects of climate change, from the computational models used by climate scientists to improve our understanding of the impact of human activities on earth systems, through to the information and control systems needed to build an effective carbon-neutral society. Accordingly, we, as software researchers and software practitioners, have a major role to play in responding to the climate crisis. In this paper we map out the space in which our contributions are likely to be needed, and suggest a possible research agenda.},
booktitle = {Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research},
pages = {99–104},
numpages = {6},
keywords = {climate change},
location = {Santa Fe, New Mexico, USA},
series = {FoSER '10}
}

@inproceedings{10.1145/1880071.1880103,
author = {Savery, Cheryl and Graham, T. C. Nicholas and Gutwin, Carl},
title = {The Human Factors of Consistency Maintenance in Multiplayer Computer Games},
year = {2010},
isbn = {9781450303873},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1880071.1880103},
doi = {10.1145/1880071.1880103},
abstract = {Consistency maintenance (CM) techniques are a crucial part of many distributed systems, and are particularly important in networked games. In this paper we describe a framework of the human factors of CM, to help designers of networked games make better decisions about its use. The framework shows that there is wide variance in the CM requirements of different game situations, identifies the types of requirements that can be considered, and analyses the effects of several consistency schemes on user experience factors. To further explore these issues, we carried out a simulation study that compared four CM algorithms. The experiment confirms many of the predictions of the framework, and reveals additional subtleties of the algorithms. Our work is the first to look comprehensively at the tradeoffs and costs of CM, and our results are a strong starting point that will help designers improve on the user's quality of experience in distributed shared environments.},
booktitle = {Proceedings of the 16th ACM International Conference on Supporting Group Work},
pages = {187–196},
numpages = {10},
keywords = {consistency maintenance, game development, game usablity},
location = {Sanibel Island, Florida, USA},
series = {GROUP '10}
}

@inproceedings{10.1145/1891903.1891933,
author = {El Ali, Abdallah and Nack, Frank and Hardman, Lynda},
title = {Understanding Contextual Factors in Location-Aware Multimedia Messaging},
year = {2010},
isbn = {9781450304146},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1891903.1891933},
doi = {10.1145/1891903.1891933},
abstract = {Location-aware messages left by people can make visible some aspects of their everyday experiences at a location. To understand the contextual factors surrounding how users produce and consume location-aware multimedia messaging (LMM), we use an experience-centered framework that makes explicit the different aspects of an experience. Using this framework, we conducted an exploratory, diary study aimed at eliciting implications for the study and design of LMM systems. In an earlier pilot study, we found that subjects did not have enough time to fully capture their everyday experiences using an LMM prototype, which led us to conduct a longer study using a multimodal diary method. The diary study data (verified for reliability using a categorization task) provided a closer look at the different aspects (spatiotemporal, social, affective, and cognitive) of people's experience. From the data, we derive three main findings (predominant LMM domains and tasks, capturing experience vs. experience of capture, context-dependent personalization) to inform the study and design of future LMM systems.},
booktitle = {International Conference on Multimodal Interfaces and the Workshop on Machine Learning for Multimodal Interaction},
articleno = {22},
numpages = {8},
keywords = {location-aware multimedia messaging (LMM), contextual factors, context-aware systems, experience-centered framework},
location = {Beijing, China},
series = {ICMI-MLMI '10}
}

@inproceedings{10.1145/1967486.1967531,
author = {Al Hakeem, Nawar and Salem, Mohamed},
title = {Novel Algorithm for Enhancing Database Access in Interactive Applications: Performance Evaluation},
year = {2010},
isbn = {9781450304214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1967486.1967531},
doi = {10.1145/1967486.1967531},
abstract = {Online applications rely heavily on database management systems (DBMS), as an essential component of knowledge discovery. DBMS searching and querying has been extensively studied resulting in significant reduction of response time for access and consequently improving the online dialogue process between servers and clients. In this paper, a decision-making algorithm (SEQUESTER) has been developed in order to further improve the performance of interaction-based online applications. The proposed approach uses information theoretic measures in order to build efficient decision trees which form the basis to optimize interactions in a range of real life online applications. The decision-making model employs a question-and-answer (Q&amp;A) approach to guide users in an interactive process to explore for information such as products in a database. The salient feature of this approach is the significant reduction of the number of interactions (accesses) of a customer to a remote application.},
booktitle = {Proceedings of the 12th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {273–282},
numpages = {10},
keywords = {electronic commerce (e-commerce), database mining, information-theoretic measures, decision trees},
location = {Paris, France},
series = {iiWAS '10}
}

@inproceedings{10.1145/1967486.1967496,
author = {Mohebbi, Keyvan and Ibrahim, Suhaimi and Khezrian, Mojtaba and Munusamy, Kanmani and Tabatabaei, Sayed Gholam Hassan},
title = {A Comparative Evaluation of Semantic Web Service Discovery Approaches},
year = {2010},
isbn = {9781450304214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1967486.1967496},
doi = {10.1145/1967486.1967496},
abstract = {Currently, most enterprises deploy their services on the Web. This augments the request for tools to perform discovery, selection, composition and invocation of Web services. Among them, Web service discovery should be considered more important. Along with the growing number of available Web services, there is a need for tools not only to perform discovery, but also to realize them in an efficient and effective manner. A number of approaches to Web service discovery have been proposed. In this paper, we provide a taxonomy which categorizes Web service discovery systems from different points of view. Moreover, current approaches to Semantic Web service discovery are classified and described. In addition, we compare the approaches with respect to some criteria from different aspects of view. The results of this study can help researchers in both academia and industry to implement a new or to select the most appropriate existing approach for Semantic Web service discovery with the aid of different criteria.},
booktitle = {Proceedings of the 12th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {33–39},
numpages = {7},
keywords = {web services, web service discovery, semantic web services, semantic web},
location = {Paris, France},
series = {iiWAS '10}
}

@inproceedings{10.1145/1967486.1967615,
author = {Al Hosni, Noura and Ali, Saqib and Ashrafi, Rafi},
title = {The Key Success Factors to Mobile Commerce for Arab Countries in Middle East},
year = {2010},
isbn = {9781450304214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1967486.1967615},
doi = {10.1145/1967486.1967615},
abstract = {A number of studies have been conducted on the diffusion of mobile commerce, its challenges, opportunities, issues and obstacles. However, few have emphasized on its adoption within Middle East countries. This paper reviews the current literature in order to assess the mobile commerce adoption in Arab countries within Middle East and identify the key success factors in mobile commerce adoption in them.},
booktitle = {Proceedings of the 12th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {787–790},
numpages = {4},
keywords = {key success factors, middle east, mobile commerce, ICT, mobile penetration},
location = {Paris, France},
series = {iiWAS '10}
}

@article{10.1145/1882471.1882480,
author = {Gupta, Manish and Li, Rui and Yin, Zhijun and Han, Jiawei},
title = {Survey on Social Tagging Techniques},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {1931-0145},
url = {https://doi.org/10.1145/1882471.1882480},
doi = {10.1145/1882471.1882480},
abstract = {Social tagging on online portals has become a trend now. It has emerged as one of the best ways of associating metadata with web objects. With the increase in the kinds of web objects becoming available, collaborative tagging of such objects is also developing along new dimensions. This popularity has led to a vast literature on social tagging. In this survey paper, we would like to summarize different techniques employed to study various aspects of tagging. Broadly, we would discuss about properties of tag streams, tagging models, tag semantics, generating recommendations using tags, visualizations of tags, applications of tags and problems associated with tagging usage. We would discuss topics like why people tag, what influences the choice of tags, how to model the tagging process, kinds of tags, different power laws observed in tagging domain, how tags are created, how to choose the right tags for recommendation, etc. We conclude with thoughts on future work in the area.},
journal = {SIGKDD Explor. Newsl.},
month = nov,
pages = {58–72},
numpages = {15},
keywords = {folk taxonomy, tagging, distributed classification, ethnoclassification, bookmarking, collaborative tagging, folksonomy, social classification, social indexing, social tagging, folk classification}
}

@inproceedings{10.1145/1882992.1883010,
author = {Suh, Myung-kyung and Evangelista, Lorraine S. and Chen, Chien-An and Han, Kyungsik and Kang, Jinha and Tu, Michael Kai and Chen, Victor and Nahapetian, Ani and Sarrafzadeh, Majid},
title = {An Automated Vital Sign Monitoring System for Congestive Heart Failure Patients},
year = {2010},
isbn = {9781450300308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1882992.1883010},
doi = {10.1145/1882992.1883010},
abstract = {Congestive heart failure (CHF) is a cardiovascular disorder that affects approximately 4.6 million Americans and is a leading cause of death in the United States. Current research shows that strategies to promote early recognition and treatment of symptoms and enhance self-care management behaviors reduce unnecessary hospitalizations. However, mechanisms to monitor patients' health status and behaviors are limited by constraints imposed by the patient's geography, infirmity, or resources. Remote monitoring supports a more dynamic connection between healthcare providers and patients, improves health promotion and patient care through monitoring of health data, communicates health reminders, and makes provisions for patient feedback. This paper will describe two versions of Weight and Activity with Blood Pressure Monitoring System (WANDA [22]) that leverages sensor technology and wireless communication to monitor health status of patients with CHF. The WANDA system is built on a three-tier architecture consisting of sensors, a web server, and back-end database tiers. The system was developed in conjunction with the UCLA School of Nursing and the UCLA Wireless Health Institute to enable early detection of key clinical symptoms indicative of CHF-related decompensation in a real-time automated fashion and allows health professionals to offer surveillance, advice, and continuity of care and triggers early implementation of strategies to enhance adherence behaviors. The small study has enabled patients to reduce or maintain the number of readings which are out of the acceptable range. For diastolic, systolic, and heart rate values, the t-test results show that the WANDA study is effective for patients with CHF.},
booktitle = {Proceedings of the 1st ACM International Health Informatics Symposium},
pages = {108–117},
numpages = {10},
keywords = {telemedicine, data integrity, real-time feedback, congestive heart failure patients monitoring, wireless health, database backup, health monitoring},
location = {Arlington, Virginia, USA},
series = {IHI '10}
}

@inproceedings{10.1145/1882992.1883124,
author = {Khan, Danish U. and Siek, Katie A. and Meyers, Jane and Haverhals, Leah M. and Cali, Steven and Ross, Stephen E.},
title = {Designing a Personal Health Application for Older Adults to Manage Medications},
year = {2010},
isbn = {9781450300308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1882992.1883124},
doi = {10.1145/1882992.1883124},
abstract = {Older adults with multiple chronic conditions are prone to care transitions, such as seeing a new doctor or being discharged after a prolonged hospital stay. These transitions are often uncoordinated and can imperil patients by omitted, duplicative, or contradictory treatment plans. We developed an open source, web-based Personal Health Application (PHA) using an iterative participatory design process that provides older adults and their caregivers the ability to manage their personal health information during care transitions. We report our findings from six user studies that establish the imperative need for interdisciplinary research and collaboration among all stakeholders - patients, caregivers, health professionals, designers, and health informaticians - to create effective PHAs. We conclude with design guidelines that encourage researchers to gradually increase functionality as users become more proficient interacting with the PHA.},
booktitle = {Proceedings of the 1st ACM International Health Informatics Symposium},
pages = {849–858},
numpages = {10},
keywords = {personal health applications, healthcare, participatory design, elderly, medication management, personal health records},
location = {Arlington, Virginia, USA},
series = {IHI '10}
}

@inproceedings{10.1145/1952222.1952308,
author = {Satchell, Christine and Foth, Marcus},
title = {Fear and Danger in Nocturnal Urban Environments},
year = {2010},
isbn = {9781450305020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1952222.1952308},
doi = {10.1145/1952222.1952308},
abstract = {At the centre of this research is an ethnographic study that saw the researcher embedded within the fabric of inner city life to better understand what characteristics of user activity and interaction could be enhanced by technology. The initial research indicated that the experience of traversing the city after dark unified an otherwise divergent user group through a shared concern for personal safety. Managing this fear and danger represented an important user need. We found that mobile social networking systems are not only integral for bringing people together, they can help in the process of users safely dispersing as well. We conclude, however, that at a time when the average iPhone staggers under the weight of a plethora of apps that do everything from acting as a carpenter's level to a pregnancy predictor, we consider the potential for the functionality of a personal safety device to be embodied within a stand alone artifact.},
booktitle = {Proceedings of the 22nd Conference of the Computer-Human Interaction Special Interest Group of Australia on Computer-Human Interaction},
pages = {380–383},
numpages = {4},
keywords = {convergence, night, privacy, safety, surveillance, the city},
location = {Brisbane, Australia},
series = {OZCHI '10}
}

@inproceedings{10.1145/1952222.1952274,
author = {McKay, Dana and Sanchez, Silvia and Parker, Rebecca},
title = {What's My Name Again? Sociotechnical Considerations for Author Name Management in Research Databases},
year = {2010},
isbn = {9781450305020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1952222.1952274},
doi = {10.1145/1952222.1952274},
abstract = {Managing names in bibliographic databases so that they have a one-to-one match with individual authors is a longstanding and complex problem. Various solutions have been proposed, from labour-intensive but accurate manual matching, to machine-learning approaches to automated matching which require little input from people, but are not perfectly accurate. Researchers have a particular interest in name management: they are often authors, and receive academic credit based on their work and need correct citation records. However they are also searchers and have an interest in finding all the works by other authors. There has been little work on the tensions between these two needs, nor on how researchers manage their own identities with their choices of name. This paper reports on a study of researchers that investigates both their relationships with their own names, and what they would like from research databases when they are searching for specific authors.},
booktitle = {Proceedings of the 22nd Conference of the Computer-Human Interaction Special Interest Group of Australia on Computer-Human Interaction},
pages = {240–247},
numpages = {8},
keywords = {information seeking, sociotechnical aspects of HCI, author names, search interfaces, researchers, research databases},
location = {Brisbane, Australia},
series = {OZCHI '10}
}

@inproceedings{10.1145/1952222.1952278,
author = {Leong, Tuck Wah and Wright, Peter and Vetere, Frank and Howard, Steve},
title = {Understanding Experience Using Dialogical Methods: The Case of Serendipity},
year = {2010},
isbn = {9781450305020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1952222.1952278},
doi = {10.1145/1952222.1952278},
abstract = {McCarthy and Wright's (2004) approach to understanding user experience provides a rich conceptual framework. In this paper, we report how this framework was used to guide the development of an approach to researching the richness of a particular experience - serendipity. Three themes were identified; life as lived and felt, the whole person, and dialogical sense making. These were used to help understand the key qualities of the strategy, tools and techniques that were required in the empirical study of the experience of serendipity. The paper explains this process and illustrates the depth of understanding that our choice of tools afforded. After describing the case study we offer some guidance on how to choose appropriate tools and methods for researching other types of experience.},
booktitle = {Proceedings of the 22nd Conference of the Computer-Human Interaction Special Interest Group of Australia on Computer-Human Interaction},
pages = {256–263},
numpages = {8},
keywords = {experience-centred design, serendipity, user experience, digital music},
location = {Brisbane, Australia},
series = {OZCHI '10}
}

@article{10.1145/1899639.1899644,
author = {Beise, Catherine and Carte, Traci A. and Vician, Chelley and Chidambaram, Laku},
title = {A Case Study of Project Management Practices in Virtual Settings: Lessons from Working in and Managing Virtual Teams},
year = {2010},
issue_date = {November 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {4},
issn = {0095-0033},
url = {https://doi.org/10.1145/1899639.1899644},
doi = {10.1145/1899639.1899644},
abstract = {In this paper we report a case study examining the communication processes engaged in by virtual project teams and their management. Twenty-two teams, using widely available groupware to communicate, work together, share documents, discuss ideas, and solve problems, designed and implemented a database. These teams were managed by a geographically-distributed management team. The case study is analyzed qualitatively and quantitatively, from two perspectives--working in, and managing, virtual teams--using a framework that integrates virtual team dynamics and project management practices. Through the critical examination of communication content from the longitudinal experiences of multiple virtual project teams and their virtual management team, we identify successful project practices and uncover underlying interaction processes. Specifically, we found that high performing project teams differed from low performing teams in terms of process management, relational development, and proactive technology use behaviors. The five-person management team paralleled the project teams in evolving its own process management and relational development over time.},
journal = {SIGMIS Database},
month = nov,
pages = {75–97},
numpages = {23},
keywords = {virtual teams, database development, groupware, computer mediated communications, project management}
}

@article{10.1145/1874391.1874402,
author = {Mishra, Amit and Misra, Sanjay},
title = {People Management in Software Industry: The Key to Success},
year = {2010},
issue_date = {November 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {6},
issn = {0163-5948},
url = {https://doi.org/10.1145/1874391.1874402},
doi = {10.1145/1874391.1874402},
abstract = {Performance differences have been proved among software professionals even in the conditions of identical task. Companies and organizations are aware of the fact that talent has great effect on their success; still most of the software development organizations are focusing so much on tools and technology and little on people. In this paper, we are trying to uncover the relation between the people management-human resource management and software engineering.},
journal = {SIGSOFT Softw. Eng. Notes},
month = nov,
pages = {1–4},
numpages = {4},
keywords = {software development, software industry, people management}
}

@inproceedings{10.1145/1925013.1925015,
author = {Jaiantilal, Abhishek and Jiang, Yifei and Mishra, Shivakant},
title = {Modeling CPU Energy Consumption for Energy Efficient Scheduling},
year = {2010},
isbn = {9781450304504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1925013.1925015},
doi = {10.1145/1925013.1925015},
abstract = {In the past few years, we have seen the rising popularity of multi-core systems, including the 4, 6, and 8-cores present in i7 processors from Intel, and the 8 and 12 cores present in Magny-Cours processors from AMD. There is a general trend that newer processors have more and more number of cores. A study [6] showed that, in data centers, the CPU load is around 10-50%; thus, when multi-core processors are used in data centers, many of the cores will be unused for a majority of the time. Such a scenario is also true for a casual desktop PC user. As an idle core still consumes energy, from the perspective of saving energy, it is important to ensure that the idle cores are put in the lowest energy state and unnecessary wakeups for these idle cores are avoided. This will ensure the lowest energy consumption for a given set of tasks.The precursor step towards developing an energy efficient CPU scheduler requires an understanding of the relation between the type of tasks and their corresponding power profile. In this paper, we show that the power profile of a task is dependent on the type of processor cycles executed by the task. We further develop a model that can predict the power consumption based on the processor cycles executed by the task. We conclude our paper showing initial results on how such a model can be used to schedule tasks and save energy.},
booktitle = {Proceedings of the 1st Workshop on Green Computing},
pages = {10–15},
numpages = {6},
location = {Bangalore, India},
series = {GCM '10}
}

@inproceedings{10.5555/2023718.2023732,
author = {Bertier, Marin and Frey, Davide and Guerraoui, Rachid and Kermarrec, Anne-Marie and Leroy, Vincent},
title = {The GOSSPLE Anonymous Social Network},
year = {2010},
isbn = {9783642169540},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {While social networks provide news from old buddies, you can learn a lot more from people you do not know, but with whom you share many interests. We show in this paper how to build a network of anonymous social acquaintances using a gossip protocol we call Gossple, and how to leverage such a network to enhance navigation within Web 2.0 collaborative applications, \`{a} la LastFM and Delicious. Gossple nodes (users) periodically gossip digests of their interest profiles and compute their distances (in terms of interest) with respect to other nodes. This is achieved with little bandwidth and storage, fast convergence, and without revealing which profile is associated with which user. We evaluate Gossple on real traces from various Web 2.0 applications with hundreds of PlanetLab hosts and thousands of simulated nodes.},
booktitle = {Proceedings of the ACM/IFIP/USENIX 11th International Conference on Middleware},
pages = {191–211},
numpages = {21},
location = {Bangalore, India},
series = {Middleware '10}
}

@inproceedings{10.1145/1900441.1900443,
author = {Winschiers-Theophilus, Heike and Chivuno-Kuria, Shilumbe and Kapuire, Gereon Koch and Bidwell, Nicola J. and Blake, Edwin},
title = {Being Participated: A Community Approach},
year = {2010},
isbn = {9781450301312},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1900441.1900443},
doi = {10.1145/1900441.1900443},
abstract = {In this paper, we explore the concept of participatory design from a different viewpoint by drawing on an African philosophy of humanness -Ubuntu-, and African rural community practices. The situational dynamics of participatory interaction become obvious throughout the design experiences within our community project. Supported by a theoretical framework we reflect upon current participatory design practices. We intend to inspire and refine participatory design concepts and methods beyond the particular context of our own experiences.},
booktitle = {Proceedings of the 11th Biennial Participatory Design Conference},
pages = {1–10},
numpages = {10},
keywords = {African context, rural interaction design, community participation},
location = {Sydney, Australia},
series = {PDC '10}
}

@article{10.1145/1898147.1898149,
author = {Haber, Eben M. and Kandogan, Eser and Maglio, Paul},
title = {Collaboration in System Administration: For Sysadmins, Solving Problems Usually Involves Collaborating with Others. How Can We Make It More Effective?},
year = {2010},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {12},
issn = {1542-7730},
url = {https://doi.org/10.1145/1898147.1898149},
doi = {10.1145/1898147.1898149},
abstract = {George was in trouble. A seemingly simple deployment was taking all morning, and there seemed no end in sight. His manager kept coming in to check on his progress, as the customer was anxious to have the deployment done. He was supposed to be leaving for a goodbye lunch for a departing co-worker, adding to the stress. He had called in all kinds of help, including colleagues, an application architect, technical support, and even one of the system developers. He used e-mail, instant messaging, face-to-face contacts, his phone, and even his office mate’s phone to communicate with everyone. And George was no novice. He had been working as a Web-hosting administrator for three years, and he had a bachelor’s degree in computer science. But it seemed that all the expertise being brought to bear was simply not enough. Why was George in trouble? We’ll find out.},
journal = {Queue},
month = dec,
pages = {10–20},
numpages = {11}
}

@inproceedings{10.1145/1899475.1899481,
author = {Liu, Yefeng and Lehdonvirta, Vili and Kleppe, Mieke and Alexandrova, Todorka and Kimura, Hiroaki and Nakajima, Tatsuo},
title = {A Crowdsourcing Based Mobile Image Translation and Knowledge Sharing Service},
year = {2010},
isbn = {9781450304245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1899475.1899481},
doi = {10.1145/1899475.1899481},
abstract = {Travelers in countries that use an unfamiliar script cannot use pocket translators or online translation services to understand menus, maps, signs and other important information, because they are unable to write the text they see. Solutions based on optical character recognition provide very limited performance in real-world situations and for complex scripts such as Chinese and Japanese. In this paper, we propose an alternative image translation solution based on crowdsourcing. A large number of human workers on mobile terminals are used to carry out the tasks of image recognition, translation and quality assurance. Compared to purely technical solutions, this human computation approach is also able to account for context and non-textual cues, and provide higher level information to the end-user. In this paper, we describe a preliminary user study to create a model of end-user requirements.},
booktitle = {Proceedings of the 9th International Conference on Mobile and Ubiquitous Multimedia},
articleno = {6},
numpages = {9},
keywords = {crowdsourcing, knowledge sharing, mobile image translation, image-text recognition, human computation},
location = {Limassol, Cyprus},
series = {MUM '10}
}

@inproceedings{10.1145/1944999.1945005,
author = {Berezovskiy, Alexander and Carr, Leslie},
title = {A Framework for Dynamic Data Source Identification and Orchestration on the Web},
year = {2010},
isbn = {9781450304184},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944999.1945005},
doi = {10.1145/1944999.1945005},
abstract = {The current Web offers a very large number of solutions and services, ranging from social networking and content delivery services to business applications and management systems. However, in a general case the solutions provided are largely disintegrated, with each product operating in its own environment. Additionally, many of the products are unknown to the end user and finding the most suitable application is commonly a nontrivial task. The current project is an effort to provide an ubiquitous interface for Web application integration. The suggested approach allows for dynamic identification of the applications most suitable for a given task and access to their data using a unified interface in the REST architectural style. A novel algorithm for identification of the most appropriate data source is introduced within the study. Evaluation of the overall system and the obtained results is provided.},
booktitle = {Proceedings of the 3rd and 4th International Workshop on Web APIs and Services Mashups},
articleno = {6},
numpages = {8},
keywords = {web integration, unified data access, data source identification, information retrieval},
location = {Ayia Napa, Cyprus},
series = {Mashups '09/'10}
}

@article{10.1145/1880018.1880019,
author = {Blagodurov, Sergey and Zhuravlev, Sergey and Fedorova, Alexandra},
title = {Contention-Aware Scheduling on Multicore Systems},
year = {2010},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {4},
issn = {0734-2071},
url = {https://doi.org/10.1145/1880018.1880019},
doi = {10.1145/1880018.1880019},
abstract = {Contention for shared resources on multicore processors remains an unsolved problem in existing systems despite significant research efforts dedicated to this problem in the past. Previous solutions focused primarily on hardware techniques and software page coloring to mitigate this problem. Our goal is to investigate how and to what extent contention for shared resource can be mitigated via thread scheduling. Scheduling is an attractive tool, because it does not require extra hardware and is relatively easy to integrate into the system. Our study is the first to provide a comprehensive analysis of contention-mitigating techniques that use only scheduling. The most difficult part of the problem is to find a classification scheme for threads, which would determine how they affect each other when competing for shared resources. We provide a comprehensive analysis of such classification schemes using a newly proposed methodology that enables to evaluate these schemes separately from the scheduling algorithm itself and to compare them to the optimal. As a result of this analysis we discovered a classification scheme that addresses not only contention for cache space, but contention for other shared resources, such as the memory controller, memory bus and prefetching hardware. To show the applicability of our analysis we design a new scheduling algorithm, which we prototype at user level, and demonstrate that it performs within 2% of the optimal. We also conclude that the highest impact of contention-aware scheduling techniques is not in improving performance of a workload as a whole but in improving quality of service or performance isolation for individual applications and in optimizing system energy consumption.},
journal = {ACM Trans. Comput. Syst.},
month = dec,
articleno = {8},
numpages = {45},
keywords = {Multicore processors, scheduling, shared resource contention}
}

@inproceedings{10.1145/1899475.1899479,
author = {Vartiainen, Elina and V\"{a}\"{a}n\"{a}nen-Vainio-Mattila, Kaisa},
title = {User Experience of Mobile Photo Sharing in the Cloud},
year = {2010},
isbn = {9781450304245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1899475.1899479},
doi = {10.1145/1899475.1899479},
abstract = {Cloud computing is a new paradigm for how applications and services are designed, implemented and accessed through Internet. In the cloud, the user can access services and his personal data real-time from any device. There are already services available in the market using cloud computing, such as email, enterprise planning software, and social media services. Still, research on cloud is in its early phase, especially when considering the user experience of mobile cloud services. In this paper, we introduce Image Exchange, a photo sharing Internet service that was designed from the cloud computing perspective. We evaluated Image Exchange through two user studies and the results presented in this paper describe important implications for cloud computing on mobile devices. Furthermore, we found special types of social interactions that emerged within the users of Image Exchange due to its cloud computing nature. The results show that the current design of Image Exchange provides a rather positive user experience, but it could be developed further to fully utilize the benefits of cloud computing.},
booktitle = {Proceedings of the 9th International Conference on Mobile and Ubiquitous Multimedia},
articleno = {4},
numpages = {10},
keywords = {user experience, internet services, photo sharing, cloud computing},
location = {Limassol, Cyprus},
series = {MUM '10}
}

@inproceedings{10.1145/1899475.1899499,
author = {Walsh, Tanja and Nurkka, Piia and Walsh, Rod},
title = {Cultural Differences in Smartphone User Experience Evaluation},
year = {2010},
isbn = {9781450304245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1899475.1899499},
doi = {10.1145/1899475.1899499},
abstract = {Through globalization it has become increasingly important to understand how culture affects the user experience (UX) of mobile devices and services. Despite the importance of cultural factors in product design, not much research has been done to study them. Our aim was to discover cultural differences in the UX of a Smartphone with remote online sentence completion method. This paper presents the results of a remote online UX evaluation survey of a Smartphone with altogether 72 respondents from India, China, USA, UK and Denmark. The results indicate that there are cultural differences in how people experience the product and also in the way people respond to UX evaluation survey and share their experiences with the product. The results show that a remote online sentence completion survey is a relatively fast and easy way of gathering international user data, although the analysis can be challenging. The use of Hofstede's cultural dimensions in the analysis of the data gave us better understanding of the impact of specific culture on the results.},
booktitle = {Proceedings of the 9th International Conference on Mobile and Ubiquitous Multimedia},
articleno = {24},
numpages = {9},
keywords = {mobile device, cross-cultural design, user experience, sentence completion technique, remote user study},
location = {Limassol, Cyprus},
series = {MUM '10}
}

@article{10.1145/1824795.1824798,
author = {Mabroukeh, Nizar R. and Ezeife, C. I.},
title = {A Taxonomy of Sequential Pattern Mining Algorithms},
year = {2010},
issue_date = {November 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/1824795.1824798},
doi = {10.1145/1824795.1824798},
abstract = {Owing to important applications such as mining web page traversal sequences, many algorithms have been introduced in the area of sequential pattern mining over the last decade, most of which have also been modified to support concise representations like closed, maximal, incremental or hierarchical sequences. This article presents a taxonomy of sequential pattern-mining techniques in the literature with web usage mining as an application. This article investigates these algorithms by introducing a taxonomy for classifying sequential pattern-mining algorithms based on important key features supported by the techniques. This classification aims at enhancing understanding of sequential pattern-mining problems, current status of provided solutions, and direction of research in this area. This article also attempts to provide a comparative performance analysis of many of the key techniques and discusses theoretical aspects of the categories in the taxonomy.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {3},
numpages = {41},
keywords = {tree projection, lexicographic order, frequent patterns, lattice theory, early pruning, sequential patterns, Web usage mining, association rules, Data mining, recommender systems, apriori property, sequence mining, prediction, pattern growth, web log}
}

@article{10.1145/1824795.1824800,
author = {Kurian, Jinu and Sarac, Kamil},
title = {A Survey on the Design, Applications, and Enhancements of Application-Layer Overlay Networks},
year = {2010},
issue_date = {November 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/1824795.1824800},
doi = {10.1145/1824795.1824800},
abstract = {This article presents a survey of recent advancements in application-layer overlay networks. Some of the most important applications that have been proposed for overlays include multicast, QoS support, denial-of-service (DoS) defense, and resilient routing. We look at some of the important approaches proposed for these applications and compare the advantages and disadvantages of these approaches. We also examine some of the enhancements that have been proposed in overlay topology design, enhanced routing performance, failure resistance, and the issues related to coexistence of overlay and native layers in the Internet. We conclude the article with a comment on the purist vs pluralist argument of overlay networks that has received much debate recently. Finally, we propose a new deployment model for service overlays that seeks to interpose between these two approaches.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {5},
numpages = {34},
keywords = {service overlay networks, enhancements, performance, deployment model, Overlay networks}
}

@inproceedings{10.5555/2433508.2433861,
author = {Bouillet, Eric and Dube, Parijat},
title = {Streaming Workload Generator for Testing Billing Mediation Platform in Telecom Industry},
year = {2010},
isbn = {9781424498642},
publisher = {Winter Simulation Conference},
abstract = {Billing Mediation Platform (BMP) in Telco is used to process real-time streams of Call Detail Records (CDRs) which can number tens of billions a day. The comprehensive records generated by BMPs can be used for billing and accounting, fraud detection, campaign management, spam filtering, traffic analysis, and churn prediction. Many of these applications are characterized by real-time processing requiring high throughput, low-latency analysis of CDRs. Testing such BMPs has different dimensions, stress testing of analytics for scalability, correctness of analytics, what-if scenarios, all of which require CDRs with realistic volumetric and contextual properties. We propose WLG, a framework for testing and benchmarking BMPs which involves generating high volumes of CDRs representative of real-world data. The framework is flexible in its ability to express and tune the workload generation to simulate CDRs from broad range of traffic patterns while preserving different spatio-temporal correlations and content-level information observed in real-world CDRs.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2842–2852},
numpages = {11},
location = {Baltimore, Maryland},
series = {WSC '10}
}

@inproceedings{10.5555/2433508.2433540,
author = {van der Zee, Durk-Jouke and Pidd, Mike and Tolk, Andreas and Kotiadis, Kathy and Tako, Antuela A. and Balci, Osman and Elder, Mark},
title = {Panel Discussion: Education on Conceptual Modeling for Simulation - Challenging the Art},
year = {2010},
isbn = {9781424498642},
publisher = {Winter Simulation Conference},
abstract = {This panel seeks to initiate a discussion within the modeling and simulation community about the way we teach conceptual modeling for simulation with the view of bringing about improvements. The challenge addressed is how to educate and equip the novice analyst to become a professional rather than letting him become an artist -- being very much the current practice. The need for professionalism is related to good quality research and education in a straightforward way. Emerging insights from literature on the relevance of conceptual modeling for project success, increasing system complexity, and stakeholders taking up an active role in conceptual modeling, further stress this need. This paper highlights key observations motivating the panel, and presents "position papers" on panelists' views on the way forward for education in conceptual modeling. The paper concludes with some themes from the viewpoints in the format of a SWOT (Strengths, Weaknesses, Opportunities and Threats) analysis.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {290–304},
numpages = {15},
location = {Baltimore, Maryland},
series = {WSC '10}
}

@inproceedings{10.5555/2433508.2433870,
author = {Juan, Angel A. and Marqu\`{e}s, Joan M. and Ionescu, Dragos and Faulin, Javier},
title = {Reliability and Availability Issues in Large-Scale Distributed Systems},
year = {2010},
isbn = {9781424498642},
publisher = {Winter Simulation Conference},
abstract = {Large-scale distributed systems, such as Overnet, BOINC (SETI@home) or PlanetLab, provide attractive options through aggregation and sharing of heterogeneous and geographically dispersed computer resources. However, in order to be efficient, these systems need to consider some issues related to the Reliability and Availability (R&amp;A) levels of their nodes and the services they offer. These systems are usually characterized by extremely dynamic and heterogeneous environments, where nodes offering different computer capabilities and features can enter and leave freely. But dynamism and heterogeneity introduce uncertainty and make it difficult to develop accurate models to predict the temporal evolution of the R&amp;A levels in distributed environments. This paper reviews some R&amp;A issues in large-scale distributed systems and studies how they relate to the quality of service offered to the users. The paper also discusses the role of simulation as the most natural way to deal with these issues and introduces a simulation-based methodology that allows to design reliable and cost-efficient distributed services.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2915–2926},
numpages = {12},
location = {Baltimore, Maryland},
series = {WSC '10}
}

@inproceedings{10.1145/1920320.1920323,
author = {Anderson, Nick and Edwards, Kelly},
title = {Building a Chain of Trust: Using Policy and Practice to Enhance Trustworthy Clinical Data Discovery and Sharing},
year = {2010},
isbn = {9781450304467},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1920320.1920323},
doi = {10.1145/1920320.1920323},
abstract = {Advances and significant national infrastructure investment into clinical information systems are spurring a demand for secondary use and sharing of clinical and genetic data for translational research. In this paper, we describe the need for technically leveraged policy models and governance strategies to support data sharing between a range of disparate stakeholders where trust is not easily established or maintained.},
booktitle = {Proceedings of the 2010 Workshop on Governance of Technology, Information and Policies},
pages = {15–20},
numpages = {6},
keywords = {trust, clinical data, data sharing, compliance with government regulations, translational health research, policy governance},
location = {Austin, Texas, USA},
series = {GTIP '10}
}

@article{10.1145/1899928.1899946,
author = {Simons, Joshua E. and Buell, Jeffrey},
title = {Virtualizing High Performance Computing},
year = {2010},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {4},
issn = {0163-5980},
url = {https://doi.org/10.1145/1899928.1899946},
doi = {10.1145/1899928.1899946},
abstract = {While virtualization is widely used in commercial enterprise environments, it has not to date played any significant role in High Performance Computing (HPC). However, with the rise of cloud computing and its promise of computing on demand, the HPC community's interest in virtualization (a key cloud enabler) is increasing. Beyond cloud computing, virtualization offers additional potential benefits for HPC, among them reactive and proactive application fault tolerance, secure and fault-isolated use of shared-resource clusters, dynamic provisioning, job migration, and support for heterogeneous HPC facilities. This paper describes both the promises and challenges in this new, emerging area, including a discussion of performance-related issues},
journal = {SIGOPS Oper. Syst. Rev.},
month = dec,
pages = {136–145},
numpages = {10},
keywords = {resilience, virtualization, HPC, cloud computing}
}

@inproceedings{10.1145/2369220.2369254,
author = {Rao, Kasina V. and Ramamritham, Krithi and Sonar, R. M.},
title = {Examining the Viability of Mixed Framework for Evaluating Mobile Services Impact in Rural India},
year = {2010},
isbn = {9781450307871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2369220.2369254},
doi = {10.1145/2369220.2369254},
abstract = {This paper examines the proposed framework for evaluating the impact of the intervention of mobile-based services on socio-economic development of Indian rural areas. Framework suitability has been studied using case study method with pilot test data. Existing literature shows multiple ways of studying mobile impact through different frameworks. The need for uniform framework is the felt need as various user-centric mobile services launched across rural markets. India becomes a field-testing ground for most of the multinational firms who want to test their innovative business models. This framework provides a testing method for socioeconomic development impact on rural areas. This study adopted socio economic criteria (SEC) used by Indian marketers as basis for sample selection. The pilot study clearly shown that field is ready to test the proposed framework.},
booktitle = {Proceedings of the 4th ACM/IEEE International Conference on Information and Communication Technologies and Development},
articleno = {36},
numpages = {10},
keywords = {socio-economic impact, socio-economic criteria, mobile services, user needs},
location = {London, United Kingdom},
series = {ICTD '10}
}

@inproceedings{10.1145/1900520.1900525,
author = {Marcus, Aaron},
title = {Cross-Cultural User-Interface Design for Work, Home, Play, and on the Way},
year = {2010},
isbn = {9781450305273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1900520.1900525},
doi = {10.1145/1900520.1900525},
booktitle = {ACM SIGGRAPH ASIA 2010 Courses},
articleno = {5},
numpages = {160},
location = {Seoul, Republic of Korea},
series = {SA '10}
}

@inproceedings{10.1145/1900354.1900417,
author = {Koutepova, Tatyana and Liu, Yantong and Lan, Xiao and Jeong, Jihyun},
title = {Enhancing Video Games in Real Time with Biofeedback Data},
year = {2010},
isbn = {9781450305242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1900354.1900417},
doi = {10.1145/1900354.1900417},
abstract = {All video games have the ability to affect a player and the result can be seen in changes of his or her heart rate, perspiration, focus or concentration. This change is a large part of what draws a person to play a game in the first place but overtime players body starts to adjust to the stimuli in the game thus decreasing the interest. What if the game could continuously adjust to players biofeedback and keep the engagement and excitement levels high longer?},
booktitle = {ACM SIGGRAPH ASIA 2010 Posters},
articleno = {56},
numpages = {1},
location = {Seoul, Republic of Korea},
series = {SA '10}
}

@inproceedings{10.1145/1926180.1926203,
author = {Quinn, John A. and Okori, Washington and Gidudu, Anthony},
title = {Increased-Specificity Famine Prediction Using Satellite Observation Data},
year = {2010},
isbn = {9781450304733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1926180.1926203},
doi = {10.1145/1926180.1926203},
abstract = {This paper examines the use of remote sensing satellite data to predict food shortages among different categories of households in famine-prone areas. Normalized Difference Vegetation Index (NDVI) and rainfall estimate data, which can be derived from multi-spectral satellite radiometer images, has long been used to predict crop yields and hence famine. This gives an overall prediction of food insecurity in an area, though in a heterogeneous population it does not directly predict which sectors of society or households are most at risk.In this work we use information on 3094 households across Uganda collected between 2004--2005. We describe a method for clustering households in such a way that the cluster decision boundaries are both relevant for improved-specificity famine prediction and are easily communicated. We then give classification results for predicting food security status at a household level given different combinations of satellite data, demographic data, and household category indices found by our clustering method. The food security classification performance of this model demonstrates the potential of this approach for making predictions of famine for specific areas and demographic groups.},
booktitle = {Proceedings of the First ACM Symposium on Computing for Development},
articleno = {18},
numpages = {6},
location = {London, United Kingdom},
series = {ACM DEV '10}
}

@article{10.1145/1870085.1870089,
author = {Song, Yang and Fang, Yuguang},
title = {Cross-Layer Interactions in Multihop Wireless Sensor Networks: A Constrained Queueing Model},
year = {2010},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1049-3301},
url = {https://doi.org/10.1145/1870085.1870089},
doi = {10.1145/1870085.1870089},
abstract = {In this article, we propose a constrained queueing model to investigate the performance of multihop wireless sensor networks. Specifically, the cross-layer interactions of rate admission control, traffic engineering, dynamic routing, and adaptive link scheduling are studied jointly with the proposed queueing model. In addition, the stochastic network utility maximization problem in wireless sensor networks is addressed within this framework. We propose an adaptive network resource allocation scheme, called the ANRA algorithm, which provides a joint solution to the multiple-layer components of the stochastic network utility maximization problem. We show that the proposed ANRA algorithm achieves a near-optimal solution, that is, (1-ϵ) of the global optimum network utility where ϵ can be arbitrarily small, with a trade-off with the average delay experienced in the network. The proposed ANRA algorithm enjoys the merit of self-adaptability through its online nature and thus is of particular interest for time-varying scenarios such as multihop wireless sensor networks.},
journal = {ACM Trans. Model. Comput. Simul.},
month = dec,
articleno = {4},
numpages = {26},
keywords = {stochastic utility maximization, Cross-layer design, stochastic network optimization, online algorithms}
}

@article{10.1145/1877766.1877772,
author = {Choudhury, Munmun De and Sundaram, Hari and John, Ajita and Seligmann, Doree Duncan},
title = {Extraction, Characterization and Utility of Prototypical Communication Groups in the Blogosphere},
year = {2011},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/1877766.1877772},
doi = {10.1145/1877766.1877772},
abstract = {This article analyzes communication within a set of individuals to extract the representative prototypical groups and provides a novel framework to establish the utility of such groups. Corporations may want to identify representative groups (which are indicative of the overall communication set) because it is easier to track the prototypical groups rather than the entire set. This can be useful for advertising, identifying “hot” spots of resource consumption as well as in mining representative moods or temperature of a community. Our framework has three parts: extraction, characterization, and utility of prototypical groups. First, we extract groups by developing features representing communication dynamics of the individuals. Second, to characterize the overall communication set, we identify a subset of groups within the community as the prototypical groups. Third, we justify the utility of these prototypical groups by using them as predictors of related external phenomena; specifically, stock market movement of technology companies and political polls of Presidential candidates in the 2008 U.S. elections.We have conducted extensive experiments on two popular blogs, Engadget and Huffington Post. We observe that the prototypical groups can predict stock market movement/political polls satisfactorily with mean error rate of 20.32%. Further, our method outperforms baseline methods based on alternative group extraction and prototypical group identification methods. We evaluate the quality of the extracted groups based on their conductance and coverage measures and develop metrics: predictivity and resilience to evaluate their ability to predict a related external time-series variable (stock market movement/political polls). This implies that communication dynamics of individuals are essential in extracting groups in a community, and the prototypical groups extracted by our method are meaningful in characterizing the overall communication sets.},
journal = {ACM Trans. Inf. Syst.},
month = dec,
articleno = {6},
numpages = {53},
keywords = {Blogosphere, Huffington Post, social communication, political polls, social network analysis, Engadget, prototypical groups, stock market movement, communication dynamics}
}

@article{10.1145/1866739.1866755,
author = {Haber, Eben M. and Kandogan, Eser and Maglio, Paul P.},
title = {Collaboration in System Administration},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0001-0782},
url = {https://doi.org/10.1145/1866739.1866755},
doi = {10.1145/1866739.1866755},
abstract = {For sysadmins, solving problems usually involves collaborating with others. How can we make it more effective?},
journal = {Commun. ACM},
month = jan,
pages = {46–53},
numpages = {8}
}

@article{10.1145/1925019.1925023,
author = {Shepard, Clayton and Rahmati, Ahmad and Tossell, Chad and Zhong, Lin and Kortum, Phillip},
title = {LiveLab: Measuring Wireless Networks and Smartphone Users in the Field},
year = {2011},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {3},
issn = {0163-5999},
url = {https://doi.org/10.1145/1925019.1925023},
doi = {10.1145/1925019.1925023},
abstract = {We present LiveLab, a methodology to measure real-world smartphone usage and wireless networks with a reprogrammable indevice logger designed for long-term user studies. We discuss the challenges of privacy protection and power impact in LiveLab and offer our solutions. We present an iPhone 3GS based deployment of LiveLab with 25 users intended for one year. Early results from the data collection so far highlight the unique strengths and potential of LiveLab. We have two objectives in this position paper. First, we demonstrate the feasibility and capability of LiveLab. By sharing our experience, we seek to advocate LiveLab as a network and user measurement methodology. Second, we present our preliminary findings, and seek feedback from the community regarding what data to collect.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = jan,
pages = {15–20},
numpages = {6}
}

@inproceedings{10.5555/2002669.2002694,
author = {Petukhova, Volha and Bunt, Harry},
title = {Incremental Dialogue Act Understanding},
year = {2011},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {This paper presents a machine learning-based approach to the incremental understanding of dialogue utterances, with a focus on the recognition of their communicative functions. A token-based approach combining the use of local classifiers, which exploit local utterance features, and global classifiers which use the outputs of local classifiers applied to previous and subsequent tokens, is shown to result in excellent dialogue act recognition scores for unsegmented spoken dialogue. This can be seen as a significant step forward towards the development of fully incremental, on-line methods for computing the meaning of utterances in spoken dialogue.},
booktitle = {Proceedings of the Ninth International Conference on Computational Semantics},
pages = {235–244},
numpages = {10},
location = {Oxford, United Kingdom},
series = {IWCS '11}
}

@inproceedings{10.5555/2459296.2459302,
author = {Huda, Shamsul and Yearwood, John and Stranieri, Andrew},
title = {Hybrid Wrapper-Filter Approaches for Input Feature Selection Using Maximum Relevance-Minimum Redundancy and Artificial Neural Network Input Gain Measurement Approximation (ANNIGMA)},
year = {2011},
isbn = {9781920682934},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Feature selection processes improve the accuracy, computational efficiency and scalability of classification process in data mining applications. This paper proposes two filter and wrapper hybrid approaches for feature selection techniques by combining the filter's feature ranking score in the wrapper stage. The first approach hybridizes a Mutual Information (MI) based Maximum Relevance (MR) filter ranking heuristic with an Artificial Neural Network (ANN) based wrapper approach where Artificial Neural Network Input Gain Measurement Approximation (ANNIGMA) has been combined with MR (MR-ANNIGMA) to guide the search process in the wrapper. The second hybrid combines an improved version of MI based (Maximum Relevance and Minimum Redundancy; MaxRel-MinRed) filter ranking heuristic with the wrapper heuristic ANNIGMA (MaxRel-MinRed-ANNIGMA). The novelty of our approach is that we integrate the capability of wrapper approach to find better feature subset by combining filter's ranking score with the wrapper-heuristic's score that take advantages of both filter and wrapper heuristics. The performances of the hybrid approaches have been verified using synthetic, bench mark data sets and real life data set and compared to both independent filter and wrapper based approaches. Experimental results show that hybrid approaches (MR-ANNIGMA and MaxRel-MinRed-ANNIGMA) achieve more compact feature sets and higher accuracies than filter and wrapper approaches alone.},
booktitle = {Proceedings of the Thirty-Fourth Australasian Computer Science Conference - Volume 113},
pages = {43–52},
numpages = {10},
keywords = {maximum-relevance and minimum redundancy, wrapper, hybrid feature selection, ANNIGMA wrapper, filter maximum-relevance},
location = {Perth, Australia},
series = {ACSC '11}
}

@inproceedings{10.5555/2459936.2459953,
author = {Devey, Adrian and Carbone, Angela},
title = {Helping First Year Novice Programming Students PASS},
year = {2011},
isbn = {9781920682941},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {In this paper, we report the results of introducing a face-to-face Peer Assisted Study Scheme (PASS) and an electronic Peer Assisted Study Scheme (ePASS) into a first year introductory programming unit, core to four undergraduate IT degrees. PASS is a program of supplementary instruction through which successful senior students facilitate weekly face-to-face study sessions in targeted key first year units. Sessions are open to all students enrolled in the target units and participation in PASS is voluntary. ePASS is a discussion board monitored by PASS Leaders. Results show that although attendance at face-to-face sessions is less than 25%, the students that attended found the sessions very useful. Of those that participated in PASS, over 40% attended to help them achieve an excellent grade, and not purely to obtain a pass grade It was therefore not surprising that the proportion of regular PASS attendees who failed the target unit was much lower than in the unit overall, while the proportion of regular PASS attendees achieving Distinctions and High Distinctions was higher. ePASS did not meet our objectives either in terms of the volume or nature of use.},
booktitle = {Proceedings of the Thirteenth Australasian Computing Education Conference - Volume 114},
pages = {135–144},
numpages = {10},
keywords = {first year programming, peer assisted study},
location = {Perth, Australia},
series = {ACE '11}
}

@inproceedings{10.5555/2460416.2460425,
author = {Campbell, Scott and Chan, Stephen and Lee, Jason R.},
title = {Detection of Fast Flux Service Networks},
year = {2011},
isbn = {9781920682965},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Fast Flux Service Networks (FFSN) apply high availability server techniques to the business of malware distribution. FFSNs are similar to commercial content distribution networks (CDN), such as Akamai, in terms of size, scope, and business model, serving as an outsourced content delivery service for clients. Using an analysis of DNS traffic, we derive a sequential hypothesis-testing algorithm based entirely on traffic characteristics and dynamic white listing to provide real time detection of FFSNs in live traffic. We improve on existing work, providing faster and more accurate detection of FFSNs. We also investigate a category of hosts not fully explored in previous detectors - Open Content Distribution Networks (OCDN) that share many of the characteristics of FFSNs.},
booktitle = {Proceedings of the Ninth Australasian Information Security Conference - Volume 116},
pages = {57–66},
numpages = {10},
keywords = {DNS, fast flux, CDN},
location = {Perth, Australia},
series = {AISC '11}
}

@article{10.1145/1925861.1925879,
author = {Keshav, Srinivasan and Rosenberg, Catherine},
title = {How Internet Concepts and Technologies Can Help Green and Smarten the Electrical Grid},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0146-4833},
url = {https://doi.org/10.1145/1925861.1925879},
doi = {10.1145/1925861.1925879},
abstract = {Several powerful forces are gathering to make fundamental and irrevocable changes to the century-old grid. The next-generation grid, often called the 'smart grid,' will feature distributed energy production, vastly more storage, tens of millions of stochastic renewable-energy sources, and the use of communication technologies both to allow precise matching of supply to demand and to incentivize appropriate consumer behaviour. These changes will have the effect of reducing energy waste and reducing the carbon footprint of the grid, making it 'smarter' and 'greener.' In this position paper, we discuss how the concepts and techniques pioneered by the Internet, the fruit of four decades of research in this area, are directly applicable to the design of a smart, green grid. This is because both the Internet and the electrical grid are designed to meet fundamental needs, for information and for energy, respectively, by connecting geographically dispersed suppliers with geographically dispersed consumers. Keeping this and other similarities (and fundamental differences, as well) in mind, we propose several specific areas where Internet concepts and technologies can contribute to the development of a smart, green grid. We also describe some areas where the Internet operations can be improved based on the experience gained in the electrical grid. We hope that our work will initiate a dialogue between the Internet and the smart grid communities.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = jan,
pages = {109–114},
numpages = {6},
keywords = {electrical grid, green networking}
}

@article{10.1145/1925861.1925878,
author = {Krioukov, Andrew and Mohan, Prashanth and Alspaugh, Sara and Keys, Laura and Culler, David and Katz, Randy},
title = {NapSAC: Design and Implementation of a Power-Proportional Web Cluster},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0146-4833},
url = {https://doi.org/10.1145/1925861.1925878},
doi = {10.1145/1925861.1925878},
abstract = {Energy consumption is a major and costly problem in data centers. A large fraction of this energy goes to powering idle machines that are not doing any useful work. We identify two causes of this inefficiency: low server utilization and a lack of power-proportionality. To address this problem we present a design for an power-proportional cluster consisting of a power-aware cluster manager and a set of heterogeneous machines. Our design makes use of currently available energy-efficient hardware, mechanisms for transitioning in and out of low-power sleep states, and dynamic provisioning and scheduling to continually adjust to workload and minimize power consumption. With our design we are able to reduce energy consumption while maintaining acceptable response times for a web service workload based on Wikipedia. With our dynamic provisioning algorithms we demonstrate via simulation a 63% savings in power usage in a typically provisioned datacenter where all machines are left on and awake at all times. Our results show that we are able to achieve close to 90% of the savings a theoretically optimal provisioning scheme would achieve. We have also built a prototype cluster which runs Wikipedia to demonstrate the use of our design in a real environment.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = jan,
pages = {102–108},
numpages = {7},
keywords = {data center, power proportional, web application, heterogenous hardware, power management, energy, cluster, web server}
}

@inproceedings{10.5555/2133036.2133044,
author = {Im, Sungjin and Moseley, Benjamin},
title = {An Online Scalable Algorithm for Minimizing <i>l</i><sub><i>k</i></sub>-Norms of Weighted Flow Time on Unrelated Machines},
year = {2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
abstract = {We consider the problem of scheduling jobs that arrive online in the unrelated machine model to minimize lk norms of weighted flowtime. In the unrelated setting, the processing time and weight of a job depends on the machine it is assigned to, and it is perhaps the most general machine model considered in scheduling literature. Chadha et al. [10] obtained a recent breakthrough result in obtaining the first non-trivial algorithm for minimizing weighted flowtime (that is, the l1 norm) in this very general setting via a novel potential function based analysis. They described a simple algorithm and showed that for any ε &gt; 0 it is (1 + ε)-speed O(1/ε2)-competitive (a scalable algorithm).In this paper we give the first non-trivial and scalable algorithm for minimizing lk norms of weighted flowtime in the unrelated machine model; for any ε &gt; 0, the algorithm is O(k/ε2+2/k)-competitive. The algorithm is immediate-dispatch and non-migratory. Our result is of both practical and theoretical interest. Scheduling to minimize lk norms of flowtime for some small k &gt; 1 has been shown to balance total response time and fairness, which is desirable in practice. On the theoretical side, lk norms for k &gt; 1 pose substantial technical hurdles when compared to when k = 1 even for the single machine case. Our work develops a novel potential function as well as several tools that can be used to lower bound the optimal solution.},
booktitle = {Proceedings of the Twenty-Second Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {95–108},
numpages = {14},
location = {San Francisco, California},
series = {SODA '11}
}

@article{10.1145/1889681.1889687,
author = {Ward, Jamie A. and Lukowicz, Paul and Gellersen, Hans W.},
title = {Performance Metrics for Activity Recognition},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/1889681.1889687},
doi = {10.1145/1889681.1889687},
abstract = {In this article, we introduce and evaluate a comprehensive set of performance metrics and visualisations for continuous activity recognition (AR). We demonstrate how standard evaluation methods, often borrowed from related pattern recognition problems, fail to capture common artefacts found in continuous AR—specifically event fragmentation, event merging and timing offsets. We support our assertion with an analysis on a set of recently published AR papers. Building on an earlier initial work on the topic, we develop a frame-based visualisation and corresponding set of class-skew invariant metrics for the one class versus all evaluation. These are complemented by a new complete set of event-based metrics that allow a quick graphical representation of system performance—showing events that are correct, inserted, deleted, fragmented, merged and those which are both fragmented and merged. We evaluate the utility of our approach through comparison with standard metrics on data from three different published experiments. This shows that where event- and frame-based precision and recall lead to an ambiguous interpretation of results in some cases, the proposed metrics provide a consistently unambiguous explanation.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
articleno = {6},
numpages = {23},
keywords = {metrics, performance evaluation, Activity recognition}
}

@article{10.1145/1889681.1889689,
author = {Bao, Xinlong and Dietterich, Thomas G.},
title = {FolderPredictor: Reducing the Cost of Reaching the Right Folder},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/1889681.1889689},
doi = {10.1145/1889681.1889689},
abstract = {Helping computer users rapidly locate files in their folder hierarchies is a practical research problem involving both intelligent systems and user interface design. This article reports on FolderPredictor, a software system that can reduce the cost of locating files in hierarchical folders. FolderPredictor applies a cost-sensitive prediction algorithm to the user's previous file access information to predict the next folder that will be accessed. Experimental results show that, on average, FolderPredictor reduces the number of clicks spent on locating a file by 50%. Several variations of the cost-sensitive prediction algorithm are discussed. An experimental study shows that the best algorithm among them is a mixture of the most recently used (MRU) folder and the cost-sensitive predictions. Furthermore, FolderPredictor does not require users to adapt to a new interface, but rather meshes with the existing interface for opening files on the Windows platform.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
articleno = {8},
numpages = {23},
keywords = {prediction, intelligent systems, shortcuts, intelligent user interfaces, folders, recommendation, tasks, user interface, directories, Activities}
}

@inproceedings{10.1145/1926385.1926405,
author = {Prountzos, Dimitrios and Manevich, Roman and Pingali, Keshav and McKinley, Kathryn S.},
title = {A Shape Analysis for Optimizing Parallel Graph Programs},
year = {2011},
isbn = {9781450304900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1926385.1926405},
doi = {10.1145/1926385.1926405},
abstract = {Computations on unstructured graphs are challenging to parallelize because dependences in the underlying algorithms are usually complex functions of runtime data values, thwarting static parallelization. One promising general-purpose parallelization strategy for these algorithms is optimistic parallelization.This paper identifies the optimization of optimistically parallelized graph programs as a new application area, and develops the first shape analysis for addressing this problem. Our shape analysis identifies failsafe points in the program after which the execution is guaranteed not to abort and backup copies of modified data are not needed; additionally, the analysis can be used to eliminate redundant conflict checking. It uses two key ideas: a novel top-down heap abstraction that controls state space explosion, and a strategy for predicate discovery that exploits common patterns of data structure usage.We implemented the shape analysis in TVLA, and used it to optimize benchmarks from the Lonestar suite. The optimized programs were executed on the Galois system. The analysis was successful in eliminating all costs related to rollback logging for our benchmarks. Additionally, it reduced the number of lock acquisitions by a factor ranging from 10x to 50x, depending on the application and the number of threads. These optimizations were effective in reducing the running times of the benchmarks by factors of 2x to 12x.},
booktitle = {Proceedings of the 38th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {159–172},
numpages = {14},
keywords = {optimistic parallelization, amorphous data-parallelism, parallelism, shape analysis, static analysis, cautious operators, abstract interpretation, compiler optimization, synchronization overheads, irregular programs, concurrency},
location = {Austin, Texas, USA},
series = {POPL '11}
}

@article{10.1145/1925844.1926405,
author = {Prountzos, Dimitrios and Manevich, Roman and Pingali, Keshav and McKinley, Kathryn S.},
title = {A Shape Analysis for Optimizing Parallel Graph Programs},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0362-1340},
url = {https://doi.org/10.1145/1925844.1926405},
doi = {10.1145/1925844.1926405},
abstract = {Computations on unstructured graphs are challenging to parallelize because dependences in the underlying algorithms are usually complex functions of runtime data values, thwarting static parallelization. One promising general-purpose parallelization strategy for these algorithms is optimistic parallelization.This paper identifies the optimization of optimistically parallelized graph programs as a new application area, and develops the first shape analysis for addressing this problem. Our shape analysis identifies failsafe points in the program after which the execution is guaranteed not to abort and backup copies of modified data are not needed; additionally, the analysis can be used to eliminate redundant conflict checking. It uses two key ideas: a novel top-down heap abstraction that controls state space explosion, and a strategy for predicate discovery that exploits common patterns of data structure usage.We implemented the shape analysis in TVLA, and used it to optimize benchmarks from the Lonestar suite. The optimized programs were executed on the Galois system. The analysis was successful in eliminating all costs related to rollback logging for our benchmarks. Additionally, it reduced the number of lock acquisitions by a factor ranging from 10x to 50x, depending on the application and the number of threads. These optimizations were effective in reducing the running times of the benchmarks by factors of 2x to 12x.},
journal = {SIGPLAN Not.},
month = jan,
pages = {159–172},
numpages = {14},
keywords = {parallelism, synchronization overheads, irregular programs, compiler optimization, optimistic parallelization, amorphous data-parallelism, concurrency, shape analysis, abstract interpretation, cautious operators, static analysis}
}

@article{10.14778/1952376.1952382,
author = {Cao, Zhao and Sutton, Charles and Diao, Yanlei and Shenoy, Prashant},
title = {Distributed Inference and Query Processing for RFID Tracking and Monitoring},
year = {2011},
issue_date = {February 2011},
publisher = {VLDB Endowment},
volume = {4},
number = {5},
issn = {2150-8097},
url = {https://doi.org/10.14778/1952376.1952382},
doi = {10.14778/1952376.1952382},
abstract = {In this paper, we present the design of a scalable, distributed stream processing system for RFID tracking and monitoring. Since RFID data lacks containment and location information that is key to query processing, we propose to combine location and containment inference with stream query processing in a single architecture, with inference as an enabling mechanism for high-level query processing. We further consider challenges in instantiating such a system in large distributed settings and design techniques for distributed inference and query processing. Our experimental results, using both real-world data and large synthetic traces, demonstrate the accuracy, efficiency, and scalability of our proposed techniques.},
journal = {Proc. VLDB Endow.},
month = feb,
pages = {326–337},
numpages = {12}
}

