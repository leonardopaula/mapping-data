@article{10.1145/1921632.1921634,
author = {Kang, U. and Tsourakakis, Charalampos E. and Appel, Ana Paula and Faloutsos, Christos and Leskovec, Jure},
title = {HADI: Mining Radii of Large Graphs},
year = {2011},
issue_date = {February 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {2},
issn = {1556-4681},
url = {https://doi.org/10.1145/1921632.1921634},
doi = {10.1145/1921632.1921634},
abstract = {Given large, multimillion-node graphs (e.g., Facebook, Web-crawls, etc.), how do they evolve over time? How are they connected? What are the central nodes and the outliers? In this article we define the Radius plot of a graph and show how it can answer these questions. However, computing the Radius plot is prohibitively expensive for graphs reaching the planetary scale.There are two major contributions in this article: (a) We propose HADI (HAdoop DIameter and radii estimator), a carefully designed and fine-tuned algorithm to compute the radii and the diameter of massive graphs, that runs on the top of the Hadoop/MapReduce system, with excellent scale-up on the number of available machines (b) We run HADI on several real world datasets including YahooWeb (6B edges, 1/8 of a Terabyte), one of the largest public graphs ever analyzed.Thanks to HADI, we report fascinating patterns on large networks, like the surprisingly small effective diameter, the multimodal/bimodal shape of the Radius plot, and its palindrome motion over time.},
journal = {ACM Trans. Knowl. Discov. Data},
month = feb,
articleno = {8},
numpages = {24},
keywords = {Radius plot, graph mining, HADI, hadoop, small web}
}

@article{10.1145/1897816.1897838,
author = {Wachs, Juan Pablo and K\"{o}lsch, Mathias and Stern, Helman and Edan, Yael},
title = {Vision-Based Hand-Gesture Applications},
year = {2011},
issue_date = {February 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/1897816.1897838},
doi = {10.1145/1897816.1897838},
abstract = {Body posture and finger pointing are a natural modality for human-machine interaction, but first the system must know what it's seeing.},
journal = {Commun. ACM},
month = feb,
pages = {60–71},
numpages = {12}
}

@article{10.1145/1925109.1925111,
author = {Lagar-Cavilla, H. Andr\'{e}s and Whitney, Joseph A. and Bryant, Roy and Patchin, Philip and Brudno, Michael and de Lara, Eyal and Rumble, Stephen M. and Satyanarayanan, M. and Scannell, Adin},
title = {SnowFlock: Virtual Machine Cloning as a First-Class Cloud Primitive},
year = {2011},
issue_date = {February 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {1},
issn = {0734-2071},
url = {https://doi.org/10.1145/1925109.1925111},
doi = {10.1145/1925109.1925111},
abstract = {A basic building block of cloud computing is virtualization. Virtual machines (VMs) encapsulate a user’s computing environment and efficiently isolate it from that of other users. VMs, however, are large entities, and no clear APIs exist yet to provide users with programatic, fine-grained control on short time scales.We present SnowFlock, a paradigm and system for cloud computing that introduces VM cloning as a first-class cloud abstraction. VM cloning exploits the well-understood and effective semantics of UNIX fork. We demonstrate multiple usage models of VM cloning: users can incorporate the primitive in their code, can wrap around existing toolchains via scripting, can encapsulate the API within a parallel programming framework, or can use it to load-balance and self-scale clustered servers.VM cloning needs to be efficient to be usable. It must efficiently transmit VM state in order to avoid cloud I/O bottlenecks. We demonstrate how the semantics of cloning aid us in realizing its efficiency: state is propagated in parallel to multiple VM clones, and is transmitted during runtime, allowing for optimizations that substantially reduce the I/O load. We show detailed microbenchmark results highlighting the efficiency of our optimizations, and macrobenchmark numbers demonstrating the effectiveness of the different usage models of SnowFlock.},
journal = {ACM Trans. Comput. Syst.},
month = feb,
articleno = {2},
numpages = {45},
keywords = {Virtualization, cloud computing}
}

@inproceedings{10.1145/1940761.1940792,
author = {Lopatovska, Irene},
title = {Researching Emotion: Challenges and Solutions},
year = {2011},
isbn = {9781450301213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1940761.1940792},
doi = {10.1145/1940761.1940792},
abstract = {Interest in emotions within the information use context is on the rise. Yet, the reports of the emotion studies rarely mention some of the methodological challenges involved in research. New researchers who are entering the field are often unaware of the challenges and potential solutions related to emotions' examinations. This paper attempts to educate researchers about some of the methodological options that are available at various stages of emotion study, including selection of theory and methods, data collection and analysis, extraction of meaning from data, and application of the findings to the real life problems. The paper offers recommendations for handling some of the challenges that might arise during a project.},
booktitle = {Proceedings of the 2011 IConference},
pages = {225–229},
numpages = {5},
keywords = {information use, measurement, affect, emotion, research methodology, information retrieval, information behavior},
location = {Seattle, Washington, USA},
series = {iConference '11}
}

@article{10.1145/1942776.1942782,
author = {Ahmad, Yanif and Burns, Randal and Kazhdan, Michael and Meneveau, Charles and Szalay, Alex and Terzis, Andreas},
title = {Scientific Data Management at the Johns Hopkins Institute for Data Intensive Engineering and Science},
year = {2011},
issue_date = {September 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {3},
issn = {0163-5808},
url = {https://doi.org/10.1145/1942776.1942782},
doi = {10.1145/1942776.1942782},
journal = {SIGMOD Rec.},
month = feb,
pages = {18–23},
numpages = {6}
}

@inproceedings{10.1145/1940761.1940924,
author = {Heverin, Thomas},
title = {Microblogging for Distributed Surveillance in Response to Violent Crises: Ethical Considerations},
year = {2011},
isbn = {9781450301213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1940761.1940924},
doi = {10.1145/1940761.1940924},
abstract = {The increased use of social media technologies over the past few years has altered the communication and information sharing activities surrounding crises. Local and non-local citizens can now create and distribute their own crisis-related information to a wide audience bypassing official communication channels. The purpose of our research is to identify patterns in citizen communications transmitted over Twitter and to identify ethical considerations of citizen participation through Twitter in response to violent crises. In a preliminary study, we examined the patterns of Twitter communications sent in response to a 2009 violent attack in the U.S. and found that the majority of communications contained information sharing content focused on the suspect and law enforcement activity. We also examined ethical considerations of the Twitter communications and found four main categories of behaviors that could potentially lead to more violence or harm to others including disseminating misinformation, promoting vigilante justice, conducting virtual attacks on fellow participants, and sharing real-time information on law enforcement locations. Data for four other U.S. 2009--2010 attacks have been collected and a more in depth analysis is in progress.},
booktitle = {Proceedings of the 2011 IConference},
pages = {827–828},
numpages = {2},
keywords = {crisis informatics, surveillance, microblogging},
location = {Seattle, Washington, USA},
series = {iConference '11}
}

@inproceedings{10.1145/1940761.1940799,
author = {Xie, Bo and Wang, Mo and Feldman, Robert},
title = {Preferences for Health Information and Decision-Making: Development of the Health Information Wants (HIW) Questionnaire},
year = {2011},
isbn = {9781450301213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1940761.1940799},
doi = {10.1145/1940761.1940799},
abstract = {The Health Information Wants (HIW) Questionnaire was developed to measure 1) a broad range of the types and amount of each type of information health consumers want to have in dealing with health-related issues; and 2) the degree to which health consumers want to participate in each type of decision-making in each corresponding area. With parallel items in each corresponding area of information and decision-making, this instrument can reveal the relationship between information and decision-making preferences in each area. This paper reports the multi-stage development process of this instrument that lasted for over two years. This process included: 1) a grounded theory-driven exploratory study that identified the core framework; 2) initial item development based on the literature and the exploratory study; 3) content validity testing; 4) cognitive testing; and 5) a pilot study testing the psychometrics of the instrument.},
booktitle = {Proceedings of the 2011 IConference},
pages = {273–280},
numpages = {8},
keywords = {decision-making, instrument development, health information wants (HIW), health information},
location = {Seattle, Washington, USA},
series = {iConference '11}
}

@inproceedings{10.1145/1935826.1935869,
author = {Nakashole, Ndapandula and Theobald, Martin and Weikum, Gerhard},
title = {Scalable Knowledge Harvesting with High Precision and High Recall},
year = {2011},
isbn = {9781450304931},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1935826.1935869},
doi = {10.1145/1935826.1935869},
abstract = {Harvesting relational facts from Web sources has received great attention for automatically constructing large knowledge bases. Stateof-the-art approaches combine pattern-based gathering of fact candidates with constraint-based reasoning. However, they still face major challenges regarding the trade-offs between precision, recall, and scalability. Techniques that scale well are susceptible to noisy patterns that degrade precision, while techniques that employ deep reasoning for high precision cannot cope with Web-scale data.This paper presents a scalable system, called PROSPERA, for high-quality knowledge harvesting. We propose a new notion of ngram-itemsets for richer patterns, and use MaxSat-based constraint reasoning on both the quality of patterns and the validity of fact candidates.We compute pattern-occurrence statistics for two benefits: they serve to prune the hypotheses space and to derive informative weights of clauses for the reasoner. The paper shows how to incorporate these building blocks into a scalable architecture that can parallelize all phases on a Hadoop-based distributed platform. Our experiments with the ClueWeb09 corpus include comparisons to the recent ReadTheWeb experiment. We substantially outperform these prior results in terms of recall, with the same precision, while having low run-times.},
booktitle = {Proceedings of the Fourth ACM International Conference on Web Search and Data Mining},
pages = {227–236},
numpages = {10},
keywords = {information extraction, knowledhe harvesting, scalability},
location = {Hong Kong, China},
series = {WSDM '11}
}

@article{10.1145/1921614.1921617,
author = {Grieser, Karl and Baldwin, Timothy and Bohnert, Fabian and Sonenberg, Liz},
title = {Using Ontological and Document Similarity to Estimate Museum Exhibit Relatedness},
year = {2011},
issue_date = {March 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {1556-4673},
url = {https://doi.org/10.1145/1921614.1921617},
doi = {10.1145/1921614.1921617},
abstract = {Exhibits within cultural heritage collections such as museums and art galleries are arranged by experts with intimate knowledge of the domain, but there may exist connections between individual exhibits that are not evident in this representation. For example, the visitors to such a space may have their own opinions on how exhibits relate to one another. In this article, we explore the possibility of estimating the perceived relatedness of exhibits by museum visitors through a variety of ontological and document similarity-based methods. Specifically, we combine the Wikipedia category hierarchy with lexical similarity measures, and evaluate the correlation with the relatedness judgements of visitors. We compare our measure with simple document similarity calculations, based on either Wikipedia documents or Web pages taken from the Web site for the museum of interest. We also investigate the hypothesis that physical distance in the museum space is a direct representation of the conceptual distance between exhibits. We demonstrate that ontological similarity measures are highly effective at capturing perceived relatedness and that the proposed RACO (Related Article Conceptual Overlap) method is able to achieve results closest to relatedness judgements provided by human annotators compared to existing state-of-the art measures of semantic relatedness.},
journal = {J. Comput. Cult. Herit.},
month = feb,
articleno = {10},
numpages = {20},
keywords = {WordNet, museum exhibit, Wikipedia, document similarity, Ontological similarity}
}

@inproceedings{10.1145/1941553.1941561,
author = {Chafi, Hassan and Sujeeth, Arvind K. and Brown, Kevin J. and Lee, HyoukJoong and Atreya, Anand R. and Olukotun, Kunle},
title = {A Domain-Specific Approach to Heterogeneous Parallelism},
year = {2011},
isbn = {9781450301190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1941553.1941561},
doi = {10.1145/1941553.1941561},
abstract = {Exploiting heterogeneous parallel hardware currently requires mapping application code to multiple disparate programming models. Unfortunately, general-purpose programming models available today can yield high performance but are too low-level to be accessible to the average programmer. We propose leveraging domain-specific languages (DSLs) to map high-level application code to heterogeneous devices. To demonstrate the potential of this approach we present OptiML, a DSL for machine learning. OptiML programs are implicitly parallel and can achieve high performance on heterogeneous hardware with no modification required to the source code. For such a DSL-based approach to be tractable at large scales, better tools are required for DSL authors to simplify language creation and parallelization. To address this concern, we introduce Delite, a system designed specifically for DSLs that is both a framework for creating an implicitly parallel DSL as well as a dynamic runtime providing automated targeting to heterogeneous parallel hardware. We show that OptiML running on Delite achieves single-threaded, parallel, and GPU performance superior to explicitly parallelized MATLAB code in nearly all cases.},
booktitle = {Proceedings of the 16th ACM Symposium on Principles and Practice of Parallel Programming},
pages = {35–46},
numpages = {12},
keywords = {domain-specific languages, runtimes, dynamic optimizations, parallel programming},
location = {San Antonio, TX, USA},
series = {PPoPP '11}
}

@article{10.1145/2038037.1941561,
author = {Chafi, Hassan and Sujeeth, Arvind K. and Brown, Kevin J. and Lee, HyoukJoong and Atreya, Anand R. and Olukotun, Kunle},
title = {A Domain-Specific Approach to Heterogeneous Parallelism},
year = {2011},
issue_date = {August 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {8},
issn = {0362-1340},
url = {https://doi.org/10.1145/2038037.1941561},
doi = {10.1145/2038037.1941561},
abstract = {Exploiting heterogeneous parallel hardware currently requires mapping application code to multiple disparate programming models. Unfortunately, general-purpose programming models available today can yield high performance but are too low-level to be accessible to the average programmer. We propose leveraging domain-specific languages (DSLs) to map high-level application code to heterogeneous devices. To demonstrate the potential of this approach we present OptiML, a DSL for machine learning. OptiML programs are implicitly parallel and can achieve high performance on heterogeneous hardware with no modification required to the source code. For such a DSL-based approach to be tractable at large scales, better tools are required for DSL authors to simplify language creation and parallelization. To address this concern, we introduce Delite, a system designed specifically for DSLs that is both a framework for creating an implicitly parallel DSL as well as a dynamic runtime providing automated targeting to heterogeneous parallel hardware. We show that OptiML running on Delite achieves single-threaded, parallel, and GPU performance superior to explicitly parallelized MATLAB code in nearly all cases.},
journal = {SIGPLAN Not.},
month = feb,
pages = {35–46},
numpages = {12},
keywords = {domain-specific languages, dynamic optimizations, parallel programming, runtimes}
}

@inproceedings{10.1145/1961634.1961636,
author = {Jancsary, Jeremy and Neubarth, Friedrich and Schreitter, Stephanie and Trost, Harald},
title = {Towards a Context-Sensitive Online Newspaper},
year = {2011},
isbn = {9781450306256},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1961634.1961636},
doi = {10.1145/1961634.1961636},
abstract = {We give a detailed account of our experiences in implementing a personalized online newspaper that draws---among other hints---on the context of the user. At the algorithmic core of our framework lies a machine learning model that incorporates numerous features of the eligible articles and the user's current situation. Some of the most important design decisions, however, concern the presentation of suggestions, the collection of explicit and implicit feedback, as well as diversity of the recommendations. We present numerical results obtained during the pilot phase of the project that address a number of these concerns and end with a discussion of open questions and future directions.},
booktitle = {Proceedings of the 2011 Workshop on Context-Awareness in Retrieval and Recommendation},
pages = {2–9},
numpages = {8},
keywords = {online newspaper, user profiling, context-awareness},
location = {Palo Alto, California, USA},
series = {CaRR '11}
}

@article{10.1145/1945023.1945026,
author = {Gupta, Vishakha and Knauerhase, Rob and Schwan, Karsten},
title = {Attaining System Performance Points: Revisiting the End-to-End Argument in System Design for Heterogeneous Many-Core Systems},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5980},
url = {https://doi.org/10.1145/1945023.1945026},
doi = {10.1145/1945023.1945026},
abstract = {Trends indicate a rapid increase in the number of cores on chip, exhibiting various types of performance and functional asymmetries present in hardware to gain scalability with balanced power vs. performance requirements. This poses new challenges in platform resource management, which are further exacerbated by the need for runtime power budgeting and by the increased dynamics in workload behavior observed in consolidated datacenter and cloudcomputing systems. This paper considers the implications of these challenges for the virtualization layer of abstraction, which is the base layer for resource management in such heterogeneous multicore platforms. Specifically, while existing and upcoming management methods routinely leverage system-level information available to the hypervisor about current and global platform state, we argue that for future systems there will be an increased necessity for additional information about applications and their needs. This 'end-to-end' argument leads us to propose 'performance points' as a general interface between the virtualization system and higher layers like the guest operating systems that run application workloads. Building on concrete examples from past work on APIs with which applications can inform systems of phase or workload changes and conversely, with which systems can indicate to applications desired changes in power consumption, performance points are shown to be an effective way to better exploit asymmetries and gain the power/performance improvements promised by heterogeneous multicore systems.},
journal = {SIGOPS Oper. Syst. Rev.},
month = feb,
pages = {3–10},
numpages = {8},
keywords = {asymmetry, heterogeneous multicore, virtualization}
}

@article{10.1145/1945023.1945029,
author = {Vasudevan, Vijay and Andersen, David G. and Kaminsky, Michael and Franklin, Jason and Kozuch, Michael A. and Moraru, Iulian and Pillai, Padmanabhan and Tan, Lawrence},
title = {Challenges and Opportunities for Efficient Computing with FAWN},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5980},
url = {https://doi.org/10.1145/1945023.1945029},
doi = {10.1145/1945023.1945029},
abstract = {This paper presents the architecture and motivation for a clusterbased, many-core computing architecture for energy-efficient, dataintensive computing. FAWN, a Fast Array of Wimpy Nodes, consists of a large number of slower but efficient nodes coupled with low-power storage. We present the computing trends that motivate a FAWN-like approach, for CPU, memory, and storage. We follow with a set of microbenchmarks to explore under what workloads these FAWN nodes perform well (or perform poorly), and briefly examine scenarios in which both code and algorithms may need to be re-designed or optimized to perform well on an efficient platform. We conclude with an outline of the longer-term implications of FAWN that lead us to select a tightly integrated stacked chip and-memory architecture for future FAWN development.},
journal = {SIGOPS Oper. Syst. Rev.},
month = feb,
pages = {34–44},
numpages = {11},
keywords = {design, measurement, performance, energy efficiency, flash, cluster computing}
}

@inproceedings{10.1145/1943513.1943537,
author = {Xi, Bowei and Kantarcioglu, Murat and Inan, Ali},
title = {Mixture of Gaussian Models and Bayes Error under Differential Privacy},
year = {2011},
isbn = {9781450304665},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943513.1943537},
doi = {10.1145/1943513.1943537},
abstract = {Gaussian mixture models are an important tool in Bayesian decision theory. In this study, we focus on building such models over statistical database protected under differential privacy. Our approach involves querying necessary statistics from a database and building a Bayesian classifier over the noise added responses generated according to differential privacy. We formally analyze the sensitivity of our query set. Since there are multiple methods to query a statistic, either directly or indirectly, we analyze the sensitivities for different querying methods. Furthermore we establish theoretical bounds for the Bayes error for the univariate (one dimensional) case. We study the Bayes error for the multivariate (high dimensional) case in experiments with both simulated data and real life data. We discover that adding Laplace noise to a statistic under certain constraint is problematic. For example variance-covariance matrix is no longer positive definite after noise addition. We propose a heuristic method to fix the noise added variance-covariance matrix.},
booktitle = {Proceedings of the First ACM Conference on Data and Application Security and Privacy},
pages = {179–190},
numpages = {12},
keywords = {differential privacy, mixture models, classification, statistical databases},
location = {San Antonio, TX, USA},
series = {CODASPY '11}
}

@inproceedings{10.1145/1980022.1980198,
author = {Siddesh, G. M. and Srinivasa, K. G. and Venugopal, K. R.},
title = {GRM: A Reliable and Fault Tolerant Data Replication Middleware for Grid Environment},
year = {2011},
isbn = {9781450304498},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1980022.1980198},
doi = {10.1145/1980022.1980198},
abstract = {Existing approaches to replication based middleware suffers from performance limitations with the additional traffic in the Grid. Hence the proposed approach provides a replication middleware which offers highly efficient, consistent and fully replicated system for the Grid environment. This paper proposes a highly available fault tolerant Grid based replication middleware, which achieves replication of data dynamically upon incoming transaction request from the clients. The Grid based Replication Middleware (GRM) offers: Semi active replication strategy based on Total Ordering-Multicasting, SOAP based message communication, Dijkstra and Scholten election algorithm, improved Membership service and Hash based replica Location service to achieve high availability, heterogeneity, Fault tolerance, improved scalability, efficient data management services respectively and security features like authentication, authorization, message confidentiality are also addressed. Proposed GRM reduces the system overhead by reducing the traffic in the Grid and thereby improving the performance of data management for large scale complex Grid based applications.},
booktitle = {Proceedings of the International Conference &amp; Workshop on Emerging Trends in Technology},
pages = {810–815},
numpages = {6},
keywords = {grid environment, middleware, data management, replication, total ordering},
location = {Mumbai, Maharashtra, India},
series = {ICWET '11}
}

@inproceedings{10.1145/2090116.2090131,
author = {Fournier, H\'{e}l\`{e}ne and Kop, Rita and Sitlia, Hanan},
title = {The Value of Learning Analytics to Networked Learning on a Personal Learning Environment},
year = {2011},
isbn = {9781450309448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2090116.2090131},
doi = {10.1145/2090116.2090131},
abstract = {Some might argue that the analytics tools at our disposal are currently mainly used for boring purposes, such as improving processes and making money. In this paper we will try to define learning analytics and their purpose for learning and education. We will ponder on the best possible fit of particular types of research methods and their analysis. Methodological concerns related to the analysis of Big Data collected on online networks as well as ethical and privacy concerns will also be highlighted and a case study of the use of learning analytics in a Massive Open Online Course explored.},
booktitle = {Proceedings of the 1st International Conference on Learning Analytics and Knowledge},
pages = {104–109},
numpages = {6},
keywords = {analytics tools, big data, educational research, learning analytics, massive open online courses},
location = {Banff, Alberta, Canada},
series = {LAK '11}
}

@inproceedings{10.1145/2090116.2090129,
author = {Vatrapu, Ravi and Teplovs, Chris and Fujita, Nobuko and Bull, Susan},
title = {Towards Visual Analytics for Teachers' Dynamic Diagnostic Pedagogical Decision-Making},
year = {2011},
isbn = {9781450309448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2090116.2090129},
doi = {10.1145/2090116.2090129},
abstract = {The focus of this paper is to delineate and discuss design considerations for supporting teachers' dynamic diagnostic decision-making in classrooms of the 21st century. Based on the Next Generation Teaching Education and Learning for Life (NEXT-TELL) European Commission integrated project, we envision classrooms of the 21st century to (a) incorporate 1:1 computing, (b) provide computational as well as methodological support for teachers to design, deploy and assess learning activities and (c) immerse students in rich, personalized and varied learning activities in information ecologies resulting in high-performance, high-density, high-bandwidth, and data-rich classrooms. In contrast to existing research in educational data mining and learning analytics, our vision is to employ visual analytics techniques and tools to support teachers dynamic diagnostic pedagogical decision-making in real-time and in actual classrooms. The primary benefits of our vision is that learning analytics becomes an integral part of the teaching profession so that teachers can provide timely, meaningful, and actionable formative assessments to on-going learning activities in-situ. Integrating emerging developments in visual analytics and the established methodological approach of design-based research (DBR) in the learning sciences, we introduce a new method called "Teaching Analytics" and explore a triadic model of teaching analytics (TMTA). TMTA adapts and extends the Pair Analytics method in visual analytics which in turn was inspired by the pair programming model of the extreme programming paradigm. Our preliminary vision of TMTA consists of a collocated collaborative triad of a Teaching Expert (TE), a Visual Analytics Expert (VAE), and a Design-Based Research Expert (DBRE) analyzing, interpreting and acting upon real-time data being generated by students' learning activities by using a range of visual analytics tools. We propose an implementation of TMTA using open learner models (OLM) and conclude with an outline of future work},
booktitle = {Proceedings of the 1st International Conference on Learning Analytics and Knowledge},
pages = {93–98},
numpages = {6},
keywords = {learning analytics, learning sciences, multivocality, teaching analytics, computer supported collaborative learning (CSCL), visual analytics},
location = {Banff, Alberta, Canada},
series = {LAK '11}
}

@inproceedings{10.1145/2090116.2090128,
author = {Brooks, Christopher and Epp, Carrie Demmans and Logan, Greg and Greer, Jim},
title = {The Who, What, When, and Why of Lecture Capture},
year = {2011},
isbn = {9781450309448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2090116.2090128},
doi = {10.1145/2090116.2090128},
abstract = {Video lecture capture is rapidly being deploying in higher-education institutions as a means of increasing student learning, outreach, and experience. Understanding how learners use these systems and relating this use back to pedagogical and institutional goals is a hard issue that has largely been unexplored. This work describes a novel web-based lecture presentation system which contains fine-grained user tracking features. These features, along with student surveys, have been used to help analyse the behaviour of hundreds of students over an academic term, quantifying both the learning approaches of students and their perceptions on learning with lecture capture.},
booktitle = {Proceedings of the 1st International Conference on Learning Analytics and Knowledge},
pages = {86–92},
numpages = {7},
keywords = {lecture capture, participation, analytics, clustering, recollect, student experience},
location = {Banff, Alberta, Canada},
series = {LAK '11}
}

@inproceedings{10.1145/2090116.2090135,
author = {Sharkey, Mike},
title = {Academic Analytics Landscape at the University of Phoenix},
year = {2011},
isbn = {9781450309448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2090116.2090135},
doi = {10.1145/2090116.2090135},
abstract = {The University of Phoenix understands that in order to serve its large population of non-traditional students, it needs to rely on data. We have created a strong foundation with an integrated data repository that connects data from all parts of the organization. With this repository in place, we can now undertake a variety of analytics projects. One such project is an attempt to predict a student's persistence in their program using available data indicators such as schedule, grades, content usage, and demographics.},
booktitle = {Proceedings of the 1st International Conference on Learning Analytics and Knowledge},
pages = {122–126},
numpages = {5},
keywords = {learning analytics, predictive analytics, data modeling, integrated data, Hadoop, academic data},
location = {Banff, Alberta, Canada},
series = {LAK '11}
}

@article{10.1145/1897852.1897870,
author = {Kamp, Poul-Henning},
title = {B.Y.O.C (1,342 Times and Counting)},
year = {2011},
issue_date = {March 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/1897852.1897870},
doi = {10.1145/1897852.1897870},
abstract = {Why can't we all use standard libraries for commonly needed algorithms?},
journal = {Commun. ACM},
month = mar,
pages = {56–58},
numpages = {3}
}

@article{10.14778/1978665.1978670,
author = {Jahani, Eaman and Cafarella, Michael J. and R\'{e}, Christopher},
title = {Automatic Optimization for MapReduce Programs},
year = {2011},
issue_date = {March 2011},
publisher = {VLDB Endowment},
volume = {4},
number = {6},
issn = {2150-8097},
url = {https://doi.org/10.14778/1978665.1978670},
doi = {10.14778/1978665.1978670},
abstract = {The MapReduce distributed programming framework has become popular, despite evidence that current implementations are inefficient, requiring far more hardware than a traditional relational databases to complete similar tasks. MapReduce jobs are amenable to many traditional database query optimizations (B+Trees for selections, column-store-style techniques for projections, etc), but existing systems do not apply them, substantially because free-form user code obscures the true data operation being performed. For example, a selection in SQL is easily detected, but a selection in a MapReduce program is embedded in Java code along with lots of other program logic. We could ask the programmer to provide explicit hints about the program's data semantics, but one of MapReduce's attractions is precisely that it does not ask the user for such information.This paper covers Manimal, which automatically analyzes MapReduce programs and applies appropriate data-aware optimizations, thereby requiring no additional help at all from the programmer. We show that Manimal successfully detects optimization opportunities across a range of data operations, and that it yields speedups of up to 1,121% on previously-written MapReduce programs.},
journal = {Proc. VLDB Endow.},
month = mar,
pages = {385–396},
numpages = {12}
}

@inproceedings{10.1145/1957656.1957669,
author = {Sabelli, Alessandra Maria and Kanda, Takayuki and Hagita, Norihiro},
title = {A Conversational Robot in an Elderly Care Center: An Ethnographic Study},
year = {2011},
isbn = {9781450305617},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1957656.1957669},
doi = {10.1145/1957656.1957669},
abstract = {This paper reports an ethnographic study on the use of a conversational robot. We placed a robot for 3.5 months in an elderly care center. Assuming a real deployment scenario, the robot was managed by a single non-programmer person during the field trial, who teleoperated the robot and updated the contents. The robot was designed to engage in daily greetings and chatting with elderly people. Through the ethnographic approach, we clarified how the elderly people interacted with this conversational robot, how the deployment process adopted to introduce the robot was designed, and how the organization's personnel involved themselves in this deployment.},
booktitle = {Proceedings of the 6th International Conference on Human-Robot Interaction},
pages = {37–44},
numpages = {8},
keywords = {robots for elderly, ethnography, communication robots, robots in organizations},
location = {Lausanne, Switzerland},
series = {HRI '11}
}

@inproceedings{10.1145/1953163.1953268,
author = {Turner, Scott and P\'{e}rez-Qui\~{n}ones, Manuel A. and Edwards, Stephen and Chase, Joseph},
title = {Student Attitudes and Motivation for Peer Review in CS2},
year = {2011},
isbn = {9781450305006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1953163.1953268},
doi = {10.1145/1953163.1953268},
abstract = {Computer science students need experience with essential concepts and professional activities. Peer review is one way to meet these goals. In this work, we examine the students' attitudes towards and engagement in the peer review process, in early, object-oriented, computer science courses. To do this, we used peer review exercises in two CS2 classes at neighboring universities over the course of a semester. Using three groups (one reviewing their peers, one reviewing the instructor, and one completing small design or coding exercises), we measured the students' attitudes, their perceptions of their abilities, and how many of the reviews they completed. We found moderately positive attitudes that generally increased over time but were not significantly different between groups. We also saw a lower completion rate for students reviewing peers than for the other groups. The students' internal motivation, as measured by their need for cognition, was not shown to be strongly related to their attitudes nor to the number of assignments completed. Overall, our results show a strong need for external motivation to help engage students in peer reviews.},
booktitle = {Proceedings of the 42nd ACM Technical Symposium on Computer Science Education},
pages = {347–352},
numpages = {6},
keywords = {learning, attitude, peer review, engagement, peer assessment, computer science education},
location = {Dallas, TX, USA},
series = {SIGCSE '11}
}

@inproceedings{10.1145/1953163.1953307,
author = {VanDeGrift, Tammy and Caruso, Tamara and Hill, Natalie and Simon, Beth},
title = {Experience Report: Getting Novice Programmers to THINK about Improving Their Software Development Process},
year = {2011},
isbn = {9781450305006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1953163.1953307},
doi = {10.1145/1953163.1953307},
abstract = {Expertise is developed through both a) self-reflection and b) making useful plans for improvement [3, 10]. Traditional novice-level programming assignments require neither of these skills to be used. Could we get students to think about improving their software development processes? What areas would they identify as needing improvement? Could they write effective plans for themselves? In this experience report, we analyze the results of an intervention with 236 CS1.5 students asking them to do these activities. We find that they most commonly make improvements in planning, compared to coding and testing. Additionally, over half of the plans they make are so vague as to be of little use in helping students identify if they have, in fact, improved. Finally, we asked students at the end of the term to reflect on how their experiences with programming assignments changed over the term. We discuss our results in light of how instructors can focus instruction to help students become more meta-cognitive about their own software development processes.},
booktitle = {Proceedings of the 42nd ACM Technical Symposium on Computer Science Education},
pages = {493–498},
numpages = {6},
keywords = {metacognition, programming, novice, software quality},
location = {Dallas, TX, USA},
series = {SIGCSE '11}
}

@inproceedings{10.1145/1953163.1953344,
author = {Cennamo, Katherine and Douglas, Sarah A. and Vernon, Mitzi and Brandt, Carol and Scott, Brigitte and Reimer, Yolanda and McGrath, Margarita},
title = {Promoting Creativity in the Computer Science Design Studio},
year = {2011},
isbn = {9781450305006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1953163.1953344},
doi = {10.1145/1953163.1953344},
abstract = {Revolutionary advances in technologies will require computer science professionals who are able to develop innovative software solutions. In order to identify techniques that can lead students to creative insights in their work, we have conducted an ethnographic study of the studio method as enacted in architecture, industrial design (ID), and human-computer interaction (HCI) classes. Our analysis of the activities conducted during studio critiques revealed that while the ID and architecture studios had a primary focus on experimentation, the primary emphasis of the HCI studios was on idea refinement. In this paper, we describe four barriers to creative thought observed in the HCI classrooms and identify ways that the architecture and ID instructors helped students to overcome similar challenges.},
booktitle = {Proceedings of the 42nd ACM Technical Symposium on Computer Science Education},
pages = {649–654},
numpages = {6},
keywords = {creativity, design, computer science education research, studio},
location = {Dallas, TX, USA},
series = {SIGCSE '11}
}

@inproceedings{10.1145/1958824.1958847,
author = {Hu, Bin and Zheng, Fang and Liu, Li},
title = {Ubiquitous Awareness and Intelligent Solutions Lab: Lanzhou University},
year = {2011},
isbn = {9781450305563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1958824.1958847},
doi = {10.1145/1958824.1958847},
booktitle = {Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work},
pages = {151–158},
numpages = {8},
keywords = {human computer interaction, computer supported collaborative work, bio-data},
location = {Hangzhou, China},
series = {CSCW '11}
}

@inproceedings{10.1145/1958824.1958876,
author = {Newman, Mark W. and Lauterbach, Debra and Munson, Sean A. and Resnick, Paul and Morris, Margaret E.},
title = {It's Not That i Don't Have Problems, i'm Just Not Putting Them on Facebook: Challenges and Opportunities in Using Online Social Networks for Health},
year = {2011},
isbn = {9781450305563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1958824.1958876},
doi = {10.1145/1958824.1958876},
abstract = {To understand why and how people share health information online, we interviewed fourteen people with significant health concerns who participate in both online health communities and Facebook. Qualitative analysis of these interviews highlighted the ways that people think about with whom and how to share different types of information as they pursue social goals related to their personal health, including emotional support, motivation, accountability, and advice. Our study suggests that success in these goals depends on how well they develop their social networks and how effectively they communicate within those networks. Effective communication is made more challenging by the need to strike a balance between sharing information related to specific needs and the desire to manage self-presentation. Based on these observations, we outline a set of design opportunities for future systems to support health-oriented social interactions online, including tools to help users shape their social networks and communicate effectively within those.},
booktitle = {Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work},
pages = {341–350},
numpages = {10},
keywords = {social support, online health communities, Facebook},
location = {Hangzhou, China},
series = {CSCW '11}
}

@inproceedings{10.1145/1958824.1958848,
author = {Chi, Changyan and Liao, Qinying and Pan, Yingxin and Zhao, Shiwan and Matthews, Tara and Moran, Thomas and Zhou, Michelle X. and Millen, David and Lin, Ching-Yung and Guy, Ido},
title = {Smarter Social Collaboration at IBM Research},
year = {2011},
isbn = {9781450305563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1958824.1958848},
doi = {10.1145/1958824.1958848},
abstract = {In this paper we feature a set of research projects done at several IBM Research laboratories across the world. The work featured here focuses on the topic of smart social collaboration, which studies, designs, and develops social collaboration principles and technologies that can help customize and enhance existing social collaboration tools to suit specific user needs, including cultural, business, and personal needs.},
booktitle = {Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work},
pages = {159–166},
numpages = {8},
keywords = {culture, social collaboration, business},
location = {Hangzhou, China},
series = {CSCW '11}
}

@inproceedings{10.1145/1958824.1958864,
author = {Wang, Hao-Chuan and Fussell, Susan R. and Cosley, Dan},
title = {From Diversity to Creativity: Stimulating Group Brainstorming with Cultural Differences and Conversationally-Retrieved Pictures},
year = {2011},
isbn = {9781450305563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1958824.1958864},
doi = {10.1145/1958824.1958864},
abstract = {Group brainstorming, or collaboratively generating ideas through idea sharing, demands diverse contributions to spark more ideas and improve creativity. One approach to supporting group brainstorming is to introduce conceptual diversity. In this study, we evaluate the effects of two sources of diversity on group brainstorming: cultural differences internal to multicultural groups and pictures related to the conversation retrieved by a computer agent. The pictures generally enhanced performance as measured by both originality and diversity of ideas. The pictures also helped to convert cultural diversity into a creative outcome, the diversity of ideas generated. We argue that with appropriate technology mediation, cultural diversity may be used strategically to enhance task outcomes.},
booktitle = {Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work},
pages = {265–274},
numpages = {10},
keywords = {intercultural collaboration, group creativity, creativity support tools, group brainstorming, cultural diversity},
location = {Hangzhou, China},
series = {CSCW '11}
}

@inproceedings{10.1145/1958824.1958875,
author = {Munson, Sean A. and Rosengren, Emily and Resnick, Paul},
title = {Thanks and Tweets: Comparing Two Public Displays},
year = {2011},
isbn = {9781450305563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1958824.1958875},
doi = {10.1145/1958824.1958875},
abstract = {Two public display systems, with different methods of posting, were deployed over several years. One, the Thank You Board, was designed to give people an outlet specifically for publicly thanking and acknowledging others in the community. The other, SI Display, showed any Twitter post directed to the display and did not have explicit usage guidelines. People preferred the flexibility of the latter, but ambiguity about its purpose and norms of usage persisted even six months after deployment and made some people hesitant to post. Also, using Twitter as the posting mechanism facilitated participation for some but also created barriers for those not using Twitter and for Twitter users who were wary of mixing their professional and non-professional contexts.},
booktitle = {Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work},
pages = {331–340},
numpages = {10},
keywords = {norms, twitter, adoption, interpretations, public displays},
location = {Hangzhou, China},
series = {CSCW '11}
}

@inproceedings{10.1145/1982185.1982209,
author = {Antonie, Luiza and Bessonov, Kyrylo},
title = {Classifying Microarray Data with Association Rules},
year = {2011},
isbn = {9781450301138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1982185.1982209},
doi = {10.1145/1982185.1982209},
abstract = {In this paper we investigate a method for classifying microarray data using association rules. Associative classifiers, classification systems based on association rules, show good performance level while being easy to read and understand. This feature is especially attractive for biological data where experts can read and validate the association rules. Relevant features are selected using Support Vector Machines with Recursive Feature Elimination. These features are discretized according to their relative expression levels (upregulated, downregulated or no change) and then they are used to build an associative classifier. The proposed combination proves highly accurate for the studied microarray data collection. In addition the classification rules discovered and employed in the classification process prove to be biologically relevant.},
booktitle = {Proceedings of the 2011 ACM Symposium on Applied Computing},
pages = {94–99},
numpages = {6},
keywords = {association rules, microarray data, classification},
location = {TaiChung, Taiwan},
series = {SAC '11}
}

@inproceedings{10.1145/1980422.1980428,
author = {Hyser, Chris and Gmach, Daniel and Ml, Umesh and Chen, Yuan and Suryanarayana, Vijay},
title = {Improving Server Power Management in Research and Development Data Centers},
year = {2011},
isbn = {9781450307505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1980422.1980428},
doi = {10.1145/1980422.1980428},
abstract = {Research data centers are often composed of thousands of diverse computer systems used for ongoing research, development, software regression and hardware compatibility testing. The usage patterns of many of these systems result in periodic non-use and extended periods of idleness. Users routinely fail to ensure that idle machines are powered down prior to overnight or extended absence periods. The annual amount of wasted energy in the HP Bangalore development data center is estimated at 14400 MWh resulting in over 8600 tons of CO2 emissions per year. In this paper, we propose Idle Machine Power Savings (IMPS), which seeks to address potential power cost savings and minimize environmental impact. IMPS consists of a low overhead, highly scalable data acquisition framework enabling the development of algorithms (an artificial neural network is used in the initial prototype) for automatic "extended idle" notifications and optional automatic shutdown of unused computers in data centers. This paper describes our approach, the framework, a prototype implementation and provides preliminary results. The results show an enormous potential for energy savings that translate directly into financial savings and lowered greenhouse gas emissions.},
booktitle = {Proceedings of the Fourth Annual ACM Bangalore Conference},
articleno = {6},
numpages = {6},
keywords = {data mining, machine learning algorithms, sustainable computing, power management, sustainability},
location = {Bangalore, India},
series = {COMPUTE '11}
}

@inproceedings{10.1145/1963192.1963341,
author = {Das, Dipankar},
title = {Analysis and Tracking of Emotions in English and Bengali Texts: A Computational Approach},
year = {2011},
isbn = {9781450306379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1963192.1963341},
doi = {10.1145/1963192.1963341},
abstract = {The present discussion highlights the aspects of an ongoing doctoral thesis grounded on the analysis and tracking of emotions from English and Bengali texts. Development of lexical resources and corpora meets the preliminary urgencies. The research spectrum aims to identify the evaluative emotional expressions at word, phrase, sentence, and document level granularities along with their associated holders and topics. Tracking of emotions based on topic or event was carried out by employing sense based affect scoring techniques. The labeled emotion corpora are being prepared from unlabeled examples to cope with the scarcity of emotional resources, especially for the resource constraint language like Bengali. Different unsupervised, supervised and semi-supervised strategies, adopted for coloring each outline of the research spectrum produce satisfactory outcomes},
booktitle = {Proceedings of the 20th International Conference Companion on World Wide Web},
pages = {343–348},
numpages = {6},
keywords = {svm, syntactic argument structure, expression, crf, topic, holder, tracking, emotions, blogs, bengwal},
location = {Hyderabad, India},
series = {WWW '11}
}

@inproceedings{10.1145/1963192.1963365,
author = {Pal, Joyojeet and Pradhan, Manas and Shah, Mihir and Babu, Rakesh},
title = {Assistive Technology for Vision-Impairments: Anagenda for the ICTD Community},
year = {2011},
isbn = {9781450306379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1963192.1963365},
doi = {10.1145/1963192.1963365},
abstract = {In recent years, ICTD (Information Communications Technology and Development) has grown in significance as an area of engineering research that has focused on low-cost appropriate technologies for the needs of a developing world largely underserved by the dominant modes of technology design. Assistive Technologies (AT) used by people with disabilities facilitate greater equity in the social and economic public sphere. However, by and large such technologies are designed in the industrialized world, for people living in those countries. This is especially true in the case of AT for people with vision impairments -- market-prevalent technologies are both very expensive and are built to support the language and infrastructure typical in the industrialized world. While the community of researchers in the Web Accessibility space have made significant strides, the operational concerns of networks in the developing world, as well as challenges in support for new languages and contexts raises a new set of challenges for technologists in this space. We discuss the state of various technologies in the context of the developing world and propose directions in scientific and community-contributed efforts to increase the relevance and access to AT and accessibility in the developing world.},
booktitle = {Proceedings of the 20th International Conference Companion on World Wide Web},
pages = {513–522},
numpages = {10},
keywords = {accessibility, assistive technology, visually impaired},
location = {Hyderabad, India},
series = {WWW '11}
}

@inproceedings{10.1145/1963192.1963358,
author = {Chen, Jay and Hutchful, David and Thies, William and Subramanian, Lakshminarayanan},
title = {Analyzing and Accelerating Web Access in a School in Peri-Urban India},
year = {2011},
isbn = {9781450306379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1963192.1963358},
doi = {10.1145/1963192.1963358},
abstract = {While computers and Internet access have growing penetration amongst schools in the developing world, intermittent connectivity and limited bandwidth often prevent them from being fully utilized by students and teachers. In this paper, we make two contributions to help address this problem. First, we characterize six weeks of HTTP traffic from a primary school outside of Bangalore, India, illuminating opportunities and constraints for improving performance in such settings. Second, we deploy an aggressive caching and prefetching engine and show that it accelerates a user's overall browsing experience (apart from video content) by 2.8x. Our accelerator leverages innovative techniques that have been proposed, but not evaluated in detail, including the effectiveness of serving stale pages, cached page highlighting, and client-side prefetching. Unlike proxy-based techniques, our system is bundled as an open-source Firefox plugin and runs directly on client machines. This allows easy installation and configuration by end users, which is especially important in developing regions where a lack of permissions or technical expertise often prevents modification of internal network settings.},
booktitle = {Proceedings of the 20th International Conference Companion on World Wide Web},
pages = {443–452},
numpages = {10},
keywords = {browser extension, web acceleration, connectivity},
location = {Hyderabad, India},
series = {WWW '11}
}

@inproceedings{10.1145/1982624.1982630,
author = {Moraru, Alexandra and Mladenic, Dunja and Vucnik, Matevz and Porcius, Maria and Fortuna, Carolina and Mohorcic, Mihael},
title = {Exposing Real World Information for the Web of Things},
year = {2011},
isbn = {9781450306201},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1982624.1982630},
doi = {10.1145/1982624.1982630},
abstract = {In this paper, we propose SemSense architecture for collecting real world data from a physical system of sensors and publishing it on the Web, thus contributing to the Web of Things. SemSense comprises of four components: (1) the data collection component, (2) the storage component (3) the semantic enrichment component and (4) the publishing component, which are described and implemented for an existing deployment of a sensor network. Through these components, the real world data is collected from the physical devices, processed, equipped with semantic information and published on the Web. The paper addresses challenges of efficiently collecting data and meta-data from sensors and publishing it following the linked data principles.},
booktitle = {Proceedings of the 8th International Workshop on Information Integration on the Web: In Conjunction with WWW 2011},
articleno = {6},
numpages = {6},
keywords = {semantic web, sensor, sensor network, web of things, linked data},
location = {Hyderabad, India},
series = {IIWeb '11}
}

@article{10.1145/1952383.1952385,
author = {Jeon, Myounghoon and Walker, Bruce N.},
title = {Spindex (Speech Index) Improves Auditory Menu Acceptance and Navigation Performance},
year = {2011},
issue_date = {April 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {1936-7228},
url = {https://doi.org/10.1145/1952383.1952385},
doi = {10.1145/1952383.1952385},
abstract = {Users interact with mobile devices through menus, which can include many items. Auditory menus have the potential to make those devices more accessible to a wide range of users. However, auditory menus are a relatively new concept, and there are few guidelines that describe how to design them. In this paper, we detail how visual menu concepts may be applied to auditory menus in order to help develop design guidelines. Specifically, we examine how to optimize the designs of a new contextual cue, called “spindex” (i.e., speech index). We developed and evaluated various design alternatives for spindex and iteratively refined the design with sighted users and visually impaired users. As a result, the “attenuated” spindex was the best in terms of preference as well as performance, across user groups. Nevertheless, sighted and visually impaired participants showed slightly different responses and feedback. Results are discussed in terms of acoustical theory, practical display design, and assistive technology design.},
journal = {ACM Trans. Access. Comput.},
month = apr,
articleno = {10},
numpages = {26},
keywords = {Auditory menus, spindex, assistive technology}
}

@inproceedings{10.1145/2107556.2107569,
author = {Aljenaa, E. and Al-Anzi, F. S. and Alshayeji, M.},
title = {Towards an Efficient E-Learning System Based on Cloud Computing},
year = {2011},
isbn = {9781450307932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2107556.2107569},
doi = {10.1145/2107556.2107569},
abstract = {The rapid development in Information and Communication Technology has had a significant impact on traditional educational systems and learning. Today, E-Learning has become a widely accepted way of learning. With increasing numbers of users, a wide range of learning services and the growth of educational content, E-Learning has emerged as the mode for future learning. However, the volatile user load and massive storage and transfer of rich multimedia content have lead to a need for effective utilization of server side system resources in providing E-Learning services. Cloud computing offers a dynamic provision of virtualized resources, elasticity, scalability, pays as you use and measured service with the ability to dynamically provision and de-provision computing resources as needed. Cloud computing is ideally suited for E-learning systems.In this paper, an E-Learning framework based on cloud computing is presented which efficiently addresses the current challenges in E-Learning. Specifically, the architecture and core components in an efficient E-Learning system are introduced for efficient deployment in the cloud. Moreover, the proposed new framework efficiently blends different components that serve for E-Learning systems as a general architecture and wraps it under---E-Learning as services|| (EaaS). Our case study-based evaluation suggests that the proposed framework of E-Learning using cloud computing is best suited for the Kuwait Ministry of Education. In addition to better performance and availability, the proposed framework delivers reliable and scalable services for E- Learning systems.},
booktitle = {Proceedings of the Second Kuwait Conference on E-Services and e-Systems},
articleno = {13},
numpages = {7},
keywords = {automation, cloud computing, cloud ontology, e-learning, e-learning as a service, operation, framework},
location = {Kuwait City, Kuwait},
series = {KCESS '11}
}

@inproceedings{10.1145/2107556.2107564,
author = {Hussain, Mohammed and Abdulsalam, Hanady},
title = {SECaaS: Security as a Service for Cloud-Based Applications},
year = {2011},
isbn = {9781450307932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2107556.2107564},
doi = {10.1145/2107556.2107564},
abstract = {Cloud computing is a great target for many applications since it provides the storage and computation needs for cloud users with relatively low-cost. Although the area of cloud computing has grown rapidly in the last few years, the area still lacks appropriate security measures that protect the data and/or applications for cloud users. We introduce a new architecture, namely Security as a Service (SECaaS) that addresses the security issues for cloud-based applications. SECaaS deals with existing services of cloud computing on its different levels. SECaaS takes a user-centric approach, in which cloud users have more control over their security. It provides security means for both cloud users and providers.},
booktitle = {Proceedings of the Second Kuwait Conference on E-Services and e-Systems},
articleno = {8},
numpages = {4},
keywords = {security, cloud computing, security as a service},
location = {Kuwait City, Kuwait},
series = {KCESS '11}
}

@inproceedings{10.1145/1966445.1966467,
author = {Wester, Benjamin and Chen, Peter M. and Flinn, Jason},
title = {Operating System Support for Application-Specific Speculation},
year = {2011},
isbn = {9781450306348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1966445.1966467},
doi = {10.1145/1966445.1966467},
abstract = {Speculative execution is a technique that allows serial tasks to execute in parallel. An implementation of speculative execution can be divided into two parts: (1) a policy that specifies what operations and values to predict, what actions to allow during speculation, and how to compare results; and (2) the mechanisms that support speculative execution, such as checkpointing, rollback, causality tracking, and output buffering.In this paper, we show how to separate policy from mechanism. We implement a speculation mechanism in the operating system, where it can coordinate speculations across all applications and kernel state. Policy decisions are delegated to applications, which have the most semantic information available to direct speculation.We demonstrate how custom policies can be used in existing applications to add new features that would otherwise be difficult to implement. Using custom policies in our separated speculation system, we can hide 85% of program load time by predicting the program's launch, decrease SSL connection latency by 15% in Firefox, and increase a BFT client's request rate by 82%. Despite the complexity of the applications, small modifications can implement these features since they only specify policy choices and rely on the system to realize those policies. We provide this increased programmability with a modest performance trade-off, executing only 8% slower than an optimized, application-implemented speculation system.},
booktitle = {Proceedings of the Sixth Conference on Computer Systems},
pages = {229–242},
numpages = {14},
keywords = {policy, speculative execution, mechanism},
location = {Salzburg, Austria},
series = {EuroSys '11}
}

@inproceedings{10.1145/1966445.1966477,
author = {Nightingale, Edmund B. and Douceur, John R. and Orgovan, Vince},
title = {Cycles, Cells and Platters: An Empirical Analysisof Hardware Failures on a Million Consumer PCs},
year = {2011},
isbn = {9781450306348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1966445.1966477},
doi = {10.1145/1966445.1966477},
abstract = {We present the first large-scale analysis of hardware failure rates on a million consumer PCs. We find that many failures are neither transient nor independent. Instead, a large portion of hardware induced failures are recurrent: a machine that crashes from a fault in hardware is up to two orders of magnitude more likely to crash a second time. For example, machines with at least 30 days of accumulated CPU time over an 8 month period had a 1 in 190 chance of crashing due to a CPU subsystem fault. Further, machines that crashed once had a probability of 1 in 3.3 of crashing a second time. Our study examines failures due to faults within the CPU, DRAM and disk subsystems. Our analysis spans desktops and laptops, CPU vendor, overclocking, underclocking, generic vs. brand name, and characteristics such as machine speed and calendar age. Among our many results, we find that CPU fault rates are correlated with the number of cycles executed, underclocked machines are significantly more reliable than machines running at their rated speed, and laptops are more reliable than desktops.},
booktitle = {Proceedings of the Sixth Conference on Computer Systems},
pages = {343–356},
numpages = {14},
keywords = {reliability, fault tolerance},
location = {Salzburg, Austria},
series = {EuroSys '11}
}

@inproceedings{10.1145/1991996.1992008,
author = {Li, Xirong and Snoek, Cees G. M. and Worring, Marcel and Smeulders, Arnold W. M.},
title = {Social Negative Bootstrapping for Visual Categorization},
year = {2011},
isbn = {9781450303361},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1991996.1992008},
doi = {10.1145/1991996.1992008},
abstract = {To learn classifiers for many visual categories, obtaining labeled training examples in an efficient way is crucial. Since a classifier tends to misclassify negative examples which are visually similar to positive examples, inclusion of such informative negatives should be stressed in the learning process. However, they are unlikely to be hit by random sampling, the de facto standard in literature. In this paper, we go beyond random sampling by introducing a novel social negative bootstrapping approach. Given a visual category and a few positive examples, the proposed approach adaptively and iteratively harvests informative negatives from a large amount of social-tagged images. To label negative examples without human interaction, we design an effective virtual labeling procedure based on simple tag reasoning. Virtual labeling, in combination with adaptive sampling, enables us to select the most misclassified negatives as the informative samples. Learning from the positive set and the informative negative sets results in visual classifiers with higher accuracy. Experiments on two present-day image benchmarks employing 650K virtually labeled negative examples show the viability of the proposed approach. On a popular visual categorization benchmark our precision at 20 increases by 34%, compared to baselines trained on randomly sampled negatives. We achieve more accurate visual categorization without the need of manually labeling any negatives.},
booktitle = {Proceedings of the 1st ACM International Conference on Multimedia Retrieval},
articleno = {12},
numpages = {8},
keywords = {negative bootstrapping, social-tagged examples},
location = {Trento, Italy},
series = {ICMR '11}
}

@article{10.1145/1963559.1963561,
author = {Yadgar, Gala and Factor, Michael and Li, Kai and Schuster, Assaf},
title = {Management of Multilevel, Multiclient Cache Hierarchies with Application Hints},
year = {2011},
issue_date = {May 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {0734-2071},
url = {https://doi.org/10.1145/1963559.1963561},
doi = {10.1145/1963559.1963561},
abstract = {Multilevel caching, common in many storage configurations, introduces new challenges to traditional cache management: data must be kept in the appropriate cache and replication avoided across the various cache levels. Additional challenges are introduced when the lower levels of the hierarchy are shared by multiple clients. Sharing can have both positive and negative effects. While data fetched by one client can be used by another client without incurring additional delays, clients competing for cache buffers can evict each other’s blocks and interfere with exclusive caching schemes.We present a global noncentralized, dynamic and informed management policy for multiple levels of cache, accessed by multiple clients. Our algorithm, MC2, combines local, per client management with a global, system-wide scheme, to emphasize the positive effects of sharing and reduce the negative ones. Our local management scheme, Karma, uses readily available information about the client’s future access profile to save the most valuable blocks, and to choose the best replacement policy for them. The global scheme uses the same information to divide the shared cache space between clients, and to manage this space. Exclusive caching is maintained for nonshared data and is disabled when sharing is identified.Previous studies have partially addressed these challenges through minor changes to the storage interface. We show that all these challenges can in fact be addressed by combining minor interface changes with smart allocation and replacement policies. We show the superiority of our approach through comparison to existing solutions, including LRU, ARC, MultiQ, LRU-SP, and Demote, as well as a lower bound on optimal I/O response times. Our simulation results demonstrate better cache performance than all other solutions and up to 87% better performance than LRU on representative workloads.},
journal = {ACM Trans. Comput. Syst.},
month = may,
articleno = {5},
numpages = {51},
keywords = {multilevel, hints, Cache}
}

@article{10.5555/2007456.2007459,
author = {Coursaris, Constantinos K. and Kim, Dan J.},
title = {A Meta-Analytical Review of Empirical Mobile Usability Studies},
year = {2011},
issue_date = {May 2011},
publisher = {Usability Professionals' Association},
address = {Bloomingdale, IL},
volume = {6},
number = {3},
issn = {1931-3357},
abstract = {In this paper we present an adapted usability evaluation framework to the context of a mobile computing environment. Using this framework, we conducted a qualitative meta-analytical review of more than 100 empirical mobile usability studies. The results of the qualitative review include (a) the contextual factors studied; (b) the core and peripheral usability dimensions measured; and (c) key findings in the form of a research agenda for future mobile usability research, including open and unstructured tasks are underutilized, interaction effects between interactivity and complexity warrant further investigation, increasing research on accessibility may improve the usability of products and services for often overlooked audiences, studying novel technology and environmental factors will deepen contextual mobile usability knowledge, understanding which hedonic factors impact the aesthetic appeal of a mobile device or service and in turn usability, and a high potential for neuroscience research in mobile usability. Numerous additional findings and takeaways for practitioners are also discussed.},
journal = {J. Usability Studies},
month = may,
pages = {117–171},
numpages = {55},
keywords = {mobile device, effectiveness, usability, context, mobile, meta-analysis, Human Computer Interaction, satisfaction, empirical, efficiency, wireless}
}

@inproceedings{10.5555/2030470.2030533,
author = {Rosenfeld, Avi and Kraus, Sarit},
title = {Using Aspiration Adaptation Theory to Improve Learning},
year = {2011},
isbn = {0982657153},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Creating agents that properly simulate and interact with people is critical for many applications. Towards creating these agents, models are needed that quickly and accurately predict how people behave in a variety of domains and problems. This paper explores how one bounded rationality theory, Aspiration Adaptation Theory (AAT), can be used to aid in this task. We extensively studied two types of problems -- a relatively simple optimization problem and two complex negotiation problems. We compared the predictive capabilities of traditional learning methods with those where we added key elements of AAT and other optimal and bounded rationality models. Within the extensive empirical studies we conducted, we found that machine learning models combined with AAT were most effective in quickly and accurately predicting people's behavior.},
booktitle = {The 10th International Conference on Autonomous Agents and Multiagent Systems - Volume 1},
pages = {423–430},
numpages = {8},
keywords = {cognitive models, agent learning, bounded rationality},
location = {Taipei, Taiwan},
series = {AAMAS '11}
}

@inproceedings{10.5555/2030470.2030513,
author = {Sollenberger, Derek J. and Singh, Munindar P.},
title = {Kokomo: An Empirically Evaluated Methodology for Affective Applications},
year = {2011},
isbn = {0982657153},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {The introduction of affect or emotion modeling into software opens up new possibilities for improving user experience. Yet, current techniques for building affective applications are limited, with the treatment of affect in essence handcrafted in each application. The multiagent middleware Koko attempts to reduce the burden of incorporating affect modeling into applications. However, Koko can be effective only if the models it needs to function are suitably constructed.We propose Kokomo, a methodology that employs expressive communicative acts as an organizing principle for affective applications. Kokomo specifies the steps needed to create an affective application in Koko. A key motivation is that Kokomo would facilitate the construction of an affective application by engineers who may lack a prior background in affective modeling.We empirically evaluate Kokomo's utility through a developer study. The results are positive and demonstrate that the developers who used Kokomo were able to develop an affective application in less time, with fewer lines of code, and with a reduced perception of difficulty than developers who worked without Kokomo.},
booktitle = {The 10th International Conference on Autonomous Agents and Multiagent Systems - Volume 1},
pages = {293–300},
numpages = {8},
keywords = {software engineering, affective computing, computational architectures for learning},
location = {Taipei, Taiwan},
series = {AAMAS '11}
}

@article{10.1145/1961189.1961194,
author = {Bonchi, Francesco and Castillo, Carlos and Gionis, Aristides and Jaimes, Alejandro},
title = {Social Network Analysis and Mining for Business Applications},
year = {2011},
issue_date = {April 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/1961189.1961194},
doi = {10.1145/1961189.1961194},
abstract = {Social network analysis has gained significant attention in recent years, largely due to the success of online social networking and media-sharing sites, and the consequent availability of a wealth of social network data. In spite of the growing interest, however, there is little understanding of the potential business applications of mining social networks. While there is a large body of research on different problems and methods for social network mining, there is a gap between the techniques developed by the research community and their deployment in real-world applications. Therefore the potential business impact of these techniques is still largely unexplored.In this article we use a business process classification framework to put the research topics in a business context and provide an overview of what we consider key problems and techniques in social network analysis and mining from the perspective of business applications. In particular, we discuss data acquisition and preparation, trust, expertise, community structure, network dynamics, and information propagation. In each case we present a brief overview of the problem, describe state-of-the art approaches, discuss business application examples, and map each of the topics to a business process classification framework. In addition, we provide insights on prospective business applications, challenges, and future research directions. The main contribution of this article is to provide a state-of-the-art overview of current techniques while providing a critical perspective on business applications of social network analysis and mining.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
articleno = {22},
numpages = {37},
keywords = {community structure, influence propagation, Social networks, viral marketing, expert finding, networks dynamics and evolution}
}

@inproceedings{10.1145/1978942.1978967,
author = {Chau, Duen Horng and Kittur, Aniket and Hong, Jason I. and Faloutsos, Christos},
title = {Apolo: Making Sense of Large Network Data by Combining Rich User Interaction and Machine Learning},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978967},
doi = {10.1145/1978942.1978967},
abstract = {Extracting useful knowledge from large network datasets has become a fundamental challenge in many domains, from scientific literature to social networks and the web. We introduce Apolo, a system that uses a mixed-initiative approach - combining visualization, rich user interaction and machine learning - to guide the user to incrementally and interactively explore large network data and make sense of it. Apolo engages the user in bottom-up sensemaking to gradually build up an understanding over time by starting small, rather than starting big and drilling down. Apolo also helps users find relevant information by specifying exemplars, and then using a machine learning method called Belief Propagation to infer which other nodes may be of interest. We evaluated Apolo with twelve participants in a between-subjects study, with the task being to find relevant new papers to update an existing survey paper. Using expert judges, participants using Apolo found significantly more relevant papers. Subjective feedback of Apolo was also very positive.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {167–176},
numpages = {10},
keywords = {belief propagation, large network, sensemaking},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979419,
author = {Nguyen, David H. and Bedford, Aurora and Bretana, Alexander Gerard and Hayes, Gillian R.},
title = {Situating the Concern for Information Privacy through an Empirical Study of Responses to Video Recording},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979419},
doi = {10.1145/1978942.1979419},
abstract = {In this paper, we present the results of an empirical study of perceptions towards pervasive video recording. We describe a commonly used model for understanding information privacy, the Concern for Information Privacy (CFIP) model, and present the ways that this model and its associated questionnaire can shed light on information privacy concerns about pervasive and ubiquitous computing technologies. Specifically, the CFIP model encourages analysis of data across four facets of experience: the collection of personal data, the risk of improper access, the potential for unauthorized secondary use, and the challenge of preventing or correcting errors in the data. We further identify areas not well handled by this model of information privacy and suggest avenues for future work, including research on how and when to notify people about recording technologies, awareness of data provenance and leakage, and understanding of and access to the data assemblage being created about individuals.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3207–3216},
numpages = {10},
keywords = {CFIP, CCTV, video recording, information privacy},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978945,
author = {Raij, Andrew and Ghosh, Animikh and Kumar, Santosh and Srivastava, Mani},
title = {Privacy Risks Emerging from the Adoption of Innocuous Wearable Sensors in the Mobile Environment},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978945},
doi = {10.1145/1978942.1978945},
abstract = {Wearable sensors are revolutionizing healthcare and science by enabling capture of physiological, psychological, and behavioral measurements in natural environments. However, these seemingly innocuous measurements can be used to infer potentially private behaviors such as stress, conversation, smoking, drinking, illicit drug usage, and others. We conducted a study to assess how concerned people are about disclosure of a variety of behaviors and contexts that are embedded in wearable sensor data. Our results show participants are most concerned about disclosures of conversation episodes and stress - inferences that are not yet widely publicized. These concerns are mediated by temporal and physical context associated with the data and the participant's personal stake in the data. Our results provide key guidance on the extent to which people understand the potential for harm and data characteristics researchers should focus on to reduce the perceived harm from such datasets.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {11–20},
numpages = {10},
keywords = {information disclosure, privacy, wearable sensors, mobile health, user study},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

