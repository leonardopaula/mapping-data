@inproceedings{10.1145/1796900.1796946,
author = {Gupta, Saurabh and Bostrom, Robert P. and Anson, Robert},
title = {Do I Matter? The Impact of Individual Differences on Training Process},
year = {2010},
isbn = {9781450300049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1796900.1796946},
doi = {10.1145/1796900.1796946},
abstract = {The increasing investment in technology for training and learning in organizations underscores the fundamental importance for researchers to understand and investigate technology-mediated learning (TML). Currently, a great deal of Information Systems (IS) training for both IS professionals and end-users has a TML component. With the continuing growth of TML and advances in information technology, there will be a likely increate in TML-based IS training in the future. Advances in technology have created opportunities to deliver mass training as well as to personalize learning. To facilitate understanding in this area, this research analyzes the impact of individual differences on end-user training (EUT) in a TML environment. Using Adaptive Structuration Theory (AST), the learning process is modeled as the appropriation of a training method. Individual differences, or internal structures, are argued to have a significant direct effect on training outcomes and to impact the level of faithfulness of appropriation of learning/training method, thus, having an important indirect effect on learning outcomes. In this study, multiple individual differences were investigated in a laboratory experiment. Data was analyzed using SEM. The results of the study provide a vehicle for researchers, both in IS and Education, to better design and develop training methods and technology tools.},
booktitle = {Proceedings of the 2010 Special Interest Group on Management Information System's 48th Annual Conference on Computer Personnel Research on Computer Personnel Research},
pages = {112–120},
numpages = {9},
keywords = {technology mediated learning, personalization, SEM, learning process, individual differences, end-user training, e-learning},
location = {Vancouver, BC, Canada},
series = {SIGMIS-CPR '10}
}

@inproceedings{10.1145/1815695.1815697,
author = {Giat, Avichai and Pelleg, Dan and Raichstein, Eran and Ronen, Amir},
title = {Using Machine Learning Techniques to Enhance the Performance of an Automatic Backup and Recovery System},
year = {2010},
isbn = {9781605589084},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1815695.1815697},
doi = {10.1145/1815695.1815697},
abstract = {A typical disaster recovery system will have mirrored storage at a site that is geographically separate from the main operational site. In many cases, communication between the local site and the backup repository site is performed over a network which is inherently slow, such as a WAN, or is highly strained, for example due to a whole-site disaster recovery operation.The goal of this work is to alleviate the performance impact of the network in such a scenario, and to do so using machine learning techniques. We focus on two main areas, prefetching and read-ahead size determination. In both cases we significantly improve the performance of the system.Our main contributions are as follows: We introduce a theoretical model of the system and the problem we are trying to solve and bound the gain from prefetching techniques. We construct two frequent pattern mining algorithms and use them for prefetching. A framework for controlling and combining multiple prefetch algorithms is presented as well. These algorithms, as well as various simple prefetch algorithms, are compared on a simulation environment. We introduce a novel algorithm for determining the amount of read ahead on such a system that is based on intuition from online competitive analysis and on regression techniques. The significant positive impact of this algorithm is demonstrated on IBM's FastBack system.Much of our improvements have been applied with little or no modification of the current implementation's internals. We therefore feel confident in stating that the techniques are general and are likely to have applications elsewhere.},
booktitle = {Proceedings of the 3rd Annual Haifa Experimental Systems Conference},
articleno = {1},
numpages = {10},
keywords = {file and storage systems, readahead, machine learning, systems, prefetching},
location = {Haifa, Israel},
series = {SYSTOR '10}
}

@inproceedings{10.1145/1815695.1815714,
author = {Ishizaki, Kazuaki and Mizuno, Ken and Suganuma, Toshio and Silva, Daniel and Koseki, Akira and Komatsu, Hideaki and Ueda, Yohei and Nakatani, Toshio},
title = {Parallel Programming Framework for Large Batch Transaction Processing on Scale-out Systems},
year = {2010},
isbn = {9781605589084},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1815695.1815714},
doi = {10.1145/1815695.1815714},
abstract = {A scale-out system is a cluster of commodity machines, and offers a good platform to support steadily increasing workloads that process growing data sets. Sharding [4] is a method of partitioning data and processing a computation on a scale-out system. In a database system, a large table can be partitioned into small tables so each node can process its part of the computation. The sharding approach in a large batch transaction processing, which is important in financial area, presents two hard problems to programmers. Programmers have to write complex code (1) to transfer the input data so as to align the computations with the data partitions, and (2) to manage the distributed transactions. This paper presents a new parallel programming framework that makes parallel transactional programming easier by specifying transaction scopes and partitioners to simplify the code. Transaction scopes include series of subtransactions, each of which performs local operations. The system manages the distributed transactions automatically. A partitioner represents how the computation should be decomposed and aligned with the data partitions to avoid remote database accesses. Between paired of subtransactions, the system handles the data shuffling across the network. We implemented our parallel programming framework as a new Java class library. We hide all of the complex details of data transfer and distributed transaction management in the library. Our programming framework can eliminate almost 66% of the lines of code compared to a current programming approach without programming framework support. We also confirmed good scalability, with a scaling factor of 20.6 on 24 nodes using our modified batch program for the TPC-C benchmark.},
booktitle = {Proceedings of the 3rd Annual Haifa Experimental Systems Conference},
articleno = {15},
numpages = {14},
keywords = {scale-out, batch transaction, sharding, programming framework},
location = {Haifa, Israel},
series = {SYSTOR '10}
}

@inproceedings{10.1145/1842993.1843008,
author = {McCrae, James and Glueck, Michael and Grossman, Tovi and Khan, Azam and Singh, Karan},
title = {Exploring the Design Space of Multiscale 3D Orientation},
year = {2010},
isbn = {9781450300766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1842993.1843008},
doi = {10.1145/1842993.1843008},
abstract = {Recently, research in 3D computer graphics and interaction has started to move beyond the narrow domain of single object authoring and inspection, and has begun to consider complex multiscale objects and environments. This generalization of problem scope calls for more general solutions, which are more akin to information visualization techniques than traditional computer graphics approaches.We consider the general problem of the user's understanding of their position and orientation within a multiscale 3D scene and propose a classification of the design space. To ground this theoretical discussion, we present initial explorations into grouping techniques, visualizations, and interactions to facilitate multiscale 3D orientation.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
pages = {81–88},
numpages = {8},
keywords = {design space, multiscale, 3D orientation, visualization},
location = {Roma, Italy},
series = {AVI '10}
}

@article{10.1145/1754428.1754430,
author = {Kandylas, Vasileios and Upham, S. Phineas and Ungar, Lyle H.},
title = {Analyzing Knowledge Communities Using Foreground and Background Clusters},
year = {2010},
issue_date = {May 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {2},
issn = {1556-4681},
url = {https://doi.org/10.1145/1754428.1754430},
doi = {10.1145/1754428.1754430},
abstract = {Insight into the growth (or shrinkage) of “knowledge communities” of authors that build on each other's work can be gained by studying the evolution over time of clusters of documents. We cluster documents based on the documents they cite in common using the Streemer clustering method, which finds cohesive foreground clusters (the knowledge communities) embedded in a diffuse background. We build predictive models with features based on the citation structure, the vocabulary of the papers, and the affiliations and prestige of the authors and use these models to study the drivers of community growth and the predictors of how widely a paper will be cited. We find that scientific knowledge communities tend to grow more rapidly if their publications build on diverse information and use narrow vocabulary and that papers that lie on the periphery of a community have the highest impact, while those not in any community have the lowest impact.},
journal = {ACM Trans. Knowl. Discov. Data},
month = may,
articleno = {7},
numpages = {35},
keywords = {Text mining, community evolution, knowledge communities, clustering, citation analysis}
}

@article{10.1145/1743546.1743582,
author = {Kietzmann, Jan and Angell, Ian},
title = {Panopticon Revisited},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/1743546.1743582},
doi = {10.1145/1743546.1743582},
journal = {Commun. ACM},
month = jun,
pages = {135–138},
numpages = {4}
}

@inproceedings{10.1145/1810085.1810118,
author = {Bisset, Keith R. and Chen, Jiangzhuo and Feng, Xizhou and Ma, Yifei and Marathe, Madhav V.},
title = {Indemics: An Interactive Data Intensive Framework for High Performance Epidemic Simulation},
year = {2010},
isbn = {9781450300186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1810085.1810118},
doi = {10.1145/1810085.1810118},
abstract = {To respond to the serious threat of pandemics (e.g. 2009 H1N1 influenza) to human society, we developed Indemics (<u>In</u>teractive Epi<u>demic</u> <u>S</u>imulation), an interactive, data intensive, high performance modeling environment for realtime pandemic planning, situation assessment, and course of action analysis. Indemics was built upon a model of interactive data intensive scientific computation, supporting online interactions between users and simulations and enabling epidemic simulations over detailed social contact networks and realistic representations of complex public policies and intervention strategies.Instead of simply making a highly optimized parallel application run even faster, Indemics introduced several innovative ideas such as online interactive computation and HPC-DBMS integration that significantly improved the functionality, flexibility, modularity, and usability of HPC software. Our performance evaluation suggests that additional computational overhead incurred by Indemics compared to non-interactive simulations is easily offset by its new capabilities. Preliminary results show that Indemics significantly broadens the range of course of action scenarios that can be simulated and enables domain experts to analyze problems that were previously not possible to study.},
booktitle = {Proceedings of the 24th ACM International Conference on Supercomputing},
pages = {233–242},
numpages = {10},
keywords = {modeling and simulation, infectious disease, network dynamics, parallel computation, interactive computation},
location = {Tsukuba, Ibaraki, Japan},
series = {ICS '10}
}

@inproceedings{10.5555/1867735.1867740,
author = {von Etter, Peter and Huttunen, Silja and Vihavainen, Arto and Vuorinen, Matti and Yangarber, Roman},
title = {Assessment of Utility in Web Mining for the Domain of Public Health},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {This paper presents ongoing work on application of Information Extraction (IE) technology to domain of Public Health, in a real-world scenario. A central issue in IE is the quality of the results. We present two novel points. First, we distinguish the criteria for quality: the objective criteria that measure correctness of the system's analysis in traditional terms (F-measure, recall and precision), and, on the other hand, subjective criteria that measure the utility of the results to the end-user.Second, to obtain measures of utility, we build an environment that allows users to interact with the system by rating the analyzed content. We then build and compare several classifiers that learn from the user's responses to predict the relevance scores for new events. We conduct experiments with learning to predict relevance, and discuss the results and their implications for text mining in the domain of Public Health.},
booktitle = {Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents},
pages = {29–37},
numpages = {9},
location = {Los Angeles, California},
series = {Louhi '10}
}

@inproceedings{10.5555/1867735.1867737,
author = {Bhatia, Ramanjot S. and Graystone, Amber and Davies, Ross A. and McClinton, Susan and Morin, Jason and Davies, Richard F.},
title = {Extracting Information for Generating a Diabetes Report Card from Free Text in Physicians Notes},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Achieving guideline-based targets in patients with diabetes is crucial for improving clinical outcomes and preventing long-term complications. Using electronic heath records (EHRs) to identify high-risk patients for further intervention by screening large populations is limited because many EHRs store clinical information as dictated and transcribed free text notes that are not amenable to statistical analysis. This paper presents the process of extracting elements needed for generating a diabetes report card from free text notes written in English. Numerical measurements, representing lab values and physical examinations results are extracted from free text documents and then stored in a structured database. Extracting diagnosis information and medication lists are work in progress. The complete dataset for this project is comprised of 81,932 documents from 30,459 patients collected over a period of 5 years. The patient population is considered high risk for diabetes as they have existing cardiovascular complications. Experimental results validate our method, demonstrating high precision (88.8--100%).},
booktitle = {Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents},
pages = {8–14},
numpages = {7},
location = {Los Angeles, California},
series = {Louhi '10}
}

@inproceedings{10.5555/1867735.1867743,
author = {Allvin, Helen and Carlsson, Elin and Dalianis, Hercules and Danielsson-Ojala, Riitta and Daudaravi\v{c}ius, Vidas and Hassel, Martin and Kokkinakis, Dimitrios and Lundgren-Laine, Helj\"{a} and Nilsson, Gunnar and Nytr\o{}, \O{}ystein and Salanter\"{a}, Sanna and Skeppstedt, Maria and Suominen, Hanna and Velupillai, Sumithra},
title = {Characteristics and Analysis of Finnish and Swedish Clinical Intensive Care Nursing Narratives},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {We present a comparative study of Finnish and Swedish free-text nursing narratives from intensive care. Although the two languages are linguistically very dissimilar, our hypothesis is that there are similarities that are important and interesting from a language technology point of view. This may have implications when building tools to support producing and using health care documentation. We perform a comparative qualitative analysis based on structure and content, as well as a comparative quantitative analysis on Finnish and Swedish Intensive Care Unit (ICU) nursing narratives. Our findings are that ICU nursing narratives in Finland and Sweden have many properties in common, but that many of these are challenging when it comes to developing language technology tools.},
booktitle = {Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents},
pages = {53–60},
numpages = {8},
location = {Los Angeles, California},
series = {Louhi '10}
}

@inproceedings{10.5555/1860631.1860644,
author = {Lloret, Elena and Saggion, Horacio and Palomar, Manuel},
title = {Experiments on Summary-Based Opinion Classification},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {We investigate the effect of text summarisation in the problem of rating-inference -- the task of associating a fine-grained numerical rating to an opinionated document. We set-up a comparison framework to study the effect of different summarisation algorithms of various compression rates in this task and compare the classification accuracy of summaries and documents for associating documents to classes. We make use of SVM algorithms to associate numerical ratings to opinionated documents. The algorithms are informed by linguistic and sentiment-based features computed from full documents and summaries. Preliminary results show that some types of summaries could be as effective or better as full documents in this problem.},
booktitle = {Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text},
pages = {107–115},
numpages = {9},
location = {Los Angeles, California},
series = {CAAGET '10}
}

@inproceedings{10.5555/1860631.1860643,
author = {Volkova, Ekaterina P. and Mohler, Betty J. and Meurers, Detmar and Gerdemann, Dale and B\"{u}lthoff, Heinrich H.},
title = {Emotional Perception of Fairy Tales: Achieving Agreement in Emotion Annotation of Text},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Emotion analysis (EA) is a rapidly developing area in computational linguistics. An EA system can be extremely useful in fields such as information retrieval and emotion-driven computer animation. For most EA systems, the number of emotion classes is very limited and the text units the classes are assigned to are discrete and predefined. The question we address in this paper is whether the set of emotion categories can be enriched and whether the units to which the categories are assigned can be more flexibly defined. We present an experiment showing how an annotation task can be set up so that untrained participants can perform emotion analysis with high agreement even when not restricted to a predetermined annotation unit and using a rich set of emotion categories. As such it sets the stage for the development of more complex EA systems which are closer to the actual human emotional perception of text.},
booktitle = {Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text},
pages = {98–106},
numpages = {9},
location = {Los Angeles, California},
series = {CAAGET '10}
}

@inproceedings{10.5555/1860649.1860653,
author = {Gerv\'{a}s, Pablo},
title = {Engineering Linguistic Creativity: Bird Flight and Jet Planes},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Man achieved flight by studying how birds fly, and yet the solution that engineers came up with (jet planes) is very different from the one birds apply. In this paper I review a number of efforts in automated story telling and poetry generation, identifying which human abilities are being modelled in each case. In an analogy to the classic example of bird-flight and jet planes, I explore how the computational models relate to (the little we know about) human performance, what the similarities are between the case for linguistic creativity and the case for flight, and what the analogy might have to say about artificial linguistic creativity if it were valid.},
booktitle = {Proceedings of the NAACL HLT 2010 Second Workshop on Computational Approaches to Linguistic Creativity},
pages = {23–30},
numpages = {8},
location = {Los Angeles, California},
series = {CALC '10}
}

@inproceedings{10.5555/1860631.1860632,
author = {Bellegarda, Jerome R.},
title = {Emotion Analysis Using Latent Affective Folding and Embedding},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Though data-driven in nature, emotion analysis based on latent semantic analysis still relies on some measure of expert knowledge in order to isolate the emotional keywords or keysets necessary to the construction of affective categories. This makes it vulnerable to any discrepancy between the ensuing taxonomy of affective states and the underlying domain of discourse. This paper proposes a more general strategy which leverages two distincts semantic levels, one that encapsulates the foundations of the domain considered, and one that specifically accounts for the overall affective fabric of the language. Exposing the emergent relationship between these two levels advantageously informs the emotion classification process. Empirical evidence suggests that this is a promising solution for automatic emotion detection in text.},
booktitle = {Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text},
pages = {1–9},
numpages = {9},
location = {Los Angeles, California},
series = {CAAGET '10}
}

@inproceedings{10.1145/1807167.1807247,
author = {Rastogi, Vibhor and Nath, Suman},
title = {Differentially Private Aggregation of Distributed Time-Series with Transformation and Encryption},
year = {2010},
isbn = {9781450300322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807167.1807247},
doi = {10.1145/1807167.1807247},
abstract = {We propose the first differentially private aggregation algorithm for distributed time-series data that offers good practical utility without any trusted server. This addresses two important challenges in participatory data-mining applications where (i) individual users collect temporally correlated time-series data (such as location traces, web history, personal health data), and (ii) an untrusted third-party aggregator wishes to run aggregate queries on the data.To ensure differential privacy for time-series data despite the presence of temporal correlation, we propose the Fourier Perturbation Algorithm (FPAk). Standard differential privacy techniques perform poorly for time-series data. To answer n queries, such techniques can result in a noise of Θ(n) to each query answer, making the answers practically useless if n is large. Our FPAk algorithm perturbs the Discrete Fourier Transform of the query answers. For answering n queries, FPAk improves the expected error from Θ(n) to roughly Θ(k) where k is the number of Fourier coefficients that can (approximately) reconstruct all the n query answers. Our experiments show that k &lt;&lt; n for many real-life data-sets resulting in a huge error-improvement for FPAk.To deal with the absence of a trusted central server, we propose the Distributed Laplace Perturbation Algorithm (DLPA) to add noise in a distributed way in order to guarantee differential privacy. To the best of our knowledge, DLPA is the first distributed differentially private algorithm that can scale with a large number of users: DLPA outperforms the only other distributed solution for differential privacy proposed so far, by reducing the computational load per user from O(U) to O(1) where U is the number of users.},
booktitle = {Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data},
pages = {735–746},
numpages = {12},
keywords = {output perturbation, time-series data, participatory data mining, distributed noise addition, private data analysis},
location = {Indianapolis, Indiana, USA},
series = {SIGMOD '10}
}

@inproceedings{10.1145/1807085.1807101,
author = {Nelson, Jelani and Woodruff, David P.},
title = {Fast Manhattan Sketches in Data Streams},
year = {2010},
isbn = {9781450300339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807085.1807101},
doi = {10.1145/1807085.1807101},
abstract = {The L1-distance, also known as the Manhattan or taxicab distance, between two vectors x, y in Rn is ∑_{i=1}overn |xi-y_i|. Approximating this distance is a fundamental primitive on massive databases, with applications to clustering, nearest neighbor search, network monitoring, regression, sampling, and support vector machines. We give the first 1-pass streaming algorithm for this problem in the turnstile model with O*(1/ε2) space and O*(1) update time. The O* notation hides polylogarithmic factors in ε, n, and the precision required to store vector entries. All previous algorithms either required Ω(1/ε3) space or Ω(1/ε2) update time and/or could not work in the turnstile model (i.e., support an arbitrary number of updates to each coordinate). Our bounds are optimal up to O*(1) factors.},
booktitle = {Proceedings of the Twenty-Ninth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
pages = {99–110},
numpages = {12},
keywords = {clustering, streaming, data mining, sketching},
location = {Indianapolis, Indiana, USA},
series = {PODS '10}
}

@inproceedings{10.1145/1807085.1807106,
author = {Kifer, Daniel and Lin, Bing-Rong},
title = {Towards an Axiomatization of Statistical Privacy and Utility},
year = {2010},
isbn = {9781450300339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807085.1807106},
doi = {10.1145/1807085.1807106},
abstract = {"Privacy" and "utility" are words that frequently appear in the literature on statistical privacy. But what do these words really mean? In recent years, many problems with intuitive notions of privacy and utility have been uncovered. Thus more formal notions of privacy and utility, which are amenable to mathematical analysis, are needed. In this paper we present our initial work on an axiomatization of privacy and utility. In particular, we study how these concepts are affected by randomized algorithms. Our analysis yields new insights into the construction of both privacy definitions and mechanisms that generate data according to such definitions. In particular, it characterizes a class of relaxations of differential privacy and shows that desirable outputs of a differentially private mechanism are best interpreted as certain graphs rather than query answers or synthetic data.},
booktitle = {Proceedings of the Twenty-Ninth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
pages = {147–158},
numpages = {12},
keywords = {privacy, utility, axioms},
location = {Indianapolis, Indiana, USA},
series = {PODS '10}
}

@inproceedings{10.5555/1866696.1866697,
author = {Callison-Burch, Chris and Dredze, Mark},
title = {Creating Speech and Language Data with Amazon's Mechanical Turk},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {In this paper we give an introduction to using Amazon's Mechanical Turk crowdsourcing platform for the purpose of collecting data for human language technologies. We survey the papers published in the NAACL-2010 Workshop. 24 researchers participated in the workshop's shared task to create data for speech and language applications with $100.},
booktitle = {Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon's Mechanical Turk},
pages = {1–12},
numpages = {12},
location = {Los Angeles, California},
series = {CSLDAMT '10}
}

@inproceedings{10.1145/1807167.1807291,
author = {Biem, Alain and Bouillet, Eric and Feng, Hanhua and Ranganathan, Anand and Riabov, Anton and Verscheure, Olivier and Koutsopoulos, Haris and Moran, Carlos},
title = {IBM Infosphere Streams for Scalable, Real-Time, Intelligent Transportation Services},
year = {2010},
isbn = {9781450300322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807167.1807291},
doi = {10.1145/1807167.1807291},
abstract = {With the widespread adoption of location tracking technologies like GPS, the domain of intelligent transportation services has seen growing interest in the last few years. Services in this domain make use of real-time location-based data from a variety of sources, combine this data with static location-based data such as maps and points of interest databases, and provide useful information to end-users. Some of the major challenges in this domain include i) scalability, in terms of processing large volumes of real-time and static data; ii) extensibility, in terms of being able to add new kinds of analyses on the data rapidly, and iii) user interaction, in terms of being able to support different kinds of one-time and continuous queries from the end-user. In this paper, we demonstrate the use of IBM InfoSphere Streams, a scalable stream processing platform, for tackling these challenges. We describe a prototype system that generates dynamic, multi-faceted views of transportation information for the city of Stockholm, using real vehicle GPS and road-network data. The system also continuously derives current traffic statistics, and provides useful value-added information such as shortest-time routes from real-time observed and inferred traffic conditions. Our performance experiments illustrate the scalability of the system. For instance, our system can process over 120000 incoming GPS points per second, combine it with a map containing over 600,000 links, continuously generate different kinds of traffic statistics and answer user queries.},
booktitle = {Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data},
pages = {1093–1104},
numpages = {12},
keywords = {transportation, geostreaming, stream processing},
location = {Indianapolis, Indiana, USA},
series = {SIGMOD '10}
}

@inproceedings{10.1145/1807167.1807292,
author = {Castellanos, Malu and Wang, Song and Dayal, Umeshwar and Gupta, Chetan},
title = {SIE-OBI: A Streaming Information Extraction Platform for Operational Business Intelligence},
year = {2010},
isbn = {9781450300322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807167.1807292},
doi = {10.1145/1807167.1807292},
abstract = {Emerging business intelligence (BI) applications aim to provide situational awareness, i.e., information about real-world events that might affect the business operations of an enterprise. For instance, an enterprise might want to know whether customers are posting positive or negative comments about a new product it has just introduced; or whether some natural disaster affects its contracted suppliers. It is difficult to develop such applications today because they require extracting and correlating facts from multiple streaming and stored data sources, typically including unstructured data, which is not well supported by BI platforms today. In this paper, we describe SIE-OBI, a system that we are developing to enable the development and execution of such applications. We describe the novel features of this system, including a declarative interface for rapidly developing such applications, and a platform for optimizing and executing the applications. We illustrate its applicability through two use cases.},
booktitle = {Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data},
pages = {1105–1110},
numpages = {6},
keywords = {business intelligence, correlation, information extraction, streaming data, situational awareness, unstructured data},
location = {Indianapolis, Indiana, USA},
series = {SIGMOD '10}
}

@inproceedings{10.1145/1807167.1807194,
author = {Tsirogiannis, Dimitris and Harizopoulos, Stavros and Shah, Mehul A.},
title = {Analyzing the Energy Efficiency of a Database Server},
year = {2010},
isbn = {9781450300322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807167.1807194},
doi = {10.1145/1807167.1807194},
abstract = {Rising energy costs in large data centers are driving an agenda for energy-efficient computing. In this paper, we focus on the role of database software in affecting, and, ultimately, improving the energy efficiency of a server. We first characterize the power-use profiles of database operators under different configuration parameters. We find that common database operations can exercise the full dynamic power range of a server, and that the CPU power consumption of different operators, for the same CPU utilization, can differ by as much as 60%. We also find that for these operations CPU power does not vary linearly with CPU utilization.We then experiment with several classes of database systems and storage managers, varying parameters that span from different query plans to compression algorithms and from physical layout to CPU frequency and operating system scheduling. Contrary to what recent work has suggested, we find that within a single node intended for use in scale-out (shared-nothing) architectures, the most energy-efficient configuration is typically the highest performing one. We explain under which circumstances this is not the case, and argue that these circumstances do not warrant a retargeting of database system optimization goals. Further, our results reveal opportunities for cross-node energy optimizations and point out directions for new scale-out architectures.},
booktitle = {Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data},
pages = {231–242},
numpages = {12},
keywords = {power consumption, energy efficiency, database server, ssd, cpu power},
location = {Indianapolis, Indiana, USA},
series = {SIGMOD '10}
}

@inproceedings{10.1145/1807167.1807269,
author = {Karvounarakis, Grigoris and Ives, Zachary G. and Tannen, Val},
title = {Querying Data Provenance},
year = {2010},
isbn = {9781450300322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807167.1807269},
doi = {10.1145/1807167.1807269},
abstract = {Many advanced data management operations (e.g., incremental maintenance, trust assessment, debugging schema mappings, keyword search over databases, or query answering in probabilistic databases), involve computations that look at how a tuple was produced, e.g., to determine its score or existence. This requires answers to queries such as, "Is this data derivable from trusted tuples?"; "What tuples are derived from this relation?"; or "What score should this answer receive, given initial scores of the base tuples?". Such questions can be answered by consulting the provenance of query results.In recent years there has been significant progress on formal models for provenance. However, the issues of provenance storage, maintenance, and querying have not yet been addressed in an application-independent way. In this paper, we adopt the most general formalism for tuple-based provenance, semiring provenance. We develop a query language for provenance, which can express all of the aforementioned types of queries, as well as many more; we propose storage, processing and indexing schemes for data provenance in support of these queries; and we experimentally validate the feasibility of provenance querying and the benefits of our indexing techniques across a variety of application classes and queries.},
booktitle = {Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data},
pages = {951–962},
numpages = {12},
keywords = {query language, data provenance, annotation, query processing},
location = {Indianapolis, Indiana, USA},
series = {SIGMOD '10}
}

@inproceedings{10.1145/1809049.1809079,
author = {Eastep, Jonathan and Wingate, David and Santambrogio, Marco D. and Agarwal, Anant},
title = {Smartlocks: Lock Acquisition Scheduling for Self-Aware Synchronization},
year = {2010},
isbn = {9781450300742},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1809049.1809079},
doi = {10.1145/1809049.1809079},
abstract = {As multicore processors become increasingly prevalent, system complexity is skyrocketing. The advent of the asymmetric multicore compounds this - it is no longer practical for an average programmer to balance the system constraints associated with today's multicores and worry about new problems like asymmetric partitioning and thread interference. Adaptive, or self-aware, computing has been proposed as one method to help application and system programmers confront this complexity. These systems take some of the burden off of programmers by monitoring themselves and optimizing or adapting to meet their goals.This paper introduces a self-aware synchronization library for multicores and asymmetric multicores called Smartlocks. Smartlocks is a spin-lock library that adapts its internal implementation during execution using heuristics and machine learning to optimize toward a user-defined goal, which may relate to performance or problem-specific criteria. Smartlocks builds upon adaptation techniques from prior work like reactive locks [1], but introduces a novel form of adaptation that we term lock acquisition scheduling designed specifically to address asymmetries in multicores. Lock acquisition scheduling is optimizing which waiter will get the lock next for the best long-term effect when multiple threads (or processes) are spinning for a lock.This work demonstrates that lock scheduling is important for addressing asymmetries in multicores. We study scenarios where core speeds vary both dynamically and intrinsically under thermal throttling and manufacturing variability, respectively, and we show that Smartlocks significantly outperforms conventional spin-locks and reactive locks. Based on our findings, we provide guidelines for application scenarios where Smartlocks works best versus less optimally.},
booktitle = {Proceedings of the 7th International Conference on Autonomic Computing},
pages = {215–224},
numpages = {10},
keywords = {asymmetric multicore, performance optimization, synchronization, self-tuning, heterogeneous multicore, self-aware},
location = {Washington, DC, USA},
series = {ICAC '10}
}

@inproceedings{10.1145/1809049.1809065,
author = {Hoffmann, Henry and Eastep, Jonathan and Santambrogio, Marco D. and Miller, Jason E. and Agarwal, Anant},
title = {Application Heartbeats: A Generic Interface for Specifying Program Performance and Goals in Autonomous Computing Environments},
year = {2010},
isbn = {9781450300742},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1809049.1809065},
doi = {10.1145/1809049.1809065},
abstract = {The rise of multicore computing has greatly increased system complexity and created an additional burden for software developers. This burden is especially troublesome when it comes to optimizing software on modern computing systems. Autonomic or adaptive computing has been proposed as one method to help application programmers handle this complexity. In an autonomic computing environment, system services monitor applications and automatically adapt their behavior to increase the performance of the applications they support. Unfortunately, applications often run as performance black-boxes and adaptive services must infer application performance from low-level information or rely on system-specific ad hoc methods. This paper proposes a standard framework, Application Heartbeats, which applications can use to communicate both their current and target performance and which autonomic services can use to query these values.The Application Heartbeats framework is designed around the well-known idea of a heartbeat. At important points in the program, the application registers a heartbeat. In addition, the interface allows applications to express their performance in terms of a desired heart rate and/or a desired latency between specially tagged heartbeats. Thus, the interface provides a standard method for an application to directly communicate its performance and goals while allowing autonomic services access to this information. Thus, Heartbeat-enabled applications are no longer performance black-boxes. This paper presents the Applications Heartbeats interface, characterizes two reference implementations (one suitable for clusters and one for multicore), and illustrates the use of Heartbeats with several examples of systems adapting behavior based on feedback from heartbeats.},
booktitle = {Proceedings of the 7th International Conference on Autonomic Computing},
pages = {79–88},
numpages = {10},
keywords = {self-tuning systems, adaptive computing},
location = {Washington, DC, USA},
series = {ICAC '10}
}

@inproceedings{10.1145/1809029.1809033,
author = {Collet, Philippe and K\v{r}ikava, Filip and Montagnat, Johan and Blay-Fornarino, Mireille and Manset, David},
title = {Issues and Scenarios for Self-Managing Grid Middleware},
year = {2010},
isbn = {9781450301008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1809029.1809033},
doi = {10.1145/1809029.1809033},
abstract = {Despite significant efforts to achieve reliable grid middlewares, grid infrastructures still encounter important difficulties to implement the promise of ubiquitous, seamless and transparent computing. Identified causes are numerous, such as the complexity of middleware stacks, dependence to many distributed resources, heterogeneity of hardware and software operated or incompatibilities between software components declared as interoperable. Based on failures that occurred during a large data challenge run on a grid dedicated to neuroscience, we identify scenarios that can be handled through autonomic management associated to the grid middleware. We also outline a flexible self-adaptive framework that aims at using model-driven development to facilitate the engineering, integration and reuse of MAPE-K loops in large scale distributed systems.},
booktitle = {Proceedings of the 2nd Workshop on Grids Meets Autonomic Computing},
pages = {1–10},
numpages = {10},
keywords = {SCA, model driven engineering, grid computing, SALTY, medical image analysis, neuGRID, autonomic computing, self-adaptive systems},
location = {Washington, DC, USA},
series = {GMAC '10}
}

@inproceedings{10.1145/1809939.1809960,
author = {DeCarlo, Doug and Stone, Matthew},
title = {Visual Explanations},
year = {2010},
isbn = {9781450301251},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1809939.1809960},
doi = {10.1145/1809939.1809960},
abstract = {Human perceptual processes organize visual input to make the structure of the world explicit. Successful techniques for automatic depiction, meanwhile, create images whose structure clearly matches the visual information to be conveyed. We discuss how analyzing these structures and realizing them in formal representations can allow computer graphics to engage with perceptual science, to mutual benefit. We call these representations visual explanations: their job is to account for patterns in two dimensions as evidence of a visual world.},
booktitle = {Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering},
pages = {173–178},
numpages = {6},
keywords = {perception, non-photorealism, depiction},
location = {Annecy, France},
series = {NPAR '10}
}

@inproceedings{10.1145/1810543.1810609,
author = {Toscos, Tammy},
title = {Using Data to Promote Healthy Behavior in Children},
year = {2010},
isbn = {9781605589510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1810543.1810609},
doi = {10.1145/1810543.1810609},
abstract = {Childhood offers a number of opportunities for parents to shape the health related attitudes and behaviors of their children. The proposed research described in this paper aims to better understand the ways in which a child's personal health data can be leveraged to educate and provide a transition to healthy adult behaviors. The target population for this project is children with Type 1 Diabetes and their parents but many of the design issues may be relevant to the management of other chronic diseases as well as general health in childhood.},
booktitle = {Proceedings of the 9th International Conference on Interaction Design and Children},
pages = {344–347},
numpages = {4},
location = {Barcelona, Spain},
series = {IDC '10}
}

@article{10.1145/1754393.1754394,
author = {Chen, Teh-Chung and Dick, Scott and Miller, James},
title = {Detecting Visually Similar Web Pages: Application to Phishing Detection},
year = {2010},
issue_date = {May 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/1754393.1754394},
doi = {10.1145/1754393.1754394},
abstract = {We propose a novel approach for detecting visual similarity between two Web pages. The proposed approach applies Gestalt theory and considers a Web page as a single indivisible entity. The concept of supersignals, as a realization of Gestalt principles, supports our contention that Web pages must be treated as indivisible entities. We objectify, and directly compare, these indivisible supersignals using algorithmic complexity theory. We illustrate our approach by applying it to the problem of detecting phishing scams. Via a large-scale, real-world case study, we demonstrate that 1) our approach effectively detects similar Web pages; and 2) it accuractely distinguishes legitimate and phishing pages.},
journal = {ACM Trans. Internet Technol.},
month = jun,
articleno = {5},
numpages = {38},
keywords = {Gestalt theory, Algorithmic complexity theory, anti-phishing technologies, Web page similarity}
}

@inproceedings{10.1145/1810617.1810637,
author = {Cartledge, Charles L. and Nelson, Michael L.},
title = {Analysis of Graphs for Digital Preservation Suitability},
year = {2010},
isbn = {9781450300414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1810617.1810637},
doi = {10.1145/1810617.1810637},
abstract = {We investigate the use of autonomically created small-world graphs as a framework for the long term storage of digital objects on the Web in a potentially hostile environment. We attack the classic Erdos --- Renyi random, Barab\'{a}si and Albert power law, Watts --- Strogatz small world and our Unsupervise. Small World (USW) graphs using different attacker strategies and report their respective robustness. Using different attacker profiles, we construct a game where the attacker is allowed to use a strategy of his choice to remove a percentage of each graph's elements. The graph is then allowed to repair some portion of its self. We report on the number of alternating attack and repair turns until either the graph is disconnected, or the game exceeds the number of permitted turns. Based on our analysis, an attack strategy that focuses on removing the vertices with the highest betweenness value is most advantageous to the attacker. Power law graphs can become disconnected with the removal of a single edge; random graphs with the removal of as few as 1% of their vertices, small-world graphs with the removal of 14% vertices, and USW with the removal of 17% vertices. Watts --- Strogatz small-world graphs are more robust and resilient than random or power law graphs. USW graphs are more robust and resilient than small world graphs. A graph of USW connected WOs filled with date could outlive the individuals and institutions that created the data in an environment where WOs are lost due to random failures or directed attacks.},
booktitle = {Proceedings of the 21st ACM Conference on Hypertext and Hypermedia},
pages = {109–118},
numpages = {10},
keywords = {small world, robustness, resilience},
location = {Toronto, Ontario, Canada},
series = {HT '10}
}

@inproceedings{10.1145/1811039.1811068,
author = {Casale, Giuliano and Mi, Ningfang and Smirni, Evgenia},
title = {CWS: A Model-Driven Scheduling Policy for Correlated Workloads},
year = {2010},
isbn = {9781450300384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1811039.1811068},
doi = {10.1145/1811039.1811068},
abstract = {We define CWS, a non-preemptive scheduling policy for workloads with correlated job sizes. CWS tackles the scheduling problem by inferring the expected sizes of upcoming jobs based on the structure of correlations and on the outcome of past scheduling decisions. Size prediction is achieved using a class of Hidden Markov Models (HMM) with continuous observation densities that describe job sizes. We show how the forward-backward algorithm of HMMs applies effectively in scheduling applications and how it can be used to derive closed-form expressions for size prediction. This is particularly simple to implement in the case of observation densities that are phase-type (PH-type) distributed, where existing fitting methods for Markovian point processes may also simplify the parameterization of the HMM workload model.Based on the job size predictions, CWS emulates size-based policies which favor short jobs, with accuracy depending mainly on the HMM used to parametrize the scheduling algorithm. Extensive simulation and analysis illustrate that CWS is competitive with policies that assume exact information about the workload.},
booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {251–262},
numpages = {12},
keywords = {stochastic sheduling, model-driven scheduling, response time, correlated workload},
location = {New York, New York, USA},
series = {SIGMETRICS '10}
}

@article{10.1145/1811099.1811068,
author = {Casale, Giuliano and Mi, Ningfang and Smirni, Evgenia},
title = {CWS: A Model-Driven Scheduling Policy for Correlated Workloads},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/1811099.1811068},
doi = {10.1145/1811099.1811068},
abstract = {We define CWS, a non-preemptive scheduling policy for workloads with correlated job sizes. CWS tackles the scheduling problem by inferring the expected sizes of upcoming jobs based on the structure of correlations and on the outcome of past scheduling decisions. Size prediction is achieved using a class of Hidden Markov Models (HMM) with continuous observation densities that describe job sizes. We show how the forward-backward algorithm of HMMs applies effectively in scheduling applications and how it can be used to derive closed-form expressions for size prediction. This is particularly simple to implement in the case of observation densities that are phase-type (PH-type) distributed, where existing fitting methods for Markovian point processes may also simplify the parameterization of the HMM workload model.Based on the job size predictions, CWS emulates size-based policies which favor short jobs, with accuracy depending mainly on the HMM used to parametrize the scheduling algorithm. Extensive simulation and analysis illustrate that CWS is competitive with policies that assume exact information about the workload.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = jun,
pages = {251–262},
numpages = {12},
keywords = {model-driven scheduling, correlated workload, stochastic sheduling, response time}
}

@inproceedings{10.1145/1874590.1874616,
author = {Al-Jedaiah, Mohamad and Masadeh, Shadi R. and Abu-Errub, Aymen M. and Areiqat, Ahmad Y.},
title = {The Impact of Web Applications on Decision-Making Process in the Public Sector},
year = {2010},
isbn = {9781450304757},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1874590.1874616},
doi = {10.1145/1874590.1874616},
abstract = {This paper aims to identify the impact of Web Applications on the decision-making process in the public sector. By citing international experiences (The Taxation System in Europe Union) and the Solid Waste Association of North America as case studies. The most important findings were firstly that the public sector has to gather complex information through using technological equipments and software. Secondly, public sector organizations can build their own web applications. And finally, Web applications provide a significant help to the decision maker, and enable to exchange information with other governments.},
booktitle = {Proceedings of the 1st International Conference on Intelligent Semantic Web-Services and Applications},
articleno = {26},
numpages = {5},
keywords = {public sector, information technology, web applications, e-government},
location = {Amman, Jordan},
series = {ISWSA '10}
}

@inproceedings{10.1145/1814433.1814450,
author = {Ganti, Raghu K. and Pham, Nam and Ahmadi, Hossein and Nangia, Saurabh and Abdelzaher, Tarek F.},
title = {GreenGPS: A Participatory Sensing Fuel-Efficient Maps Application},
year = {2010},
isbn = {9781605589855},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1814433.1814450},
doi = {10.1145/1814433.1814450},
abstract = {This paper develops a navigation service, called GreenGPS, that uses participatory sensing data to map fuel consumption on city streets, allowing drivers to find the most fuel efficient routes for their vehicles between arbitrary end-points. The service exploits measurements of vehicular fuel consumption sensors, available via the OBD-II interface standardized in all vehicles sold in the US since 1996. The interface gives access to most gauges and engine instrumentation. The most fuel-efficient route does not always coincide with the shortest or fastest routes, and may be a function of vehicle type. Our experimental study shows that a participatory sensing system can influence routing decisions of individual users and also answers two questions related to the viability of the new service. First, can it survive conditions of sparse deployment? Second, how much fuel can it save? A challenge in participatory sensing is to generalize from sparse sampling of high-dimensional spaces to produce compact descriptions of complex phenomena. We illustrate this by developing models that can predict fuel consumption of a set of sixteen different cars on the streets of the city of Urbana-Champaign. We provide experimental results from data collection suggesting that a 1% average prediction error is attainable and that an average 10% savings in fuel can be achieved by choosing the right route.},
booktitle = {Proceedings of the 8th International Conference on Mobile Systems, Applications, and Services},
pages = {151–164},
numpages = {14},
keywords = {green navigation, participatory sensing, green GPS, model clustering},
location = {San Francisco, California, USA},
series = {MobiSys '10}
}

@inproceedings{10.1145/1839379.1839430,
author = {Lefter, Iulia and Wiggers, Pascal and Rothkrantz, Leon J. M.},
title = {EmoReSp: An Online Emotion Recognizer Based on Speech},
year = {2010},
isbn = {9781450302432},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839379.1839430},
doi = {10.1145/1839379.1839430},
abstract = {The paper describes the development of an online real-time system able to recognize emotions from speech. A prosodic feature set was extracted from four databases of emotional speech (three with acted emotions and one with spontaneous ones). Two models were trained using support vector machines (SVM) or merged databases, for the purpose of providing a larger range of examples to the classifier and making it more general. The system outputs probabilities of a closed set of emotions and provides a time track of the emotions recognized in the valence and arousal continuum.},
booktitle = {Proceedings of the 11th International Conference on Computer Systems and Technologies and Workshop for PhD Students in Computing on International Conference on Computer Systems and Technologies},
pages = {287–292},
numpages = {6},
keywords = {emotional speech databases, real-time emotion recognition, machine learning, speech},
location = {Sofia, Bulgaria},
series = {CompSysTech '10}
}

@inproceedings{10.1145/1822348.1822365,
author = {McGee, Kevin and Abraham, Aswin Thomas},
title = {Real-Time Team-Mate AI in Games: A Definition, Survey, &amp; Critique},
year = {2010},
isbn = {9781605589374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1822348.1822365},
doi = {10.1145/1822348.1822365},
abstract = {Many contemporary games are team-based and there is a growing interest in, and need for, advances in team-mate AI for games. However, although there have been surveys of agent AI in games, to date there has been no survey of work on team-mate AI. Furthermore, the concept of "team-mate AI" is not currently well delineated to distinguish between work on independently-acting agents that happen to be on the same side from work on agents the coordinate their behaviors and decision-making in terms of their teammates behaviors, intentions, and the like. Also, it is important to distinguish between game AI that is used as an optimization technique from real-time game AI, so this paper proposes a definition for real-time team-mate AI (highlighted with examples by game genre), reviews work to date to implement real-time team-mate AI for games in terms of a number of AI research areas (e.g., coordinated action, prediction, learning), and concludes with a brief discussion of significant issues about the state of the art.},
booktitle = {Proceedings of the Fifth International Conference on the Foundations of Digital Games},
pages = {124–131},
numpages = {8},
location = {Monterey, California},
series = {FDG '10}
}

@inproceedings{10.1145/1822348.1822370,
author = {Rossoff, Sam and Tzanetakis, George and Gooch, Bruce},
title = {Adapting Personal Music for Synesthetic Game Play},
year = {2010},
isbn = {9781605589374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1822348.1822370},
doi = {10.1145/1822348.1822370},
abstract = {Music can significantly effect game play and help players understand underlying patterns in the game, or the effects of their actions on the characters. Conversely, inappropriate music can have a negative effect on players by creating additional difficulties. While game makers recognize the effects of music on game play, solutions that provide users with a choice in personal music are not forthcoming. We design, implement and evaluate an algorithm for automatically adapting an arbitrary music track from a personal library and synchronizing play back to the user, without requiring any access to the video game source code.},
booktitle = {Proceedings of the Fifth International Conference on the Foundations of Digital Games},
pages = {163–170},
numpages = {8},
location = {Monterey, California},
series = {FDG '10}
}

@inproceedings{10.1145/1822018.1822057,
author = {Schmidt, Benedikt and Stoitsev, Todor and M\"{u}hlh\"{a}user, Max},
title = {Activity-Centric Support for Weakly-Structured Business Processes},
year = {2010},
isbn = {9781450300834},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1822018.1822057},
doi = {10.1145/1822018.1822057},
abstract = {Knowledge-intensive tasks are a blind spot for business process management systems, as these tasks are executed in an unsupervised, highly individual manner. Hence, individual experience is not disseminated and task execution largely depends on implicit knowledge.In this paper we present a framework, realizing situation-specific and personalized task execution support for knowledge-intensive tasks in business processes. As a core concept we suggest activity scheme: a structure capturing a probabilistic task execution model. Activity schemes seamlessly integrate the organizational business process with the individual task execution process based on personalization and generalization of user interactions in the working applications.},
booktitle = {Proceedings of the 2nd ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
pages = {251–260},
numpages = {10},
keywords = {knowledge work support, human-computer interaction, task execution support},
location = {Berlin, Germany},
series = {EICS '10}
}

@inproceedings{10.1145/1815961.1816002,
author = {Janapa Reddi, Vijay and Lee, Benjamin C. and Chilimbi, Trishul and Vaid, Kushagra},
title = {Web Search Using Mobile Cores: Quantifying and Mitigating the Price of Efficiency},
year = {2010},
isbn = {9781450300537},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1815961.1816002},
doi = {10.1145/1815961.1816002},
abstract = {The commoditization of hardware, data center economies of scale, and Internet-scale workload growth all demand greater power efficiency to sustain scalability. Traditional enterprise workloads, which are typically memory and I/O bound, have been well served by chip multiprocessors com- prising of small, power-efficient cores. Recent advances in mobile computing have led to modern small cores capable of delivering even better power efficiency. While these cores can deliver performance-per-Watt efficiency for data center workloads, small cores impact application quality-of-service robustness, and flexibility, as these workloads increasingly invoke computationally intensive kernels. These challenges constitute the price of efficiency. We quantify efficiency for an industry-strength online web search engine in production at both the microarchitecture- and system-level, evaluating search on server and mobile-class architectures using Xeon and Atom processors.},
booktitle = {Proceedings of the 37th Annual International Symposium on Computer Architecture},
pages = {314–325},
numpages = {12},
keywords = {web search, bing, mobile cores, energy efficiency},
location = {Saint-Malo, France},
series = {ISCA '10}
}

@article{10.1145/1816038.1816002,
author = {Janapa Reddi, Vijay and Lee, Benjamin C. and Chilimbi, Trishul and Vaid, Kushagra},
title = {Web Search Using Mobile Cores: Quantifying and Mitigating the Price of Efficiency},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {3},
issn = {0163-5964},
url = {https://doi.org/10.1145/1816038.1816002},
doi = {10.1145/1816038.1816002},
abstract = {The commoditization of hardware, data center economies of scale, and Internet-scale workload growth all demand greater power efficiency to sustain scalability. Traditional enterprise workloads, which are typically memory and I/O bound, have been well served by chip multiprocessors com- prising of small, power-efficient cores. Recent advances in mobile computing have led to modern small cores capable of delivering even better power efficiency. While these cores can deliver performance-per-Watt efficiency for data center workloads, small cores impact application quality-of-service robustness, and flexibility, as these workloads increasingly invoke computationally intensive kernels. These challenges constitute the price of efficiency. We quantify efficiency for an industry-strength online web search engine in production at both the microarchitecture- and system-level, evaluating search on server and mobile-class architectures using Xeon and Atom processors.},
journal = {SIGARCH Comput. Archit. News},
month = jun,
pages = {314–325},
numpages = {12},
keywords = {mobile cores, energy efficiency, web search, bing}
}

@inproceedings{10.1145/1851476.1851572,
author = {Bhagawaty, Harsha and Jiang, Lei and Pothanis, Sreekanth and Allen, Gabrielle and Brener, Nathan and Kosar, Tevfik},
title = {Design, Implementation and Use of a Simulation Data Archive for Coastal Science},
year = {2010},
isbn = {9781605589428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851476.1851572},
doi = {10.1145/1851476.1851572},
abstract = {With many researchers now having easy access to supercomputers, coastal scientists are able to develop and run simulations that model the physical and ecological processes in ocean or nearshore areas in a distributed and collaborative environment. However, the increase in capacity of computational resources does not lead directly to a rapid improvement of the simulations themselves. Instead, it brings a new challenge that motivates scientists to fully utilize the huge amount of simulation data created in supercomputers, thus fostering advanced scientific research. Driven by the urgent need for in-depth investigations in Louisiana coastal areas, especially during hurricane seasons, a data center, which provides research communities with scientific data resources on demand, is imperative. In this paper, we present the design, implementation and use of such a simulation data archive for coastal science. The simulation data archive is capable of providing interfaces based on the requirements of user groups and its application incorporates multiple use cases. The enabling technology, as well as the challenges in the development of this simulation data archive, are also described in this paper.},
booktitle = {Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing},
pages = {651–657},
numpages = {7},
location = {Chicago, Illinois},
series = {HPDC '10}
}

@inproceedings{10.1145/1851476.1851593,
author = {Ekanayake, Jaliya and Li, Hui and Zhang, Bingjing and Gunarathne, Thilina and Bae, Seung-Hee and Qiu, Judy and Fox, Geoffrey},
title = {Twister: A Runtime for Iterative MapReduce},
year = {2010},
isbn = {9781605589428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851476.1851593},
doi = {10.1145/1851476.1851593},
abstract = {MapReduce programming model has simplified the implementation of many data parallel applications. The simplicity of the programming model and the quality of services provided by many implementations of MapReduce attract a lot of enthusiasm among distributed computing communities. From the years of experience in applying MapReduce to various scientific applications we identified a set of extensions to the programming model and improvements to its architecture that will expand the applicability of MapReduce to more classes of applications. In this paper, we present the programming model and the architecture of Twister an enhanced MapReduce runtime that supports iterative MapReduce computations efficiently. We also show performance comparisons of Twister with other similar runtimes such as Hadoop and DryadLINQ for large scale data parallel applications.},
booktitle = {Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing},
pages = {810–818},
numpages = {9},
keywords = {iterative algorithms, cloud technologies, MapReduce},
location = {Chicago, Illinois},
series = {HPDC '10}
}

@inproceedings{10.1145/1851476.1851487,
author = {Du, Juan and Gu, Xiaohui and Reeves, Douglas S.},
title = {Highly Available Component Sharing in Large-Scale Multi-Tenant Cloud Systems},
year = {2010},
isbn = {9781605589428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851476.1851487},
doi = {10.1145/1851476.1851487},
abstract = {A multi-tenant cloud system allows multiple users to share a common physical computing infrastructure in a cost-effective way. Component sharing is highly desired in such a shared computing infrastructure, where different tenants can leverage each other's information and expertise to fulfill their own tasks. However, it is challenging to maintain the availability of sharable component resources in a large-scale cloud infrastructure, as cloud tenants are fully autonomous and highly dynamic. In this paper, we present a novel highly available component sharing system for large-scale multi-tenant cloud systems. We describe a component availability prediction scheme to identify endangered components (i.e., components at risk of extinction) within the infrastructure. The system then performs predictive replication based on the availability prediction results to preserve those endangered components. Thus, our system can preserve the availability of all component resources with low cost. Theoretical analysis and large-scale simulation are used to quantify the accuracy of our component availability prediction, and the efficiency of predictive replication. Experimental results show that our scheme can predict endangered components with high accuracy, and achieve up to 99% availability with about 15% of the full replication cost.},
booktitle = {Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing},
pages = {85–94},
numpages = {10},
keywords = {component sharing, high availability, cloud computing},
location = {Chicago, Illinois},
series = {HPDC '10}
}

@inproceedings{10.1145/1851476.1851562,
author = {Wojciechowski, Maciej and Capot\u{a}, Mihai and Pouwelse, Johan and Iosup, Alexandru},
title = {BTWorld: Towards Observing the Global BitTorrent File-Sharing Network},
year = {2010},
isbn = {9781605589428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851476.1851562},
doi = {10.1145/1851476.1851562},
abstract = {Today, the BitTorrent Peer-to-Peer file-sharing network is one of the largest Internet applications---it generates massive traffic volumes, it is deployed in thousands of independent communities, and it serves millions of unique users worldwide. Despite a large number of empirical and theoretical studies, observing the state of the global BitTorrent network remains a grand challenge for the BitTorrent community. To address this challenge, in this work we introduce BT-World, an architecture for observing the global BitTorrent network without help from the ISPs. We design BTWorld around three main features specific to BitTorrent measurements. First, our architecture is able to find public trackers, that is, the BitTorrent components that offer unrestricted service to peers around the world. Second, by observing the state of these trackers, BTWorld obtains information about the performance, scalability, and reliability of BitTorrent. Third, BTWorld is designed to pre-process the large volumes of recorded data for later analysis. We demonstrate the viability of our architecture by deploying it in practice, to observe and analyze one week of operation of a large part of the global BitTorrent network--over 10 million swarms and tens of millions of concurrent users. We also show that BT-World can shed light on BitTorrent phenomena, such as the presence of spam trackers and giant swarms.},
booktitle = {Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing},
pages = {581–588},
numpages = {8},
location = {Chicago, Illinois},
series = {HPDC '10}
}

@inproceedings{10.1145/1851476.1851506,
author = {Rajanna, Vijay Shankar and Shah, Smit and Jahagirdar, Anand and Lemoine, Christopher and Gopalan, Kartik},
title = {XCo: Explicit Coordination to Prevent Network Fabric Congestion in Cloud Computing Cluster Platforms},
year = {2010},
isbn = {9781605589428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851476.1851506},
doi = {10.1145/1851476.1851506},
abstract = {Large cluster-based cloud computing platforms increasingly use commodity Ethernet technologies, such as Gigabit Ethernet, 10GigE, and Fibre Channel over Ethernet (FCoE), for intra-cluster communication. Traffic congestion can become a performance concern in the Ethernet due to consolidation of data, storage, and control traffic over a common layer-2 fabric, as well as consolidation of multiple virtual machines (VMs) over less physical hardware. Even as networking vendors race to develop switch-level hardware support for congestion management, we make the case that virtualization has opened up a complementary set of opportunities to reduce or even eliminate network congestion in cloud computing clusters. We present the design, implementation, and evaluation of a system called XCo, that performs explicit coordination of network transmissions over a shared Ethernet fabric to proactively prevent network congestion. XCo is a software-only distributed solution executing only in the end-nodes. A central controller uses explicit permissions to temporally separate (at millisecond granularity) the transmissions from competing senders through congested links. XCo is fully transparent to applications, presently deployable, and independent of any switch-level hardware support. We present a detailed evaluation of our XCo prototype across a number of network congestion scenarios, and demonstrate that XCo significantly improves network performance during periods of congestion.},
booktitle = {Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing},
pages = {252–263},
numpages = {12},
keywords = {ethernet, virtualization, congestion},
location = {Chicago, Illinois},
series = {HPDC '10}
}

@inproceedings{10.1145/1816123.1816168,
author = {Angrosh, M. A. and Cranefield, Stephen and Stanger, Nigel},
title = {Context Identification of Sentences in Related Work Sections Using a Conditional Random Field: Towards Intelligent Digital Libraries},
year = {2010},
isbn = {9781450300858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1816123.1816168},
doi = {10.1145/1816123.1816168},
abstract = {Identification of contexts associated with sentences is becoming increasingly necessary for developing intelligent information retrieval systems. This article describes a supervised learning mechanism employing a conditional random field (CRF) for context identification and sentence classification. Specifically, we focus on sentences in related work sections in research articles. Based on a generic rhetorical pattern, a framework for modelling the sequential flow in these sections is proposed. Adopting a generalization strategy, each of these sentences is transformed into a set of features, which forms our dataset. We distinguish between two kinds of features for each of these sentences viz., citation features and sentence features. While an overall accuracy of 96.51% is achieved by using a combination of both citation and sentence features, the use of sentence features alone yields an accuracy of 93.22%. The results also show F-Scores ranging from 0.99 to 0.90 for various classes indicating the robustness of our application.},
booktitle = {Proceedings of the 10th Annual Joint Conference on Digital Libraries},
pages = {293–302},
numpages = {10},
keywords = {linear chain CRFs, citation classification, conditional random fields, sentence classification},
location = {Gold Coast, Queensland, Australia},
series = {JCDL '10}
}

@inproceedings{10.1145/1816123.1816150,
author = {Bae, Soonil and Kim, DoHyoung and Meintanis, Konstantinos and Moore, J. Michael and Zacchi, Anna and Shipman, Frank and Hsieh, Haowei and Marshall, Catherine C.},
title = {Supporting Document Triage via Annotation-Based Multi-Application Visualizations},
year = {2010},
isbn = {9781450300858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1816123.1816150},
doi = {10.1145/1816123.1816150},
abstract = {For open-ended information tasks, users must sift through many potentially relevant documents, a practice we refer to as document triage. Normally, people perform triage using multiple applications in concert: a search engine interface presents lists of potentially relevant documents; a document reader displays their contents; and a third tool--a text editor or personal information management application--is used to record notes and assessments. To support document triage, we have developed an extensible multi-application architecture that initially includes an information workspace and a document reader. An Interest Profile Manager infers users' interests from their interactions with the triage applications, coupled with the characteristics of the documents they are interacting with. The resulting interest profile is used to generate visualizations that direct users' attention to documents or parts of documents that match their inferred interests. The novelty of our approach lies in the aggregation of activity records across applications to generate fine-grained models of user interest.},
booktitle = {Proceedings of the 10th Annual Joint Conference on Digital Libraries},
pages = {177–186},
numpages = {10},
keywords = {visualization, multi-application user modeling, document triage},
location = {Gold Coast, Queensland, Australia},
series = {JCDL '10}
}

@inproceedings{10.1145/1839294.1839317,
author = {Byrne, Richard and Eslambolchilar, Parisa and Crossan, Andrew},
title = {Health Monitoring Using Gait Phase Effects},
year = {2010},
isbn = {9781450300711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839294.1839317},
doi = {10.1145/1839294.1839317},
abstract = {The need to monitor patients after they leave the hospital or clinics is of growing concern and doctors may need the facility to monitor certain patients more than others. For example patients with high blood pressure are sometimes fitted with a mobile monitor which can be used to track the patients blood pressure over time. Patients suffering from depression, however, may also need to be monitored to ensure that they are in a happy emotional state. In this paper we introduce an alternative approach to mood detection and tracking based on built-in accelerometer sensors found in common mobile phones. Our method can be seen to compliment the need to monitor such patients allowing for doctors to get in touch with them when their mood has altered. We build a system based on neural networks which takes the gait information and learns the associated mood of the user. This trained model is then used to detect the mood of the individuals. We demonstrate preliminary results on mood detection using a mobile prototype system.},
booktitle = {Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {19},
numpages = {7},
keywords = {mood tracking, mood detection, health monitoring, tracking, gait, gait phase, gait phase effects},
location = {Samos, Greece},
series = {PETRA '10}
}

@inproceedings{10.1145/1839294.1839346,
author = {Liolios, Charalampos and Doukas, Charalampos and Fourlas, George and Maglogiannis, Ilias},
title = {An Overview of Body Sensor Networks in Enabling Pervasive Healthcare and Assistive Environments},
year = {2010},
isbn = {9781450300711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839294.1839346},
doi = {10.1145/1839294.1839346},
abstract = {The use of sensor networks for healthcare, well-being, and working in extreme environments has long roots in the engineering sector in medicine and biology community. With the growing needs in ubiquitous communications and recent advances in very-low-power wireless technologies, there has been considerable interest in the development and application of wireless networks around humans. With the maturity of wireless sensor networks, body area networks (BANs), and wireless BANs (WBANs), recent efforts in promoting the concept of body sensor networks (BSNs) aim to move beyond sensor connectivity to adopt a system-level approach to address issues related to biosensor design, interfacing, and embodiment, as well as ultra low-power processing / communication, power scavenging, autonomic sensing, data mining, inferencing, and integrated wireless sensor microsystems. As a result, the system architecture based on WBAN and BSN is becoming a widely accepted method of organization for ambulatory and ubiquitous monitoring systems. This review paper presents an up-to-date report of the current research and enabling applications and addresses some of the challenges and implementation issues.},
booktitle = {Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {43},
numpages = {10},
keywords = {healthcare applications, body sensor networks, ubiquitous computing, wireless body area networks},
location = {Samos, Greece},
series = {PETRA '10}
}

@inproceedings{10.1145/1839294.1839356,
author = {Xefteris, Stefanos and Haritou, Maria and Tserpes, Konstantinos and Serretti, Alessandro and Llopart, Josep Ramon and Calati, Raffaella and Varvarigou, Theodora},
title = {Analysis of Requirements and Specifications for a Monitoring System to Support the Self-Management of Dementia Patients at Home},
year = {2010},
isbn = {9781450300711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839294.1839356},
doi = {10.1145/1839294.1839356},
abstract = {Telemedicine systems are nowadays making significant advances in healthcare by decentralising it, offering innovative services to patients and doctors worldwide, and making medical practice more efficient and cost-effective in a plethora of its subfields. There is although a field that has not yet been successfully coped with, even though it induces a significant burden, both socially and financially. This field includes patients suffering from dementia, as well as their carers, who run the risk of developing depression symptoms themselves and often face social withdrawal and heavy additional private costs. ALADDIN is a technology platform that intends to progress "state-of-the-art" in integration of existing technological solutions. In order to develop and validate an innovative monitoring system for health promotion, risk assessment, prevention and sustainable impact of self management tools and education for patients suffering from dementia and their care-givers. In this paper the authors present the envisaged services of the ALADDIN platform, the user requirements and ALADDIN's functional specifications.},
booktitle = {Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {52},
numpages = {8},
keywords = {assisted living, risk analysis, e-health and assistive infrastructures, non-obtrusive monitoring, cognitive states, Dementia, quality of life},
location = {Samos, Greece},
series = {PETRA '10}
}

@inproceedings{10.1145/1839294.1839336,
author = {Makedon, Fillia and Zhang, Rong and Alexandrakis, Georgios and Owen, Charles B. and Huang, Heng and Saykin, Andrew J.},
title = {An Interactive User Interface System for Alzheimer's Intervention},
year = {2010},
isbn = {9781450300711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839294.1839336},
doi = {10.1145/1839294.1839336},
abstract = {Alzheimer's Disease (AD) is a neurological affliction that impacts primarily the aged due to brain tissue deterioration. It has been shown that this deterioration can be slowed down by engaging the person with daily interactive activities that include gaming, social interaction, memory exercises and physical activity. In this paper, we describe ZPLAY, a game-based user interface system which is designed to be web-based and to provide intervention therapy for AD. ZPLAY has two versions: the @lab version which is designed for diagnosis and used to measure different brain activation responses of AD and the @home version which is used to promote subject engagement and rehabilitation in a home environment in-between visits to the clinic.},
booktitle = {Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {35},
numpages = {5},
keywords = {motion capture, Alzheimer's, machine learning, rehabilitation, functional near infrared (fNIR) imaging, human computer interaction, data stream synchronization, game design, Dementia, physical therapy},
location = {Samos, Greece},
series = {PETRA '10}
}

@inproceedings{10.1145/1839294.1839337,
author = {Qudah, Islam and Leijdekkers, Peter and Gay, Valerie},
title = {Using Mobile Phones to Improve Medication Compliance and Awareness for Cardiac Patients},
year = {2010},
isbn = {9781450300711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839294.1839337},
doi = {10.1145/1839294.1839337},
abstract = {Improving cardiac patients' medication compliance is a major factor in reducing mortality rate and reducing hospitalization rate. This paper describes a novel medication compliance management system. Its novelty lies in the combination of functionalities that helps the patient to comply with their medication regimen, together with a personal health monitoring system that monitors their health and collects vital signs data using a mobile phone and wireless bio sensors. The system is designed to collect and analyse medication compliance, side effects and symptom responses and transfers the collected data in real time to a web based system for remote monitoring by caregivers and health professionals. Health professionals can use the system to assess the effect of the medication regimen on their patients' health and adapt it to reduce side effects and maximise the patient's wellbeing.},
booktitle = {Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {36},
numpages = {7},
keywords = {medication compliance, cardiac rehabilitation, ambulatory monitoring, tele-monitoring},
location = {Samos, Greece},
series = {PETRA '10}
}

@inproceedings{10.1145/1839294.1839300,
author = {Lin, Yong (Yates) and Le, Zhengyi and Becker, Eric and Makedon, Fillia},
title = {Acoustical Implicit Communication in Human-Robot Interaction},
year = {2010},
isbn = {9781450300711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839294.1839300},
doi = {10.1145/1839294.1839300},
abstract = {Explicit communication addresses the use of distinct language or protocol to convey the idea. Implicit communication helps to compensate many hidden meanings omitted from the explicit language. In some situations, implicit communication may even take the place of explicit communication. For the autonomous robot, implicit communication provides an alternative way to interact with people. This paper introduces the acoustic techniques for implicit communication in human-robot interaction, and the design of acoustical implicit communication based robot games.},
booktitle = {Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {5},
numpages = {5},
keywords = {acoustic communication, implicit communication, human-robot interface},
location = {Samos, Greece},
series = {PETRA '10}
}

