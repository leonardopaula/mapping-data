@inproceedings{10.4108/icst.bodynets.2013.253725,
author = {Zheng, Jiewen and Shen, Yuhong and Zhang, Zhengbo and Wu, Taihu and Zhang, Guang and Lu, Hengzhi},
title = {Emerging Wearable Medical Devices towards Personalized Healthcare},
year = {2013},
isbn = {9781936968893},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.bodynets.2013.253725},
doi = {10.4108/icst.bodynets.2013.253725},
abstract = {The increasingly aging population and prevalence of chronic diseases have been observed in many countries, which increase great burden for the health care system over recent few decades. With the technology innovation in IT and biomedical engineering, more and more advanced wearable medical technologies and products are emerging and coming to use by the public. Since wearable medical is deemed as one of the most promising approaches for healthcare monitoring, early diagnose and personalized treatment, wearable medical devices will contribute to the development of more cost-effective and sustainable healthcare system. In this paper, recent advancements in wearable medical products for personalized medicine and E-health are reviewed, including wearable multi-parameter physiological devices, wearable patch physiological monitoring devices, fitness training devices, wearable biofeedback training devices, and mobile phone based healthcare applications. Finally, future development of wearable medical technologies, specially, the related policies and plans in China, are discussed.},
booktitle = {Proceedings of the 8th International Conference on Body Area Networks},
pages = {427–431},
numpages = {5},
keywords = {health care, e-health, wearable medical system, personalized medicine},
location = {Boston, Massachusetts},
series = {BodyNets '13}
}

@inproceedings{10.1145/2513002.2513006,
author = {Aponte, Diego Fernando Gutierrez and Richards, Deborah},
title = {Managing Cyber-Bullying in Online Educational Virtual Worlds},
year = {2013},
isbn = {9781450322546},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2513002.2513006},
doi = {10.1145/2513002.2513006},
abstract = {Online Educational Virtual Worlds offer promise that is currently not being realised because of potential threats to the child's safety and wellbeing. This paper seeks to better understand the behavioural and psychological issues, particularly relating to cyber-bullying, faced by school children when they are online and what solutions currently exist. As an outcome of this understanding we make recommendations regarding how cyber-bullying should be managed in educational virtual worlds taking a hybrid approach involving policy, technology and non-technology based solutions.},
booktitle = {Proceedings of The 9th Australasian Conference on Interactive Entertainment: Matters of Life and Death},
articleno = {18},
numpages = {9},
keywords = {cyber-victim, eSafety, cyber-bullying, educational virtual worlds},
location = {Melbourne, Australia},
series = {IE '13}
}

@inproceedings{10.4108/icst.bodynets.2013.253721,
author = {Fortino, Giancarlo and Gravina, Raffaele and Guerrieri, Antonio and Di Fatta, Giuseppe},
title = {Engineering Large-Scale Body Area Networks Applications},
year = {2013},
isbn = {9781936968893},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.bodynets.2013.253721},
doi = {10.4108/icst.bodynets.2013.253721},
abstract = {This paper presents an approach to design and deploy large-scale applications for body area networks (BANs). The approach is based on BodyCloud, which is a Cloud-based multi-tier application-level architecture. BodyCloud integrates a Cloud computing platform and the SPINE BAN middleware. It specifically provides programming abstractions, such as group, modality, workflow and view, which support the rapid and effective development of community BAN applications. This work provides an overview of the general architecture of BodyCloud and discusses several large-scale application services that can be deployed on BodyCloud.},
booktitle = {Proceedings of the 8th International Conference on Body Area Networks},
pages = {363–369},
numpages = {7},
keywords = {wearable computing, body area networks, SaaS, large-scale distributed applications, cloud computing},
location = {Boston, Massachusetts},
series = {BodyNets '13}
}

@inproceedings{10.4108/icst.bodynets.2013.253697,
author = {Andrews, Ryan P. and Garcia, Alejandra P. and Dryer, Brandon R. and Bonney, Scott F. and Badjou, Salah and Dow, Douglas E.},
title = {Rowing Training System for On-the-Water Rehabilitation and Sport},
year = {2013},
isbn = {9781936968893},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.bodynets.2013.253697},
doi = {10.4108/icst.bodynets.2013.253697},
abstract = {Quantitative and continuous performance assessment enhances effective physical training in sports and rehabilitation. Rowing uses the large muscles of the body in an aerobic and strength building manner. Rowing has utilization as a competitive sport, an aerobic exercise, or a rehabilitation exercise, such as related to spinal cord injury, stroke, trauma, old age, obesity, chronic obstructive pulmonary disease or osteoporosis. Guidance from a physically present coach or therapists has high cost and time requirements that limit accessibility. A computerized system that gives instructions to the rower, monitors rowing performance, and transmits the data to a computer for analysis, storage, and communication would increase accessibility of quality feedback and guidance. Ergometers are stationary rowing stations with automatic instructions and monitoring of performance. Sensors have been developed for on-the-water monitoring of rowing, but these devices typically have disadvantages of affecting the oar, difficult mounting procedures, and high cost. This project developed modules of a system integrated with the oar, which then wirelessly transmitted the recorded force and rotational data to computer. The computer could analyze, store and communicate the data to the rowers, coach or therapist, medical staff and other appropriate family members or associates.},
booktitle = {Proceedings of the 8th International Conference on Body Area Networks},
pages = {351–354},
numpages = {4},
keywords = {accelerometer, therapy, wireless, strain gage, force, strength, power, spinal cord injury, health, exercise, endurance, oar},
location = {Boston, Massachusetts},
series = {BodyNets '13}
}

@inproceedings{10.1145/2507065.2507086,
author = {Cotugno, Clare and Fitzhugh, Shannon L. and Hoeft, Raegen},
title = {Simplifying Business Complexity with Frameworks},
year = {2013},
isbn = {9781450321310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2507065.2507086},
doi = {10.1145/2507065.2507086},
abstract = {How does an interdisciplinary team with professional training in different disciplines document and redesign a complex business process in just a few weeks? How can they persuade a global client that change is understandable and possible? By using a macroergonomic framework to parse and analyze data and educate and empower stakeholders, this team of user experience researchers and designers simplified complexity within their own process and for their client as well.},
booktitle = {Proceedings of the 31st ACM International Conference on Design of Communication},
pages = {33–38},
numpages = {6},
keywords = {usability, user experience design, human factors, macroergonomics, content strategy, business processes, ergonomics, content management},
location = {Greenville, North Carolina, USA},
series = {SIGDOC '13}
}

@inproceedings{10.1145/2523616.2523629,
author = {Appuswamy, Raja and Gkantsidis, Christos and Narayanan, Dushyanth and Hodson, Orion and Rowstron, Antony},
title = {Scale-up vs Scale-out for Hadoop: Time to Rethink?},
year = {2013},
isbn = {9781450324281},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2523616.2523629},
doi = {10.1145/2523616.2523629},
abstract = {In the last decade we have seen a huge deployment of cheap clusters to run data analytics workloads. The conventional wisdom in industry and academia is that scaling out using a cluster of commodity machines is better for these workloads than scaling up by adding more resources to a single server. Popular analytics infrastructures such as Hadoop are aimed at such a cluster scale-out environment.Is this the right approach? Our measurements as well as other recent work shows that the majority of real-world analytic jobs process less than 100 GB of input, but popular infrastructures such as Hadoop/MapReduce were originally designed for petascale processing. We claim that a single "scale-up" server can process each of these jobs and do as well or better than a cluster in terms of performance, cost, power, and server density. We present an evaluation across 11 representative Hadoop jobs that shows scale-up to be competitive in all cases and significantly better in some cases, than scale-out. To achieve that performance, we describe several modifications to the Hadoop runtime that target scale-up configuration. These changes are transparent, do not require any changes to application code, and do not compromise scale-out performance; at the same time our evaluation shows that they do significantly improve Hadoop's scale-up performance.},
booktitle = {Proceedings of the 4th Annual Symposium on Cloud Computing},
articleno = {20},
numpages = {13},
location = {Santa Clara, California},
series = {SOCC '13}
}

@article{10.1145/2500892,
author = {Hoonlor, Apirak and Szymanski, Boleslaw K. and Zaki, Mohammed J.},
title = {Trends in Computer Science Research},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/2500892},
doi = {10.1145/2500892},
abstract = {Keywords in the ACM Digital Library and IEEE Xplore digital library and in NSF grants anticipate future CS research.},
journal = {Commun. ACM},
month = oct,
pages = {74–83},
numpages = {10}
}

@article{10.5555/2527148.2527183,
author = {Chiu, David and Wallace, Scott A.},
title = {On the "Science" in Computer Science: Integrating Research Preparedness in Undergraduate CS},
year = {2013},
issue_date = {October 2013},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {29},
number = {1},
issn = {1937-4771},
abstract = {In this paper we introduce the concept of "research preparatory" projects. We have begun to include these open-ended projects in our existing undergraduate curriculum to improve our student's ability to reason analytically; design experiments to test their assumptions and to evaluate their solutions; and to communicate effectively. We describe the research preparatory projects in two of our courses and our initial experiences in the classroom.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {157–163},
numpages = {7}
}

@inproceedings{10.1145/2523616.2523633,
author = {Vavilapalli, Vinod Kumar and Murthy, Arun C. and Douglas, Chris and Agarwal, Sharad and Konar, Mahadev and Evans, Robert and Graves, Thomas and Lowe, Jason and Shah, Hitesh and Seth, Siddharth and Saha, Bikas and Curino, Carlo and O'Malley, Owen and Radia, Sanjay and Reed, Benjamin and Baldeschwieler, Eric},
title = {Apache Hadoop YARN: Yet Another Resource Negotiator},
year = {2013},
isbn = {9781450324281},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2523616.2523633},
doi = {10.1145/2523616.2523633},
abstract = {The initial design of Apache Hadoop [1] was tightly focused on running massive, MapReduce jobs to process a web crawl. For increasingly diverse companies, Hadoop has become the data and computational agor\'{a}---the de facto place where data and computational resources are shared and accessed. This broad adoption and ubiquitous usage has stretched the initial design well beyond its intended target, exposing two key shortcomings: 1) tight coupling of a specific programming model with the resource management infrastructure, forcing developers to abuse the MapReduce programming model, and 2) centralized handling of jobs' control flow, which resulted in endless scalability concerns for the scheduler.In this paper, we summarize the design, development, and current state of deployment of the next generation of Hadoop's compute platform: YARN. The new architecture we introduced decouples the programming model from the resource management infrastructure, and delegates many scheduling functions (e.g., task fault-tolerance) to per-application components. We provide experimental evidence demonstrating the improvements we made, confirm improved efficiency by reporting the experience of running YARN on production environments (including 100% of Yahoo! grids), and confirm the flexibility claims by discussing the porting of several programming frameworks onto YARN viz. Dryad, Giraph, Hoya, Hadoop MapReduce, REEF, Spark, Storm, Tez.},
booktitle = {Proceedings of the 4th Annual Symposium on Cloud Computing},
articleno = {5},
numpages = {16},
location = {Santa Clara, California},
series = {SOCC '13}
}

@inproceedings{10.1145/2523616.2523627,
author = {Do, Thanh and Hao, Mingzhe and Leesatapornwongsa, Tanakorn and Patana-anake, Tiratat and Gunawi, Haryadi S.},
title = {Limplock: Understanding the Impact of Limpware on Scale-out Cloud Systems},
year = {2013},
isbn = {9781450324281},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2523616.2523627},
doi = {10.1145/2523616.2523627},
abstract = {We highlight one often-overlooked cause of performance failure: limpware -- "limping" hardware whose performance degrades significantly compared to its specification. We report anecdotes of degraded disks and network components seen in large-scale production. To measure the system-level impact of limpware, we assembled limpbench, a set of benchmarks that combine data-intensive load and limpware injections. We benchmark five cloud systems (Hadoop, HDFS, ZooKeeper, Cassandra, and HBase) and find that limpware can severely impact distributed operations, nodes, and an entire cluster. From this, we introduce the concept of limplock, a situation where a system progresses slowly due to the presence of limpware and is not capable of failing over to healthy components. We show how each cloud system that we analyze can exhibit operation, node, and cluster limplock. We conclude that many cloud systems are not limpware tolerant.},
booktitle = {Proceedings of the 4th Annual Symposium on Cloud Computing},
articleno = {14},
numpages = {14},
location = {Santa Clara, California},
series = {SOCC '13}
}

@inproceedings{10.1145/2513456.2513504,
author = {Nottingham, Alastair and Irwin, Barry},
title = {Towards a GPU Accelerated Virtual Machine for Massively Parallel Packet Classification and Filtering},
year = {2013},
isbn = {9781450321129},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2513456.2513504},
doi = {10.1145/2513456.2513504},
abstract = {This paper considers the application of GPU co-processors to accelerate the analysis of packet data, particularly within extremely large packet traces spanning months or years of traffic. Discussion focuses on the construction, performance and limitations of the experimental GPF (GPU Packet Filter), which employs a prototype massively-parallel protocol-independent multi-match algorithm to rapidly compare packets against multiple arbitrary filters. The paper concludes with a consideration of mechanisms to expand the flexibility and power of the GPF algorithm to construct a fully programmable GPU packet classification virtual machine, which can perform massively parallel classification, data-mining and data-transformation to explore and analyse packet traces. This virtual machine is a component of a larger framework of capture analysis tools which together provide capture indexing, manipulation, filtering and visualisation functions.},
booktitle = {Proceedings of the South African Institute for Computer Scientists and Information Technologists Conference},
pages = {27–36},
numpages = {10},
keywords = {CUDA, network security, GPU, packet classification, parallel programming},
location = {East London, South Africa},
series = {SAICSIT '13}
}

@inproceedings{10.1145/2512938.2512954,
author = {Correa, Denzil and Sureka, Ashish},
title = {Fit or Unfit: Analysis and Prediction of 'closed Questions' on Stack Overflow},
year = {2013},
isbn = {9781450320849},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2512938.2512954},
doi = {10.1145/2512938.2512954},
abstract = {Stack Overflow is widely regarded as the most popular Community driven Question Answering (CQA) website for programmers. Questions posted on Stack Overflow which are not related to programming topics, are marked as `closed' by experienced users and community moderators. A question can be `closed' for five reasons -- duplicate, off-topic, subjective, not a real question and too localized. In this work, we present the first study of `closed' questions on Stack Overflow. We download 4 years of publicly available data which contains 3.4 Million questions. We first analyze and characterize the complete set of 0.1 Million `closed' questions. Next, we use a machine learning framework and build a predictive model to identify a `closed' question at the time of question creation.One of our key findings is that despite being marked as `closed', subjective questions contain high information value and are very popular with the users. We observe an increasing trend in the percentage of closed questions over time and find that this increase is positively correlated to the number of newly registered users. In addition, we also see a decrease in community participation to mark a `closed' question which has led to an increase in moderation job time. We also find that questions closed with the Duplicate and Off Topic labels are relatively more prone to reputation gaming. Our analysis suggests broader implications for content quality maintenance on CQA websites. For the `closed' question prediction task, we make use of multiple genres of feature sets based on - user profile, community process, textual style and question content. We use a state-of-art machine learning classifier based on an ensemble framework and achieve an overall accuracy of 70.3%. Analysis of the feature space reveals that `closed' questions are relatively less informative and descriptive than non-`closed' questions. To the best of our knowledge, this is the first experimental study to analyze and predict `closed' questions on Stack Overflow.},
booktitle = {Proceedings of the First ACM Conference on Online Social Networks},
pages = {201–212},
numpages = {12},
keywords = {question-answering, stack overflow, question quality},
location = {Boston, Massachusetts, USA},
series = {COSN '13}
}

@inproceedings{10.1145/2512938.2512951,
author = {Gon\c{c}alves, Pollyanna and Ara\'{u}jo, Matheus and Benevenuto, Fabr\'{\i}cio and Cha, Meeyoung},
title = {Comparing and Combining Sentiment Analysis Methods},
year = {2013},
isbn = {9781450320849},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2512938.2512951},
doi = {10.1145/2512938.2512951},
abstract = {Several messages express opinions about events, products, and services, political views or even their author's emotional state and mood. Sentiment analysis has been used in several applications including analysis of the repercussions of events in social networks, analysis of opinions about products and services, and simply to better understand aspects of social communication in Online Social Networks (OSNs). There are multiple methods for measuring sentiments, including lexical-based approaches and supervised machine learning methods. Despite the wide use and popularity of some methods, it is unclear which method is better for identifying the polarity (i.e., positive or negative) of a message as the current literature does not provide a method of comparison among existing methods. Such a comparison is crucial for understanding the potential limitations, advantages, and disadvantages of popular methods in analyzing the content of OSNs messages. Our study aims at filling this gap by presenting comparisons of eight popular sentiment analysis methods in terms of coverage (i.e., the fraction of messages whose sentiment is identified) and agreement (i.e., the fraction of identified sentiments that are in tune with ground truth). We develop a new method that combines existing approaches, providing the best coverage results and competitive agreement. We also present a free Web service called iFeel, which provides an open API for accessing and comparing results across different sentiment methods for a given text.},
booktitle = {Proceedings of the First ACM Conference on Online Social Networks},
pages = {27–38},
numpages = {12},
keywords = {sentiment analysis, social networks, public mood},
location = {Boston, Massachusetts, USA},
series = {COSN '13}
}

@inproceedings{10.1145/2513456.2513493,
author = {Mushfieldt, Diego and Ghaziasgar, Mehrdad and Connan, James},
title = {Robust Facial Expression Recognition in the Presence of Rotation and Partial Occlusion},
year = {2013},
isbn = {9781450321129},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2513456.2513493},
doi = {10.1145/2513456.2513493},
abstract = {The research presented in this paper proposes an approach to recognizing facial expressions in the presence of rotations and partial occlusions of the face. The research is in the context of automatic machine translation of South African Sign Language (SASL) to English. The proposed method achieved a high average recognition accuracy of 85% for frontal facial images. It also achieved a high average recognition accuracy of 80% for faces rotated at 60°. It was also shown that the method is able to continue to recognize facial expressions even in the presence of full occlusions of the eyes, mouth and left and right sides of the face. An additional finding was that both the left and the right sides of the face are required for recognition. This was due to the fact that subjects are seen to regularly perform facial expressions with more emphasis on either side, affecting the recognition accuracy.},
booktitle = {Proceedings of the South African Institute for Computer Scientists and Information Technologists Conference},
pages = {186–193},
numpages = {8},
keywords = {support vector machine, sign language, image processing, SASL},
location = {East London, South Africa},
series = {SAICSIT '13}
}

@article{10.1145/2508037.2508051,
author = {Baralis, Elena and Cerquitelli, Tania and Chiusano, Silvia and D'elia, Vincenzo and Molinari, Riccardo and Susta, Davide},
title = {Early Prediction of the Highest Workload in Incremental Cardiopulmonary Tests},
year = {2013},
issue_date = {September 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
issn = {2157-6904},
url = {https://doi.org/10.1145/2508037.2508051},
doi = {10.1145/2508037.2508051},
abstract = {Incremental tests are widely used in cardiopulmonary exercise testing, both in the clinical domain and in sport sciences. The highest workload (denoted Wpeak) reached in the test is key information for assessing the individual body response to the test and for analyzing possible cardiac failures and planning rehabilitation, and training sessions. Being physically very demanding, incremental tests can significantly increase the body stress on monitored individuals and may cause cardiopulmonary overload. This article presents a new approach to cardiopulmonary testing that addresses these drawbacks. During the test, our approach analyzes the individual body response to the exercise and predicts the Wpeak value that will be reached in the test and an evaluation of its accuracy. When the accuracy of the prediction becomes satisfactory, the test can be prematurely stopped, thus avoiding its entire execution. To predict Wpeak, we introduce a new index, the CardioPulmonary Efficiency Index (CPE), summarizing the cardiopulmonary response of the individual to the test. Our approach analyzes the CPE trend during the test, together with the characteristics of the individual, and predicts Wpeak. A K-nearest-neighbor-based classifier and an ANN-based classier are exploited for the prediction. The experimental evaluation showed that the Wpeak value can be predicted with a limited error from the first steps of the test.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = oct,
articleno = {70},
numpages = {20},
keywords = {multivariate data, Incremental test, highest workload prediction, classification techniques, physiological signals analysis}
}

@inproceedings{10.1145/2501988.2502034,
author = {Kim, Juho and Zhang, Haoqi and Andr\'{e}, Paul and Chilton, Lydia B. and Mackay, Wendy and Beaudouin-Lafon, Michel and Miller, Robert C. and Dow, Steven P.},
title = {Cobi: A Community-Informed Conference Scheduling Tool},
year = {2013},
isbn = {9781450322683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2501988.2502034},
doi = {10.1145/2501988.2502034},
abstract = {Effectively planning a large multi-track conference requires an understanding of the preferences and constraints of organizers, authors, and attendees. Traditionally, the onus of scheduling the program falls on a few dedicated organizers. Resolving conflicts becomes difficult due to the size and complexity of the schedule and the lack of insight into community members' needs and desires. Cobi presents an alternative approach to conference scheduling that engages the entire community in the planning process. Cobi comprises (a) communitysourcing applications that collect preferences, constraints, and affinity data from community members, and (b) a visual scheduling interface that combines communitysourced data and constraint-solving to enable organizers to make informed improvements to the schedule. This paper describes Cobi's scheduling tool and reports on a live deployment for planning CHI 2013, where organizers considered input from 645 authors and resolved 168 scheduling conflicts. Results show the value of integrating community input with an intelligent user interface to solve complex planning tasks.},
booktitle = {Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology},
pages = {173–182},
numpages = {10},
keywords = {communitysourcing, crowdsourcing, mixed-initiative, conference scheduling, cobi, community, constraint solving},
location = {St. Andrews, Scotland, United Kingdom},
series = {UIST '13}
}

@article{10.1145/2516971.2516976,
author = {Ju, Eunjung and Won, Jungdam and Lee, Jehee and Choi, Byungkuk and Noh, Junyong and Choi, Min Gyu},
title = {Data-Driven Control of Flapping Flight},
year = {2013},
issue_date = {September 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {5},
issn = {0730-0301},
url = {https://doi.org/10.1145/2516971.2516976},
doi = {10.1145/2516971.2516976},
abstract = {We present a physically based controller that simulates the flapping behavior of a bird in flight. We recorded the motion of a dove using marker-based optical motion capture and high-speed video cameras. The bird flight data thus acquired allow us to parameterize natural wingbeat cycles and provide the simulated bird with reference trajectories to track in physics simulation. Our controller simulates articulated rigid bodies of a bird's skeleton and deformable feathers to reproduce the aerodynamics of bird flight. Motion capture from live birds is not as easy as human motion capture because of the lack of cooperation from subjects. Therefore, the flight data we could acquire were limited. We developed a new method to learn wingbeat controllers even from sparse, biased observations of real bird flight. Our simulated bird imitates life-like flapping of a flying bird while actively maintaining its balance. The bird flight is interactively controllable and resilient to external disturbances.},
journal = {ACM Trans. Graph.},
month = oct,
articleno = {151},
numpages = {12},
keywords = {data-driven control, animal locomotion, Bird flight, physically based simulation, motion capture, flapping}
}

@inproceedings{10.1145/2501988.2501993,
author = {Rubin, Steve and Berthouzoz, Floraine and Mysore, Gautham J. and Li, Wilmot and Agrawala, Maneesh},
title = {Content-Based Tools for Editing Audio Stories},
year = {2013},
isbn = {9781450322683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2501988.2501993},
doi = {10.1145/2501988.2501993},
abstract = {Audio stories are an engaging form of communication that combine speech and music into compelling narratives. Existing audio editing tools force story producers to manipulate speech and music tracks via tedious, low-level waveform editing. In contrast, we present a set of tools that analyze the audio content of the speech and music and thereby allow producers to work at much higher level. Our tools address several challenges in creating audio stories, including (1) navigating and editing speech, (2) selecting appropriate music for the score, and (3) editing the music to complement the speech. Key features include a transcript-based speech editing tool that automatically propagates edits in the transcript text to the corresponding speech track; a music browser that supports searching based on emotion, tempo, key, or timbral similarity to other songs; and music retargeting tools that make it easy to combine sections of music with the speech. We have used our tools to create audio stories from a variety of raw speech sources, including scripted narratives, interviews and political speeches. Informal feedback from first-time users suggests that our tools are easy to learn and greatly facilitate the process of editing raw footage into a final story.},
booktitle = {Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology},
pages = {113–122},
numpages = {10},
keywords = {storytelling, transcript-based editing, audio editing, music browsing, music retargeting},
location = {St. Andrews, Scotland, United Kingdom},
series = {UIST '13}
}

@inproceedings{10.1145/2513591.2527071,
author = {Cuzzocrea, Alfredo and Sacc\`{a}, Domenico and Ullman, Jeffrey D.},
title = {Big Data: A Research Agenda},
year = {2013},
isbn = {9781450320252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2513591.2527071},
doi = {10.1145/2513591.2527071},
abstract = {Recently, a great deal of interest for Big Data has risen, mainly driven from a widespread number of research problems strongly related to real-life applications and systems, such as representing, modeling, processing, querying and mining massive, distributed, large-scale repositories (mostly being of unstructured nature). Inspired by this main trend, in this paper we discuss three important aspects of Big Data research, namely OLAP over Big Data, Big Data Posting, and Privacy of Big Data. We also depict future research directions, hence implicitly defining a research agenda aiming at leading future challenges in this research field.},
booktitle = {Proceedings of the 17th International Database Engineering &amp; Applications Symposium},
pages = {198–203},
numpages = {6},
keywords = {OLAP over big data, big data, big data posting, privacy of big data},
location = {Barcelona, Spain},
series = {IDEAS '13}
}

@inproceedings{10.1145/2499393.2499401,
author = {Menzies, Tim},
title = {Beyond Data Mining; towards "Idea Engineering"},
year = {2013},
isbn = {9781450320160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499393.2499401},
doi = {10.1145/2499393.2499401},
abstract = {Pablo Picasso said "computers are stupid- they only give you answers". I seek to build reasoners that are not stupid- that know predictions and decisions are important, but so too are the questions and insights generated on the way to those conclusions. Within a society of carbon and/or silicon-based agents, discussion systems let us share, reflect, and try to improve each other's insights.},
booktitle = {Proceedings of the 9th International Conference on Predictive Models in Software Engineering},
articleno = {11},
numpages = {6},
keywords = {landscape mining, idea engineering, discussion mining, decision mining, AI},
location = {Baltimore, Maryland, USA},
series = {PROMISE '13}
}

@inproceedings{10.1145/2513591.2513659,
author = {Martins, Pedro and Abbasi, Maryam and Furtado, Pedro},
title = {Cloudy: Heterogeneous Middleware for in Time Queries Processing},
year = {2013},
isbn = {9781450320252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2513591.2513659},
doi = {10.1145/2513591.2513659},
abstract = {Parallel share-nothing architectures are currently used to handle large amounts of data arriving in real-time for processing. The continuous increase on data volume and organization, introduce several limitations to scalability and quality of service (QoS) due to processing requirements and joins. Parallelism may improve query performance, however some business require timely results (results not faster or slower than specified) which, even with additional parallelism and significant upgrade costs (both monetary and due to disturbance of normal operations), cannot be guaranteed. We propose a timely-aware execution architecture, Cloudy, which balances data and queries processing among an elastic set of non-dedicated and heterogeneous nodes in order to provide scale-out performance and timely results, nor faster or slower, using both Complex Event Processing (CEP) and database (DB). Data is distributed by nodes accordingly with their hardware characteristics, then a set of layered mechanisms rearrange queries in order to provide in timely results. We present experimental evaluation of Cloudy and demonstrate its ability to provide timely results.},
booktitle = {Proceedings of the 17th International Database Engineering &amp; Applications Symposium},
pages = {5–13},
numpages = {9},
keywords = {timely execution, scalability, elastic parallel, architecture, database (BD), complex event processing (CEP), integration},
location = {Barcelona, Spain},
series = {IDEAS '13}
}

@inproceedings{10.1145/2507157.2507180,
author = {Kaminskas, Marius and Ricci, Francesco and Schedl, Markus},
title = {Location-Aware Music Recommendation Using Auto-Tagging and Hybrid Matching},
year = {2013},
isbn = {9781450324090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2507157.2507180},
doi = {10.1145/2507157.2507180},
abstract = {We propose a novel approach to context-aware music recommendation - recommending music suited for places of interest (POIs). The suggested hybrid approach combines two techniques -- one based on representing both POIs and music with tags, and the other based on the knowledge of the semantic relations between the two types of items. We show that our approach can be scaled up using a novel music auto-tagging technique and we compare it in a live user study to: two non-hybrid solutions, either based on tags or on semantic relations; and to a context-free but personalized recommendation approach. In the considered scenario, i.e., a situation defined by a context (the POI), we show that personalization (via music preference) is not sufficient and it is important to implement effective adaptation techniques to the user's context. In fact, we show that the users are more satisfied with the recommendations generated by combining the tag-based and knowledge-based context adaptation techniques, which exploit orthogonal types of relations between places and music tracks.},
booktitle = {Proceedings of the 7th ACM Conference on Recommender Systems},
pages = {17–24},
numpages = {8},
keywords = {auto-tagging, tag prediction, music recommendation, context-aware recommendation, hybrid recommendation},
location = {Hong Kong, China},
series = {RecSys '13}
}

@inproceedings{10.1145/2507157.2507189,
author = {Aiolli, Fabio},
title = {Efficient Top-n Recommendation for Very Large Scale Binary Rated Datasets},
year = {2013},
isbn = {9781450324090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2507157.2507189},
doi = {10.1145/2507157.2507189},
abstract = {We present a simple and scalable algorithm for top-N recommendation able to deal with very large datasets and (binary rated) implicit feedback. We focus on memory-based collaborative filtering algorithms similar to the well known neighboor based technique for explicit feedback. The major difference, that makes the algorithm particularly scalable, is that it uses positive feedback only and no explicit computation of the complete (user-by-user or item-by-item) similarity matrix needs to be performed.The study of the proposed algorithm has been conducted on data from the Million Songs Dataset (MSD) challenge whose task was to suggest a set of songs (out of more than 380k available songs) to more than 100k users given half of the user listening history and complete listening history of other 1 million people.In particular, we investigate on the entire recommendation pipeline, starting from the definition of suitable similarity and scoring functions and suggestions on how to aggregate multiple ranking strategies to define the overall recommendation. The technique we are proposing extends and improves the one that already won the MSD challenge last year.},
booktitle = {Proceedings of the 7th ACM Conference on Recommender Systems},
pages = {273–280},
numpages = {8},
keywords = {implicit feedback, collaborative filtering, top-n recommendation, million song dataset challenge},
location = {Hong Kong, China},
series = {RecSys '13}
}

@inproceedings{10.1145/2516821.2516839,
author = {Legout, Vincent and Jan, Mathieu and Pautet, Laurent},
title = {A Scheduling Algorithm to Reduce the Static Energy Consumption of Multiprocessor Real-Time Systems},
year = {2013},
isbn = {9781450320580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2516821.2516839},
doi = {10.1145/2516821.2516839},
abstract = {Energy consumption of real-time embedded systems is a growing concern. It includes both static and dynamic consumption and is now dominated by static consumption as the semiconductor technology moves to deep sub-micron scale. In this paper, we propose a new approach to efficiently use the low-power states of multiprocessor embedded hard real-time systems in order to reduce their static consumption. In a low-power state, the processor is not active and the deeper the low-power state is, the lower is the energy consumption but the higher is the transition delay to come back to the active state. Our approach increases the duration of the idle periods to allow the activation of deeper low-power states. Offline, we use an additional task to model the idle time and we use mixed integer linear programming to reduce its number of preemptions. Online, we extend an existing scheduling algorithm to increase the length of the idle periods. To the best of our knowledge, this is the first optimal multiprocessor scheduling algorithm minimizing static consumption. Simulations show that the energy consumption while processors are idle is dramatically reduced with our solution compared to existing multiprocessor real-time scheduling algorithms.},
booktitle = {Proceedings of the 21st International Conference on Real-Time Networks and Systems},
pages = {99–108},
numpages = {10},
location = {Sophia Antipolis, France},
series = {RTNS '13}
}

@article{10.1145/2502436,
author = {Sang, Jitao and Xu, Changsheng},
title = {Social Influence Analysis and Application on Multimedia Sharing Websites},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1s},
issn = {1551-6857},
url = {https://doi.org/10.1145/2502436},
doi = {10.1145/2502436},
abstract = {Social media is becoming popular these days, where users necessarily interact with each other to form social networks. Influence network, as one special case of social network, has been recognized as significantly impacting social activities and user decisions. We emphasize in this article that the inter-user influence is essentially topic-sensitive, as for different tasks users tend to trust different influencers and be influenced most by them. While existing research focuses on global influence modeling and applies to text-based networks, this work investigates the problem of topic-sensitive influence modeling in the multimedia domain.According to temporal data justification, we propose a multimodal probabilistic model, considering both users' textual annotation and uploaded visual images. This model is capable of simultaneously extracting user topic distributions and topic-sensitive influence strengths. By identifying the topic-sensitive influencer, we are able to conduct applications, like collective search and collaborative recommendation. A risk minimization-based general framework for personalized image search is further presented, where the image search task is transferred to measure the distance of image and personalized query language models. The framework considers the noisy tag issue and enables easy incorporation of social influence. We have conducted experiments on a large-scale Flickr dataset. Qualitative as well as quantitative evaluation results have validated the effectiveness of the topic-sensitive influencer mining model, and demonstrated the advantage of incorporating topic-sensitive influence in personalized image search and topic-based image recommendation.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = oct,
articleno = {53},
numpages = {24},
keywords = {Social relation analysis, social media, influence analysis, topic model}
}

@inproceedings{10.1145/2502081.2502279,
author = {Gupta, Amarnath and Jain, Ramesh},
title = {Social Life Networks: A Multimedia Problem?},
year = {2013},
isbn = {9781450324045},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2502081.2502279},
doi = {10.1145/2502081.2502279},
abstract = {Connecting people to the resources they need is a fundamental task for any society. We present the idea of a technology that can be used by the middle tier of a society so that it uses people's mobile devices and social networks to connect the needy with providers. We conceive of a world observatory called the Social Life Network (SLN) that connects together people and things and monitors for people's needs as their life situations evolve. To enable such a system we need SLN to register and recognize situations by combining people's activities and data streaming from personal devices and environment sensors, and based on the situations make the connections when possible. But is this a multimedia problem? We show that many pattern recognition, machine learning, sensor fusion and information retrieval techniques used in multimedia-related research are deeply connected to the SLN problem. We sketch the functional architecture of such a system and show the place for these techniques.},
booktitle = {Proceedings of the 21st ACM International Conference on Multimedia},
pages = {203–212},
numpages = {10},
keywords = {situation recognition, social networks, event-based system, social computing},
location = {Barcelona, Spain},
series = {MM '13}
}

@inproceedings{10.1145/2512530.2512533,
author = {Valstar, Michel and Schuller, Bj\"{o}rn and Smith, Kirsty and Eyben, Florian and Jiang, Bihan and Bilakhia, Sanjay and Schnieder, Sebastian and Cowie, Roddy and Pantic, Maja},
title = {AVEC 2013: The Continuous Audio/Visual Emotion and Depression Recognition Challenge},
year = {2013},
isbn = {9781450323956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2512530.2512533},
doi = {10.1145/2512530.2512533},
abstract = {Mood disorders are inherently related to emotion. In particular, the behaviour of people suffering from mood disorders such as unipolar depression shows a strong temporal correlation with the affective dimensions valence and arousal. In addition, psychologists and psychiatrists take the observation of expressive facial and vocal cues into account while evaluating a patient's condition. Depression could result in expressive behaviour such as dampened facial expressions, avoiding eye contact, and using short sentences with flat intonation. It is in this context that we present the third Audio-Visual Emotion recognition Challenge (AVEC 2013). The challenge has two goals logically organised as sub-challenges: the first is to predict the continuous values of the affective dimensions valence and arousal at each moment in time. The second sub-challenge is to predict the value of a single depression indicator for each recording in the dataset. This paper presents the challenge guidelines, the common data used, and the performance of the baseline system on the two tasks.},
booktitle = {Proceedings of the 3rd ACM International Workshop on Audio/Visual Emotion Challenge},
pages = {3–10},
numpages = {8},
keywords = {depression, affective computing, emotion recognition},
location = {Barcelona, Spain},
series = {AVEC '13}
}

@inproceedings{10.1145/2513383.2513392,
author = {Rector, Kyle and Bennett, Cynthia L. and Kientz, Julie A.},
title = {Eyes-Free Yoga: An Exergame Using Depth Cameras for Blind &amp; Low Vision Exercise},
year = {2013},
isbn = {9781450324052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2513383.2513392},
doi = {10.1145/2513383.2513392},
abstract = {People who are blind or low vision may have a harder time participating in exercise classes due to inaccessibility, travel difficulties, or lack of experience. Exergames can encourage exercise at home and help lower the barrier to trying new activities, but there are often accessibility issues since they rely on visual feedback to help align body positions. To address this, we developed Eyes-Free Yoga, an exergame using the Microsoft Kinect that acts as a yoga instructor, teaches six yoga poses, and has customized auditory-only feedback based on skeletal tracking. We ran a controlled study with 16 people who are blind or low vision to evaluate the feasibility and feedback of Eyes-Free Yoga. We found participants enjoyed the game, and the extra auditory feedback helped their understanding of each pose. The findings of this work have implications for improving auditory-only feedback and on the design of exergames using depth cameras.},
booktitle = {Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {12},
numpages = {8},
keywords = {kinect, yoga, exergames, health, eyes-free, video games, accessibility, visual impairments, audio feedback},
location = {Bellevue, Washington},
series = {ASSETS '13}
}

@inproceedings{10.1145/2509352.2509401,
author = {Pongpaichet, Siripen and Singh, Vivek K. and Jain, Ramesh and Pentland, Alex (Sandy)},
title = {Situation Fencing: Making Geo-Fencing Personal and Dynamic},
year = {2013},
isbn = {9781450323970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2509352.2509401},
doi = {10.1145/2509352.2509401},
abstract = {Geo-fencing has recently been applied to multiple applications including media recommendation, advertisements, wildlife monitoring, and recreational activities. However current geo-fencing systems work with static geographical boundaries. Situation Fencing allows for these boundaries to vary automatically based on situations derived by a combination of global and personal data streams. We present a generic approach for situation fencing, and demonstrate how it can be operationalized in practice. The results obtained in a personalized allergy alert application are encouraging and open door for building thousands of similar applications using the same framework in near future.},
booktitle = {Proceedings of the 1st ACM International Workshop on Personal Data Meets Distributed Multimedia},
pages = {3–10},
numpages = {8},
keywords = {situation recognition, geographic data, situation, geo-fencing, sensor networks, social networks, events},
location = {Barcelona, Spain},
series = {PDM '13}
}

@inproceedings{10.1145/2509352.2509400,
author = {Jalali, Laleh and Jain, Ramesh},
title = {Building Health Persona from Personal Data Streams},
year = {2013},
isbn = {9781450323970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2509352.2509400},
doi = {10.1145/2509352.2509400},
abstract = {Most people already use phones with myriad sensors that continuously generate data streams related to most aspects of their life. By detecting events in basic data streams and correlating and reasoning among them, it is possible to create a chronicle of personal life. We call it Personicle and use this to build individual Health Persona. Such Health Persona may then be used for understanding societal health as well as making decisions in emerging Social Life Networks. In this paper, we present a framework that collects, manages, and correlates personal data from heterogeneous data sources and detects events happening at personal level to build health persona. We use several data streams such as motion tracking, location tracking, activity level, and personal calendar data. We illustrate how two recognition algorithms based on Formal Concept Analysis and Decision Trees can be applied to Life Event detection problem. Also, we demonstrate the applicability of this framework on simulated data from Moves app, GPS, Nike fuel band, and Google calendar. We expect to soon have results for several individuals using real data streams from disparate wearable and smart phone sensors.},
booktitle = {Proceedings of the 1st ACM International Workshop on Personal Data Meets Distributed Multimedia},
pages = {19–26},
numpages = {8},
keywords = {personicle, wearable sensors, personal eventshop, life event, eventshop, health persona, health and wellness},
location = {Barcelona, Spain},
series = {PDM '13}
}

@inproceedings{10.1145/2591888.2591896,
author = {Nam, Taewoo},
title = {Government 3.0 in Korea: Fad or Fashion?},
year = {2013},
isbn = {9781450324564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591888.2591896},
doi = {10.1145/2591888.2591896},
abstract = {Korea puts forth Government 3.0 as a new paradigm of the government workings. President Park's strong pledge for public sector reform through the Government 3.0 drive envisions realizing a transparent, competent, and service-oriented government. Although value judgment on Government 3.0 is so premature yet, the Park administration sees as many critiques as eulogies for it. The Government 3.0 drive offers far more than what the technological potentials of Web 3.0 promise. What the drive suggests is not really novel. The details of Government 3.0 are similar to what Government 2.0 offers based on the interactive potentials of Web 2.0. The Government 3.0 drive is too normative to make practical results. Public agencies that lead the Government 3.0 drive may have confusion between its ends and means; as a result, goal displacement. Opening more information can impose more burdens on public employees' shoulder in warranting accuracy of information released and security of information sharing settings. Government 3.0 as political rhetoric may be ephemeral with political swings.},
booktitle = {Proceedings of the 7th International Conference on Theory and Practice of Electronic Governance},
pages = {46–55},
numpages = {10},
keywords = {government 3.0, government 2.0, symbolic policy, e-government, policy rhetoric},
location = {Seoul, Republic of Korea},
series = {ICEGOV '13}
}

@inproceedings{10.1145/2591888.2591914,
author = {Lu, Jianying and Zheng, Lei},
title = {Air Quality Information Disclosure in China: Needs and Capabilities},
year = {2013},
isbn = {9781450324564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591888.2591914},
doi = {10.1145/2591888.2591914},
abstract = {Air quality issue has become a global problem and air pollution is a serious threat to human health and the environment. This paper studies the public needs and government capabilities required as efforts of making air quality information public in Shanghai, China. It aims to explore people's various needs for air quality information and the challenges government is faced with in satisfying these needs. The paper also provides recommendation to Shanghai Environmental Monitoring Center with regard to how to satisfy or balance the various public needs.},
booktitle = {Proceedings of the 7th International Conference on Theory and Practice of Electronic Governance},
pages = {158–165},
numpages = {8},
keywords = {capabilities, needs, air quality, disclosure, China},
location = {Seoul, Republic of Korea},
series = {ICEGOV '13}
}

@inproceedings{10.1145/2504730.2504731,
author = {Stringhini, Gianluca and Wang, Gang and Egele, Manuel and Kruegel, Christopher and Vigna, Giovanni and Zheng, Haitao and Zhao, Ben Y.},
title = {Follow the Green: Growth and Dynamics in Twitter Follower Markets},
year = {2013},
isbn = {9781450319539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2504730.2504731},
doi = {10.1145/2504730.2504731},
abstract = {The users of microblogging services, such as Twitter, use the count of followers of an account as a measure of its reputation or influence. For those unwilling or unable to attract followers naturally, a growing industry of "Twitter follower markets" provides followers for sale. Some markets use fake accounts to boost the follower count of their customers, while others rely on a pyramid scheme to turn non-paying customers into followers for each other, and into followers for paying customers. In this paper, we present a detailed study of Twitter follower markets, report in detail on both the static and dynamic properties of customers of these markets, and develop and evaluate multiple techniques for detecting these activities. We show that our detection system is robust and reliable, and can detect a significant number of customers in the wild.},
booktitle = {Proceedings of the 2013 Conference on Internet Measurement Conference},
pages = {163–176},
numpages = {14},
keywords = {follower markets, online social networks, sybils, twitter},
location = {Barcelona, Spain},
series = {IMC '13}
}

@inproceedings{10.1145/2505515.2505572,
author = {Valkanas, George and Gunopulos, Dimitrios},
title = {How the Live Web Feels about Events},
year = {2013},
isbn = {9781450322638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2505515.2505572},
doi = {10.1145/2505515.2505572},
abstract = {Microblogging platforms, such as Twitter, Tumblr etc., have been established as key components in the contemporary Web ecosystem. Users constantly post snippets of information regarding their actions, interests or perception of their surroundings, which is why they have been attributed the term Live Web. Nevertheless, research on such platforms has been quite limited when it comes to identifying events, but is rapidly gaining ground. Event identification is a key step to news reporting, proactive or reactive crisis management at multiple scales, efficient resource allocation, etc. In this paper, we focus on the problem of automatically identifying events as they occur, in such a user-driven, fast paced and voluminous setting. We propose a novel and natural way to address the issue using notions from emotional theories, combined with spatiotemporal information and employ online event detection mechanisms to solve it at large scale in a distributed fashion. We present a modular framework that incorporates all of our key ideas and experimentally validate its superiority, in terms of both efficiency and effectiveness, over the state-of-the-art using real life data from the Twitter stream. We also present empirical evidence on the importance of spatiotemporal information in event detection for this setting.},
booktitle = {Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management},
pages = {639–648},
numpages = {10},
keywords = {live web, event identification, emotions, sentiment analysis},
location = {San Francisco, California, USA},
series = {CIKM '13}
}

@inproceedings{10.1145/2505515.2505741,
author = {Tangwongsan, Kanat and Pavan, A. and Tirthapura, Srikanta},
title = {Parallel Triangle Counting in Massive Streaming Graphs},
year = {2013},
isbn = {9781450322638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2505515.2505741},
doi = {10.1145/2505515.2505741},
abstract = {The number of triangles in a graph is a fundamental metric widely used in social network analysis, link classification and recommendation, and more. In these applications, modern graphs of interest tend to both large and dynamic. This paper presents the design and implementation of a fast parallel algorithm for estimating the number of triangles in a massive undirected graph whose edges arrive as a stream. Our algorithm is designed for shared-memory multicore machines and can make efficient use of parallelism and the memory hierarchy. We provide theoretical guarantees on performance and accuracy, and our experiments on real-world datasets show accurate results and substantial speedups compared to an optimized sequential implementation.},
booktitle = {Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management},
pages = {781–786},
numpages = {6},
keywords = {massive graphs, streaming algorithm, parallel cache oblivious (pco), triangle counting, parallel algorithm},
location = {San Francisco, California, USA},
series = {CIKM '13}
}

@inproceedings{10.1145/2505515.2505717,
author = {Diaz, Fernando and White, Ryen and Buscher, Georg and Liebling, Dan},
title = {Robust Models of Mouse Movement on Dynamic Web Search Results Pages},
year = {2013},
isbn = {9781450322638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2505515.2505717},
doi = {10.1145/2505515.2505717},
abstract = {Understanding how users examine result pages across a broad range of information needs is critical for search engine design. Cursor movements can be used to estimate visual attention on search engine results page (SERP) components, including traditional snippets, aggregated results, and advertisements. However, these signals can only be leveraged for SERPs where cursor tracking was enabled, limiting their utility for informing the design of new SERPs. In this work, we develop robust, log-based mouse movement models capable of estimating searcher attention on novel SERP arrangements. These models can help improve SERP design by anticipating searchers' engagement patterns given a proposed arrangement. We demonstrate the efficacy of our method using a large set of mouse-tracking data collected from two independent commercial search engines.},
booktitle = {Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management},
pages = {1451–1460},
numpages = {10},
keywords = {mouse-tracking, cascade model},
location = {San Francisco, California, USA},
series = {CIKM '13}
}

@inproceedings{10.1145/2541329.2541338,
author = {Swalens, Janwillem and Renaux, Thierry and Hoste, Lode and Marr, Stefan and De Meuter, Wolfgang},
title = {Cloud PARTE: Elastic Complex Event Processing Based on Mobile Actors},
year = {2013},
isbn = {9781450326025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2541329.2541338},
doi = {10.1145/2541329.2541338},
abstract = {Traffic monitoring or crowd management systems produce large amounts of data in the form of events that need to be processed to detect relevant incidents. Rule-based pattern recognition is a promising approach for these applications, however, increasing amounts of data as well as large and complex rule sets demand for more and more processing power and memory. In order to scale such applications, a rule-based pattern detection system needs to be distributable over multiple machines. Today's approaches are however focused on static distribution of rules or do not support reasoning over the full set of events. We propose Cloud PARTE, a complex event detection system that implements the Rete algorithm on top of mobile actors. These actors can migrate between machines to respond to changes in the work load distribution. Cloud PARTE is an extension of PARTE and offers the first rule engine specifically tailored for continuous complex event detection that is able to benefit from elastic systems as provided by cloud computing platforms. It supports fully automatic load balancing and supports online rules with access to the entire event pool.},
booktitle = {Proceedings of the 2013 Workshop on Programming Based on Actors, Agents, and Decentralized Control},
pages = {3–12},
numpages = {10},
keywords = {online reasoning, mobile actors, complex event processing, rete, load balancing},
location = {Indianapolis, Indiana, USA},
series = {AGERE! 2013}
}

@inproceedings{10.1145/2505515.2505719,
author = {Kong, Weize and Aktolga, Elif and Allan, James},
title = {Improving Passage Ranking with User Behavior Information},
year = {2013},
isbn = {9781450322638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2505515.2505719},
doi = {10.1145/2505515.2505719},
abstract = {User behavior information has proved valuable for inferring document relevance, but its role in deducing relevance at the passage/section level is not well explored. In this paper, we study how user behavior information implies section relevance, and use this information to improve section ranking. More specifically, we focus on four types of user search behavior that occur while browsing a document -- dwell time, highlighting, copying and clicks at the section level. Experimental results based on a commercial query log show that user behavior information can significantly improve section ranking. While section-level click information is a very powerful signal of relevance, it depends on an interface supporting section-level links. We find comparable levels of gain using other behavior information that does not depend upon such an interface.},
booktitle = {Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management},
pages = {1999–2008},
numpages = {10},
keywords = {user behavior, passage retrieval, dwell time},
location = {San Francisco, California, USA},
series = {CIKM '13}
}

@inproceedings{10.1145/2505515.2505699,
author = {Broccolo, Daniele and Macdonald, Craig and Orlando, Salvatore and Ounis, Iadh and Perego, Raffaele and Silvestri, Fabrizio and Tonellotto, Nicola},
title = {Load-Sensitive Selective Pruning for Distributed Search},
year = {2013},
isbn = {9781450322638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2505515.2505699},
doi = {10.1145/2505515.2505699},
abstract = {A search engine infrastructure must be able to provide the same quality of service to all queries received during a day. During normal operating conditions, the demand for resources is considerably lower than under peak conditions, yet an oversized infrastructure would result in an unnecessary waste of computing power. A possible solution adopted in this situation might consist of defining a maximum threshold processing time for each query, and dropping queries for which this threshold elapses, leading to disappointed users. In this paper, we propose and evaluate a different approach, where, given a set of different query processing strategies with differing efficiency, each query is considered by a framework that sets a maximum query processing time and selects which processing strategy is the best for that query, such that the processing time for all queries is kept below the threshold. The processing time estimates used by the scheduler are learned from past queries. We experimentally validate our approach on 10,000 queries from a standard TREC dataset with over 50 million documents, and we compare it with several baselines. These experiments encompass testing the system under different query loads and different maximum tolerated query response times. Our results show that, at the cost of a marginal loss in terms of response quality, our search system is able to answer 90% of queries within half a second during times of high query volume.},
booktitle = {Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management},
pages = {379–388},
numpages = {10},
keywords = {query efficiency prediction, scheduling},
location = {San Francisco, California, USA},
series = {CIKM '13}
}

@inproceedings{10.1145/2536146.2536191,
author = {Soler, Luciana S. and Gregorio, Leandro T. and Leal, Paulo and Gon\c{c}alves, Demerval and Londe, Luciana and Soriano, \'{E}rico and Cardoso, Jarbas and Coutinho, Marcos and Santos, Leonardo B. L. and Saito, Silvia},
title = {Challenges and Perspectives of Innovative Digital Ecosystems Designed to Monitor and Warn Natural Disasters in Brazil},
year = {2013},
isbn = {9781450320047},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2536146.2536191},
doi = {10.1145/2536146.2536191},
abstract = {The increasing figures of natural disasters and related human and material losses represent a major challenge to be faced by the Brazilian government, the scientific community and civil society all together. Landslides and floods resulting from climatic extremes have been associated not only to global climatic changes, but mostly due to the increase of population vulnerability and the lack of effective mitigation actions. Core governmental responses to mitigate such losses include the creation of operational centers for disaster monitoring and management -- Cemaden (National Early Warning and Monitoring Centre of Natural Disasters) and CENAD (Centro Nacional de Gerenciamento de Riscos e Desastres). The establishment of these institutions associated with investments to map risky areas are key to implement landslides and floods monitoring systems. Despite significant investments, the implementation of such natural disaster monitoring systems depend much on cooperative actions among organizations and entities from different sectors of the society. The main objective of this work is to present the challenges and perspectives of innovative digital ecosystems designed to effectively monitor, warn and respond to natural disasters related to landslides and floods in Brazil. The several methodologies adopted make use of technical, scientific and empirical knowledge to establish a rain gauge network of 1400 automatic pluviometers and 1100 semiautomatic pluviometers, distributed in more than 800 municipalities defined as priority ones by the Brazilian National Plan of Risk Management and Response to Natural Disasters. Pilot projects of landslides monitoring systems are also included in the methodology in key municipalities where the number of human losses has been significant in recent disasters. In order to develop such challenging methodologies, Cemaden has worked together with the Center for Information Technology Renato Archer (CTI), CENAD, a number of research institutions, the private sector, local and regional governments and non-governmental organizations as well as the civil society. The combination of different types of knowledge, technological approaches and levels of interaction to population under risk of such a variety of organizations shall configure a collective intelligence able to improve the efficiency and confidence of early warnings of landslides and floods, as well as to promote further commitment of local governments and communities to respond to warnings.},
booktitle = {Proceedings of the Fifth International Conference on Management of Emergent Digital EcoSystems},
pages = {254–261},
numpages = {8},
keywords = {flood, remote sensors networks, early warnings, natural disasters, cooperative entities, monitoring systems, collective intelligence, landslide, Brazil},
location = {Luxembourg, Luxembourg},
series = {MEDES '13}
}

@inproceedings{10.1145/2516540.2516563,
author = {Angelini, Leonardo and Carrino, Francesco and Carrino, Stefano and Caon, Maurizio and Lalanne, Denis and Khaled, Omar Abou and Mugellini, Elena},
title = {Opportunistic Synergy: A Classifier Fusion Engine for Micro-Gesture Recognition},
year = {2013},
isbn = {9781450324786},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2516540.2516563},
doi = {10.1145/2516540.2516563},
abstract = {In this paper, we present a novel opportunistic paradigm for in-vehicle gesture recognition. This paradigm allows using two or more subsystems in a synergistic manner: they can work in parallel but the lack of some of them does not compromise the functioning of the whole system. In order to segment and recognize micro-gestures performed by the user on the steering wheel, we combine a wearable approach based on the electromyography of the user's forearm muscles, with an environmental approach based on pressure sensors integrated directly on the steering wheel. We present and analyze several fusion methods and gesture segmentation strategies. A prototype has been developed and evaluated with data from nine subjects. The results prove that the proposed opportunistic system performs equal or better than each stand-alone subsystem while increasing the interaction possibilities.},
booktitle = {Proceedings of the 5th International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
pages = {30–37},
numpages = {8},
keywords = {tangible gestures, ubiquitous computing, in-vehicle interaction, micro-gestures, electromyography, environmental and wearable paradigms},
location = {Eindhoven, Netherlands},
series = {AutomotiveUI '13}
}

@inproceedings{10.1145/2509578.2509583,
author = {Mayer, Mika\"{e}l and Kuncak, Viktor},
title = {Game Programming by Demonstration},
year = {2013},
isbn = {9781450324724},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2509578.2509583},
doi = {10.1145/2509578.2509583},
abstract = {The increasing adoption of smartphones and tablets has provided tens of millions of users with substantial resources for computation, communication and sensing. The availability of these resources has a huge potential to positively transform our society and empower individuals. Unfortunately, although the number of users has increased dramatically, the number of developers is still limited by the high barrier that existing programming environments impose.To understand possible directions for helping end users to program, we present Pong Designer, an environment for developing 2D physics games through direct manipulation of object behaviors. Pong Designer is built using Scala and runs on Android tablets with the multi-touch screen as the main input. We show that Pong Designer can create simple games in a few steps. This includes (multi-player and multi-screen) Pong, Brick Breaker, Pacman, Tilting maze. We make available Pong Designer as well as several editable games that we created using it. This paper describes the main principles behind Pong Designer, and illustrates the process of developing and customizing behavior in this approach},
booktitle = {Proceedings of the 2013 ACM International Symposium on New Ideas, New Paradigms, and Reflections on Programming &amp; Software},
pages = {75–90},
numpages = {16},
keywords = {program synthesis, programming by demonstration, machine learning},
location = {Indianapolis, Indiana, USA},
series = {Onward! 2013}
}

@inproceedings{10.1145/2509136.2509547,
author = {Miller, Heather and Haller, Philipp and Burmako, Eugene and Odersky, Martin},
title = {Instant Pickles: Generating Object-Oriented Pickler Combinators for Fast and Extensible Serialization},
year = {2013},
isbn = {9781450323741},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2509136.2509547},
doi = {10.1145/2509136.2509547},
abstract = {As more applications migrate to the cloud, and as "big data" edges into even more production environments, the performance and simplicity of exchanging data between compute nodes/devices is increasing in importance. An issue central to distributed programming, yet often under-considered, is serialization or pickling, i.e., persisting runtime objects by converting them into a binary or text representation. Pickler combinators are a popular approach from functional programming; their composability alleviates some of the tedium of writing pickling code by hand, but they don't translate well to object-oriented programming due to qualities like open class hierarchies and subtyping polymorphism. Furthermore, both functional pickler combinators and popular, Java-based serialization frameworks tend to be tied to a specific pickle format, leaving programmers with no choice of how their data is persisted. In this paper, we present object-oriented pickler combinators and a framework for generating them at compile-time, called scala/pickling, designed to be the default serialization mechanism of the Scala programming language. The static generation of OO picklers enables significant performance improvements, outperforming Java and Kryo in most of our benchmarks. In addition to high performance and the need for little to no boilerplate, our framework is extensible: using the type class pattern, users can provide both (1) custom, easily interchangeable pickle formats and (2) custom picklers, to override the default behavior of the pickling framework. In benchmarks, we compare scala/pickling with other popular industrial frameworks, and present results on time, memory usage, and size when pickling/unpickling a number of data types used in real-world, large-scale distributed applications and frameworks.},
booktitle = {Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages &amp; Applications},
pages = {183–202},
numpages = {20},
keywords = {serialization, distributed programming, pickling, meta-programming, scala},
location = {Indianapolis, Indiana, USA},
series = {OOPSLA '13}
}

@article{10.1145/2544173.2509547,
author = {Miller, Heather and Haller, Philipp and Burmako, Eugene and Odersky, Martin},
title = {Instant Pickles: Generating Object-Oriented Pickler Combinators for Fast and Extensible Serialization},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/2544173.2509547},
doi = {10.1145/2544173.2509547},
abstract = {As more applications migrate to the cloud, and as "big data" edges into even more production environments, the performance and simplicity of exchanging data between compute nodes/devices is increasing in importance. An issue central to distributed programming, yet often under-considered, is serialization or pickling, i.e., persisting runtime objects by converting them into a binary or text representation. Pickler combinators are a popular approach from functional programming; their composability alleviates some of the tedium of writing pickling code by hand, but they don't translate well to object-oriented programming due to qualities like open class hierarchies and subtyping polymorphism. Furthermore, both functional pickler combinators and popular, Java-based serialization frameworks tend to be tied to a specific pickle format, leaving programmers with no choice of how their data is persisted. In this paper, we present object-oriented pickler combinators and a framework for generating them at compile-time, called scala/pickling, designed to be the default serialization mechanism of the Scala programming language. The static generation of OO picklers enables significant performance improvements, outperforming Java and Kryo in most of our benchmarks. In addition to high performance and the need for little to no boilerplate, our framework is extensible: using the type class pattern, users can provide both (1) custom, easily interchangeable pickle formats and (2) custom picklers, to override the default behavior of the pickling framework. In benchmarks, we compare scala/pickling with other popular industrial frameworks, and present results on time, memory usage, and size when pickling/unpickling a number of data types used in real-world, large-scale distributed applications and frameworks.},
journal = {SIGPLAN Not.},
month = oct,
pages = {183–202},
numpages = {20},
keywords = {scala, distributed programming, meta-programming, serialization, pickling}
}

@inproceedings{10.1145/2509136.2509541,
author = {Kansal, Aman and Saponas, Scott and Brush, A.J. Bernheim and McKinley, Kathryn S. and Mytkowicz, Todd and Ziola, Ryder},
title = {The Latency, Accuracy, and Battery (LAB) Abstraction: Programmer Productivity and Energy Efficiency for Continuous Mobile Context Sensing},
year = {2013},
isbn = {9781450323741},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2509136.2509541},
doi = {10.1145/2509136.2509541},
abstract = {Emerging mobile applications that sense context are poised to delight and entertain us with timely news and events, health tracking, and social connections. Unfortunately, sensing algorithms quickly drain the phone's battery. Developers can overcome battery drain by carefully optimizing context sensing but that makes programming with context arduous and ties applications to current sensing hardware. These types of applications embody a twist on the classic tension between programmer productivity and performance due to their combination of requirements.This paper identifies the latency, accuracy, battery (LAB) abstraction to resolve this tension. We implement and evaluate LAB in a system called Senergy. Developers specify their LAB requirements independent of inference algorithms and sensors. Senergy delivers energy efficient context while meeting the requirements and adapts as hardware changes. We demonstrate LAB's expressiveness by using it to implement 22 context sensing algorithms for four types of context (location, driving, walking, and stationary) and six diverse applications. To demonstrate LAB's energy optimizations, we show often an order of magnitude improvements in energy efficiency on applications compared to prior approaches. This relatively simple, priority based API, may serve as a blueprint for future API design in an increasingly complex design space that must tradeoff latency, accuracy, and efficiency to meet application needs and attain portability across evolving, sensor-rich, heterogeneous, and power constrained hardware.},
booktitle = {Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages &amp; Applications},
pages = {661–676},
numpages = {16},
keywords = {sensor api, mobile sensing},
location = {Indianapolis, Indiana, USA},
series = {OOPSLA '13}
}

@article{10.1145/2544173.2509541,
author = {Kansal, Aman and Saponas, Scott and Brush, A.J. Bernheim and McKinley, Kathryn S. and Mytkowicz, Todd and Ziola, Ryder},
title = {The Latency, Accuracy, and Battery (LAB) Abstraction: Programmer Productivity and Energy Efficiency for Continuous Mobile Context Sensing},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/2544173.2509541},
doi = {10.1145/2544173.2509541},
abstract = {Emerging mobile applications that sense context are poised to delight and entertain us with timely news and events, health tracking, and social connections. Unfortunately, sensing algorithms quickly drain the phone's battery. Developers can overcome battery drain by carefully optimizing context sensing but that makes programming with context arduous and ties applications to current sensing hardware. These types of applications embody a twist on the classic tension between programmer productivity and performance due to their combination of requirements.This paper identifies the latency, accuracy, battery (LAB) abstraction to resolve this tension. We implement and evaluate LAB in a system called Senergy. Developers specify their LAB requirements independent of inference algorithms and sensors. Senergy delivers energy efficient context while meeting the requirements and adapts as hardware changes. We demonstrate LAB's expressiveness by using it to implement 22 context sensing algorithms for four types of context (location, driving, walking, and stationary) and six diverse applications. To demonstrate LAB's energy optimizations, we show often an order of magnitude improvements in energy efficiency on applications compared to prior approaches. This relatively simple, priority based API, may serve as a blueprint for future API design in an increasingly complex design space that must tradeoff latency, accuracy, and efficiency to meet application needs and attain portability across evolving, sensor-rich, heterogeneous, and power constrained hardware.},
journal = {SIGPLAN Not.},
month = oct,
pages = {661–676},
numpages = {16},
keywords = {mobile sensing, sensor api}
}

@inproceedings{10.1145/2509136.2509510,
author = {Huang, Jipeng and Bond, Michael D.},
title = {Efficient Context Sensitivity for Dynamic Analyses via Calling Context Uptrees and Customized Memory Management},
year = {2013},
isbn = {9781450323741},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2509136.2509510},
doi = {10.1145/2509136.2509510},
abstract = {State-of-the-art dynamic bug detectors such as data race and memory leak detectors report program locations that are likely causes of bugs. However, programmers need more than static program locations to understand the behavior of increasingly complex and concurrent software. Dynamic calling context provides additional information, but it is expensive to record calling context frequently, e.g., at every read and write. Context-sensitive dynamic analyses can build and maintain a calling context tree (CCT) to track calling context--but in order to reuse existing nodes, CCT-based approaches require an expensive lookup.This paper introduces a new approach for context sensitivity that avoids this expensive lookup. The approach uses a new data structure called the calling context uptree (CCU) that adds low overhead by avoiding the lookup and instead allocating a new node for each context. A key contribution is that the approach can mitigate the costs of allocating many nodes by extending tracing garbage collection (GC): GC collects unused CCU nodes naturally and efficiently, and we extend GC to merge duplicate nodes lazily.We implement our CCU-based approach in a high-performance Java virtual machine and integrate it with a staleness-based memory leak detector and happens-before data race detector, so they can report context-sensitive program locations that cause bugs. We show that the CCU-based approach, in concert with an extended GC, provides a compelling alternative to CCT-based approaches for adding context sensitivity to dynamic analyses.},
booktitle = {Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages &amp; Applications},
pages = {53–72},
numpages = {20},
keywords = {calling context, context sensitivity, dynamic analysis, garbage collection, leak detection, race detection},
location = {Indianapolis, Indiana, USA},
series = {OOPSLA '13}
}

@article{10.1145/2544173.2509510,
author = {Huang, Jipeng and Bond, Michael D.},
title = {Efficient Context Sensitivity for Dynamic Analyses via Calling Context Uptrees and Customized Memory Management},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/2544173.2509510},
doi = {10.1145/2544173.2509510},
abstract = {State-of-the-art dynamic bug detectors such as data race and memory leak detectors report program locations that are likely causes of bugs. However, programmers need more than static program locations to understand the behavior of increasingly complex and concurrent software. Dynamic calling context provides additional information, but it is expensive to record calling context frequently, e.g., at every read and write. Context-sensitive dynamic analyses can build and maintain a calling context tree (CCT) to track calling context--but in order to reuse existing nodes, CCT-based approaches require an expensive lookup.This paper introduces a new approach for context sensitivity that avoids this expensive lookup. The approach uses a new data structure called the calling context uptree (CCU) that adds low overhead by avoiding the lookup and instead allocating a new node for each context. A key contribution is that the approach can mitigate the costs of allocating many nodes by extending tracing garbage collection (GC): GC collects unused CCU nodes naturally and efficiently, and we extend GC to merge duplicate nodes lazily.We implement our CCU-based approach in a high-performance Java virtual machine and integrate it with a staleness-based memory leak detector and happens-before data race detector, so they can report context-sensitive program locations that cause bugs. We show that the CCU-based approach, in concert with an extended GC, provides a compelling alternative to CCT-based approaches for adding context sensitivity to dynamic analyses.},
journal = {SIGPLAN Not.},
month = oct,
pages = {53–72},
numpages = {20},
keywords = {context sensitivity, calling context, race detection, leak detection, garbage collection, dynamic analysis}
}

@inproceedings{10.1145/2509136.2509533,
author = {Tripp, Omer and Koskinen, Eric and Sagiv, Mooly},
title = {Turning Nondeterminism into Parallelism},
year = {2013},
isbn = {9781450323741},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2509136.2509533},
doi = {10.1145/2509136.2509533},
abstract = {Nondeterminism is a useful and prevalent concept in the design and implementation of software systems. An important property of nondeterminism is its latent parallelism: A nondeterministic action can evaluate to multiple behaviors. If at least one of these behaviors does not conflict with concurrent tasks, then there is an admissible execution of the action in parallel with these tasks. Unfortunately, existing implementations of the atomic paradigm - optimistic as well as pessimistic - are unable to fully exhaust the parallelism potential of nondeterministic actions, lacking the means to guide concurrent tasks toward nondeterministic choices that minimize interference.This paper investigates the problem of utilizing parallelism due to nondeterminism. We observe that nondeterminism occurs in many real-world codes. We motivate the need for devising coordination mechanisms that can utilize available nondeterminism. We have developed a system featuring such mechanisms, which leverages nondeterminism in a wide class of query operations, allowing a task to look into the future of concurrent tasks that mutate the shared state during query evaluation and reduce conflict accordingly. We evaluate our system on a suite of 12 algorithmic benchmarks of wide applicability, as well as an industrial application. The results are encouraging.},
booktitle = {Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages &amp; Applications},
pages = {589–604},
numpages = {16},
keywords = {synchronization, parallelism, concurrency control, serializability, nondeterminism},
location = {Indianapolis, Indiana, USA},
series = {OOPSLA '13}
}

@article{10.1145/2544173.2509533,
author = {Tripp, Omer and Koskinen, Eric and Sagiv, Mooly},
title = {Turning Nondeterminism into Parallelism},
year = {2013},
issue_date = {October 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/2544173.2509533},
doi = {10.1145/2544173.2509533},
abstract = {Nondeterminism is a useful and prevalent concept in the design and implementation of software systems. An important property of nondeterminism is its latent parallelism: A nondeterministic action can evaluate to multiple behaviors. If at least one of these behaviors does not conflict with concurrent tasks, then there is an admissible execution of the action in parallel with these tasks. Unfortunately, existing implementations of the atomic paradigm - optimistic as well as pessimistic - are unable to fully exhaust the parallelism potential of nondeterministic actions, lacking the means to guide concurrent tasks toward nondeterministic choices that minimize interference.This paper investigates the problem of utilizing parallelism due to nondeterminism. We observe that nondeterminism occurs in many real-world codes. We motivate the need for devising coordination mechanisms that can utilize available nondeterminism. We have developed a system featuring such mechanisms, which leverages nondeterminism in a wide class of query operations, allowing a task to look into the future of concurrent tasks that mutate the shared state during query evaluation and reduce conflict accordingly. We evaluate our system on a suite of 12 algorithmic benchmarks of wide applicability, as well as an industrial application. The results are encouraging.},
journal = {SIGPLAN Not.},
month = oct,
pages = {589–604},
numpages = {16},
keywords = {synchronization, concurrency control, parallelism, nondeterminism, serializability}
}

@inproceedings{10.1145/2534088.2534107,
author = {Pipke, R. Matthew and Wegerich, Stephan W. and Saidi, Abdulfattah and Stehlik, Josef},
title = {Feasibility of Personalized Nonparametric Analytics for Predictive Monitoring of Heart Failure Patients Using Continuous Mobile Telemetry},
year = {2013},
isbn = {9781450322904},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2534088.2534107},
doi = {10.1145/2534088.2534107},
abstract = {Nonparametric model-based analytics personalized to the physiology of each patient are investigated for predictive monitoring of exacerbation in heart failure patients at home. Multivariate vital sign data are provided by means of continuous bio-signal acquisition with a mobile phone-based wearable sensor system worn by patients for several hours a day in the home ambulatory environment. Perturbation analysis demonstrates that individual patient physiological behavior is indeed effectively learned by the analytics, with high sensitivity to changes in physiological dynamics. Comparison of the analytics results with absence of unplanned medical events and self-reported wellness during regular patient follow-up demonstrate a very low false alert burden, suggesting this approach is efficient for remote clinical surveillance.},
booktitle = {Proceedings of the 4th Conference on Wireless Health},
articleno = {7},
numpages = {8},
keywords = {medical expert systems, wearable sensors, biological system modeling, machine learning algorithms, biomedical monitoring, medical conditions, cardiology, diseases},
location = {Baltimore, Maryland},
series = {WH '13}
}

@inproceedings{10.5555/2655780.2655908,
author = {Jones, Kyle M. L.},
title = {Learning Analytics &amp; FERPA: Issues of Student Privacy and New Boundaries of Student Data},
year = {2013},
isbn = {0877155453},
publisher = {American Society for Information Science},
address = {USA},
abstract = {In keeping with the conference's theme of "Rethinking Information Boundaries," this poster describes preliminary research results from a case study regarding how Hammond University is employing analytic technologies to examine student data across boundaries: within the technological domain of their campus and from disparate sources beyond.},
booktitle = {Proceedings of the 76th ASIS&amp;T Annual Meeting: Beyond the Cloud: Rethinking Information Boundaries},
articleno = {128},
numpages = {5},
location = {Montreal, Quebec, Canada},
series = {ASIST '13}
}

@inproceedings{10.1145/2534088.2534106,
author = {Altini, Marco and Penders, Julien and Vullers, Ruud and Amft, Oliver},
title = {Combining Wearable Accelerometer and Physiological Data for Activity and Energy Expenditure Estimation},
year = {2013},
isbn = {9781450322904},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2534088.2534106},
doi = {10.1145/2534088.2534106},
abstract = {Physical Activity (PA) is one of the most important determinants of health. Wearable sensors have great potential for accurate assessment of PA (activity type and Energy Expenditure (EE)) in daily life. In this paper we investigate the benefit of multiple physiological signals (Heart Rate (HR), respiration rate, Galvanic Skin Response (GSR), skin humidity) as well as accelerometer (ACC) data from two locations (wrist - combining ACC, GSR and skin humidity - and chest - combining ACC and HR) on PA type and EE estimation. We implemented single regression, activity recognition and activity-specific EE models on data collected from 16 subjects, while performing a set of PAs, grouped into six clusters (lying, sedentary, dynamic, walking, biking and running). Our results show that combining ACC and physiological signals improves performance for activity recognition (by 2 and 8% for the chest and wrist) and EE (by 36 - chest - and 35% - wrist - for single regression models, and by 18 - chest - and 46% - wrist - for activity-specific models). Physiological signals other than HR showed a coarser relation with level of physical exertion, resulting in being better predictors of activity cluster type and separation between inactivity and activity than EE, due to the weak correlation to EE within an activity cluster.},
booktitle = {Proceedings of the 4th Conference on Wireless Health},
articleno = {1},
numpages = {8},
location = {Baltimore, Maryland},
series = {WH '13}
}

@inproceedings{10.5555/2655780.2655868,
author = {Alberts, Inge},
title = {Challenges of Information System Use by Knowledge Workers: The Email Productivity Paradox},
year = {2013},
isbn = {0877155453},
publisher = {American Society for Information Science},
address = {USA},
abstract = {With the growing importance of social media, cloud computing and mobile device interactions, the digital work environment is being perpetually transformed while forcing users to adapt to the emerging technologies. In this volatile environment, research leading to innovative approaches to better support the information practices of knowledge workers is acquiring a critical importance. Aiming to improve the technological and organizational policy-making decisions for the implementation of new information systems, this paper examines the current challenges of 34 knowldege workers using information systems to perform their daily tasks. A qualitative research approch entailing the use of semi-directed interviews and diary journals is followed to this end. The outcomes of this research are both theoretical and practical. This research provides a critical insight into the key challenges facing knowledge workers in the digital work environment. From a purely practical perspective, this study helps uncover the needs and expectations of knowledge workers as they use email and other technologies to achieve their work tasks. In light of this study, the technological and organizational policy-making decisions for the implementation of new information systems must ensure that email as a tool drives true productivity and avoids the productivity paradox.},
booktitle = {Proceedings of the 76th ASIS&amp;T Annual Meeting: Beyond the Cloud: Rethinking Information Boundaries},
articleno = {88},
numpages = {10},
keywords = {user study, productivity, personal information management, email overload},
location = {Montreal, Quebec, Canada},
series = {ASIST '13}
}

@article{10.1145/2503823,
author = {Bentley, Frank and Tollmar, Konrad and Stephenson, Peter and Levy, Laura and Jones, Brian and Robertson, Scott and Price, Ed and Catrambone, Richard and Wilson, Jeff},
title = {Health Mashups: Presenting Statistical Patterns between Wellbeing Data and Context in Natural Language to Promote Behavior Change},
year = {2013},
issue_date = {November 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {5},
issn = {1073-0516},
url = {https://doi.org/10.1145/2503823},
doi = {10.1145/2503823},
abstract = {People now have access to many sources of data about their health and wellbeing. Yet, most people cannot wade through all of this data to answer basic questions about their long-term wellbeing: Do I gain weight when I have busy days? Do I walk more when I work in the city? Do I sleep better on nights after I work out?We built the Health Mashups system to identify connections that are significant over time between weight, sleep, step count, calendar data, location, weather, pain, food intake, and mood. These significant observations are displayed in a mobile application using natural language, for example, “You are happier on days when you sleep more.” We performed a pilot study, made improvements to the system, and then conducted a 90-day trial with 60 diverse participants, learning that interactions between wellbeing and context are highly individual and that our system supported an increased self-understanding that lead to focused behavior changes.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = nov,
articleno = {30},
numpages = {27},
keywords = {wellbeing, context, mobile, Health, mashups}
}

@inproceedings{10.5555/2655780.2655797,
author = {Kriesberg, Adam and Frank, Rebecca D. and Faniel, Ixchel M. and Yakel, Elizabeth},
title = {The Role of Data Reuse in the Apprenticeship Process},
year = {2013},
isbn = {0877155453},
publisher = {American Society for Information Science},
address = {USA},
abstract = {The availability of research data through digital repositories has made data reuse a possibility in a growing number of fields. This paper reports on the results of interviews with 27 zoologists, 43 quantitative social scientists and 22 archaeologists. It examines how data reuse contributes to the apprenticeship process and aids students in becoming full members of scholarly disciplines. Specifically, it investigates how data reuse contributes to the processes by which novice researchers join academic communities of practice. We demonstrate how projects involving data reuse provide a unique opportunity for advisors to mentor novices through the process of creating knowledge. In these situations, senior researchers model general reuse practices and impart skills for their students to use in the future when selecting, evaluating, and analyzing data they did not collect. For novices, data reuse constitutes a form of legitimate peripheral participation, a way for them to enter the community of practice by analyzing data that has been previously collected and reflecting on others' methodologies. Our study findings indicate that reuse occurs across each target community studied. They also suggest how repositories can help foster a reuse culture by providing access to data and building trust in research communities.},
booktitle = {Proceedings of the 76th ASIS&amp;T Annual Meeting: Beyond the Cloud: Rethinking Information Boundaries},
articleno = {17},
numpages = {10},
keywords = {disciplinary repositories, communities of practice, cognitive apprenticeship, digital repositories, data reuse, legitimate peripheral participation},
location = {Montreal, Quebec, Canada},
series = {ASIST '13}
}

@inproceedings{10.5555/2655780.2655920,
author = {Trembach, Stan},
title = {Pioneers in Uncharted Territory: VINITI and the Communist Influence on the U.S. Scientific and Technical Information System},
year = {2013},
isbn = {0877155453},
publisher = {American Society for Information Science},
address = {USA},
abstract = {Given that the rise of the Internet has greatly intensified information management problems in contemporary society, the historical perspective, or looking at the roots, is viewed by many as an indispensable component of the quest for practical solutions to information overload. This historical comparative study intends to narrow the gap in the existing knowledge about the impact of the Soviet military-industrial complex on the rise of the scientific and technical information management system in the mid-20th century United States, particularly in such agencies as the National Science Foundation (NSF) and the National Technical Information Service (NTIS). Along with a chronological analysis of primary and secondary documents, data are being collected via a series of interviews with prominent experts in the field whose research has revolved around both VINITI and the formative years of the U.S. scientific and technical information domain. Conclusions regarding the NSF and NTIS reactions to the Soviet developments are being made based on such indicators as organizational changes, budget allocations, and manpower changes.},
booktitle = {Proceedings of the 76th ASIS&amp;T Annual Meeting: Beyond the Cloud: Rethinking Information Boundaries},
articleno = {140},
numpages = {3},
keywords = {information explosion, information overload, VINITI, cold war, scientific and technical information management, NSF, NTIS},
location = {Montreal, Quebec, Canada},
series = {ASIST '13}
}

@inproceedings{10.1145/2524211.2524212,
author = {Birman, Ken and Sohn, Heesung},
title = {Hosting Dynamic Data in the Cloud with Isis2 and the Ida DHT},
year = {2013},
isbn = {9781450324632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2524211.2524212},
doi = {10.1145/2524211.2524212},
abstract = {The big-data community generally favors a two stage methodology whereby data is first collected, then uploaded for analysis using tools like MapReduce. During analysis the data won't change; this simplifies fault-tolerance and makes it worthwhile to cache intermediary results. In contrast, when it is necessary to capture data continuously and query it on the fly, cloud storage and access technologies must be reexamined. Isis2 aims at such scenarios, offering a base set of mechanisms that replicate data and perform computation with strong consistency and other assurance properties, then layering higher level abstractions over this core. Here we a focus on a subsystem called the Isis2 interactive data analysis infrastructure: Ida. Ida is a strongly-consistent distributed key-value store on which surprisingly complex computational tasks are feasible.},
booktitle = {Proceedings of the First ACM SIGOPS Conference on Timely Results in Operating Systems},
articleno = {10},
numpages = {15},
location = {Farmington, Pennsylvania},
series = {TRIOS '13}
}

@inproceedings{10.1145/2517349.2522716,
author = {Ousterhout, Kay and Wendell, Patrick and Zaharia, Matei and Stoica, Ion},
title = {Sparrow: Distributed, Low Latency Scheduling},
year = {2013},
isbn = {9781450323888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517349.2522716},
doi = {10.1145/2517349.2522716},
abstract = {Large-scale data analytics frameworks are shifting towards shorter task durations and larger degrees of parallelism to provide low latency. Scheduling highly parallel jobs that complete in hundreds of milliseconds poses a major challenge for task schedulers, which will need to schedule millions of tasks per second on appropriate machines while offering millisecond-level latency and high availability. We demonstrate that a decentralized, randomized sampling approach provides near-optimal performance while avoiding the throughput and availability limitations of a centralized design. We implement and deploy our scheduler, Sparrow, on a 110-machine cluster and demonstrate that Sparrow performs within 12% of an ideal scheduler.},
booktitle = {Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles},
pages = {69–84},
numpages = {16},
location = {Farminton, Pennsylvania},
series = {SOSP '13}
}

@inproceedings{10.1145/2517349.2522737,
author = {Zaharia, Matei and Das, Tathagata and Li, Haoyuan and Hunter, Timothy and Shenker, Scott and Stoica, Ion},
title = {Discretized Streams: Fault-Tolerant Streaming Computation at Scale},
year = {2013},
isbn = {9781450323888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517349.2522737},
doi = {10.1145/2517349.2522737},
abstract = {Many "big data" applications must act on data in real time. Running these applications at ever-larger scales requires parallel platforms that automatically handle faults and stragglers. Unfortunately, current distributed stream processing models provide fault recovery in an expensive manner, requiring hot replication or long recovery times, and do not handle stragglers. We propose a new processing model, discretized streams (D-Streams), that overcomes these challenges. D-Streams enable a parallel recovery mechanism that improves efficiency over traditional replication and backup schemes, and tolerates stragglers. We show that they support a rich set of operators while attaining high per-node throughput similar to single-node systems, linear scaling to 100 nodes, sub-second latency, and sub-second fault recovery. Finally, D-Streams can easily be composed with batch and interactive query models like MapReduce, enabling rich applications that combine these modes. We implement D-Streams in a system called Spark Streaming.},
booktitle = {Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles},
pages = {423–438},
numpages = {16},
location = {Farminton, Pennsylvania},
series = {SOSP '13}
}

@inproceedings{10.1145/2508222.2508229,
author = {Ortiz, Antonio M. and Royo, Fernando and Olivares, Teresa and Crespi, Noel and Orozco-Barbosa, Luis},
title = {Smart Wireless Design Scheme: Fuzzy-Logic Routing and TDMA MAC Protocol Integration},
year = {2013},
isbn = {9781450323550},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508222.2508229},
doi = {10.1145/2508222.2508229},
abstract = {Integration of algorithms and protocols from different layers will make possible the deployment of large-scale wireless sensor networks. The growing number of nodes that comprises within these networks requires a correct organization and an efficient node synchronization to ensure data reliability. In this study, we focus on the integration of fuzzy-logic based routing with a TDMA MAC protocol. By considering the experimental results of them working separately, we have integrated them to work together, so forming a cross-layer framework. By using a fast configuration and efficient slot assignment from the MAC protocol, and the accuracy of the logical tree created by fuzzy logic based routing, nodes in the network are both organized and synchronized, while load balance is achieved to extend network lifetime and provide efficient communications.},
booktitle = {Proceedings of the 11th ACM International Symposium on Mobility Management and Wireless Access},
pages = {81–88},
numpages = {8},
keywords = {artificial intelligence, mac, fuzzy logic, wireless sensor networks, protocol integration, routing},
location = {Barcelona, Spain},
series = {MobiWac '13}
}

@inproceedings{10.1145/2517349.2522723,
author = {Thereska, Eno and Ballani, Hitesh and O'Shea, Greg and Karagiannis, Thomas and Rowstron, Antony and Talpey, Tom and Black, Richard and Zhu, Timothy},
title = {IOFlow: A Software-Defined Storage Architecture},
year = {2013},
isbn = {9781450323888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517349.2522723},
doi = {10.1145/2517349.2522723},
abstract = {In data centers, the IO path to storage is long and complex. It comprises many layers or "stages" with opaque interfaces between them. This makes it hard to enforce end-to-end policies that dictate a storage IO flow's performance (e.g., guarantee a tenant's IO bandwidth) and routing (e.g., route an untrusted VM's traffic through a sanitization middlebox). These policies require IO differentiation along the flow path and global visibility at the control plane. We design IOFlow, an architecture that uses a logically centralized control plane to enable high-level flow policies. IOFlow adds a queuing abstraction at data-plane stages and exposes this to the controller. The controller can then translate policies into queuing rules at individual stages. It can also choose among multiple stages for policy enforcement.We have built the queue and control functionality at two key OS stages-- the storage drivers in the hypervisor and the storage server. IOFlow does not require application or VM changes, a key strength for deployability. We have deployed a prototype across a small testbed with a 40 Gbps network and storage devices. We have built control applications that enable a broad class of multi-point flow policies that are hard to achieve today.},
booktitle = {Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles},
pages = {182–196},
numpages = {15},
location = {Farminton, Pennsylvania},
series = {SOSP '13}
}

@inproceedings{10.1145/2508222.2508235,
author = {Cinque, Marcello and Coronato, Antonio and Testa, Alessandro and Di Martino, Catello},
title = {A Survey on Resiliency Assessment Techniques for Wireless Sensor Networks},
year = {2013},
isbn = {9781450323550},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508222.2508235},
doi = {10.1145/2508222.2508235},
abstract = {Resiliency is becoming one of the most important non functional properties of Wireless Sensor Networks (WSNs), as their adoption is more and more hypothesized in critical application scenarios. Hence, assessing the resiliency of WSN applications, protocols, and platforms is starting to be an import concern for WSN designers and developers. This paper presents the techniques that are currently used in the field of WSN resiliency assessment, categorized as experimental, simulative, analytical and formal techniques. After reporting the state-of-art according to the four categories, the paper discusses research trends, strengths and weaknesses of existing approaches, and concludes with open issues and ongoing challenges.},
booktitle = {Proceedings of the 11th ACM International Symposium on Mobility Management and Wireless Access},
pages = {73–80},
numpages = {8},
keywords = {dependability, wireless sensor networks, resiliency, survey},
location = {Barcelona, Spain},
series = {MobiWac '13}
}

@inproceedings{10.1145/2517840.2517848,
author = {Kerschbaum, Florian and Lim, Hoon Wei and Gudymenko, Ivan},
title = {Privacy-Preserving Billing for e-Ticketing Systems in Public Transportation},
year = {2013},
isbn = {9781450324854},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517840.2517848},
doi = {10.1145/2517840.2517848},
abstract = {Many electronic ticketing systems for public transportation have been deployed around the world. Using the example of Singapore's EZ-Link system we show that it is easy to invade a traveller's privacy and obtain his travel records in a real-world system. Then we propose encrypted bill processing of the travel records preventing any kind of privacy breach. Clear advantages of using bill processing instead of electronic cash are the possibility of privacy-preserving data mining analyses by the transportation company and monthly billing entailing a tighter customer relation and advanced tariffs. Moreover, we provide an implementation to demonstrate the feasibility of our solution.},
booktitle = {Proceedings of the 12th ACM Workshop on Workshop on Privacy in the Electronic Society},
pages = {143–154},
numpages = {12},
keywords = {security analysis, data mining, electronic tickets, privacy, bill processing},
location = {Berlin, Germany},
series = {WPES '13}
}

@inproceedings{10.1145/2517312.2517317,
author = {Sinha, Arunesh and Li, Yan and Bauer, Lujo},
title = {What You Want is Not What You Get: Predicting Sharing Policies for Text-Based Content on Facebook},
year = {2013},
isbn = {9781450324885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517312.2517317},
doi = {10.1145/2517312.2517317},
abstract = {As the amount of content users publish on social networking sites rises, so do the danger and costs of inadvertently sharing content with an unintended audience. Studies repeatedly show that users frequently misconfigure their policies or misunderstand the privacy features offered by social networks.A way to mitigate these problems is to develop automated tools to assist users in correctly setting their policy. This paper explores the viability of one such approach: we examine the extent to which machine learning can be used to deduce users' sharing preferences for content posted on Facebook. To generate data on which to evaluate our approach, we conduct an online survey of Facebook users, gathering their Facebook posts and associated policies, as well as their intended privacy policy for a subset of the posts. We use this data to test the efficacy of several algorithms at predicting policies, and the effects on prediction accuracy of varying the features on which they base their predictions. We find that Facebook's default behavior of assigning to a new post the privacy settings of the preceding one correctly assigns policies for only 67% of posts. The best of the prediction algorithms we tested outperforms this baseline for 80% of participants, with an average accuracy of 81%; this equates to a 45% reduction in the number of posts with misconfigured policies. Further, for those participants (66%) whose implemented policy usually matched their intended policy, our approach predicts the correct privacy settings for 94% of posts.},
booktitle = {Proceedings of the 2013 ACM Workshop on Artificial Intelligence and Security},
pages = {13–24},
numpages = {12},
keywords = {natural language processing, privacy, social network, facebook, machine learning},
location = {Berlin, Germany},
series = {AISec '13}
}

@inproceedings{10.1145/2534921.2534927,
author = {Vatsavai, Ranga Raju},
title = {Object Based Image Classification: State of the Art and Computational Challenges},
year = {2013},
isbn = {9781450325349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2534921.2534927},
doi = {10.1145/2534921.2534927},
abstract = {As the spatial resolution of satellite remote sensing imagery is advancing towards sub meter, the predominantly pixel based (or single instance) classification methods needs be redesigned to take advantage of the spatial and structural patterns found in the very high resolution imagery. In this work, we look at the advantages of object based image analysis methods through the newer multiple instance learning learning schemes. We analyze these methods in the context of big geospatial data and allude readers to some of the outstanding computational challenges.},
booktitle = {Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Analytics for Big Geospatial Data},
pages = {73–80},
numpages = {8},
keywords = {multiple instance learning, big spatial data, pattern matching, machine learning, object based image analysis},
location = {Orlando, Florida},
series = {BigSpatial '13}
}

@inproceedings{10.1145/2517312.2517316,
author = {Wressnegger, Christian and Schwenk, Guido and Arp, Daniel and Rieck, Konrad},
title = {A Close Look on <i>n</i>-Grams in Intrusion Detection: Anomaly Detection vs. Classification},
year = {2013},
isbn = {9781450324885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517312.2517316},
doi = {10.1145/2517312.2517316},
abstract = {Detection methods based on n-gram models have been widely studied for the identification of attacks and malicious software. These methods usually build on one of two learning schemes: anomaly detection, where a model of normality is constructed from n-grams, or classification, where a discrimination between benign and malicious n-grams is learned. Although successful in many security domains, previous work falls short of explaining why a particular scheme is used and more importantly what renders one favorable over the other for a given type of data. In this paper we provide a close look on n-gram models for intrusion detection. We specifically study anomaly detection and classification using n-grams and develop criteria for data being used in one or the other scheme. Furthermore, we apply these criteria in the scope of web intrusion detection and empirically validate their effectiveness with different learning-based detection methods for client-side and service-side attacks.},
booktitle = {Proceedings of the 2013 ACM Workshop on Artificial Intelligence and Security},
pages = {67–76},
numpages = {10},
keywords = {machine learning, n-gram models, intrusion detection},
location = {Berlin, Germany},
series = {AISec '13}
}

@inproceedings{10.1145/2508859.2516697,
author = {Dolan-Gavitt, Brendan and Leek, Tim and Hodosh, Josh and Lee, Wenke},
title = {Tappan Zee (North) Bridge: Mining Memory Accesses for Introspection},
year = {2013},
isbn = {9781450324779},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508859.2516697},
doi = {10.1145/2508859.2516697},
abstract = {The ability to introspect into the behavior of software at runtime is crucial for many security-related tasks, such as virtual machine-based intrusion detection and low-artifact malware analysis. Although some progress has been made in this task by automatically creating programs that can passively retrieve kernel-level information, two key challenges remain. First, it is currently difficult to extract useful information from user-level applications, such as web browsers. Second, discovering points within the OS and applications to hook for active monitoring is still an entirely manual process. In this paper we propose a set of techniques to mine the memory accesses made by an operating system and its applications to locate useful places to deploy active monitoring, which we call tap points. We demonstrate the efficacy of our techniques by finding tap points for useful introspection tasks such as finding SSL keys and monitoring web browser activity on five different operating systems (Windows 7, Linux, FreeBSD, Minix and Haiku) and two processor architectures (ARM and x86).},
booktitle = {Proceedings of the 2013 ACM SIGSAC Conference on Computer &amp; Communications Security},
pages = {839–850},
numpages = {12},
keywords = {active monitoring, reverse engineering, introspection},
location = {Berlin, Germany},
series = {CCS '13}
}

@inproceedings{10.1145/2508859.2516657,
author = {Dyer, Kevin P. and Coull, Scott E. and Ristenpart, Thomas and Shrimpton, Thomas},
title = {Protocol Misidentification Made Easy with Format-Transforming Encryption},
year = {2013},
isbn = {9781450324779},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508859.2516657},
doi = {10.1145/2508859.2516657},
abstract = {Deep packet inspection (DPI) technologies provide much-needed visibility and control of network traffic using port-independent protocol identification, where a network flow is labeled with its application-layer protocol based on packet contents. In this paper, we provide the first comprehensive evaluation of a large set of DPI systems from the point of view of protocol misidentification attacks, in which adversaries on the network attempt to force the DPI to mislabel connections. Our approach uses a new cryptographic primitive called format-transforming encryption (FTE), which extends conventional symmetric encryption with the ability to transform the ciphertext into a format of our choosing. We design an FTE-based record layer that can encrypt arbitrary application-layer traffic, and we experimentally show that this forces misidentification for all of the evaluated DPI systems. This set includes a proprietary, enterprise-class DPI system used by large corporations and nation-states. We also show that using FTE as a proxy system incurs no latency overhead and as little as 16% bandwidth overhead compared to standard SSH tunnels. Finally, we integrate our FTE proxy into the Tor anonymity network and demonstrate that it evades real-world censorship by the Great Firewall of China.},
booktitle = {Proceedings of the 2013 ACM SIGSAC Conference on Computer &amp; Communications Security},
pages = {61–72},
numpages = {12},
keywords = {regular expressions, deep packet inspection, protocol classification, applied cryptography, censorship circumvention},
location = {Berlin, Germany},
series = {CCS '13}
}

@inproceedings{10.1145/2508859.2516728,
author = {Wu, Lei and Grace, Michael and Zhou, Yajin and Wu, Chiachih and Jiang, Xuxian},
title = {The Impact of Vendor Customizations on Android Security},
year = {2013},
isbn = {9781450324779},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508859.2516728},
doi = {10.1145/2508859.2516728},
abstract = {The smartphone market has grown explosively in recent years, as more and more consumers are attracted to the sensor-studded multipurpose devices. Android is particularly ascendant; as an open platform, smartphone manufacturers are free to extend and modify it, allowing them to differentiate themselves from their competitors. However, vendor customizations will inherently impact overall Android security and such impact is still largely unknown.In this paper, we analyze ten representative stock Android images from five popular smartphone vendors (with two models from each vendor). Our goal is to assess the extent of security issues that may be introduced from vendor customizations and further determine how the situation is evolving over time. In particular, we take a three-stage process: First, given a smartphone's stock image, we perform provenance analysis to classify each app in the image into three categories: apps originating from the AOSP, apps customized or written by the vendor, and third-party apps that are simply bundled into the stock image. Such provenance analysis allows for proper attribution of detected security issues in the examined Android images. Second, we analyze permission usages of pre-loaded apps to identify overprivileged ones that unnecessarily request more Android permissions than they actually use. Finally, in vulnerability analysis, we detect buggy pre-loaded apps that can be exploited to mount permission re-delegation attacks or leak private information.Our evaluation results are worrisome: vendor customizations are significant on stock Android devices and on the whole responsible for the bulk of the security problems we detected in each device. Specifically, our results show that on average 85.78% of all pre-loaded apps in examined stock images are overprivileged with a majority of them directly from vendor customizations. In addition, 64.71% to 85.00% of vulnerabilities we detected in examined images from every vendor (except for Sony) arose from vendor customizations. In general, this pattern held over time -- newer smartphones, we found, are not necessarily more secure than older ones.},
booktitle = {Proceedings of the 2013 ACM SIGSAC Conference on Computer &amp; Communications Security},
pages = {623–634},
numpages = {12},
keywords = {android, provenance, customization, static analysis},
location = {Berlin, Germany},
series = {CCS '13}
}

@inproceedings{10.1145/2536689.2536807,
author = {Le, Long T. and Eliassi-Rad, Tina and Provost, Foster and Moores, Lauren},
title = {Hyperlocal: Inferring Location of IP Addresses in Real-Time Bid Requests for Mobile Ads},
year = {2013},
isbn = {9781450325332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2536689.2536807},
doi = {10.1145/2536689.2536807},
abstract = {To conduct a successful targeting campaign in mobile advertising, one needs to have reliable location information from real-time bid requests. However, many real-time bid requests do not include fine-grained location information (such as latitude and longitude) because (1) the device or the application did not collect that information or (2) some components of the real-time bid ecosystem did not forward that information. In this paper, we present a three-step approach that takes as input hashed public IP addresses in real-time bid requests and (1) creates a weighted heterogenous network, (2) applies network-inference techniques to infer fine-grain (but possibly noisy) location information for the hashed public IPs, and (3) uses k-nearest neighbor and census data to assign census block group IDs to those hashed public IPs. Our experiments on two large real-world datasets show the accuracy of our approach to be over 74% for hashed IPs (regardless of their type: mobile or non-mobile) when basing the inference on only hashed public mobile IPs. This is notable since our inference is over 212K possibilities.},
booktitle = {Proceedings of the 6th ACM SIGSPATIAL International Workshop on Location-Based Social Networks},
pages = {24–33},
numpages = {10},
keywords = {location inference, location-based services, mobile mining},
location = {Orlando, Florida},
series = {LBSN '13}
}

@inproceedings{10.1145/2517881.2517887,
author = {Van Zoonen, Liesbet and Turner, Georgina},
title = {Taboos and Desires of the UK Public for Identity Management in the Future: Findings from Two Survey Games},
year = {2013},
isbn = {9781450324939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517881.2517887},
doi = {10.1145/2517881.2517887},
abstract = {In this paper, we analyze user experiences and expectations about the future of identification and authentication (I&amp;A). We focus on structural taboos and desires around I&amp;A and try to tap into fundamental concerns that may be relevant across particular technologies or contexts. We collected data by running two gamified surveys in which a representative sample of the UK public (N=1000) were engaged in I&amp;A narratives that were accompanied by a colorful design, visuals and audio effects. We found that people use a traditional set of I&amp;A instruments, i.e. passport, driving license, bank card, pincodes and passwords. Few of them are heavy users of biometrics. People experience little problems with their current means of I&amp;A and do not like the kind of futuristic means of I&amp;A that are presented in popular culture, arts and design, and some R&amp;D departments of big corporations. If people see room for improvements of their future means of I&amp;A, they tend to desire higher ease and transparency of the cards they use. People hope and expect I&amp;A in the future to become even more personalized; they hope to get more control over their online identities but there is widespread doubt this will become possible; they fear and expect commercialization of I&amp;A services, and expect that surveillance will expand (about which they have mixed feelings). We end the paper with recommendations for further research and for designers of I&amp;A systems.},
booktitle = {Proceedings of the 2013 ACM Workshop on Digital Identity Management},
pages = {37–44},
numpages = {8},
keywords = {diffusion of innovation, authentication, technology acceptance, identification, cultural frames, gamification, rfid, smart tokens, passwords, biometrics, identity management, pincodes},
location = {Berlin, Germany},
series = {DIM '13}
}

@inproceedings{10.1145/2517351.2517427,
author = {Quer, Giorgio and Nwokafor, Anthony and Ganguly, Arindam and Rashid, Nafi and Zhu, John and Navani, Dheeraj and Rao, Ramesh R.},
title = {Bliss Buzzer, a System to Monitor Health and Stress with Real-Time Feedback},
year = {2013},
isbn = {9781450320276},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517351.2517427},
doi = {10.1145/2517351.2517427},
abstract = {"The search for biomarkers of stress and health remains a challenging task for researchers and clinicians alike," as noted in [9]. Against this backdrop, the recent emergence of medical devices that can collect time series for long durations at very high sampling rates makes it possible to study temporal patterns in biophysical signals. We demonstrate a functional system to collect and analyze physiological signals, and provide real-time feedback to the end user.},
booktitle = {Proceedings of the 11th ACM Conference on Embedded Networked Sensor Systems},
articleno = {83},
numpages = {2},
location = {Roma, Italy},
series = {SenSys '13}
}

@inproceedings{10.1145/2517351.2517368,
author = {Hsieh, Cheng-Kang and Tangmunarunkit, Hongsuda and Alquaddoomi, Faisal and Jenkins, John and Kang, Jinha and Ketcham, Cameron and Longstaff, Brent and Selsky, Joshua and Dawson, Betta and Swendeman, Dallas and Estrin, Deborah and Ramanathan, Nithya},
title = {Lifestreams: A Modular Sense-Making Toolset for Identifying Important Patterns from Everyday Life},
year = {2013},
isbn = {9781450320276},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517351.2517368},
doi = {10.1145/2517351.2517368},
abstract = {Smartphones can capture diverse spatio-temporal data about an individual; including both intermittent self-report, and continuous passive data collection from onboard sensors and applications. The resulting personal data streams can support powerful inference about the user's state, behavior, well-being and environment. However making sense and acting on these multi-dimensional, heterogeneous data streams requires iterative and intensive exploration of the datasets, and development of customized analysis techniques that are appropriate for a particular health domain.Lifestreams is a modular and extensible open-source data analysis stack designed to facilitate the exploration and evaluation of personal data stream sense-making. Lifestreams analysis modules include: feature extraction from raw data; feature selection; pattern and trend inference; and interactive visualization. The system was iteratively designed during a 6-month pilot in which 44 young mothers used an open-source participatory mHealth platform to record both self-report and passive data about their diet, stress and exercise. Feedback as participants and the study coordinator attempted to use the Lifestreams dashboard to make sense of their data collected during this intensive study were critical inputs into the design process. In order to explore the generality and extensibility of Lifestreams pipeline, it was then applied to two additional studies with different datasets, including a continuous stream of audio data, self-report data, and mobile system analytics. In all three studies, Lifestreams' integrated analysis pipeline was able to identify key behaviors and trends in the data that were not otherwise identified by participants.},
booktitle = {Proceedings of the 11th ACM Conference on Embedded Networked Sensor Systems},
articleno = {5},
numpages = {13},
keywords = {mobile systems, mobile health, personal data analysis},
location = {Roma, Italy},
series = {SenSys '13}
}

@article{10.1145/2532780.2532805,
author = {Chauhan, Sandeep and Sharma, Arun and Grover, P. S.},
title = {Developing Self Managing Software Systems Using Agile Modeling},
year = {2013},
issue_date = {November 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {6},
issn = {0163-5948},
url = {https://doi.org/10.1145/2532780.2532805},
doi = {10.1145/2532780.2532805},
abstract = {Design, development and operation of self managing systems are extremely challenging. Having an appropriate development model is of paramount significance for self managing systems. Various approaches have been studied and used in the past. It has been observed that self managing systems may be very good candidates for agile modelling and development. In this paper, we propose a generic architecture along with a life cycle and an Agile Modelling Approach (AMA) for developing self-managing systems. AMA may be applied to software development projects in an effective, flexible and lightweight manner. Moreover, AMA may be used for requirements, analysis, architecture and design, along with the use-case, object, aspect, data or user-interface models.},
journal = {SIGSOFT Softw. Eng. Notes},
month = nov,
pages = {1–3},
numpages = {3},
keywords = {self properties, agile modelling, autonomic computing}
}

@inproceedings{10.1145/2535597.2535607,
author = {Mu\~{n}oz, Diego and Cornejo, Raymundo and Ochoa, Sergio F. and Favela, Jes\'{u}s and Gutierrez, Francisco and Tentori, M\'{o}nica},
title = {Aligning Intergenerational Communication Patterns and Rhythms in the Age of Social Media},
year = {2013},
isbn = {9781450322003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2535597.2535607},
doi = {10.1145/2535597.2535607},
abstract = {Social media is increasingly being used to support interaction among family members. However, differences in media preferences and interaction patterns challenge intergenerational communication. It impacts negatively on the physical and mental health of older adults. Trying to bridge such a communication asymmetry, this paper reports the primary results of an analysis conducted on an existent dataset from two 21-weeks deployment studies, along with a 3-week design study, to understand intergenerational communication mismatches among older adults and relatives. Results indicate opportunities that informed the design and implementation of the Social Connector system, a software application that allows older adults to establish synchronous and asynchronous social interactions with their relatives. The paper also describes this system and discusses the main design decisions made to try reducing the stated communication asymmetry.},
booktitle = {Proceedings of the 2013 Chilean Conference on Human - Computer Interaction},
pages = {66–71},
numpages = {6},
keywords = {familiar communities, social media, older adults, communication asymmetry},
location = {Temuco, Chile},
series = {ChileCHI '13}
}

@inproceedings{10.1145/2534142.2534151,
author = {Yen, Yu-Chuan and Chu, Cing-Yu and Yeh, Su-Ling and Chu, Hao-Hua and Huang, Polly},
title = {Lab Experiment vs. Crowdsourcing: A Comparative User Study on Skype Call Quality},
year = {2013},
isbn = {9781450324519},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2534142.2534151},
doi = {10.1145/2534142.2534151},
abstract = {To deliver voice over the Internet in a cost-effective way, it is essential to quantify the quality of user experience (i.e., QoE) of a voice service at various provisioning levels. Conducting user studies is an inevitable step facilitating quantitative studies of QoE. The two experimental methods -- lab experiment vs. crowdsourcing via Amazon Mechanical Turk [1] -- are compared in this study. We find that, for the study of Skype call quality, the crowdsourcing approach stands out in terms of efficiency and user diversity, which in turn strengthens the robustness and the depth of the analysis.},
booktitle = {Proceedings of the 9th Asian Internet Engineering Conference},
pages = {65–72},
numpages = {8},
keywords = {rate control, VoIP, QoE, mechanical turk, Skype},
location = {Chiang Mai, Thailand},
series = {AINTEC '13}
}

@inproceedings{10.1145/2536536.2536573,
author = {Conde, Miguel \'{A}. and Hern\'{a}ndez-Garc\'{\i}a, \'{A}ngel},
title = {A Promised Land for Educational Decision-Making? Present and Future of Learning Analytics},
year = {2013},
isbn = {9781450323451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2536536.2536573},
doi = {10.1145/2536536.2536573},
abstract = {There is increasing interest in Learning Analytics, a concept that has evolved in the last years from the status of buzzword or trend to the generation of a discipline within the educational field. In this paper, we introduce the Track on Learning Analytics within the Technological Ecosystems for Enhancing Multiculturality 2013 Conference.The paper provides a general overview of the motivations behind the proposal of this track, including a review of the current state of Learning Analytics, from its origins and a definition of the term to some pending issues for future research, which are addressed by the papers participating in the track and which hopefully will be expanded by future studies. The paper also includes an insight on the submission management and participants' selection process, which is followed by a detailed summary of the manuscripts accepted for participation in the conference and how they are linked to the track objectives.},
booktitle = {Proceedings of the First International Conference on Technological Ecosystem for Enhancing Multiculturality},
pages = {239–243},
numpages = {5},
keywords = {educational data mining, knowledge management, decision making, learning analytics, academic analytics, visual analytics, educational technologies, predictive analytics},
location = {Salamanca, Spain},
series = {TEEM '13}
}

@inproceedings{10.1145/2526968.2526982,
author = {Vivian, Rebecca and Falkner, Katrina and Falkner, Nickolas},
title = {Computer Science Students' Causal Attributions for Successful and Unsuccessful Outcomes in Programming Assignments},
year = {2013},
isbn = {9781450324823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2526968.2526982},
doi = {10.1145/2526968.2526982},
abstract = {While some students excel in introductory programming courses, others find the course to be significantly challenging and demanding. The way that students reason about the factors that contribute to success or failure may affect their self-efficacy, motivation, future success and whether or not they persist in Computer Science (CS). What factors do students' perceive to cause successful or unsuccessful learning outcomes in first-year programming assignments? Such findings can assist us in identifying causal reasoning that may be detrimental to future success and persistence. We use Attribution Theory (AT) as a framework to explore the "causal attributions" that students apply to explain their causes for success or failure in introductory programming assignments, alluded to in their reflective essays about performance in a course. Our research demonstrates that reflective essays, integrated into learning tasks, can be one effective and efficient way to extract students' casual attributions. Our results indicate that the students raised a number of causal attributions in their essays that were specific to the CS-context and were attributed to both internal and external causes. We highlight problematic areas of casual reasoning and a need to correct misleading reasoning to ensure CS students understand their control over the success of their future programming assignments. This research offers opportunities for future research to develop activities that may encourage students to correctly identify causes of performance outcomes in programming assignments and to determine if such interventions can prevent students from leaving CS.},
booktitle = {Proceedings of the 13th Koli Calling International Conference on Computing Education Research},
pages = {125–134},
numpages = {10},
keywords = {computer science education and self-assessment, failure, attributes, attribution theory, success, programming assignments, university students, self-reflection},
location = {Koli, Finland},
series = {Koli Calling '13}
}

@inproceedings{10.1145/2526968.2526988,
author = {Silva, David and Tedre, Matti and Apiola, Mikko},
title = {Pedagogy of 1:1 Computing in Colombia: A Case Study of Three Rural Schools},
year = {2013},
isbn = {9781450324823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2526968.2526988},
doi = {10.1145/2526968.2526988},
abstract = {The utilization of one-to-one computing (each students is equipped with a personal device) has slowly started to become available into educational contexts in developing countries. One crucial challenge in relation to the understanding and developing of one-to-one computing related learning and teaching practices in developing educational contexts is the lack of context-situated educational research on the topic. This study participated in addressing the lacks in educational research by exploring the pedagogical strategies utilized in three rural schools in Colombia. The results consist of rich descriptions of teachers' pedagogical approaches. The results show high empowerment in teachers' efforts in developing and contextualizing one-to-one related pedagogical approaches into their teaching. Many of the teachers' approaches were found to be well aligned with a number of constructivist and student-centered pedagogical approaches. This study adds important new educational results to the ongoing scientific discussion about education with one-to-one computing},
booktitle = {Proceedings of the 13th Koli Calling International Conference on Computing Education Research},
pages = {179–187},
numpages = {9},
keywords = {TEL, escuela nueva, ICT4D, pedagogy, OLPC, 1:1 computing},
location = {Koli, Finland},
series = {Koli Calling '13}
}

@inproceedings{10.1145/2503210.2503279,
author = {Zheng, Fang and Yu, Hongfeng and Hantas, Can and Wolf, Matthew and Eisenhauer, Greg and Schwan, Karsten and Abbasi, Hasan and Klasky, Scott},
title = {GoldRush: Resource Efficient in Situ Scientific Data Analytics Using Fine-Grained Interference Aware Execution},
year = {2013},
isbn = {9781450323789},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2503210.2503279},
doi = {10.1145/2503210.2503279},
abstract = {Severe I/O bottlenecks on High End Computing platforms call for running data analytics in situ. Demonstrating that there exist considerable resources in compute nodes un-used by typical high end scientific simulations, we leverage this fact by creating an agile runtime, termed GoldRush, that can harvest those otherwise wasted, idle resources to efficiently run in situ data analytics. GoldRush uses fine-grained scheduling to "steal" idle resources, in ways that minimize interference between the simulation and in situ analytics. This involves recognizing the potential causes of on-node resource contention and then using scheduling methods that prevent them. Experiments with representative science applications at large scales show that resources harvested on compute nodes can be leveraged to perform useful analytics, significantly improving resource efficiency, reducing data movement costs incurred by alternate solutions, and posing negligible impact on scientific simulations.},
booktitle = {Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
articleno = {78},
numpages = {12},
location = {Denver, Colorado},
series = {SC '13}
}

@inproceedings{10.1145/2503210.2503267,
author = {Llort, Germ\'{a}n and Servat, Harald and Gonz\'{a}lez, Juan and Gim\'{e}nez, Judit and Labarta, Jes\'{u}s},
title = {On the Usefulness of Object Tracking Techniques in Performance Analysis},
year = {2013},
isbn = {9781450323789},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2503210.2503267},
doi = {10.1145/2503210.2503267},
abstract = {Understanding the behavior of a parallel application is crucial if we are to tune it to achieve its maximum performance. Yet the behavior the application exhibits may change over time and depend on the actual execution scenario: particular inputs and program settings, the number of processes used, or hardware-specific problems. So beyond the details of a single experiment a far more interesting question arises: how does the application behavior respond to changes in the execution conditions?In this paper, we demonstrate that object tracking concepts from computer vision have huge potential to be applied in the context of performance analysis. We leverage tracking techniques to analyze how the behavior of a parallel application evolves through multiple scenarios where the execution conditions change. This method provides comprehensible insights on the influence of different parameters on the application behavior, enabling us to identify the most relevant code regions and their performance trends.},
booktitle = {Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
articleno = {29},
numpages = {11},
keywords = {tracing, object tracking, performance analysis, clustering},
location = {Denver, Colorado},
series = {SC '13}
}

@inproceedings{10.1145/2534329.2534342,
author = {Ahn, Jong-gil and Kim, Gerard J. and Yeon, Hyemin and Hyun, Eunja and Choi, Kyoung},
title = {Supporting Augmented Reality Based Children's Play with pro-Cam Robot: Three User Perspectives},
year = {2013},
isbn = {9781450325905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2534329.2534342},
doi = {10.1145/2534329.2534342},
abstract = {This paper shares the experiences from the application of AR using the pro-cam robot assistant to managing children's play from three user perspectives, namely, the operator (teacher), the actors (children), and the audience (mainly children).First a preliminary expert survey was conducted to assess the expected benefits and any particular provisions needed both educationally and technically. Based on the expert survey, the original implementation was slightly modified, particularly for the robot control interface design for the teachers (e.g. to support easier multi-tasking). Finally, a formative evaluation and analysis was conducted to assess the educational effects to the children (both actors and audiences) and their attitudes when a pro-cam robot was used to run an AR based play, as compared to when a conventional approach was used.The study has found that robot-assisted AR based play showed improved learning effects, compared to the conventional play, in language and creativity and this is attributed to the operational flexibility, novelty, robotic mediation and capturing the attention of the children. The result was also made possible in part by designing an effective interface for the teachers to control the robots and manage the simultaneously occurring tasks.},
booktitle = {Proceedings of the 12th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry},
pages = {17–24},
numpages = {8},
keywords = {human robot interaction, education, projector robot, children's dramatic play, interface design, augmented reality},
location = {Hong Kong, Hong Kong},
series = {VRCAI '13}
}

@inproceedings{10.5555/2555523.2555537,
author = {Khalifa, Shady and Jiang, Tianbin and Martin, Patrick},
title = {MapReduce "Garbage" Collection},
year = {2013},
publisher = {IBM Corp.},
address = {USA},
abstract = {Recently, Hadoop, an open source implementation of MapReduce, has become very popular due to its characteristics such as simple programming syntax, and its support for distributed computing and fault tolerance. Although Hadoop is able to automatically reschedule failed tasks, it is powerless to deal with tasks with poor performance. Managing such tasks is vital as they lower the whole job's performance. Thus in this work, we design a novel garbage collection technique that identifies and collects "garbage" tasks. Three research questions are addressed in this work. The first, does collecting (shutting down) garbage (slow) tasks help in reducing the total job completion time and resources cost? The second, when is it most efficient to invoke the Garbage Collector? The third, how to identify garbage (slow) tasks and what are the major factors causing a task to slow down?. The proposed Garbage Collector is evaluated on Amazon EC2 using two metrics: (i) the time for a single job completion, and (ii) resource costs. The empirical results using the TeraSort benchmark show that collecting garbage tasks does reduce the job completion time by 16% and resources cost by 27%. The results also show that the Garbage Collector needs to be invoked before the job is 40% completed, otherwise it would be better to leave the slow tasks till the end of the job because at this point the cost of re-executing these slow tasks becomes high. Finally, our results show that CPU utilization is a good indicator of slow tasks.},
booktitle = {Proceedings of the 2013 Conference of the Center for Advanced Studies on Collaborative Research},
pages = {121–130},
numpages = {10},
location = {Ontario, Canada},
series = {CASCON '13}
}

@inproceedings{10.1145/2542266.2542267,
author = {Mitra, Niloy and Wand, Michael and Zhang, Hao (Richard) and Cohen-Or, Daniel and Kim, Vladimir and Huang, Qi-Xing},
title = {Structure-Aware Shape Processing},
year = {2013},
isbn = {9781450326315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2542266.2542267},
doi = {10.1145/2542266.2542267},
abstract = {Shape structure is about the arrangement and relations between shape parts. Structure-aware shape processing goes beyond local geometry and low level processing, and analyzes and processes shapes at a high level. It focuses more on the global inter and intra semantic relations among the parts of shape rather than on their local geometry.With recent developments in easy shape acquisition, access to vast repositories of 3D models, and simple-to-use desktop fabrication possibilities, the study of structure in shapes has become a central research topic in shape analysis, editing, and modeling. A whole new line of structure-aware shape processing algorithms has emerged that base their operation on an attempt to understand such structure in shapes. The algorithms broadly consist of two key phases: an analysis phase, which extracts structural information from input data; and a (smart) processing phase, which utilizes the extracted information for exploration, editing, and synthesis of novel shapes.In this course, we will organize, summarize, and present the key concepts and methodological approaches towards efficient structure-aware shape processing. We discuss common models of structure, their implementation in terms of mathematical formalism and algorithms, and explain the key principles in the context of a number of state-of-the-art approaches. Further, we attempt to list the key open problems and challenges, both at the technical and at the conceptual level, to make it easier for new researchers to better explore and contribute to this topic.Our goal is to both give the practitioner an overview of available structure-aware shape processing techniques, as well as identify future research questions in this important, emerging, and fascinating research area.},
booktitle = {SIGGRAPH Asia 2013 Courses},
articleno = {1},
numpages = {20},
location = {Hong Kong, Hong Kong},
series = {SA '13}
}

@article{10.1145/2555810.2555811,
author = {Yang, Christopher C. and Leroy, Gondy and Ananiadou, Sophia},
title = {Smart Health and Wellbeing},
year = {2013},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
issn = {2158-656X},
url = {https://doi.org/10.1145/2555810.2555811},
doi = {10.1145/2555810.2555811},
abstract = {Healthcare informatics has drawn substantial attention in recent years. Current work on healthcare informatics is highly interdisciplinary involving methodologies from computing, engineering, information science, behavior science, management science, social science, as well as many different areas in medicine and public health. Three major tracks, (i) systems, (ii) analytics, and (iii) human factors, can be identified. The systems track focuses on healthcare system architecture, framework, design, engineering, and application; the analytics track emphasizes data/information processing, retrieval, mining, analytics, as well as knowledge discovery; the human factors track targets the understanding of users or context, interface design, and user studies of healthcare applications. In this article, we discuss some of the latest development and introduce several articles selected for this special issue. We envision that the development of computing-oriented healthcare informatics research will continue to grow rapidly. The integration of different disciplines to advance the healthcare and wellbeing of our society will also be accelerated.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = dec,
articleno = {15},
numpages = {8}
}

@article{10.1145/2490832,
author = {Saguna, Saguna and Zaslavsky, Arkady and Chakraborty, Dipanjan},
title = {Complex Activity Recognition Using Context-Driven Activity Theory and Activity Signatures},
year = {2013},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {6},
issn = {1073-0516},
url = {https://doi.org/10.1145/2490832},
doi = {10.1145/2490832},
abstract = {In pervasive and ubiquitous computing systems, human activity recognition has immense potential in a large number of application domains. Current activity recognition techniques (i) do not handle variations in sequence, concurrency and interleaving of complex activities; (ii) do not incorporate context; and (iii) require large amounts of training data. There is a lack of a unifying theoretical framework which exploits both domain knowledge and data-driven observations to infer complex activities. In this article, we propose, develop and validate a novel Context-Driven Activity Theory (CDAT) for recognizing complex activities. We develop a mechanism using probabilistic and Markov chain analysis to discover complex activity signatures and generate complex activity definitions. We also develop a Complex Activity Recognition (CAR) algorithm. It achieves an overall accuracy of 95.73% using extensive experimentation with real-life test data. CDAT utilizes context and links complex activities to situations, which reduces inference time by 32.5% and also reduces training data by 66%.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = dec,
articleno = {32},
numpages = {34},
keywords = {context-driven activity theory, Activity recognition, concurrent activities, experimentation, evaluation, complex activity, interleaved activities, context-awareness, test bed, prototype}
}

@article{10.1145/2542214.2542215,
author = {Sayyadi, Hassan and Raschid, Louiqa},
title = {A Graph Analytical Approach for Topic Detection},
year = {2013},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/2542214.2542215},
doi = {10.1145/2542214.2542215},
abstract = {Topic detection with large and noisy data collections such as social media must address both scalability and accuracy challenges. KeyGraph is an efficient method that improves on current solutions by considering keyword cooccurrence. We show that KeyGraph has similar accuracy when compared to state-of-the-art approaches on small, well-annotated collections, and it can successfully filter irrelevant documents and identify events in large and noisy social media collections. An extensive evaluation using Amazon’s Mechanical Turk demonstrated the increased accuracy and high precision of KeyGraph, as well as superior runtime performance compared to other solutions.},
journal = {ACM Trans. Internet Technol.},
month = dec,
articleno = {4},
numpages = {23},
keywords = {community detection, network analysis, KeyGraph-based Topic Detection, Topic detection}
}

@article{10.1145/2577554.2577562,
author = {Adibuzzaman, Mohammad and Jain, Niharika and Steinhafel, Nicholas and Haque, Munir and Ahmed, Ferdaus and Ahamed, Sheikh and Love, Richard},
title = {In Situ Affect Detection in Mobile Devices: A Multimodal Approach for Advertisement Using Social Network},
year = {2013},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {1559-6915},
url = {https://doi.org/10.1145/2577554.2577562},
doi = {10.1145/2577554.2577562},
abstract = {Affect detection has been widely advocated to be implemented in a natural environment. But due to constraints such as correct labeling and lack of usable sensors in natural environment most of the research in multi-modal affect detection has been done in laboratory environment. In this paper, we investigate affect detection in natural environment using sensors available in smart phones. We use facial expression and energy expenditure of a person to classify a person's affective state by continuously recording accelerometer data for energy and camera image for facial expression and measure the performance of the system. We have deployed our system in a natural environment and have provided special attention on annotation for the training data to validate the 'ground truth'. We have found important relationship between valence and arousal space for better accuracy of affect detection by using facial image and energy. This validates Russell's two dimensional theory of emotion using arousal and valence space. In this paper, we have presented initial findings in multi-modal affect detection. Using the multimodal technique, we propose a system that can be used in social networks for affect sensitive advertisement.},
journal = {SIGAPP Appl. Comput. Rev.},
month = dec,
pages = {67–77},
numpages = {11},
keywords = {experimentation, human factors, algorithms}
}

@article{10.1145/2530540,
author = {Gerber, Elizabeth M. and Hui, Julie},
title = {Crowdfunding: Motivations and Deterrents for Participation},
year = {2013},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {6},
issn = {1073-0516},
url = {https://doi.org/10.1145/2530540},
doi = {10.1145/2530540},
abstract = {Crowdfunding is changing how, why, and which ideas are brought into existence. With the increasing number of crowdfunded projects, it is important to understand what drives people to either create or fund these projects. To shed light on this new social phenomenon, we present a grounded theory of motivation informed by the first cross-platform qualitative study of the crowdfunding community. By performing 83 semistructured interviews, we uncover creator motivations, which include the desire to raise funds, expand awareness of work, connect with others, gain approval, maintain control, and learn; and supporter motivations, which include the desire to collect rewards, help others, support causes, and be part of a community. We also explore deterrents to crowdfunding participation, including, among creators, fear of failure, and, for supporters, lack of trust. Based on these findings, we provide three emergent design principles to inform the design of effective crowdfunding platforms and support tools.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = dec,
articleno = {34},
numpages = {32},
keywords = {Creative work, innovation, psychology}
}

@article{10.1145/2544048,
author = {Spina, Gabriele and Amft, Oliver},
title = {Toward Smartphone Assisted Personal Rehabilitation Training},
year = {2013},
issue_date = {Winter 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {2},
issn = {1528-4972},
url = {https://doi.org/10.1145/2544048},
doi = {10.1145/2544048},
abstract = {When utilizing internal sensors, modern smartphones are inexpensive and powerful wearable devices for sensor data acquisition, processing, and feedback in personal daily health applications.},
journal = {XRDS},
month = dec,
pages = {33–37},
numpages = {5}
}

@article{10.1145/2532643,
author = {Sherkat, Reza and Li, Jing and Mamoulis, Nikos},
title = {Efficient Time-Stamped Event Sequence Anonymization},
year = {2013},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
issn = {1559-1131},
url = {https://doi.org/10.1145/2532643},
doi = {10.1145/2532643},
abstract = {With the rapid growth of applications which generate timestamped sequences (click streams, GPS trajectories, RFID sequences), sequence anonymization has become an important problem, in that should such data be published or shared. Existing trajectory anonymization techniques disregard the importance of time or the sensitivity of events. This article is the first, to our knowledge, thorough study on time-stamped event sequence anonymization. We propose a novel and tunable generalization framework tailored to event sequences. We generalize time stamps using time intervals and events using a taxonomy which models the domain semantics. We consider two scenarios: (i) sharing the data with a single receiver (the SSR setting), where the receiver’s background knowledge is confined to a set of time stamps and time generalization suffices, and (ii) sharing the data with colluding receivers (the SCR setting), where time generalization should be combined with event generalization. For both cases, we propose appropriate anonymization methods that prevent both user identification and event prediction. To achieve computational efficiency and scalability, we propose optimization techniques for both cases using a utility-based index, compact summaries, fast to compute bounds for utility, and a novel taxonomy-aware distance function. Extensive experiments confirm the effectiveness of our approach compared with state of the art, in terms of information loss, range query distortion, and preserving temporal causality patterns. Furthermore, our experiments demonstrate efficiency and scalability on large-scale real and synthetic datasets.},
journal = {ACM Trans. Web},
month = dec,
articleno = {4},
numpages = {53},
keywords = {privacy-preserving data publishing, user browsing history, time and URL generalization, Anonymity}
}

@inproceedings{10.1145/2536853.2536866,
author = {Xu, Yongchun and Stojanovic, Nenad and Stojanovic, Ljiljana and Kostic, Dusan},
title = {An Approach for Dynamic Personal Monitoring Based on Mobile Complex Event Processing},
year = {2013},
isbn = {9781450321068},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2536853.2536866},
doi = {10.1145/2536853.2536866},
abstract = {In this paper we present a novel approach for dynamic remote activity monitoring based on mobile complex event processing that has been used in a use case in the eHealth domain. Using complex event processing (CEP) in mobile environment enables a more flexible and efficient processing of personal sensor data and environment data, which are detected by sensors embedded in a mobile device. The main advantages of our approach are: an efficient combination of the mobile and server-side event processing through the semantic event model, optimal usage of mobile resources through dynamic management of mobile event processing and modelling of complex situations by using more expressive knowledge representation formalism. We present the settings for the use case and the results from the preliminary evaluation.},
booktitle = {Proceedings of International Conference on Advances in Mobile Computing &amp; Multimedia},
pages = {464–473},
numpages = {10},
keywords = {Mobile application, Health Monitoring, Event Processing, Complex Situations},
location = {Vienna, Austria},
series = {MoMM '13}
}

@inproceedings{10.1145/2536853.2536873,
author = {Sigg, Stephan and Shi, Shuyu and Buesching, Felix and Ji, Yusheng and Wolf, Lars},
title = {Leveraging RF-Channel Fluctuation for Activity Recognition: Active and Passive Systems, Continuous and RSSI-Based Signal Features},
year = {2013},
isbn = {9781450321068},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2536853.2536873},
doi = {10.1145/2536853.2536873},
abstract = {We consider the recognition of activities from passive entities by analysing radio-frequency (RF)-channel fluctuation. In particular, we focus on the recognition of activities by active Software-defined-radio (SDR)-based Device-free Activity Recognition (DFAR) systems and investigate the localisation of activities performed, the generalisation of features for alternative environments and the distinction between walking speeds. Furthermore, we conduct case studies for Received Signal Strength (RSS)-based active and continuous signal-based passive systems to exploit the accuracy decrease in these related cases. All systems are compared to an accelerometer-based recognition system.},
booktitle = {Proceedings of International Conference on Advances in Mobile Computing &amp; Multimedia},
pages = {43–52},
numpages = {10},
keywords = {RF-sensing, Device-free activity recognition},
location = {Vienna, Austria},
series = {MoMM '13}
}

@inproceedings{10.1145/2539150.2539186,
author = {Yoshikuni, Ayano and Watanabe, Chiemi},
title = {Account Reachability: A Measure of Privacy Risk for Exposure of a User's Multiple SNS Accounts},
year = {2013},
isbn = {9781450321136},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2539150.2539186},
doi = {10.1145/2539150.2539186},
abstract = {With the increased worldwide popularity of social networking services (SNSs), the leakage of a user's private information is becoming a serious problem. An increased number of users now have multiple accounts on various social networks and they tend to use each account to write different user experiments. Aggregating information from different accounts leads to the unintended leakage of personal information. Therefore, we argue that SNS users should be vigilant in protecting the relationship between multiple accounts.In this paper, we propose the use of Account Reachability, a measure of privacy risk which demonstrates the possibility of a stranger finding a user's private account based on information in their public account. In addition, we present ARChecker, a tool to calculate the value of account reachability. ARChecker also provides advice on how to modify the user's profiles and messages to decrease the privacy risk. By checking the privacy measure and modifying the profiles and messages of their SNS accounts, users can protect their multiple accounts from the risk of an unintended leakage of personal information.},
booktitle = {Proceedings of International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {542–549},
numpages = {8},
keywords = {Web, Social networking service, Privacy},
location = {Vienna, Austria},
series = {IIWAS '13}
}

@inproceedings{10.1145/2542050.2542072,
author = {Tuan, Nguyen Ngoc and Thang, Huynh Quyet},
title = {Combining Maturity with Agility: Lessons Learnt from a Case Study},
year = {2013},
isbn = {9781450324540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2542050.2542072},
doi = {10.1145/2542050.2542072},
abstract = {Although both high maturity and agility appeared as different ways to address and overcome issues related to software development (including maximizing resources and minimizing risks), there has been a mixed understanding about the possibility for their co-existence within an organization. Outside of the dogmatic debate regarding their co-existence, however, voices have been raised recently that recognize that both approaches have their merits. This paper presents the results of a case study on the practices that a purely agile organization has put in place in order to profit from the opportunities that higher maturity can offer in respect to value creation for clients. Our conclusion is that both high maturity and agility contribute to customer satisfaction, high quality and waste reduction; and that complying with standards does not necessarily impose restriction on 'being agile'. Implication for practice is that companies and their clients can benefit from a development approach that embraces both maturity and agility. To achieve this goal, guidelines are needed that direct organizations towards adopting practices that are linked to higher maturity, as well as to agility.},
booktitle = {Proceedings of the Fourth Symposium on Information and Communication Technology},
pages = {267–274},
numpages = {8},
keywords = {agile project management, resource management, risk management, software process improvement standards},
location = {Danang, Vietnam},
series = {SoICT '13}
}

@inproceedings{10.1145/2537052.2537059,
author = {Mathew, Daniel J. and Samarth, Amit and Johar, Zeena and Seth, Aaditeshwar},
title = {Jury: An Automation Framework for Protocolised Primary Healthcare Delivery},
year = {2013},
isbn = {9781450325585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2537052.2537059},
doi = {10.1145/2537052.2537059},
abstract = {It is often hard to get trained doctors as primary healthcare providers in rural India. In an emergent tiered model, clinicians trained in basic health practices are deployed at rural clinics, and instructed to follow structured clinical protocols. Medical records are maintained electronically and a regular medical audit is performed on the records by skilled doctors to ensure that the clinicians stationed in rural clinics provide high quality delivery of care. Manual audit of the medical records is however non-scalable and prone to error. We describe the development of Jury, a highly configurable and extensible framework for automation of clinical audit of electronic medical records (EMRs). Socio-economic complexities and paradigmatic differences between public health research and computer science throw up interesting challenges that were tackled on the way to arriving at a solution. A pilot implementation was done for the hypertension protocol. Our field partner ICTPH has evinced interest in integrating Jury into their regular workflow.},
booktitle = {Proceedings of the 4th Annual Symposium on Computing for Development},
articleno = {7},
numpages = {9},
keywords = {protocol, healthcare},
location = {Cape Town, South Africa},
series = {ACM DEV-4 '13}
}

@inproceedings{10.1145/2537052.2537058,
author = {Heimerl, Kurtis and Hasan, Shaddi and Ali, Kashif and Parikh, Tapan and Brewer, Eric},
title = {An Experiment in Reducing Cellular Base Station Power Draw with Virtual Coverage},
year = {2013},
isbn = {9781450325585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2537052.2537058},
doi = {10.1145/2537052.2537058},
abstract = {Lack of access to cellular service often goes hand-in-hand with lack of access to power. For example, the GSM Association estimates that 95% of people living without cellular access in East Africa also lack access to grid power. This situation forces cellular network operators to build out power infrastructure along with their network infrastructure, dramatically increasing costs. While numerous equipment providers offer "low-power" GSM Base Stations (BTS) for use with renewable energy sources, these have a power floor of roughly 70W, which still necessitates a large upfront expenditure. The na\"{\i}ve solution to this problem is duty-cycling---simply turning off the equipment for portions of the day, usually at night. This commonly-adopted approach prevents important use cases such as all-hours emergency calling.Recently, we proposed a technique called virtual coverage to provide on-demand cellular coverage by introducing a "sleep" mode for cellular equipment. The solution turns off the BTS during low-utilization periods, but allows users to power the system back on using specialized autonomous radios if they need to communicate. Incoming communications also wake the BTS, facilitating two-way correspondence. While a potential solution, no real-world deployments have yet validated virtual coverage.The core goal of this work is do just that; we utilize virtual coverage to provide both low power consumption and on-demand access in a real cellular network during a six-month deployment in rural Papua, Indonesia. We demonstrate that the system was used and understood by customers, with more than half of subscribers using the system during "night" (i.e., on-battery) hours, making 730 outbound and receiving 755 inbound communications. Our scheme also allowed the BTS to be in low-power mode for 87% of night hours, reducing night power draw by 56.6%. We believe these results demonstrate that virtual coverage is a viable solution for reducing power draw in rural cellular networks.},
booktitle = {Proceedings of the 4th Annual Symposium on Computing for Development},
articleno = {6},
numpages = {9},
keywords = {information and communications technology for development},
location = {Cape Town, South Africa},
series = {ACM DEV-4 '13}
}

@inproceedings{10.1145/2516604.2516613,
author = {Underwood, Heather and Sterling, S. Revi and Bennett, John K.},
title = {The PartoPen in Practice: Evaluating the Impact of Digital Pen Technology on Maternal Health in Kenya},
year = {2013},
isbn = {9781450319065},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2516604.2516613},
doi = {10.1145/2516604.2516613},
abstract = {This paper critically examines the use of digital pen technology at two key points in the healthcare system in Kenya: nursing student training and patient care in public labor wards. The PartoPen system -- a digital pen software designed to enhance the paper labor monitoring tool known as the partograph -- was evaluated with 95 nursing students at the University of Nairobi (UoN), and with 50 nurses in the labor ward at Kenyatta National Hospital (KNH). Students using the PartoPen had significantly higher scores on partograph worksheets than students using a silent PartoPen, especially on challenging and high-risk labor cases and on difficult sections of the partograph. In the maternity ward study, nurses unanimously reported positive improvements in the number of partographs they were able to complete, but these qualitative responses were not supported by the quantitative data. We discuss the results of both studies, and what these results suggest about the potential value of the PartoPen at different levels of the healthcare delivery and training hierarchy.},
booktitle = {Proceedings of the Sixth International Conference on Information and Communication Technologies and Development: Full Papers - Volume 1},
pages = {274–283},
numpages = {10},
keywords = {maternal health, digital pen technology, Kenya, partograph, ICTD},
location = {Cape Town, South Africa},
series = {ICTD '13}
}

@inproceedings{10.1145/2517899.2517934,
author = {Chandwani, Rajesh and De, Rahul},
title = {Doctor-Patient Interaction in Telemedicine: Linking the Structurational Aspects to Institutionalization},
year = {2013},
isbn = {9781450319072},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517899.2517934},
doi = {10.1145/2517899.2517934},
abstract = {This paper focuses on telemedicine implementation and use, which can be used to extend modern medical knowledge to remote areas in developing countries. By examining doctor patient interactions in two different contexts of telemedicine programs in India, we posit how the actors interacting over virtual media reinforce and shape the structures, which in turn, are determined by the institutional logics of the context. This process determines the adaption and evolution of a new technology. The paper draws on the tenets of structuration theory and institutional logics to extend the theoretical understanding of the process of evolution of a new technology and emphasizes the essential role of considering the existing institutional logics in the design and implementation process.},
booktitle = {Proceedings of the Sixth International Conference on Information and Communications Technologies and Development: Notes - Volume 2},
pages = {17–20},
numpages = {4},
keywords = {institutional logics, telemedicine, structuration},
location = {Cape Town, South Africa},
series = {ICTD '13}
}

@inproceedings{10.1145/2540708.2540736,
author = {Li, Chao and Hu, Yang and Zhou, Ruijin and Liu, Ming and Liu, Longjun and Yuan, Jingling and Li, Tao},
title = {Enabling Datacenter Servers to Scale out Economically and Sustainably},
year = {2013},
isbn = {9781450326384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2540708.2540736},
doi = {10.1145/2540708.2540736},
abstract = {As cloud applications proliferate and data-processing demands increase, server resources must grow to unleash the performance of emerging workloads that scale well with large number of compute nodes. Nevertheless, power has become a crucial bottleneck that restricts horizontal scaling (scale out) of server systems, especially in datacenters that employ power over-subscription. When a datacenter hits the maximum capacity of its power provisioning equipment, the owner has to either build another facility or upgrade existing utility power infrastructure -- both approaches add huge capital expenditure, require significant construction lead time, and can further increase the owner's carbon footprint.This paper proposes Oasis, a power provisioning scheme for enabling power-/carbon- constrained datacenter servers to scale out economically and sustainably. Oasis naturally supports incremental power capacity expansion with near-zero environmental impact as it takes advantages of modular renewable energy system and emerging distributed battery architecture. It allows scale-out datacenter to double its capacity using 100% green energy with up to 25% less overhead cost. This paper also describes our implementation of Oasis prototype and introduces our multi-source driven power management scheme Ozone. Ozone allows Oasis to identify the most suitable power supply control strategies and adjust server load cooperatively to maximize overall system efficiency and reliability. Our results show that Ozone could reduce the performance degradation of Oasis to 1%, extend Oasis battery lifetime by over 50%, and almost triple the average battery backup capacity which is crucial for mission-critical systems.},
booktitle = {Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {322–333},
numpages = {12},
keywords = {sustainability, datacenter, power management, scalability, cloud workload, energy storage, green energy},
location = {Davis, California},
series = {MICRO-46}
}

@inproceedings{10.1145/2516604.2516612,
author = {Wardoyo, Reidinar Juliane and Mahmud, Nadia},
title = {Benefits and Barriers of Learning and Using ICTs at Open University: A Case Study of Indonesian Domestic Workers in Singapore},
year = {2013},
isbn = {9781450319065},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2516604.2516612},
doi = {10.1145/2516604.2516612},
abstract = {ICT's biggest impact in higher education has been to facilitate distance learning, and open universities around the world have extended education to marginalized groups for whom it would usually be beyond reach. The conditions particular to migrant domestic workers warrant further investigation. Using Banuri et al.'s [2005] value-of-ICTs-to-education framework and adapting Chib et al.'s [2008] ICTs for healthcare development model for education, the present study employed a qualitative method to examine the benefits of using ICTs as an opportunity producer, capacity enhancer, knowledge producer and social enabler, as well as the economic, technological, infrastructural and socio-cultural barriers to effective ICT use. In-depth interviews (N = 20) were conducted with Indonesian domestic workers enrolled in the Open University. The findings suggested that the women see value and gain various benefits from using ICTs for their learning process, in their current role as a domestic worker and professional orientation. However, multiple barriers need to be overcome, including the negotiation of multiple roles as their family's breadwinner, domestic worker and student. Implications and direction for future research are discussed.},
booktitle = {Proceedings of the Sixth International Conference on Information and Communication Technologies and Development: Full Papers - Volume 1},
pages = {215–226},
numpages = {12},
keywords = {women, ICT, domestic workers, barriers, employment, Singapore, benefits, migration, development, education, gender},
location = {Cape Town, South Africa},
series = {ICTD '13}
}

@inproceedings{10.1145/2540708.2540743,
author = {Fung, Wilson W. L. and Aamodt, Tor M.},
title = {Energy Efficient GPU Transactional Memory via Space-Time Optimizations},
year = {2013},
isbn = {9781450326384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2540708.2540743},
doi = {10.1145/2540708.2540743},
abstract = {Many applications with regular parallelism have been shown to benefit from using Graphics Processing Units (GPUs). However, employing GPUs for applications with irregular parallelism tends to be a risky process, involving significant effort from the programmer. One major, non-trivial effort/risk is to expose the available parallelism in the application as 1000s of concurrent threads without introducing data races or deadlocks via fine-grained data synchronization. To reduce this effort, prior work has proposed supporting transactional memory on GPU architectures. One hardware proposal, Kilo TM, can scale to 1000s of concurrent transaction. However, performance and energy overhead of Kilo TM may deter GPU vendors from incorporating it into future designs.In this paper, we analyze the performance and energy efficiency of Kilo TM and propose two enhancements: (1) Warp-level transaction management allows transactions within a warp to be managed as a group. This aggregates protocol messages to reduce communication overhead and captures spatial locality from multiple transactions to increase memory subsystem utility. (2) Temporal conflict detection uses globally synchronized timers to detect conflicts in read-only transactions with low overhead. Our evaluation shows that combining the two enhancements in combination can improve the overall performance and energy efficiency of Kilo TM by 65% and 34% respectively. Kilo TM with the above two enhancements achieves 66% of the performance of fine-grained locking with 34% energy overhead.},
booktitle = {Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {408–420},
numpages = {13},
keywords = {GPU, transactional memory},
location = {Davis, California},
series = {MICRO-46}
}

@inproceedings{10.1145/2540708.2540719,
author = {Abdel-Majeed, Mohammad and Wong, Daniel and Annavaram, Murali},
title = {Warped Gates: Gating Aware Scheduling and Power Gating for GPGPUs},
year = {2013},
isbn = {9781450326384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2540708.2540719},
doi = {10.1145/2540708.2540719},
abstract = {With the widespread adoption of GPGPUs in varied application domains, new opportunities open up to improve GPGPU energy efficiency. Due to inherent application-level inefficiencies, GPGPU execution units experience significant idle time. In this work we propose to power gate idle execution units to eliminate leakage power, which is becoming a significant concern with technology scaling. We show that GPGPU execution units are idle for short windows of time and conventional microprocessor power gating techniques cannot fully exploit these idle windows efficiently due to power gating overhead. Current warp schedulers greedily intersperse integer and floating point instructions, which limit power gating opportunities for any given execution unit type. In order to improve power gating opportunities in GPGPU execution units, we propose a Gating Aware Two-level warp scheduler (GATES) that issues clusters of instructions of the same type before switching to another instruction type. We also propose a new power gating scheme, called Blackout, that forces a power gated execution unit to sleep for at least the break-even time necessary to overcome the power gating overhead before returning to the active state. The combination of GATES and Blackout, which we call Warped Gates, can save 31.6% and 46.5% of integer and floating point unit static energy. The proposed solutions suffer less than 1% performance and area overhead.},
booktitle = {Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {111–122},
numpages = {12},
keywords = {power gating, warp scheduling, GPGPUs},
location = {Davis, California},
series = {MICRO-46}
}

