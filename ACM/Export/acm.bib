@inproceedings{10.5555/1862242.1862251,
author = {Shang, Shuo and Deng, Ke and Zheng, Kai},
title = {Efficient Best Path Monitoring in Road Networks for Instant Local Traffic Information},
year = {2010},
isbn = {9781920682859},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {The shortest path problem has been well studied previously. To improve the utility, the traffic conditions can be modeled to associate a weight to each road segment. The recent trend is to apply data mining techniques over use history which usually covers a long period of time such as months. However, this method fails to reflect the instant (i.e. temporary) traffic conditions change such as traffic accident or road work. Due to the temporary nature, the local instant traffic conditions makes more sense when an object is moving in road networks. In this work, we investigate the shortest path monitoring problem while the instant traffic conditions in local region update repeatedly around a moving object to a given destination. A simple way is to apply A* algorithm repeatedly. However, the weakness is obvious. Because only a small fraction, i.e. the local area, of the whole networks have changed and the other parts keep intact. That means, for many vertices, that their paths (or the lower bounds of their paths) to the destination are still valid. This motivates us to maintain these information and reuse in the following computations. Our method is based on two tree structures where one records the previous computing results and the other aims to reduce the search space of subsequent processing. The experiments over real data set demonstrate an improvement of processing efficiency by one degree of magnitude at a small memory cost. In addition, the tree can be shared when monitoring the shortest paths for several moving objects to the same destination.},
booktitle = {Proceedings of the Twenty-First Australasian Conference on Database Technologies - Volume 104},
pages = {47–56},
numpages = {10},
keywords = {shortest path monitoring, instant local traffic information},
location = {Brisbane, Australia},
series = {ADC '10}
}

@inproceedings{10.5555/1862242.1862257,
author = {Sharaf, Mohamed A. and Chrysanthis, Panos K. and Labrinidis, Alexandros},
title = {Tuning QoD in Stream Processing Engines},
year = {2010},
isbn = {9781920682859},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Quality of Service (QoS) and Quality of Data (QoD) are the two major dimensions for evaluating any query processing system. In the context of data stream management systems (DSMSs), multi-query scheduling has been exploited to improve QoS. In this paper, we are proposing to exploit query scheduling to improve QoD in DSMSs. Specifically, we are presenting a new policy for scheduling multiple continuous queries with the objective of maximizing the freshness of the output data streams and hence the QoD of such outputs. The proposed Freshness-Aware Scheduling of Multiple Continuous Queries (FAS-MCQ) policy decides the execution order of continuous queries based on each query's properties (i.e., cost and selectivity) as well the properties of the input update streams (i.e., variability of updates). Our experimental results have shown that FAS-MCQ can improve QoD by up to 50% compared to existing scheduling policies used in DSMSs. Finally, we propose and evaluate a parametrized version of our FAS-MCQ scheduler that is able to balance the trade-off between freshness and response time according to the application's requirements.},
booktitle = {Proceedings of the Twenty-First Australasian Conference on Database Technologies - Volume 104},
pages = {103–112},
numpages = {10},
keywords = {data stream management systems, quality of data (QoD), data freshness, quality of service (QoS), continuous queries, operator scheduling},
location = {Brisbane, Australia},
series = {ADC '10}
}

@article{10.1145/1656255.1656259,
author = {Meerbaum--Salant, Orni and Hazzan, Orit},
title = {An Agile Constructionist Mentoring Methodology for Software Projects in the High School},
year = {2010},
issue_date = {January 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {4},
url = {https://doi.org/10.1145/1656255.1656259},
doi = {10.1145/1656255.1656259},
abstract = {This article describes the construction process and evaluation of the Agile Constructionist Mentoring Methodology (ACMM), a mentoring method for guiding software development projects in the high school. The need for such a methodology has arisen due to the complexity of mentoring software project development in the high school. We introduce the ACMM and suggest a year-long mentoring template that includes the practices required for the actual mentoring process. The evaluation of the ACMM reveals that the methodology addresses each of the challenges teachers cope with during the mentoring process, which were identified in the first phase of the research.},
journal = {ACM Trans. Comput. Educ.},
month = jan,
articleno = {21},
numpages = {29},
keywords = {Shulman’s teacher knowledge base model, agile software development, Computer science education, constructionism}
}

@article{10.1145/1653760.1653766,
author = {Eisenman, Shane B. and Miluzzo, Emiliano and Lane, Nicholas D. and Peterson, Ronald A. and Ahn, Gahng-Seop and Campbell, Andrew T.},
title = {BikeNet: A Mobile Sensing System for Cyclist Experience Mapping},
year = {2010},
issue_date = {December 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
issn = {1550-4859},
url = {https://doi.org/10.1145/1653760.1653766},
doi = {10.1145/1653760.1653766},
abstract = {We present BikeNet, a mobile sensing system for mapping the cyclist experience. Built leveraging the MetroSense architecture to provide insight into the real-world challenges of people-centric sensing, BikeNet uses a number of sensors embedded into a cyclist's bicycle to gather quantitative data about the cyclist's rides. BikeNet uses a dual-mode operation for data collection, using opportunistically encountered wireless access points in a delay-tolerant fashion by default, and leveraging the cellular data channel of the cyclist's mobile phone for real-time communication as required. BikeNet also provides a Web-based portal for each cyclist to access various representations of her data, and to allow for the sharing of cycling-related data (for example, favorite cycling routes) within cycling interest groups, and data of more general interest (for example, pollution data) with the broader community. We present: a description and prototype implementation of the system architecture based on customized Moteiv Tmote Invent motes and sensor-enabled Nokia N80 mobile phones; an evaluation of sensing and inference that quantifies cyclist performance and the cyclist environment; a report on networking performance in an environment characterized by bicycle mobility and human unpredictability; and a description of BikeNet system user interfaces.},
journal = {ACM Trans. Sen. Netw.},
month = jan,
articleno = {6},
numpages = {39},
keywords = {recreation, bicycling, Applications, systems}
}

@inproceedings{10.1145/1693453.1693482,
author = {Zhang, Eddy Z. and Jiang, Yunlian and Shen, Xipeng},
title = {Does Cache Sharing on Modern CMP Matter to the Performance of Contemporary Multithreaded Programs?},
year = {2010},
isbn = {9781605588773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1693453.1693482},
doi = {10.1145/1693453.1693482},
abstract = {Most modern Chip Multiprocessors (CMP) feature shared cache on chip. For multithreaded applications, the sharing reduces communication latency among co-running threads, but also results in cache contention.A number of studies have examined the influence of cache sharing on multithreaded applications, but most of them have concentrated on the design or management of shared cache, rather than a systematic measurement of the influence. Consequently, prior measurements have been constrained by the reliance on simulators, the use of out-of-date benchmarks, and the limited coverage of deciding factors. The influence of CMP cache sharing on contemporary multithreaded applications remains preliminarily understood.In this work, we conduct a systematic measurement of the influence on two kinds of commodity CMP machines, using a recently released CMP benchmark suite, PARSEC, with a number of potentially important factors on program, OS, and architecture levels considered. The measurement shows some surprising results. Contrary to commonly perceived importance of cache sharing, neither positive nor negative effects from the cache sharing are significant for most of the program executions, regardless of the types of parallelism, input datasets, architectures, numbers of threads, and assignments of threads to cores. After a detailed analysis, we find that the main reason is the mismatch of current development and compilation of multithreaded applications and CMP architectures. By transforming the programs in a cache-sharing-aware manner, we observe up to 36% performance increase when the threads are placed on cores appropriately.},
booktitle = {Proceedings of the 15th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
pages = {203–212},
numpages = {10},
keywords = {shared cache, parallel program optimizations, chip multiprocessors, thread scheduling},
location = {Bangalore, India},
series = {PPoPP '10}
}

@article{10.1145/1837853.1693482,
author = {Zhang, Eddy Z. and Jiang, Yunlian and Shen, Xipeng},
title = {Does Cache Sharing on Modern CMP Matter to the Performance of Contemporary Multithreaded Programs?},
year = {2010},
issue_date = {May 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {5},
issn = {0362-1340},
url = {https://doi.org/10.1145/1837853.1693482},
doi = {10.1145/1837853.1693482},
abstract = {Most modern Chip Multiprocessors (CMP) feature shared cache on chip. For multithreaded applications, the sharing reduces communication latency among co-running threads, but also results in cache contention.A number of studies have examined the influence of cache sharing on multithreaded applications, but most of them have concentrated on the design or management of shared cache, rather than a systematic measurement of the influence. Consequently, prior measurements have been constrained by the reliance on simulators, the use of out-of-date benchmarks, and the limited coverage of deciding factors. The influence of CMP cache sharing on contemporary multithreaded applications remains preliminarily understood.In this work, we conduct a systematic measurement of the influence on two kinds of commodity CMP machines, using a recently released CMP benchmark suite, PARSEC, with a number of potentially important factors on program, OS, and architecture levels considered. The measurement shows some surprising results. Contrary to commonly perceived importance of cache sharing, neither positive nor negative effects from the cache sharing are significant for most of the program executions, regardless of the types of parallelism, input datasets, architectures, numbers of threads, and assignments of threads to cores. After a detailed analysis, we find that the main reason is the mismatch of current development and compilation of multithreaded applications and CMP architectures. By transforming the programs in a cache-sharing-aware manner, we observe up to 36% performance increase when the threads are placed on cores appropriately.},
journal = {SIGPLAN Not.},
month = jan,
pages = {203–212},
numpages = {10},
keywords = {thread scheduling, chip multiprocessors, parallel program optimizations, shared cache}
}

@inproceedings{10.1145/2108616.2108641,
author = {Liu, Ying Chieh and Lin, Chad and Feng-Chia, Li},
title = {A Model of Transiting Individual Efforts to the Outcomes of Virtual Team},
year = {2010},
isbn = {9781605588933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2108616.2108641},
doi = {10.1145/2108616.2108641},
abstract = {Few studies have formulated how individuals contribute to the team process and bring the success of virtual teams. The researcher attempted to integrate Technology-Task fit (TTF), Self-disclosure and Social Networks to build a framework to formulate how individual efforts are transited to the outcome of virtual teams. This framework was validated by an experiment which was engaged in a Wiki system. The results revealed that virtual team members interact by computer-mediated communication (CMC), the social relations were formed and gradually the team was tied together as a group. The efforts of each member are integrated by social ties in order to accomplish the goals. Three suggestions were proposed: (a) an appropriate technology which fits to the tasks should be provided; (b) an adequate training of operating the technology and disclose is needed to help members convey social cues and information to accomplish the tasks; (c) a mechanism to ensure the social ties go on the right track is crucial such as the frequency of communication and the way of solving conflicts.},
booktitle = {Proceedings of the 4th International Conference on Uniquitous Information Management and Communication},
articleno = {20},
numpages = {8},
keywords = {self-disclosure, SEM, transit, TTF, virtual teams, social networks},
location = {Suwon, Republic of Korea},
series = {ICUIMC '10}
}

@inproceedings{10.5555/1873601.1873682,
author = {Christodoulou, George and Kov\'{a}cs, Annam\'{a}ria},
title = {A Deterministic Truthful PTAS for Scheduling Related Machines},
year = {2010},
isbn = {9780898716986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
abstract = {Scheduling on related machines (Q||Cmax) is one of the most important problems in the field of Algorithmic Mechanism Design. Each machine is controlled by a selffish agent and her valuation can be expressed via a single parameter, her speed. Archer and Tardos [4] showed that, in contrast to other similar problems, a (non-polynomial) allocation that minimizes the makespan can be truthfully implemented. On the other hand, if we leave out the game-theoretic issues, the complexity of the problem has been completely settled --- the problem is strongly NP-hard, while there exists a PTAS [9, 8].This problem is the most well-studied in single-parameter Algorithmic Mechanism Design. It gives an excellent ground to explore the boundary between truthfulness and efficient computation. Since the work of Archer and Tardos, quite a lot of deterministic and randomized mechanisms have been suggested. Recently, a breakthrough result [7] showed that a randomized, truthful-in-expectation PTAS exists. On the other hand, for the deterministic case, the best known approximation factor is 2.8 [10, 11].It has been a major open question whether there exists a deterministic truthful PTAS, or whether truthfulness has an essential, negative impact on the computational complexity of the problem. In this paper we give a deffinitive answer to this important question by providing a truthful deterministic PTAS.},
booktitle = {Proceedings of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {1005–1016},
numpages = {12},
location = {Austin, Texas},
series = {SODA '10}
}

@inproceedings{10.5555/1873601.1873677,
author = {Karloff, Howard and Suri, Siddharth and Vassilvitskii, Sergei},
title = {A Model of Computation for MapReduce},
year = {2010},
isbn = {9780898716986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
abstract = {In recent years the MapReduce framework has emerged as one of the most widely used parallel computing platforms for processing data on terabyte and petabyte scales. Used daily at companies such as Yahoo!, Google, Amazon, and Facebook, and adopted more recently by several universities, it allows for easy parallelization of data intensive computations over many machines. One key feature of MapReduce that differentiates it from previous models of parallel computation is that it interleaves sequential and parallel computation. We propose a model of efficient computation using the MapReduce paradigm. Since MapReduce is designed for computations over massive data sets, our model limits the number of machines and the memory per machine to be substantially sublinear in the size of the input. On the other hand, we place very loose restrictions on the computational power of of any individual machine---our model allows each machine to perform sequential computations in time polynomial in the size of the original input.We compare MapReduce to the PRAM model of computation. We prove a simulation lemma showing that a large class of PRAM algorithms can be efficiently simulated via MapReduce. The strength of MapReduce, however, lies in the fact that it uses both sequential and parallel computation. We demonstrate how algorithms can take advantage of this fact to compute an MST of a dense graph in only two rounds, as opposed to Ω(log(n)) rounds needed in the standard PRAM model. We show how to evaluate a wide class of functions using the MapReduce framework. We conclude by applying this result to show how to compute some basic algorithmic problems such as undirected s-t connectivity in the MapReduce framework.},
booktitle = {Proceedings of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {938–948},
numpages = {11},
location = {Austin, Texas},
series = {SODA '10}
}

@article{10.1145/1644873.1644875,
author = {Syed, Zeeshan and Stultz, Collin and Kellis, Manolis and Indyk, Piotr and Guttag, John},
title = {Motif Discovery in Physiological Datasets: A Methodology for Inferring Predictive Elements},
year = {2010},
issue_date = {January 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
issn = {1556-4681},
url = {https://doi.org/10.1145/1644873.1644875},
doi = {10.1145/1644873.1644875},
abstract = {In this article, we propose a methodology for identifying predictive physiological patterns in the absence of prior knowledge. We use the principle of conservation to identify activity that consistently precedes an outcome in patients, and describe a two-stage process that allows us to efficiently search for such patterns in large datasets. This involves first transforming continuous physiological signals from patients into symbolic sequences, and then searching for patterns in these reduced representations that are strongly associated with an outcome.Our strategy of identifying conserved activity that is unlikely to have occurred purely by chance in symbolic data is analogous to the discovery of regulatory motifs in genomic datasets. We build upon existing work in this area, generalizing the notion of a regulatory motif and enhancing current techniques to operate robustly on non-genomic data. We also address two significant considerations associated with motif discovery in general: computational efficiency and robustness in the presence of degeneracy and noise. To deal with these issues, we introduce the concept of active regions and new subset-based techniques such as a two-layer Gibbs sampling algorithm. These extensions allow for a framework for information inference, where precursors are identified as approximately conserved activity of arbitrary complexity preceding multiple occurrences of an event.We evaluated our solution on a population of patients who experienced sudden cardiac death and attempted to discover electrocardiographic activity that may be associated with the endpoint of death. To assess the predictive patterns discovered, we compared likelihood scores for motifs in the sudden death population against control populations of normal individuals and those with non-fatal supraventricular arrhythmias. Our results suggest that predictive motif discovery may be able to identify clinically relevant information even in the absence of significant prior knowledge.},
journal = {ACM Trans. Knowl. Discov. Data},
month = jan,
articleno = {2},
numpages = {23},
keywords = {Gibbs sampling, data mining, motifs, inference, physiological signals, knowledge discovery}
}

@inproceedings{10.1145/1935701.1935759,
author = {Portocarrero, Edwina and Cranor, David and Bove, V. Michael},
title = {Pillow-Talk: Seamless Interface for Dream Priming, Recalling and Playback},
year = {2010},
isbn = {9781450304788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1935701.1935759},
doi = {10.1145/1935701.1935759},
abstract = {Pillow-Talk is the first of a series of objects designed to aid creative endeavors through the unobtrusive acquisition of unconscious self-generated content to permit reflexive self-knowledge. Composed of a seamless recording device embedded in a pillow and a playback and visualization system in a jar, Pillow-Talk crystallizes that which we normally forget. This allows users to capture their dreams in a less mediated way, aiding recollection by priming the experience and providing no distraction for recall and capture through embodied interaction.},
booktitle = {Proceedings of the Fifth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {269–272},
numpages = {4},
keywords = {dream, visualization, seamless interface, design, memory},
location = {Funchal, Portugal},
series = {TEI '11}
}

@inproceedings{10.1145/1935701.1935730,
author = {Helmes, John and Taylor, Alex S. and Cao, Xiang and H\"{o}\"{o}k, Kristina and Schmitt, Peter and Villar, Nicolas},
title = {Rudiments 1, 2 &amp; 3: Design Speculations on Autonomy},
year = {2010},
isbn = {9781450304788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1935701.1935730},
doi = {10.1145/1935701.1935730},
abstract = {This work describes the design process and installation of three speculative, rudimentary machines, or rudiments. Through careful iterations in their design, the rudiments are intended to provoke curiosity and discussion around the possibility of autonomy in interactive systems. The design of the rudiments is described in detail, alongside the design decisions that were made to suggest a machine autonomy and to provoke discussion. Some preliminary reflections from installing the rudiments in two separate households are also reported. Widely divergent opinions of the rudiments from the two households are used to discuss a number of themes for thinking about autonomy and interactive systems design. Overall, the presented work adopts a perspective strongly oriented towards guiding future research, but, importantly, aims to do so by opening up and exposing the design possibilities rather than constraining them.},
booktitle = {Proceedings of the Fifth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {145–152},
numpages = {8},
keywords = {speculative design, autonomy, social robots},
location = {Funchal, Portugal},
series = {TEI '11}
}

@inproceedings{10.1145/1935701.1935745,
author = {Wimmer, Raphael},
title = {Grasp Sensing for Human-Computer Interaction},
year = {2010},
isbn = {9781450304788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1935701.1935745},
doi = {10.1145/1935701.1935745},
abstract = {The way we grasp an object depends on several factors, e.g. the intended goal or the hand's anatomy. Therefore, a grasp can convey meaningful information about its context. Inferring these factors from a grasp allows us to enhance interaction with grasp-sensitive objects. This paper highlights an grasp as an important source of meaningful context for human-computer interaction and gives an overview of prior work from other disciplines. This paper offers a basis and framework for further research and discussion by proposing a descriptive model of meaning in grasps. The GRASP model combines five factors that determine how an object is grasped: goal, relationship between user and object, anatomy, setting, and properties of the object. The model is validated both from an epistemological perspective and by applying it to scenarios from related work.},
booktitle = {Proceedings of the Fifth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {221–228},
numpages = {8},
keywords = {tangible user interfaces, grasp, grasp recognition, meaning},
location = {Funchal, Portugal},
series = {TEI '11}
}

@inproceedings{10.1145/1709886.1709898,
author = {Berlin, Eugen and Liu, Jun and van Laerhoven, Kristof and Schiele, Bernt},
title = {Coming to Grips with the Objects We Grasp: Detecting Interactions with Efficient Wrist-Worn Sensors},
year = {2010},
isbn = {9781605588414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1709886.1709898},
doi = {10.1145/1709886.1709898},
abstract = {The use of a wrist-worn sensor that is able to read nearby RFID tags and the wearer's gestures has been suggested frequently as a way to both detect the objects we interact with and to identify the interaction. Making such a prototype feasible for longer-term deployments is far from solved however, as plenty of challenges remain in the hardware, embedded algorithms, and the overall design of such a bracelet-like device. This paper presents several of the challenges that emerged during the development of a functioning prototype that is able to sense interaction data for several days. We focus in particular on RFID tag reading range optimization, efficient data logging methods, meaningful evaluation techniques, and long-term deployments.},
booktitle = {Proceedings of the Fourth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {57–64},
numpages = {8},
keywords = {gesture detection, wearable interaction, wrist-worn RFID},
location = {Cambridge, Massachusetts, USA},
series = {TEI '10}
}

@article{10.1145/1668862.1668863,
author = {Alvaro, Alexandre and Santana de Almeida, Eduardo and Romero de Lemos Meira, Silvio},
title = {A Software Component Quality Framework},
year = {2010},
issue_date = {January 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/1668862.1668863},
doi = {10.1145/1668862.1668863},
abstract = {One of the major problems with Component-Based Software Engineering (CBSE) is the quality of the components used in a system. The reliability of a component-based software system depends on the reliability of the components that is made of. In CBSE, the proper search, selection and evaluation process of components is considered the cornerstone for the development of any effective component-based system. So far the software industry was concentrated on the functional aspects of components, leaving aside the difficult task of assessing their quality. In this way, we propose a software component quality framework to evaluate the quality of software components in an efficient way. Moreover, an experimental study was accomplished in order to evaluate the viability of the proposed framework.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jan,
pages = {1–18},
numpages = {18}
}

@article{10.1145/1658377.1658380,
author = {Tagarelli, Andrea and Greco, Sergio},
title = {Semantic Clustering of XML Documents},
year = {2010},
issue_date = {January 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/1658377.1658380},
doi = {10.1145/1658377.1658380},
abstract = {Dealing with structure and content semantics underlying semistructured documents is challenging for any task of document management and knowledge discovery conceived for such data. In this work we address the novel problem of clustering semantically related XML documents according to their structure and content features. XML features are generated by enriching syntactic with semantic information based on a lexical knowledge base. The backbone of the proposed framework for the semantic clustering of XML documents is a data representation model that exploits the notion of tree tuple to identify semantically cohesive substructures in XML documents and represent them as transactional data. This framework is equipped with two clustering algorithms based on different paradigms, namely centroid-based partitional clustering and frequent-itemset-based hierarchical clustering. An extensive experimental evaluation was conducted on real data sets from various domains, showing the significance of our approach as a solution for the semantic clustering of XML documents.},
journal = {ACM Trans. Inf. Syst.},
month = jan,
articleno = {3},
numpages = {56},
keywords = {XML tree tuples, XML transactional modeling, XML structure and content mining, XML document clustering, similarity measures}
}

@article{10.1145/1731888.1731889,
author = {Kordon, Arthur},
title = {Issues in Applying Computational Intelligence},
year = {2010},
issue_date = {February 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
url = {https://doi.org/10.1145/1731888.1731889},
doi = {10.1145/1731888.1731889},
abstract = {Applying any emerging technology is not trivial and requires some level of risk-taking even when the competitive advantage is clear. In the case of computational intelligence the process is even harder due to the different nature of the comprising methods, the lack of marketing, affordable professional tools and application methodology. Another important factor slowing down computational intelligence applications is the wrong perception of the technology. To many potential users it looks like it's either too expensive or it's rocket science. The pendulum of expectations also swings from one extreme of anticipating a silver bullet to all problems to the other extreme of awaiting the next technology fiasco.},
journal = {SIGEVOlution},
month = feb,
pages = {2–14},
numpages = {13}
}

@article{10.1145/1716383.1731902,
author = {Creeger, Mache},
title = {CTO Roundtable: Malware Defense: The Battle is Bigger than Most of Us Realize.},
year = {2010},
issue_date = {February 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {1542-7730},
url = {https://doi.org/10.1145/1716383.1731902},
doi = {10.1145/1716383.1731902},
abstract = {As all manner of information assets migrate online, malware has kept on track to become a huge source of individual threats. In a continuously evolving game of cat and mouse, as security professionals close off points of access, attackers develop more sophisticated attacks. Today profit models from malware are comparable to any seen in the legitimate world.},
journal = {Queue},
month = feb,
pages = {40–51},
numpages = {12}
}

@inproceedings{10.1145/1718918.1718975,
author = {Mentis, Helena M. and Reddy, Madhu and Rosson, Mary Beth},
title = {Invisible Emotion: Information and Interaction in an Emergency Room},
year = {2010},
isbn = {9781605587950},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1718918.1718975},
doi = {10.1145/1718918.1718975},
abstract = {Emotions are an often overlooked aspect of work since they are not included in formal work models. However, they continue provide critical information as well as be part of a rich social context for action. The following study focuses on the expression of emotions within the context of a particular work environment -- an emergency room -- and high-lights how it is used, why it is invisible in the work, and how it continues to persist through workarounds. These workarounds provide indications towards the design of so-ciotechnical systems to continue to support the expression of invisible emotions.},
booktitle = {Proceedings of the 2010 ACM Conference on Computer Supported Cooperative Work},
pages = {311–320},
numpages = {10},
keywords = {er, articulation work, emotion expressions, documentation, healthcare},
location = {Savannah, Georgia, USA},
series = {CSCW '10}
}

@inproceedings{10.1145/1718918.1718938,
author = {Wang, Hao-Chuan and Cosley, Dan and Fussell, Susan R.},
title = {Idea Expander: Supporting Group Brainstorming with Conversationally Triggered Visual Thinking Stimuli},
year = {2010},
isbn = {9781605587950},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1718918.1718938},
doi = {10.1145/1718918.1718938},
abstract = {Creativity is central to much human problem solving and innovation. Brainstorming processes attempt to leverage group creativity, but group dynamics sometimes limit their utility. We present IdeaExpander, a tool to support group brainstorming by intelligently selecting pictorial stimuli based on the group's conversation The design is based on theories of how perception, thinking, and communication interact; a pilot study (N=16) suggests that it increases individuals' idea production and that people value it.},
booktitle = {Proceedings of the 2010 ACM Conference on Computer Supported Cooperative Work},
pages = {103–106},
numpages = {4},
keywords = {creativity support tool, group brainstorming},
location = {Savannah, Georgia, USA},
series = {CSCW '10}
}

@inproceedings{10.1145/1718918.1718965,
author = {Starbird, Kate and Palen, Leysia and Hughes, Amanda L. and Vieweg, Sarah},
title = {Chatter on the Red: What Hazards Threat Reveals about the Social Life of Microblogged Information},
year = {2010},
isbn = {9781605587950},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1718918.1718965},
doi = {10.1145/1718918.1718965},
abstract = {This paper considers a subset of the computer-mediated communication (CMC) that took place during the flooding of the Red River Valley in the US and Canada in March and April 2009. Focusing on the use of Twitter, a microblogging service, we identified mechanisms of information production, distribution, and organization. The Red River event resulted in a rapid generation of Twitter communications by numerous sources using a variety of communications forms, including autobiographical and mainstream media reporting, among other types. We examine the social life of microblogged information, identifying generative, synthetic, derivative and innovative properties that sustain the broader system of interaction. The landscape of Twitter is such that the production of new information is supported through derivative activities of directing, relaying, synthesizing, and redistributing, and is additionally complemented by socio-technical innovation. These activities comprise self-organization of information.},
booktitle = {Proceedings of the 2010 ACM Conference on Computer Supported Cooperative Work},
pages = {241–250},
numpages = {10},
keywords = {risk communication, disaster, emergency, microblogging, computer-mediated communication, crisis informatics},
location = {Savannah, Georgia, USA},
series = {CSCW '10}
}

@inproceedings{10.1145/1718918.1718941,
author = {Geiger, R. Stuart and Ribes, David},
title = {The Work of Sustaining Order in Wikipedia: The Banning of a Vandal},
year = {2010},
isbn = {9781605587950},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1718918.1718941},
doi = {10.1145/1718918.1718941},
abstract = {In this paper, we examine the social roles of software tools in the English-language Wikipedia, specifically focusing on autonomous editing programs and assisted editing tools. This qualitative research builds on recent research in which we quantitatively demonstrate the growing prevalence of such software in recent years. Using trace ethnography, we show how these often-unofficial technologies have fundamentally transformed the nature of editing and administration in Wikipedia. Specifically, we analyze "vandal fighting" as an epistemic process of distributed cognition, highlighting the role of non-human actors in enabling a decentralized activity of collective intelligence. In all, this case shows that software programs are used for more than enforcing policies and standards. These tools enable coordinated yet decentralized action, independent of the specific norms currently in force.},
booktitle = {Proceedings of the 2010 ACM Conference on Computer Supported Cooperative Work},
pages = {117–126},
numpages = {10},
keywords = {collaboration, distributed cognition, bots, wikipedia, trace ethnography, wiki, ethnography, qualitative, social},
location = {Savannah, Georgia, USA},
series = {CSCW '10}
}

@inproceedings{10.1145/2002333.2002349,
author = {Giovannella, C. and Canale, M.},
title = {Observing an Image, Storing an Image},
year = {2010},
isbn = {9781605589992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2002333.2002349},
doi = {10.1145/2002333.2002349},
abstract = {By means of an eye-tracker and a home-made software of analysis, we have investigated the relationship among the ability of the humans to memorize and recognize images (and their modifications), the characteristics of the testers (strategy of exploration, cultural background, sex, etc...) and the construction of the image.},
booktitle = {Proceedings of the 2010 Workshop on Eye Gaze in Intelligent Human Machine Interaction},
pages = {102–107},
numpages = {6},
keywords = {eye-tracking, visual memory, visual communication channel, human factors, human communication},
location = {Hong Kong, China},
series = {EGIHMI '10}
}

@inproceedings{10.1145/2002333.2002350,
author = {Giovannella, C. and Galli, G.},
title = {Visual Perception, Awareness and Self-Control: The Brentano-M\"{u}Ller-Lyer Illusion},
year = {2010},
isbn = {9781605589992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2002333.2002350},
doi = {10.1145/2002333.2002350},
abstract = {In this paper we present a study on visual perception, awareness and self-control, based on the visual exploration of the classical Brentano-M\"{u}ller Lyer illusion and of some of its variants. The study has been realized with the help of self-made software designed to analyze eye-tracker recordings. In the case of subjects that have a certain familiarity with visual illusions, although not with all its variants, it is possible to observe, after some hundreds of milliseconds, the occurrence of a transition toward an aware exploration of the images. Moreover, it has been possible to show that the awareness might or might not help - it depends on the subject - to get out from the "trap" of the illusion.},
booktitle = {Proceedings of the 2010 Workshop on Eye Gaze in Intelligent Human Machine Interaction},
pages = {108–113},
numpages = {6},
keywords = {brentano-m?ller lyer illusion, human communication, perception of illusions, human factors, eye-tracking, visual communication channel, visual awareness},
location = {Hong Kong, China},
series = {EGIHMI '10}
}

@inproceedings{10.1145/1734583.1734599,
author = {Beach, Aaron and Gartrell, Mike and Xing, Xinyu and Han, Richard and Lv, Qin and Mishra, Shivakant and Seada, Karim},
title = {Fusing Mobile, Sensor, and Social Data to Fully Enable Context-Aware Computing},
year = {2010},
isbn = {9781450300056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1734583.1734599},
doi = {10.1145/1734583.1734599},
abstract = {In this paper, we identify mobile social networks as an important new direction of research in mobile computing, and show how an expanded definition of mobile social networks that includes sensor networks can enable exciting new context-aware applications, such as context-aware video screens, music jukeboxes, and mobile health applications. We offer SocialFusion as a system capable of systematically integrating such diverse mobile, social, and sensing input streams and effectuating the appropriate context-aware output action. We explain some of the major challenges that SocialFusion must overcome. We describe some preliminary results that we have obtained in implementing the SocialFusion vision.},
booktitle = {Proceedings of the Eleventh Workshop on Mobile Computing Systems &amp; Applications},
pages = {60–65},
numpages = {6},
location = {Annapolis, Maryland},
series = {HotMobile '10}
}

@inproceedings{10.1145/1755743.1755767,
author = {D\'{o}ra, L\'{a}szl\'{o} and Holczer, Tam\'{a}s},
title = {Hide-and-Lie: Enhancing Application-Level Privacy in Opportunistic Networks},
year = {2010},
isbn = {9781605589251},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1755743.1755767},
doi = {10.1145/1755743.1755767},
abstract = {A delay-tolerant network is a mobile ad hoc network where the message dissemination is based on the store-carry-and-forward principle. This principle raises new aspects of the privacy problem. In particular, an attacker can build a user profile and trace the nodes based on this profile even if the message exchange protocol provides anonymity. In this paper, an attacker model is presented and some proposed attackers are implemented. We analyze the efficiency of both the attacks and the proposed defense mechanism, called Hide-and-Lie Strategy. We show that without any defense mechanism, the nodes are traceable, but with the Hide-and-Lie Strategy, the success probability of an attacker can be made equal to the success probability of the simple guessing. Furthermore, in some scenarios, the Hide-and-Lie Strategy increases the message delivery ratio. The number of downloaded messages and the maximal memory size required to apply the proposed privacy defense mechanism is also investigated.},
booktitle = {Proceedings of the Second International Workshop on Mobile Opportunistic Networking},
pages = {135–142},
numpages = {8},
keywords = {opportunistic networks, privacy in data forwarding},
location = {Pisa, Italy},
series = {MobiOpp '10}
}

@article{10.1145/1731035.1731038,
author = {Tepper, Michael and Xia, Fei},
title = {Inducing Morphemes Using Light Knowledge},
year = {2010},
issue_date = {March 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
issn = {1530-0226},
url = {https://doi.org/10.1145/1731035.1731038},
doi = {10.1145/1731035.1731038},
abstract = {Allomorphic variation, or form variation among morphs with the same meaning, is a stumbling block to morphological induction (MI). To address this problem, we present a hybrid approach that uses a small amount of linguistic knowledge in the form of orthographic rewrite rules to help refine an existing MI-produced segmentation. Using rules, we derive underlying analyses of morphs---generalized with respect to contextual spelling differences---from an existing surface morph segmentation, and from these we learn a morpheme-level segmentation. To learn morphemes, we have extended the Morfessor segmentation algorithm [Creutz and Lagus 2004; 2005; 2006] by using rules to infer possible underlying analyses from surface segmentations. A segmentation produced by Morfessor Categories-MAP Software v. 0.9.2 is used as input to our procedure and as a baseline that we evaluate against. To suggest analyses for our procedure, a set of language-specific orthographic rules is needed. Our procedure has yielded promising improvements for English and Turkish over the baseline approach when tested on the Morpho Challenge 2005 and 2007 style evaluations. On the Morpho Challenge 2007 test evaluation, we report gains over the current best unsupervised contestant for Turkish, where our technique shows a 2.5% absolute F-score improvement.},
journal = {ACM Transactions on Asian Language Information Processing},
month = mar,
articleno = {3},
numpages = {38},
keywords = {allomorphy, Morphological induction, computational linguistics, machine learning}
}

@article{10.1145/1731041.1731045,
author = {Baldwin, D. and Brady, A. and Danyluk, A. and Adams, J. and Lawrence, A.},
title = {Case Studies of Liberal Arts Computer Science Programs},
year = {2010},
issue_date = {March 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
url = {https://doi.org/10.1145/1731041.1731045},
doi = {10.1145/1731041.1731045},
abstract = {Many undergraduate liberal arts institutions offer computer science majors. This article illustrates how quality computer science programs can be realized in a wide variety of liberal arts settings by describing and contrasting the actual programs at five liberal arts colleges: Williams College, Kalamazoo College, the State University of New York at Geneseo, Spelman College, and Calvin College. While the example programs differ in size, mission, and the nature of their home institutions, all take advantage of their liberal arts setting to offer rich computer science educations. Comparing these programs to each other and to the latest ACM/IEEE Computer Society computer science curriculum shows that the liberal arts programs are distinguishable from the ACM/Computer Society recommendations, but at the same time are strong undergraduate majors.},
journal = {ACM Trans. Comput. Educ.},
month = mar,
articleno = {4},
numpages = {30},
keywords = {Liberal arts}
}

@article{10.1145/1689239.1689247,
author = {Ingelrest, Fran\c{c}ois and Barrenetxea, Guillermo and Schaefer, Gunnar and Vetterli, Martin and Couach, Olivier and Parlange, Marc},
title = {SensorScope: Application-Specific Sensor Network for Environmental Monitoring},
year = {2010},
issue_date = {February 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
issn = {1550-4859},
url = {https://doi.org/10.1145/1689239.1689247},
doi = {10.1145/1689239.1689247},
abstract = {SensorScope is a turnkey solution for environmental monitoring systems, based on a wireless sensor network and resulting from a collaboration between environmental and network researchers. Given the interest in climate change, environmental monitoring is a domain where sensor networks will have great impact by providing high resolution spatio-temporal data for long periods of time. SensorScope is such a system, which has already been successfully deployed multiple times in various environments (e.g., mountainous, urban). Here, we describe the overall hardware and software architectures and especially focus on the sensor network itself. We also describe one of our most prominent deployments, on top of a rock glacier in Switzerland, which resulted in the description of a micro-climate phenomenon leading to cold air release from a rock-covered glacier in a region of high alpine risks. Another focus of this paper is the description of what happened behind the scenes to turn SensorScope from a laboratory experiment into successful outdoor deployments in harsh environments. Illustrated by various examples, we point out many lessons learned while working on the project. We indicate the importance of simple code, well suited to the application, as well as the value of close interaction with end-users in planning and running the network and finally exploiting the data.},
journal = {ACM Trans. Sen. Netw.},
month = mar,
articleno = {17},
numpages = {32},
keywords = {deployment, implementation, Architecture, wireless sensor network, environmental monitoring}
}

@inproceedings{10.5555/1734454.1734561,
author = {Yu, Chen and Scheutz, Matthias and Schermerhorn, Paul},
title = {Investigating Multimodal Real-Time Patterns of Joint Attention in an Hri Word Learning Task},
year = {2010},
isbn = {9781424448937},
publisher = {IEEE Press},
abstract = {Joint attention - the idea that humans make inferences from observable behaviors of other humans by attending to the objects and events that these others humans attend to - has been recognized as a critical component in human-robot interactions. While various HRI studies showed that having robots to behave in ways that support human recognition of joint attention leads to better behavioral outcomes on the human side, there are no studies that investigate the detailed time course of interactive joint attention processes.In this paper, we present the results from an HRI study that investigates the exact time course of human multi-modal attentional processes during an HRI word learning task in an unprecedented way. Using novel data analysis techniques, we are able to demonstrate that the temporal details of human attentional behavior are critical for understanding human expectations of joint attention in HRI and that failing to do so can force humans into assuming unnatural behaviors.},
booktitle = {Proceedings of the 5th ACM/IEEE International Conference on Human-Robot Interaction},
pages = {309–316},
numpages = {8},
keywords = {joint attention, human-robot interaction},
location = {Osaka, Japan},
series = {HRI '10}
}

@inproceedings{10.5555/1734454.1734468,
author = {Weiss, Astrid and Igelsb\"{o}ck, Judith and Tscheligi, Manfred and Bauer, Andrea and K\"{u}hnlenz, Kolja and Wollherr, Dirk and Buss, Martin},
title = {Robots Asking for Directions: The Willingness of Passers-by to Support Robots},
year = {2010},
isbn = {9781424448937},
publisher = {IEEE Press},
abstract = {This paper reports about a human-robot interaction field trial conducted with the autonomous mobile robot ACE (Autonomous City Explorer) in a public place, where the ACE robot needs the support of human passers-by to find its way to a target location. Since the robot does not possess any prior map knowledge or GPS support, it has to acquire missing information through interaction with humans. The robot thus has to initiate communication by asking for the way, and retrieves information from passers-by showing the way by gestures (pointing) and marking goal positions on a still image on the touch screen of the robot. The aims of the field trial where threefold: (1) Investigating the aptitude of the navigation architecture, (2) Evaluating the intuitiveness of the interaction concept for the passers-by, (3) Assessing people's willingness to support the ACE robot in its task, i.e. assessing the social acceptability. The field trial demonstrates that the architecture enables successful autonomous path finding without any prior map knowledge just by route directions given by passers-by. An additional street survey and observational data moreover attests the intuitiveness of the interaction paradigm and the high acceptability of the ACE robot in the public place.},
booktitle = {Proceedings of the 5th ACM/IEEE International Conference on Human-Robot Interaction},
pages = {23–30},
numpages = {8},
keywords = {social acceptance, field trial, human-robot interaction, autonomous mobile robot},
location = {Osaka, Japan},
series = {HRI '10}
}

@inproceedings{10.5555/1870926.1871064,
author = {Mintarno, Evelyn and Skaf, Jo\"{e}lle and Zheng, Rui and Velamala, Jyothi and Cao, Yu and Boyd, Stephen and Dutton, Robert W. and Mitra, Subhasish},
title = {Optimized Self-Tuning for Circuit Aging},
year = {2010},
isbn = {9783981080162},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {We present a framework and control policies for optimizing dynamic control of various self-tuning parameters over lifetime in the presence of circuit aging. Our framework introduces dynamic cooling as one of the self-tuning parameters, in addition to supply voltage and clock frequency. Our optimized self-tuning satisfies performance constraints at all times and maximizes a lifetime computational power efficiency (LCPE) metric, which is defined as the total number of clock cycles achieved over lifetime divided by the total energy consumed over lifetime. Our framework features three control policies: 1. Progressive-worst-case-aging (PWCA), which assumes worst-case aging at all times; 2. Progressive-on-state-aging (POSA), which estimates aging by tracking active/sleep mode, and then assumes worst-case aging in active mode and long recovery effects in sleep mode; 3. Progressive-real-time-aging-assisted (PRTA), which estimates the actual amount of aging and initiates optimized control action. Simulation results on benchmark circuits, using aging models validated by 45nm CMOS stress measurements, demonstrate the practicality and effectiveness of our approach. We also analyze design constraints and derive system design guidelines to maximize self-tuning benefits.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {586–591},
numpages = {6},
location = {Dresden, Germany},
series = {DATE '10}
}

@inproceedings{10.5555/1870926.1871057,
author = {Marinissen, Erik Jan and Singh, Adit and Glotter, Dan and Esposito, Marco and Carulli, John M. and Nahar, Amit and Butler, Kenneth M. and Appello, Davide and Portelli, Chris},
title = {Adapting to Adaptive Testing},
year = {2010},
isbn = {9783981080162},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Adaptive testing is a generic term for a number of techniques which aim at improving the test quality and/or reducing the test application costs. In adaptive tests, the test content or pass/fail limits are not fixed as in conventional tests, but dependent on other test results of the currently or previously tested chips. Part-average testing, outlier detection, and neighborhood screening are just a few examples of adaptive testing. With this Embedded Tutorial, we are offering an introduction to this topic, which is hot in the test community, to the wider DATE audience.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {556–561},
numpages = {6},
location = {Dresden, Germany},
series = {DATE '10}
}

@inproceedings{10.1145/1734263.1734279,
author = {Sahami, Mehran and Aiken, Alex and Zelenski, Julie},
title = {Expanding the Frontiers of Computer Science: Designing a Curriculum to Reflect a Diverse Field},
year = {2010},
isbn = {9781450300063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1734263.1734279},
doi = {10.1145/1734263.1734279},
abstract = {While the discipline of computing has evolved significantly in the past 30 years, Computer Science curricula have not as readily adapted to these changes. In response, we have recently completely redesigned the undergraduate CS curriculum at Stanford University, both modernizing the program as well as highlighting new directions in the field and its multi-disciplinary nature. As we explain in this paper, our restructured major features a streamlined core of foundation courses followed by a depth concentration in a track area as well as additional elective courses. Since its deployment this past year, the new program has proven to be very attractive to students, contributing to an increase of over 40% in the number of CS major declarations. We analyze feedback we received on the program from students, as well as commentary from industrial affiliates and other universities, providing further evidence of the promise this new curriculum holds.},
booktitle = {Proceedings of the 41st ACM Technical Symposium on Computer Science Education},
pages = {47–51},
numpages = {5},
keywords = {tracks, curriculum, multi-disciplinary, concentrations},
location = {Milwaukee, Wisconsin, USA},
series = {SIGCSE '10}
}

@inproceedings{10.1145/1734263.1734388,
author = {Thomas, Stan J. and Whitener, Paul M.},
title = {In the Zone: Virtual Computing on a Budget},
year = {2010},
isbn = {9781450300063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1734263.1734388},
doi = {10.1145/1734263.1734388},
abstract = {In this paper, we report on our efforts, extending over several years, to provide computer science students experience with a variety of operating system and computing environments. We describe our explorations into the use of virtual machine environments for instructional purposes, explorations that have led to the current multifaceted approach to virtualization. We also demonstrate that implementing a diverse, sophisticated virtual computing environment does not require a large investment in computer hardware, in fact it can lead to a cost saving by extending the useful life of systems and reducing the complexity of system administration.},
booktitle = {Proceedings of the 41st ACM Technical Symposium on Computer Science Education},
pages = {366–370},
numpages = {5},
keywords = {virtualization, computing environments, operating systems},
location = {Milwaukee, Wisconsin, USA},
series = {SIGCSE '10}
}

@inproceedings{10.1145/1734263.1734299,
author = {Kaczmarczyk, Lisa C. and Petrick, Elizabeth R. and East, J. Philip and Herman, Geoffrey L.},
title = {Identifying Student Misconceptions of Programming},
year = {2010},
isbn = {9781450300063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1734263.1734299},
doi = {10.1145/1734263.1734299},
abstract = {Computing educators are often baffled by the misconceptions that their CS1 students hold. We need to understand these misconceptions more clearly in order to help students form correct conceptions. This paper describes one stage in the development of a concept inventory for Computing Fundamentals: investigation of student misconceptions in a series of core CS1 topics previously identified as both important and difficult. Formal interviews with students revealed four distinct themes, each containing many interesting misconceptions. Three of those misconceptions are detailed in this paper: two misconceptions about memory models, and data assignment when primitives are declared. Individual misconceptions are related, but vary widely, thus providing excellent material to use in the development of the CI. In addition, CS1 instructors are provided immediate usable material for helping their students understand some difficult introductory concepts.},
booktitle = {Proceedings of the 41st ACM Technical Symposium on Computer Science Education},
pages = {107–111},
numpages = {5},
keywords = {programming, cs1, misconceptions, concept inventory, curriculum, pedagogy},
location = {Milwaukee, Wisconsin, USA},
series = {SIGCSE '10}
}

@inproceedings{10.1145/1735688.1735707,
author = {Alshawabkeh, Malak and Jang, Byunghyun and Kaeli, David},
title = {Accelerating the Local Outlier Factor Algorithm on a GPU for Intrusion Detection Systems},
year = {2010},
isbn = {9781605589350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1735688.1735707},
doi = {10.1145/1735688.1735707},
abstract = {The Local Outlier Factor (LOF) is a very powerful anomaly detection method available in machine learning and classification. The algorithm defines the notion of local outlier in which the degree to which an object is outlying is dependent on the density of its local neighborhood, and each object can be assigned an LOF which represents the likelihood of that object being an outlier. Although this concept of a local outlier is a useful one, the computation of LOF values for every data object requires a large number of k-nearest neighbor queries -- this overhead can limit the use of LOF due to the computational overhead involved.Due to the growing popularity of Graphics Processing Units (GPU) in general-purpose computing domains, and equipped with a high-level programming language designed specifically for general-purpose applications (e.g., CUDA), we look to apply this parallel computing approach to accelerate LOF. In this paper we explore how to utilize a CUDA-based GPU implementation of the k-nearest neighbor algorithm to accelerate LOF classification. We achieve more than a 100X speedup over a multi-threaded dual-core CPU implementation. We also consider the impact of input data set size, the neighborhood size (i.e., the value of k) and the feature space dimension, and report on their impact on execution time.},
booktitle = {Proceedings of the 3rd Workshop on General-Purpose Computation on Graphics Processing Units},
pages = {104–110},
numpages = {7},
keywords = {GPU, parallelization, intrusion detection system, LOF},
location = {Pittsburgh, Pennsylvania, USA},
series = {GPGPU-3}
}

@inproceedings{10.1145/1743666.1743694,
author = {Moshnyaga, Vasily G.},
title = {The Use of Eye Tracking for PC Energy Management},
year = {2010},
isbn = {9781605589947},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1743666.1743694},
doi = {10.1145/1743666.1743694},
abstract = {This paper discusses a new application of eye-tracking, namely power management, and outlines its implementation in personal computer system. Unlike existing power management technology, which "senses" a PC user through keyboard and/or mouse, our technology "watches" the user through a single camera. The technology tracks the user's eyes keeping the display active only if the user looks at the screen. Otherwise it dims the display down or even switches it off to save energy. We implemented the technology in hardware and present the results of its experimental evaluation.},
booktitle = {Proceedings of the 2010 Symposium on Eye-Tracking Research &amp; Applications},
pages = {113–116},
numpages = {4},
keywords = {eye tracking, energy reduction, applications},
location = {Austin, Texas},
series = {ETRA '10}
}

@inproceedings{10.1145/1743666.1743718,
author = {Jarodzka, Halszka and Holmqvist, Kenneth and Nystr\"{o}m, Marcus},
title = {A Vector-Based, Multidimensional Scanpath Similarity Measure},
year = {2010},
isbn = {9781605589947},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1743666.1743718},
doi = {10.1145/1743666.1743718},
abstract = {A great need exists in many fields of eye-tracking research for a robust and general method for scanpath comparisons. Current measures either quantize scanpaths in space (string editing measures like the Levenshtein distance) or in time (measures based on attention maps). This paper proposes a new pairwise scanpath similarity measure. Unlike previous measures that either use AOI sequences or forgo temporal order, the new measure defines scanpaths as a series of geometric vectors and compares temporally aligned scanpaths across several dimensions: shape, fixation position, length, direction, and fixation duration. This approach offers more multifaceted insights to how similar two scanpaths are. Eight fictitious scanpath pairs are tested to elucidate the strengths of the new measure, both in itself and compared to two of the currently most popular measures - the Levenshtein distance and attention map correlation.},
booktitle = {Proceedings of the 2010 Symposium on Eye-Tracking Research &amp; Applications},
pages = {211–218},
numpages = {8},
keywords = {scanpath, vector, Levenshtein distance, sequence analysis, string edit},
location = {Austin, Texas},
series = {ETRA '10}
}

@inproceedings{10.1145/1739041.1739076,
author = {Fang, Lujun and LeFevre, Kristen},
title = {Splash: Ad-Hoc Querying of Data and Statistical Models},
year = {2010},
isbn = {9781605589459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1739041.1739076},
doi = {10.1145/1739041.1739076},
abstract = {Data mining is increasingly performed by people who are not computer scientists or professional programmers. It is often done as an iterative process involving multiple ad-hoc tasks, as well as data pre- and post-processing, all of which must be executed over large databases. In order to make data mining more accessible, it is critical to provide a simple, easy-to-use language that allows the user to specify ad-hoc data processing, model construction, and model manipulation. Simultaneously, it is necessary for the underlying system to scale up to large datasets. Unfortunately, while each of these requirements can be satisfied, individually, by existing systems, no system fully satisfies all criteria.In this paper, we present a system called Splash to fill this void. Splash supports an extended relational data model and SQL query language, which allows for the natural integration of statistical modeling and ad-hoc data processing. It also supports a novel representatives operator to help explain models using a limited number of examples. We have developed a prototype implementation of Splash. Our experimental study indicates that it scales well to large input datasets. Further, to demonstrate the simplicity of the language, we conducted a case study using Splash to perform a series of exploratory analyses using network log data. Our study indicates that the query-based interface is simpler than a common data mining software package, and it often requires less programming effort to use.},
booktitle = {Proceedings of the 13th International Conference on Extending Database Technology},
pages = {275–286},
numpages = {12},
location = {Lausanne, Switzerland},
series = {EDBT '10}
}

@inproceedings{10.1145/1774088.1774246,
author = {Doman, Marguerite and Payton, Jamie and Dahlberg, Teresa},
title = {Leveraging Fuzzy Query Processing to Support Applications in Wireless Sensor Networks},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774246},
doi = {10.1145/1774088.1774246},
abstract = {In this paper, we describe a fuzzy query processing approach to support application development in sensor networks. Using a fuzzy query, an application programmer can provide a linguistic and semantic specification of the desired data, eliminating the need to specify explicit and exact thresholds as part of a query. The returned fuzzy query results are each associated with a degree of membership measurement that indicates how closely each returned data value matches the semantic intent of the fuzzy query, providing applications with additional information that can be used to reason about the query result. Our approach to in-network fuzzy query processing allows for each sensor node to tailor its evaluation of a fuzzy query; this feature allows for consideration of micro-environments embedded within the sensor network that can impact how individual sensor data values should be interpreted with respect to the semantic intent of the query. To demonstrate that a fuzzy query processing approach is feasible, we use an application scenario to evaluate the implementation of our fuzzy query processing system in a simulated sensor network environment; results show that precision and overhead for our approach are comparable to traditional query processing.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {764–771},
numpages = {8},
keywords = {wireless sensor networks, fuzzy query processing, data management},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@inproceedings{10.1145/1754239.1754276,
author = {Ichim, Daniela},
title = {Quantile-Based Bootstrap Methods to Generate Continuous Synthetic Data},
year = {2010},
isbn = {9781605589909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1754239.1754276},
doi = {10.1145/1754239.1754276},
abstract = {To face the increasing demand from users, National Statistical Institutes (NSI) release different information products. The dissemination of this information should be performed in full compliance with the regulations pertaining to the privacy of respondents. One product that could belong to a dissemination portfolio is represented by synthetic data. In this paper a very brief review of several methods to generate synthetic data is given. The emphasis is put on bootstrap methods that might be used in complex surveys. A quantile-based bootstrap method is proposed, avoiding any model assumption. Different bootstrap strategies were empirically compared from the point of view of some univariate statistics and in a linear regression framework. The Italian Structure of Earnings Survey 2006 data were used in these preliminary experiments.},
booktitle = {Proceedings of the 2010 EDBT/ICDT Workshops},
articleno = {33},
numpages = {10},
keywords = {microdata dissemination, privacy, statistical disclosure control, synthetic data, bootstrap, data utility},
location = {Lausanne, Switzerland},
series = {EDBT '10}
}

@inproceedings{10.1145/1774088.1774505,
author = {Lee, Jusuk and Jeong, Kyoochang and Lee, Heejo},
title = {Detecting Metamorphic Malwares Using Code Graphs},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774505},
doi = {10.1145/1774088.1774505},
abstract = {Malware writers and detectors have been running an endless battle. Self-defense is the weapon most malware writers prepare against malware detectors. Malware writers have tried to evade the improved detection techniques of anti-virus(AV) products. Packing and code obfuscation are two popular evasion techniques. When these techniques are applied to malwares, they are able to change their instruction sequence while maintaining their intended function. We propose a detection mechanism defeating these self-defense techniques to improve malware detection. Since an obfuscated malware is able to change the syntax of its code while preserving its semantics, the proposed mechanism uses the semantic invariant. We convert the API call sequence of the malware into a graph, commonly known as a call graph, to extract the semantic of the malware. The call graph can be reduced to a code graph used for semantic signatures of the proposed mechanism. We show that the code graph can represent the characteristics of a program exactly and uniquely. Next, we evaluate the proposed mechanism by experiment. The mechanism has an 91% detection ratio of real-world malwares and detects 300 metamorphic malwares that can evade AV scanners. In this paper, we show how to analyze malwares by extracting program semantics using static analysis. It is shown that the proposed mechanism provides a high possibility of detecting malwares even when they attempt self-protection.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {1970–1977},
numpages = {8},
keywords = {code graph, code obfuscation, static analysis, metamorphic malware},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@inproceedings{10.1145/1739041.1739095,
author = {Barbieri, Davide Francesco and Braga, Daniele and Ceri, Stefano and Grossniklaus, Michael},
title = {An Execution Environment for C-SPARQL Queries},
year = {2010},
isbn = {9781605589459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1739041.1739095},
doi = {10.1145/1739041.1739095},
abstract = {Continuous SPARQL (C-SPARQL) is proposed as new language for continuous queries over streams of RDF data. It covers a gap in the Semantic Web abstractions which is needed for many emerging applications, including our focus on Urban Computing. In this domain, sensor-based information on roads must be processed to deduce localized traffic conditions and then produce traffic management strategies. Executing C-SPARQL queries requires the effective integration of SPARQL and streaming technologies, which capitalize over a decade of research and development; such integration poses several nontrivial challenges.In this paper we (a) show the syntax and semantics of the C-SPARQL language together with some examples; (b) introduce a query graph model which is an intermediate representation of queries devoted to optimization; (c) discuss the features of an execution environment that leverages existing technologies; (d) introduce optimizations in terms of rewriting rules applied to the query graph model, so as to efficiently exploit the execution environment; and (e) show evidence of the effectiveness of our optimizations on a prototype of execution environment.},
booktitle = {Proceedings of the 13th International Conference on Extending Database Technology},
pages = {441–452},
numpages = {12},
location = {Lausanne, Switzerland},
series = {EDBT '10}
}

@inproceedings{10.1145/1774088.1774344,
author = {de Santana, Vagner Figuer\^{e}do and Baranauskas, M. Cec\'{\i}lia C.},
title = {Summarizing Observational Client-Side Data to Reveal Web Usage Patterns},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774344},
doi = {10.1145/1774088.1774344},
abstract = {Client-side event logs may reveal patterns of usage of Web pages. Nevertheless, extracting useful and novel information from this voluminous data set is a challenge for evaluation tools, since a few minutes simple task may result in a sequence of hundreds of events. This work contributes with a technique to process these logs and build a Web page's usage graph summarizing statistical information of the Web page usage concerning one or more sessions. This graph reveals patterns of real usage data, which Human-Computer Interaction specialists may find useful for inspecting accessibility and usability issues. Moreover, Web usage miners can reuse the usage graph to apply other techniques to discover other patterns or rules.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {1219–1223},
numpages = {5},
keywords = {client-side event logs, usage patterns, websites evaluation tool},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@inproceedings{10.1145/1774088.1774449,
author = {Malkowski, Simon and Jayasinghe, Deepal and Hedwig, Markus and Park, Junhee and Kanemasa, Yasuhiko and Pu, Calton},
title = {Empirical Analysis of Database Server Scalability Using an N-Tier Benchmark with Read-Intensive Workload},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774449},
doi = {10.1145/1774088.1774449},
abstract = {The performance evaluation of database servers in N-tier applications is a serious challenge due to requirements such as non-stationary complex workloads and global consistency management when replicating database servers. We conducted an experimental evaluation of database server scalability and bottleneck identification in N-tier applications using the RUBBoS benchmark. Our experiments are comprised of a full scale-out mesh with up to nine database servers and three application servers. Additionally, the fourtier system was run in a variety of configurations, including two database management systems (MySQL and PostgreSQL), two hardware node types (normal and low-cost), and two database replication techniques (C-JDBC and MySQL Cluster). In this paper we present the analysis of results generated with a read-intensive interaction pattern (browse-only workload) in the client emulator. These empirical data can be divided into two kinds. First, for a relatively small number of servers, we find simple hardware resource bottlenecks. Consequently, system throughput increases with an increasing number of database (and application) servers. Second, when sufficient hardware resources are available, non-obvious database related bottlenecks have been found that limit system throughput. While the first kind of bottlenecks shows that there are similarities between database and application/web server scalability, the second kind of bottlenecks shows that database servers have significantly higher sophistication and complexity that require in-depth evaluation and analysis.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {1680–1687},
numpages = {8},
keywords = {database replication, bottleneck, distributed systems, RUBBoS, N-tier applications, middleware},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@article{10.1145/1670679.1670680,
author = {Salfner, Felix and Lenk, Maren and Malek, Miroslaw},
title = {A Survey of Online Failure Prediction Methods},
year = {2010},
issue_date = {March 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/1670679.1670680},
doi = {10.1145/1670679.1670680},
abstract = {With the ever-growing complexity and dynamicity of computer systems, proactive fault management is an effective approach to enhancing availability. Online failure prediction is the key to such techniques. In contrast to classical reliability methods, online failure prediction is based on runtime monitoring and a variety of models and methods that use the current state of a system and, frequently, the past experience as well. This survey describes these methods. To capture the wide spectrum of approaches concerning this area, a taxonomy has been developed, whose different approaches are explained and major concepts are described in detail.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {10},
numpages = {42},
keywords = {Error, failure prediction, fault, runtime monitoring, prediction metrics}
}

@inproceedings{10.1145/1953611.1953624,
author = {Monteiro, Pedro and Monteiro, Miguel P.},
title = {A Pattern Language for Parallelizing Irregular Algorithms},
year = {2010},
isbn = {9781450301275},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1953611.1953624},
doi = {10.1145/1953611.1953624},
abstract = {In irregular algorithms, data set's dependences and distributions cannot be statically predicted. This class of algorithms tends to organize computations in terms of data locality instead of parallelizing control in multiple threads. Thus, opportunities for exploiting parallelism vary dynamically, according to how the algorithm changes data dependences. This paper presents the first part of a pattern language for creating parallel implementations of irregular algorithms and applications. Four patterns are proposed: Amorphous Data-Parallelism, Data-Parallel Graph, Optimistic Iteration and In-Order Iteration.},
booktitle = {Proceedings of the 2010 Workshop on Parallel Programming Patterns},
articleno = {13},
numpages = {14},
location = {Carefree, Arizona, USA},
series = {ParaPLoP '10}
}

@article{10.1145/1721654.1721670,
author = {Creeger, Mache},
title = {CTO Roundtable: Malware Defense},
year = {2010},
issue_date = {April 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0001-0782},
url = {https://doi.org/10.1145/1721654.1721670},
doi = {10.1145/1721654.1721670},
abstract = {The battle is bigger than most of us realize.},
journal = {Commun. ACM},
month = apr,
pages = {43–49},
numpages = {7}
}

@article{10.1145/1721654.1721672,
author = {Armbrust, Michael and Fox, Armando and Griffith, Rean and Joseph, Anthony D. and Katz, Randy and Konwinski, Andy and Lee, Gunho and Patterson, David and Rabkin, Ariel and Stoica, Ion and Zaharia, Matei},
title = {A View of Cloud Computing},
year = {2010},
issue_date = {April 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0001-0782},
url = {https://doi.org/10.1145/1721654.1721672},
doi = {10.1145/1721654.1721672},
abstract = {Clearing the clouds away from the true potential and obstacles posed by this computing capability.},
journal = {Commun. ACM},
month = apr,
pages = {50–58},
numpages = {9}
}

@inproceedings{10.1145/1785455.1785462,
author = {Mikhail, Mina and El-Ayat, Khaled and El Kaliouby, Rana and Coan, James and Allen, John J. B.},
title = {Emotion Detection Using Noisy EEG Data},
year = {2010},
isbn = {9781605588254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1785455.1785462},
doi = {10.1145/1785455.1785462},
abstract = {Emotion is an important aspect in the interaction between humans. It is fundamental to human experience and rational decision-making. There is a great interest for detecting emotions automatically. A number of techniques have been employed for this purpose using channels such as voice and facial expressions. However, these channels are not very accurate because they can be affected by users' intentions. Other techniques use physiological signals along with electroencephalography (EEG) for emotion detection. However, these approaches are not very practical for real time applications because they either ask the participants to reduce any motion and facial muscle movement or reject EEG data contaminated with artifacts. In this paper, we propose an approach that analyzes highly contaminated EEG data produced from a new emotion elicitation technique. We also use a feature selection mechanism to extract features that are relevant to the emotion detection task based on neuroscience findings. We reached an average accuracy of 51% for joy emotion, 53% for anger, 58% for fear and 61% for sadness.},
booktitle = {Proceedings of the 1st Augmented Human International Conference},
articleno = {7},
numpages = {7},
keywords = {brain signals, affective computing, feature extraction, support vector machines},
location = {Meg\`{e}ve, France},
series = {AH '10}
}

