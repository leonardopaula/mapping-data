@inproceedings{10.1145/2656450.2656475,
author = {Fedoruk, Alan and Gong, Mingwei and McCarthy, Michael},
title = {Student Initiated Capstone Projects},
year = {2014},
isbn = {9781450326865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2656450.2656475},
doi = {10.1145/2656450.2656475},
abstract = {Capstone projects/courses, in which students undertake a significant project under supervision, have been offered in many computing programs In this paper, we present our experience for the senior project course as offered by the BCIS program at Mount Royal University, which provides an environment for students to successfully complete a capstone experience. This senior project capstone is a student initiated, single semester, individual, open ended project. We include the motivation for and the advantages of this approach as well as details of an exemplar project. The exemplar project shows student initiated projects foster student interest and motivation and enable projects with depth and breadth to be completed.},
booktitle = {Proceedings of the 15th Annual Conference on Information Technology Education},
pages = {65–70},
numpages = {6},
keywords = {computer science education, information technology education, Capstone experience},
location = {Atlanta, Georgia, USA},
series = {SIGITE '14}
}

@article{10.1145/2659891,
author = {Lison, Pierre and Meena, Raveesh},
title = {Spoken Dialogue Systems: The New Frontier in Human-Computer Interaction},
year = {2014},
issue_date = {Fall 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1528-4972},
url = {https://doi.org/10.1145/2659891},
doi = {10.1145/2659891},
abstract = {Wouldn't it be great if we could simply talk to our technical devices instead of relying on cumbersome displays and keyboards to convey what we want?},
journal = {XRDS},
month = oct,
pages = {46–51},
numpages = {6}
}

@inproceedings{10.1145/2660193.2660195,
author = {Steele, Guy L. and Lea, Doug and Flood, Christine H.},
title = {Fast Splittable Pseudorandom Number Generators},
year = {2014},
isbn = {9781450325851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2660193.2660195},
doi = {10.1145/2660193.2660195},
abstract = {We describe a new algorithm SplitMix for an object-oriented and splittable pseudorandom number generator (PRNG) that is quite fast: 9 64-bit arithmetic/logical operations per 64 bits generated. A conventional linear PRNG object provides a generate method that returns one pseudorandom value and updates the state of the PRNG, but a splittable PRNG object also has a second operation, split, that replaces the original PRNG object with two (seemingly) independent PRNG objects, by creating and returning a new such object and updating the state of the original object. Splittable PRNG objects make it easy to organize the use of pseudorandom numbers in multithreaded programs structured using fork-join parallelism. No locking or synchronization is required (other than the usual memory fence immediately after object creation). Because the generate method has no loops or conditionals, it is suitable for SIMD or GPU implementation.We derive SplitMix from the DotMix algorithm of Leiserson, Schardl, and Sukha by making a series of program transformations and engineering improvements. The end result is an object-oriented version of the purely functional API used in the Haskell library for over a decade, but SplitMix is faster and produces pseudorandom sequences of higher quality; it is also far superior in quality and speed to java.util.Random, and has been included in Java JDK8 as the class java.util.SplittableRandom.We have tested the pseudorandom sequences produced by SplitMix using two standard statistical test suites (DieHarder and TestU01) and they appear to be adequate for "everyday" use, such as in Monte Carlo algorithms and randomized data structures where speed is important.},
booktitle = {Proceedings of the 2014 ACM International Conference on Object Oriented Programming Systems Languages &amp; Applications},
pages = {453–472},
numpages = {20},
keywords = {spliterator, determinism, java, scala, pedigree, nondeterminism, random number generator, collections, recursive splitting, parallel computing, streams, pseudorandom, multithreading, object-oriented, splittable data structures},
location = {Portland, Oregon, USA},
series = {OOPSLA '14}
}

@article{10.1145/2714064.2660195,
author = {Steele, Guy L. and Lea, Doug and Flood, Christine H.},
title = {Fast Splittable Pseudorandom Number Generators},
year = {2014},
issue_date = {October 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/2714064.2660195},
doi = {10.1145/2714064.2660195},
abstract = {We describe a new algorithm SplitMix for an object-oriented and splittable pseudorandom number generator (PRNG) that is quite fast: 9 64-bit arithmetic/logical operations per 64 bits generated. A conventional linear PRNG object provides a generate method that returns one pseudorandom value and updates the state of the PRNG, but a splittable PRNG object also has a second operation, split, that replaces the original PRNG object with two (seemingly) independent PRNG objects, by creating and returning a new such object and updating the state of the original object. Splittable PRNG objects make it easy to organize the use of pseudorandom numbers in multithreaded programs structured using fork-join parallelism. No locking or synchronization is required (other than the usual memory fence immediately after object creation). Because the generate method has no loops or conditionals, it is suitable for SIMD or GPU implementation.We derive SplitMix from the DotMix algorithm of Leiserson, Schardl, and Sukha by making a series of program transformations and engineering improvements. The end result is an object-oriented version of the purely functional API used in the Haskell library for over a decade, but SplitMix is faster and produces pseudorandom sequences of higher quality; it is also far superior in quality and speed to java.util.Random, and has been included in Java JDK8 as the class java.util.SplittableRandom.We have tested the pseudorandom sequences produced by SplitMix using two standard statistical test suites (DieHarder and TestU01) and they appear to be adequate for "everyday" use, such as in Monte Carlo algorithms and randomized data structures where speed is important.},
journal = {SIGPLAN Not.},
month = oct,
pages = {453–472},
numpages = {20},
keywords = {recursive splitting, splittable data structures, pedigree, random number generator, streams, nondeterminism, scala, collections, java, object-oriented, determinism, spliterator, parallel computing, multithreading, pseudorandom}
}

@inproceedings{10.1145/2660193.2660225,
author = {Bartenstein, Thomas W. and Liu, Yu David},
title = {Rate Types for Stream Programs},
year = {2014},
isbn = {9781450325851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2660193.2660225},
doi = {10.1145/2660193.2660225},
abstract = {We introduce RATE TYPES, a novel type system to reason about and optimize data-intensive programs. Built around stream languages, RATE TYPES performs static quantitative reasoning about stream rates -- the frequency of data items in a stream being consumed, processed, and produced. Despite the fact that streams are fundamentally dynamic, we find two essential concepts of stream rate control -- throughput ratio and natural rate -- are intimately related to the program structure itself and can be effectively reasoned about by a type system. RATE TYPES is proven to correspond with a time-aware and parallelism-aware operational semantics. The strong correspondence result tolerates arbitrary schedules, and does not require any synchronization between stream filters.We further implement RATE TYPES, demonstrating its effectiveness in predicting stream data rates in real-world stream programs.},
booktitle = {Proceedings of the 2014 ACM International Conference on Object Oriented Programming Systems Languages &amp; Applications},
pages = {213–232},
numpages = {20},
keywords = {data throughput, stream programming, performance reasoning, type systems, data processing rates},
location = {Portland, Oregon, USA},
series = {OOPSLA '14}
}

@article{10.1145/2714064.2660225,
author = {Bartenstein, Thomas W. and Liu, Yu David},
title = {Rate Types for Stream Programs},
year = {2014},
issue_date = {October 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/2714064.2660225},
doi = {10.1145/2714064.2660225},
abstract = {We introduce RATE TYPES, a novel type system to reason about and optimize data-intensive programs. Built around stream languages, RATE TYPES performs static quantitative reasoning about stream rates -- the frequency of data items in a stream being consumed, processed, and produced. Despite the fact that streams are fundamentally dynamic, we find two essential concepts of stream rate control -- throughput ratio and natural rate -- are intimately related to the program structure itself and can be effectively reasoned about by a type system. RATE TYPES is proven to correspond with a time-aware and parallelism-aware operational semantics. The strong correspondence result tolerates arbitrary schedules, and does not require any synchronization between stream filters.We further implement RATE TYPES, demonstrating its effectiveness in predicting stream data rates in real-world stream programs.},
journal = {SIGPLAN Not.},
month = oct,
pages = {213–232},
numpages = {20},
keywords = {data throughput, data processing rates, stream programming, performance reasoning, type systems}
}

@inproceedings{10.1145/2658537.2658685,
author = {Crenshaw, Nicole and Nardi, Bonnie},
title = {What's in a Name? Naming Practices in Online Video Games},
year = {2014},
isbn = {9781450330145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2658537.2658685},
doi = {10.1145/2658537.2658685},
abstract = {Recent research suggests that participation in online video games allows players to create an "idealized self" through their characters, that is, a character perceived to be more attractive or interesting than the player. However, our research indicates that players use carefully created character names to develop a persistent, pragmatic identity to maintain social relationships across games and related sites, and to express their personalities by incorporating elements of popular culture, literary references, and aspects of their own personal histories. Identity in gaming is thus more complex than identification with the physical representation of the character.},
booktitle = {Proceedings of the First ACM SIGCHI Annual Symposium on Computer-Human Interaction in Play},
pages = {67–76},
numpages = {10},
keywords = {identity, online video games, names, handles, player-character relationship},
location = {Toronto, Ontario, Canada},
series = {CHI PLAY '14}
}

@inproceedings{10.1145/2658537.2658688,
author = {Dodero, Gabriella and Gennari, Rosella and Melonio, Alessandra and Torello, Santina},
title = {Towards Tangible Gamified Co-Design at School: Two Studies in Primary Schools},
year = {2014},
isbn = {9781450330145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2658537.2658688},
doi = {10.1145/2658537.2658688},
abstract = {Co-design is an ideal approach to design with users. It allows designers to create products, such as games, with their intended users and in their natural environment, e.g., children and their teachers in their school. Nowadays school contexts, however, pose their own requirements to co-design, which can affect its success. For instance, school contexts tend to be associated to boring rote by learners, who are used to interactive digital games. Gamification can then help in creating a positive engaging experience for school classes that co-design, as games do. This paper takes up such a view: it gamifies co-design contexts in order to positively engage school classes. To this end it presents two studies with gamified co-design in primary schools: heterogeneous teams co-designed prototypes by resolving missions as in a game, in the first short-term study; they did it in an even more gamified context, in the second long-term study. Results of both studies are encouraging for the approach. The paper also advances basic guidelines for tangibly gamifying co-design at school, grounded in the studies and literature.},
booktitle = {Proceedings of the First ACM SIGCHI Annual Symposium on Computer-Human Interaction in Play},
pages = {77–86},
numpages = {10},
keywords = {co-design, empirical studies, gamification, children, schools, engagement, game design},
location = {Toronto, Ontario, Canada},
series = {CHI PLAY '14}
}

@inproceedings{10.1145/2661334.2661371,
author = {McIntyre, Lesley J. and Hanson, Vicki L.},
title = {Buildings and Users with Visual Impairment: Uncovering Factors for Accessibility Using BIT-Kit},
year = {2014},
isbn = {9781450327206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661334.2661371},
doi = {10.1145/2661334.2661371},
abstract = {In this paper, we report on the experiences of visually impaired users in navigating buildings. We focus on an investigation of the way-finding experiences by 10 participants with varying levels of visual ability, as they undertook a way-finding task in an unfamiliar public building. Through applying the BIT-Kit framework in this preliminary user study, we were able to uncover 54 enabling and disabling interactions within the case study building. While this building adhered to building legislation, our findings identified a number of accessibility problems including, issues associated with using doors, hazards caused by building finishes, and difficulty in knowing what to do in the case of an emergency evacuation. This user study has demonstrated a disparity between design guidance and the accessibility needs of building users. It has uncovered evidence to enable architects to begin to design for the real needs of users who have a range of visual impairment. Furthermore, it has instigated discussion of how BIT-Kit's evidence could be incorporated into digital modelling tools currently used in architectural practice.},
booktitle = {Proceedings of the 16th International ACM SIGACCESS Conference on Computers &amp; Accessibility},
pages = {59–66},
numpages = {8},
keywords = {visual impairment, methods, buildings, way-finding, architecture, accessibility},
location = {Rochester, New York, USA},
series = {ASSETS '14}
}

@inproceedings{10.1145/2658260.2658266,
author = {Cui, Wenzhi and Qian, Chen},
title = {DiFS: Distributed Flow Scheduling for Adaptive Routing in Hierarchical Data Center Networks},
year = {2014},
isbn = {9781450328395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2658260.2658266},
doi = {10.1145/2658260.2658266},
abstract = {Data center networks leverage multiple parallel paths connecting end host pairs to offer high bisection bandwidth for cluster computing applications. However, state of the art routing protocols such as Equal Cost Multipath (ECMP) is load-oblivious due to static flow-to-link assignments. They may cause bandwidth loss due to flow collisions. Recently proposed centralized scheduling algorithm or host based adaptive routing that require network-wide condition information may suffer from scalability problems. In this paper, we present Distributed Flow Scheduling (DiFS) based Adaptive Routing for hierarchical data center networks, which is a localized and switch-only solution. DiFS allows switches to cooperate to avoid over-utilized links and find available paths without centralized control. DiFS is scalable and can react quickly to dynamic traffic, because it is independently executed on switches and requires no synchronization. DiFS provides global bounds of flow balance based on local optimization. Extensive experiments show that the aggregate throughput of DiFS using various traffic patterns is much better than that of ECMP, and is similar to or higher than those of two representative protocols that use network-wide optimization.},
booktitle = {Proceedings of the Tenth ACM/IEEE Symposium on Architectures for Networking and Communications Systems},
pages = {53–64},
numpages = {12},
keywords = {data center networks, adaptive routing},
location = {Los Angeles, California, USA},
series = {ANCS '14}
}

@inproceedings{10.1145/2661334.2661363,
author = {Gadde, Prathik and Bolchini, Davide},
title = {From Screen Reading to Aural Glancing: Towards Instant Access to Key Page Sections},
year = {2014},
isbn = {9781450327206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661334.2661363},
doi = {10.1145/2661334.2661363},
abstract = {Whereas glancing at a web page is crucial for navigation, screen readers force users to listen to content serially. This hampers efficient browsing of complex pages and maintains an accessibility divide between sighted and screen-reader users. To address this problem, we adopt a three-pronged strategy: (1) in a user study, we identified key page-level navigation problems that screen-reader users face while browsing a complex site; (2) through a crowd-sourcing system, we prioritized the most relevant sections of different page types necessary to support basic tasks; (3) we introduced DASX, a navigation approach that augments the ability of screen-reader users to "aurally glance" at a complex page by accessing at any time the most relevant page sections. In a preliminary evaluation, DASX markedly reduced the gap in page navigation efficiency between screen-reader and sighted users. Our contribution provides the groundwork for rethinking access strategies that strongly tie aural navigation to user's tasks.},
booktitle = {Proceedings of the 16th International ACM SIGACCESS Conference on Computers &amp; Accessibility},
pages = {67–74},
numpages = {8},
keywords = {web navigation, ecommerce web applications, direct web access, voice browsing, blind users, screen-reader users, fast browsing},
location = {Rochester, New York, USA},
series = {ASSETS '14}
}

@inproceedings{10.1145/2661334.2661376,
author = {Oh, Uran and Findlater, Leah},
title = {Design of and Subjective Response to On-Body Input for People with Visual Impairments},
year = {2014},
isbn = {9781450327206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661334.2661376},
doi = {10.1145/2661334.2661376},
abstract = {For users with visual impairments, who do not necessarily need the visual display of a mobile device, non-visual on-body interaction (e.g., Imaginary Interfaces) could provide accessible input in a mobile context. Such interaction provides the potential advantages of an always-available input surface, and increased tactile and proprioceptive feedback compared to a smooth touchscreen. To investigate preferences for and design of accessible on-body interaction, we conducted a study with 12 visually impaired participants. Participants evaluated five locations for on-body input and compared on-phone to on-hand interaction with one versus two hands. Our findings show that the least preferred areas were the face/neck and the forearm, while locations on the hands were considered to be more discreet and natural. The findings also suggest that participants may prioritize social acceptability over ease of use and physical comfort when assessing the feasibility of input at different locations of the body. Finally, tradeoffs were seen in preferences for touchscreen versus on-body input, with on-body input considered useful for contexts where one hand is busy (e.g., holding a cane or dog leash). We provide implications for the design of accessible on-body input.},
booktitle = {Proceedings of the 16th International ACM SIGACCESS Conference on Computers &amp; Accessibility},
pages = {115–122},
numpages = {8},
keywords = {design recommendations., eyes-free interaction, gestural interfaces, on-body input, mobile, visual impairments},
location = {Rochester, New York, USA},
series = {ASSETS '14}
}

@inproceedings{10.1145/2661334.2661372,
author = {Naftali, Maia and Findlater, Leah},
title = {Accessibility in Context: Understanding the Truly Mobile Experience of Smartphone Users with Motor Impairments},
year = {2014},
isbn = {9781450327206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661334.2661372},
doi = {10.1145/2661334.2661372},
abstract = {Lab-based studies on touchscreen use by people with motor impairments have identified both positive and negative impacts on accessibility. Little work, however, has moved beyond the lab to investigate the truly mobile experiences of users with motor impairments. We conducted two studies to investigate how smartphones are being used on a daily basis, what activities they enable, and what contextual challenges users are encountering. The first study was a small online survey with 16 respondents. The second study was much more in depth, including an initial interview, two weeks of diary entries, and a 3-hour contextual session that included neighborhood activities. Four expert smartphone users participated in the second study and we used a case study approach for analysis. Our findings highlight the ways in which smartphones are enabling everyday activities for people with motor impairments, particularly in overcoming physical accessibility challenges in the real world and supporting writing and reading. We also identified important situational impairments, such as the inability to retrieve the phone while in transit, and confirmed many lab-based findings in the real-world setting. We present design implications and directions for future work.},
booktitle = {Proceedings of the 16th International ACM SIGACCESS Conference on Computers &amp; Accessibility},
pages = {209–216},
numpages = {8},
keywords = {contextual interviews, smartphones, assistive devices, case study., accessibility, mobile},
location = {Rochester, New York, USA},
series = {ASSETS '14}
}

@inproceedings{10.1145/2688412.2688414,
author = {Dubinsky, Yael and Limonad, Lior and Mashkif, Nir},
title = {Wearable-Based Mobile App for Decision Making: The Case of a Safe Workplace},
year = {2014},
isbn = {9781450321907},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2688412.2688414},
doi = {10.1145/2688412.2688414},
abstract = {In this paper, we present the concept for the Decision Compass mobile app, an application based on wearable devices meant to enforce safety in the workplace. We illus-trate how data gathered by wearable devices can identify situations of cognitive-dissonance and may be combined with additional contextual information to identify safety related hazards. Our application is designed not only to alert on safety hazards but also to provide resolutions in cases of explicit regulation violations. Finally, we describe future directions to add customized resolutions based on gradual learning of the individual preferences.},
booktitle = {Proceedings of the 2nd International Workshop on Mobile Development Lifecycle},
pages = {19–22},
numpages = {4},
keywords = {organization safety., mobile application, wearable computing, decision making},
location = {Portland, Oregon, USA},
series = {MobileDeLi '14}
}

@inproceedings{10.1145/2687148.2687150,
author = {Waye, Lucas},
title = {Privacy Integrated Data Stream Queries},
year = {2014},
isbn = {9781450322966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2687148.2687150},
doi = {10.1145/2687148.2687150},
abstract = {Research on differential privacy is generally concerned with examining data sets that are static. Because the data sets do not change, every computation on them produces "one-shot" query results; the results do not change aside from randomness introduced for privacy. There are many circumstances, however, where this model does not apply, or is simply infeasible. Data streams are examples of non-static data sets where results may change as more data is streamed. Theoretical support for differential privacy with data streams has been researched in the form of differentially private streaming algorithms. In this paper, we present a practical framework for which a non-expert can perform differentially private operations on data streams. The system is built as an extension to PINQ (Privacy Integrated Queries), a differentially private programming framework for static data sets. The streaming extension provides a programmatic interface for the different types of streaming differential privacy from the literature so that the privacy trade-offs of each type of algorithm can be understood by a non-expert programmer.},
booktitle = {Proceedings of the 2014 International Workshop on Privacy &amp; Security in Programming},
pages = {19–26},
numpages = {8},
keywords = {differential privacy, privacy, programming languages},
location = {Portland, Oregon, USA},
series = {PSP '14}
}

@inproceedings{10.1145/2688204.2688212,
author = {Kubelka, Juraj and Bergel, Alexandre and Robbes, Romain},
title = {Asking and Answering Questions during a Programming Change Task in Pharo Language},
year = {2014},
isbn = {9781450322775},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2688204.2688212},
doi = {10.1145/2688204.2688212},
abstract = {Previous studies focus on the specific questions software engineers ask when evolving a codebase. Though these studies observe developers using statically typed languages, little is known about the developer questions using dynamically typed languages. Dynamically typed languages present new challenges to understanding and navigating in a codebase and could affect results reported by previous studies.This paper replicates a previous study and presents the analysis of six programming sessions made in Pharo, a dynamically typed language. We found a similar result when comparing sessions on an unfamiliar codebase with the previous work. Our result on the familiar code greatly deviates from the replicated study, likely caused by different tasks and development strategies. Both missing type information and test driven development affected participant behavior and prudence on codebase understanding, where some participants made changes based on assumptions.We provide a set of questions that are useful in characterizing activity related to the use of a dynamically typed language and test-driven development -- questions not explicitly considered in previous research. We also present a number of issues that we would like to discuss during the PLATEAU workshop.},
booktitle = {Proceedings of the 5th Workshop on Evaluation and Usability of Programming Languages and Tools},
pages = {1–11},
numpages = {11},
keywords = {user study, change task, development environments, program comprehension, programming tools},
location = {Portland, Oregon, USA},
series = {PLATEAU '14}
}

@article{10.1145/2684097.2684102,
author = {Hall, Brian R.},
title = {A Synthesized Definition of Computer Ethics},
year = {2014},
issue_date = {September 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {3},
issn = {0095-2737},
url = {https://doi.org/10.1145/2684097.2684102},
doi = {10.1145/2684097.2684102},
abstract = {Computing ethics is a complex area of study that is of significant importance to the computing community and global society. However, research and education in computing ethics are difficult due to the diverse meanings of ethics. This paper presents details of a content analysis study that analyzed definitions of computer ethics. The purpose of this study was to educe and present the meaning of computing ethics, resulting in a thematic definition of computing ethics for use in education and research. This paper presents definition themes that emerged: interdisciplinary, collaboration, scholars and professionals, methodically study, practically affect, contributions and costs, computing artifacts, and global society. The results of this study can assist computing ethicists with research, aid computing educators with curriculum development, and provide a theoretical frame for relating ethics to computing. This exploration demonstrates that groups within the computing community can find common ground, even on such a difficult and complex matter as ethics.},
journal = {SIGCAS Comput. Soc.},
month = oct,
pages = {21–35},
numpages = {15},
keywords = {computing, computer ethics, community, education, definition}
}

@inproceedings{10.1145/2639189.2670251,
author = {Ruf, Alessia P. and Seckler, Mirjam and Opwis, Klaus},
title = {Long-Term Modality Effect in Multimedia Learning},
year = {2014},
isbn = {9781450325424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2639189.2670251},
doi = {10.1145/2639189.2670251},
abstract = {Cognitive theories of multimedia are seeking the best way of creating materials to enhance learning outcomes. The so-called modality effect accords that learning outcomes are better if visual material such as images is presented together with auditory rather than with visual information such as text. However, previous research on this effect is conflicting. There is also some evidence that the modality effect can be reversed if the learning environment is self-paced. Finally, there is little research about the modality effect over time, and its impact on long-term memory. There is a lack of studies comparing multimodal learning in a system-paced as well as in a self-paced environment over time. Therefore, the aim of this study is (1) to compare auditory and visual learning conditions, (2) to examine the relationship between self- and system-paced learning time, and (3) to analyze the modality effect over time (immediate and after one week).},
booktitle = {Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational},
pages = {963–966},
numpages = {4},
keywords = {system-paced learning, modality effect, e-learning, self-paced learning, long-term learning},
location = {Helsinki, Finland},
series = {NordiCHI '14}
}

@inproceedings{10.1145/2639189.2639485,
author = {Thomas, Lisa and Briggs, Pam},
title = {An Older Adult Perspective on Digital Legacy},
year = {2014},
isbn = {9781450325424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2639189.2639485},
doi = {10.1145/2639189.2639485},
abstract = {A number of technologies have been developed to help users manage their digital legacy, however few user contributions in this space have been solicited from older adults. This is surprising given that older people may have to cope with a digital inheritance but be poorly equipped to do so. The current paper describes three phases of research that explore older adults understanding of and preferences for digital legacy. In phase I, we conducted a large-scale scoping exercise designed to elicit relevant scenarios around digital legacy. In phase II, we presented older adults with a selection of legacy prompts and provocations in order to promote a discussion of digital bequests. In phase III we used life-logging scenarios as prompts in an inter-generational workshop designed to elicit discussion between digital natives and older adults. This work contributes to our understanding of digital legacy from the perspective of older adults and emphasises the importance they place on family, personalisation and control of digital legacy support.},
booktitle = {Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational},
pages = {237–246},
numpages = {10},
keywords = {artefacts, technology probes, focus groups, older adults, family, death, workshops, design, legacy},
location = {Helsinki, Finland},
series = {NordiCHI '14}
}

@inproceedings{10.1145/2639189.2639219,
author = {Fuchsberger, Verena and Murer, Martin and Meneweger, Thomas and Tscheligi, Manfred},
title = {Capturing the In-between of Interactive Artifacts and Users: A Materiality-Centered Approach},
year = {2014},
isbn = {9781450325424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2639189.2639219},
doi = {10.1145/2639189.2639219},
abstract = {The materiality of interactive artifacts concerns, on one hand, design materials and activities, while on the other hand, it is strongly related to the users experiencing the materiality. However, current approaches to investigate the material and the user perspective face several shortcomings, as they focus on either the human or the artifact. In our paper, we describe a materiality-centered data analysis approach that puts the user and the artifact equally in the center of attention. Based on Actor-Network Theory and Bruno Latour's thoughts on monads, we provide examples stemming from interactions in an industrial fabrication plant in order to illustrate the potentials of such a "monadological" approach for accessing materiality from a user and artifact perspective. We show that this approach allows alternating between a human- and an artifact-oriented perspective that finally leads to the identification of material attributes of actors that are less obvious.},
booktitle = {Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational},
pages = {451–460},
numpages = {10},
keywords = {design materials, methodology, actor-network theory, interaction design, monads},
location = {Helsinki, Finland},
series = {NordiCHI '14}
}

@inproceedings{10.1145/2639189.2641215,
author = {Stals, Shenando and Smyth, Michael and Ijsselsteijn, Wijnand},
title = {Walking &amp; Talking: Probing the Urban Lived Experience},
year = {2014},
isbn = {9781450325424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2639189.2641215},
doi = {10.1145/2639189.2641215},
abstract = {With ubiquitous mobile computing devices spreading throughout the urban environment of everyday life, there is a growing need to better understand person-place relationships and how technology can play a role in this urban experience. To this end, we propose a mobile methodology called Walking &amp; Talking, an observed walking tour with participants through the city, which makes it easy and motivating for them to discuss their personal relationships with a place. The paper will describe a case study where the method was successfully applied to elicit rich, contextualized and intimate data, making it a useful research tool for the fields of urban interaction design and mobile &amp; location aware technology.},
booktitle = {Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational},
pages = {737–746},
numpages = {10},
keywords = {design fictions, place meaning, person-place relationship, place attachment, walking interview, mobile methodology, urban interaction design},
location = {Helsinki, Finland},
series = {NordiCHI '14}
}

@inproceedings{10.1145/2639189.2639225,
author = {Ganesh, Sangita and Marshall, Paul and Rogers, Yvonne and O'Hara, Kenton},
title = {FoodWorks: Tackling Fussy Eating by Digitally Augmenting Children's Meals},
year = {2014},
isbn = {9781450325424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2639189.2639225},
doi = {10.1145/2639189.2639225},
abstract = {Persuading children to eat healthily can be challenging. Parents and guardians commonly have trouble encouraging young children to eat their vegetables, who often prefer less wholesome alternatives. Parents regularly employ a range of methods that encourage or distract children to eat food they don't want to eat. Digital technologies, such as augmented reality and interactive animations offer new possibilities for enhancing this process. Our research is concerned with how such technology interventions can be used to change behavior in fussy children's eating habits by altering the context of 'playing' with food. FoodWorks was designed to digitally augment a plate of food and provide rewards for completion of the meal. An exploratory in the wild study was conducted using it with 7 families, for children aged between 3-9. The findings were encouraging, providing new insights on social interactions and the effects digital augmentation can have on eating behavior.},
booktitle = {Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational},
pages = {147–156},
numpages = {10},
keywords = {digitally-enhanced food, digital augmentation, virtual rewards, children, persuasive technologies},
location = {Helsinki, Finland},
series = {NordiCHI '14}
}

@inproceedings{10.1145/2639189.2639195,
author = {Paay, Jeni and Kjeldskov, Jesper and Brinthaparan, Umachanger and Lichon, Lars and Rasmussen, Stephan and Srikandaraja, Nirojan and Smith, Wally and Wadley, Greg and Ploderer, Bernd},
title = {<i>Quitty</i>: Using Technology to Persuade Smokers to Quit},
year = {2014},
isbn = {9781450325424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2639189.2639195},
doi = {10.1145/2639189.2639195},
abstract = {Health is an important topic in HCI research with an increasing amount of health risks surrounding individuals and society at large. It is well known that smoking cigarettes can have serious health implications. The importance of this problem motivates investigation into the use of technology to encourage behavior change. Our study was designed to gather empirical knowledge about the role a "quitting app" can play in persuading people to quit smoking. Our purpose-built app Quitty introduces different content types from different content sources to study how they are perceived and motivate health behavior change. Findings from our field study show that tailored content and push-messages are considered the most important for persuading people to stop smoking. Based on our empirical findings, we propose six guidelines on how to design mobile applications to persuade smokers to quit.},
booktitle = {Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational},
pages = {551–560},
numpages = {10},
keywords = {smoking cessation, health behavior change, online participation, persuasive technology},
location = {Helsinki, Finland},
series = {NordiCHI '14}
}

@inproceedings{10.1145/2639189.2639259,
author = {Maye, Laura A. and McDermott, Fiona E. and Ciolfi, Luigina and Avram, Gabriela},
title = {Interactive Exhibitions Design: What Can We Learn from Cultural Heritage Professionals?},
year = {2014},
isbn = {9781450325424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2639189.2639259},
doi = {10.1145/2639189.2639259},
abstract = {Within cultural heritage, curators, exhibition designers and other professionals are increasingly involved in the design of exhibits that make use of interactive digital technologies to engage visitors in novel ways. While a body of work on the design and evaluation of interactive exhibitions exists in HCI and Interaction Design, little research has been conducted thus far on understanding how cultural heritage professionals engage in the design of interactive exhibitions in terms of their attitudes, process, expectations and understandings of technology. In this paper, we present the results from an interview study involving cultural heritage professionals and aimed at understanding their involvement in designing interactive exhibitions. Our findings could provide the HCI community with a better understanding of the strategies and aspirations of domain professionals regarding interactive exhibitions, and to identify new ways to engage with them - particularly as these professionals' knowledge and understanding of interactive digital technologies becomes more advanced.},
booktitle = {Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational},
pages = {598–607},
numpages = {10},
keywords = {expert community, interactive exhibitions, cultural heritage, design strategy, interview study},
location = {Helsinki, Finland},
series = {NordiCHI '14}
}

@inproceedings{10.1145/2677855.2677889,
author = {Padmalatha, E. and Reddy, C. R. K. and Padmajarani},
title = {Efficient Learning Approaches for Agents in Data Mining},
year = {2014},
isbn = {9781450332163},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2677855.2677889},
doi = {10.1145/2677855.2677889},
abstract = {In this paper we present a technique for intrusion detection in distributed network. Here, we use the CVFDT for the identification of sort of intrusion and we use the CMAC neural network for identifying normal and abnormal data. Initially we train the dataset by calculating the radius of history concept which is necessary to identify the concept drift. In distribute network, there would be number of nodes which are represented as systems and the nodes are grouped separately by means of K-means algorithm. We choose the centroid of each group as agent and the agent would check the concept drift on corresponding nodes in the group. If a node has concept drift, the agent would transfer it to CVFDT to identify the sort of intrusion and if the node has no concept drift, the agent would transfer to CMAC to identify whether the data is normal or abnormal.},
booktitle = {Proceedings of the 2014 International Conference on Information and Communication Technology for Competitive Strategies},
articleno = {34},
numpages = {9},
keywords = {Intrusion Detection System, CMAC Neural Network, CVFDT, Distributed Network},
location = {Udaipur, Rajasthan, India},
series = {ICTCS '14}
}

@inproceedings{10.1145/2691195.2691208,
author = {Halder, Buddhadeb},
title = {Crowdsourcing Collection of Data for Crisis Governance in the Post-2015 World: Potential Offers and Crucial Challenges},
year = {2014},
isbn = {9781605586113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2691195.2691208},
doi = {10.1145/2691195.2691208},
abstract = {The practice of 'crowdsourcing' under the new technological regime has opened doors of huge data repositories. In recent years, crowdsourcing have expanded rapidly allowing citizens to connect with each other, governments to connect with common mass, to coordinate disaster response work, to map political conflicts, acquiring information quickly and participating in issues that affect day-to-day life of citizens. Crowdsourcing has the potentiality to offer smart governance by gathering and analyzing massive data from citizens. As data is a key enabler to proper public governance, this paper aims to provide a picture of potential offers that 'crowdsourcing' could make in support of crisis governance in the Post-2015 World, while it illustrates some critical challenges of data protection and privacy in different service sectors. Lastly, with a brief analysis on privacy, online data protection; and safety level of some crowdsourcing tools, this paper proposes brief guidelines for different stakeholders and some future works to avoid some mismanagement of crowdsourced data to protect data, privacy and security of end users.},
booktitle = {Proceedings of the 8th International Conference on Theory and Practice of Electronic Governance},
pages = {1–10},
numpages = {10},
keywords = {privacy, public governance, crisis governance, data, policy, PET, big data, online data protection},
location = {Guimaraes, Portugal},
series = {ICEGOV '14}
}

@inproceedings{10.1145/2677855.2677865,
author = {Balamurugan, B. and Kumar, N. Saravana and Lakshmi, G. V. Rajya and Shanmuga, Raj N. Siva},
title = {Common Cloud Architecture for Cloud Interoperability},
year = {2014},
isbn = {9781450332163},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2677855.2677865},
doi = {10.1145/2677855.2677865},
abstract = {Cloud computing is assert for communication connected through internet, along with the essentials for data storage and manipulation of it through various ways using customized cloud service providers. The Inter-Cloud heterogeneous communication provides a platform for data transmission between various deployment models of the cloud. In this paper, we have proposed an efficient framework for Interoperability of the cloud which is current core research area of cloud. In additionally, Security has been focused with the enhanced Security as a service architecture addressing the Interoperability between two cloud service provider privileges for the transmission of the data or resources. The proposed work consists of various layers such as authentication, data storage, privacy, confidentiality, auditing, monitoring and maintenance of the communication. Ontology based algorithm is used for the identification of the cloud. The implementation is carried out using the eucalyptus cloud},
booktitle = {Proceedings of the 2014 International Conference on Information and Communication Technology for Competitive Strategies},
articleno = {10},
numpages = {6},
keywords = {Framework, Inter-Cloud communication, Cloud Computing, Information retrieval},
location = {Udaipur, Rajasthan, India},
series = {ICTCS '14}
}

@inproceedings{10.1145/2691195.2691255,
author = {Adeshina, Steve A. and Ojo, Adegboyega},
title = {Towards Improved Adoption of E-Voting: Analysis of the Case of Nigeria},
year = {2014},
isbn = {9781605586113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2691195.2691255},
doi = {10.1145/2691195.2691255},
abstract = {The adoption of e-voting in different parts of the world has been generally problematic, with only few exceptions. Past studies also suggest that e-voting is embedded in the socio-politically context informing variations in the adoption patterns and nature of challenges faced during implementation. While few survey-based empirical studies have been carried out to better understand factors affecting successful adoption of e-voting, there is general paucity of ethnographic studies and analysis providing detailed insights to e-voting adoption in specific contexts. This study offers such ethnography through in-depth analysis of e-voting adoption in the 2011 Nigerian General Elections. Using a multi-level Innovation Adoption Framework as a theoretical lens, we analyze the observations made by one of the authors as a participant in the adoption and implementation of the e-voting initiative as well as the post-election reports. Results from analysis revealed core factors for the different levels of e-voting adoption constructs - socio-political context, organizations, innovation and individual. Results also identified factors and challenges that may negatively impact e-voting adoption.},
booktitle = {Proceedings of the 8th International Conference on Theory and Practice of Electronic Governance},
pages = {403–412},
numpages = {10},
keywords = {innovation adoption, voters registration, e-voting adoption, ethnography and e-voting, 2011 Nigerian general elections},
location = {Guimaraes, Portugal},
series = {ICEGOV '14}
}

@inproceedings{10.1145/2691195.2691267,
author = {Aina, Folahanmi and Faniran, Depo and Olaniyan, Kayode},
title = {The Imperative of Smart Technology for Timely Release of Official Data for National Development: A Focus on Nigeria's National Bureau of Statistics},
year = {2014},
isbn = {9781605586113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2691195.2691267},
doi = {10.1145/2691195.2691267},
abstract = {This paper describes the imperative of information and communication technology for achieving timely release of official data for national development. Development planning remains a vital component of national development while timely release of official statistics to inform policy is key to effective and efficient planning. In this paper we therefore explore the imperatives of timely releases of official statistics through computer to computer communication (C2C) for national development by the apex national statistical institution in Nigeria. The National Bureau of Statistics (NBS) is a statutory agency that anchors and warehouses all official statistics as well as the coordinator of Nigeria's National Statistical System. The paper reviews some of the periodic releases by the NBS and the dissemination mechanism using electronic and smart tools as a channel of using electronic transfer or electronic governance to make data communication convenient for both the data producer and user for national development. The paper also highlights the challenges of timely releases of data experienced by the NBS and the strategies put in place by the NBS to address these challenges. Finally, the paper also suggests policy recommendations for effective smart approach to data production and dissemination in Nigeria.},
booktitle = {Proceedings of the 8th International Conference on Theory and Practice of Electronic Governance},
pages = {20–23},
numpages = {4},
keywords = {national development, smart approach, national planning, data dissemination, national bureau of statistics, official data, data production},
location = {Guimaraes, Portugal},
series = {ICEGOV '14}
}

@inproceedings{10.1145/2691195.2691256,
author = {Hamza, Karim},
title = {State Stability: A Governance Analysis Framework for Arab Spring Countries},
year = {2014},
isbn = {9781605586113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2691195.2691256},
doi = {10.1145/2691195.2691256},
abstract = {The 2011-2012 Arab Spring uprising can be considered a new political phenomenon with respect to collective action and the origin of network governance in North Africa and the Middle East. Nevertheless, current formal and empirical models are incapable of analyzing and predicting the future of the uprisings. Therefore, the conceptualization of these models must be reviewed given the increasing need for a political analytical model that can assess the state of the state and consider the influence of non-state actors on service provision and security mechanisms inside their society. The circumstances require a simple conceptual model to describe state status (stable or unstable) in a simple representational form for countries such as Egypt following the Arab Spring.This study propose a framework to explain the influence of network governance on state stability, it was preferable that this model be general and conceptual. Thus, this framework can offer a more realistic explanation of the political transformations that occurred in the Arab Spring countries, such as Egypt. The analysis showed that formal mathematical models could not persuasively explain the Arab Spring phenomenon because such models are based on theories and ideas that are inapplicable to the changes in the political environment that occurred in these countries. The proposed framework, attempts to describe state status, whereby a state is stable or unstable and it is not necessary for the state to be a failed state. This framework aims to help political analysts develop recommendations for policy- and decision-makers on how to avoid state instability.},
booktitle = {Proceedings of the 8th International Conference on Theory and Practice of Electronic Governance},
pages = {75–84},
numpages = {10},
keywords = {turbulences, Egypt, policy modelling, Arab spring, framework, state stability, governance, fragile state, policy network},
location = {Guimaraes, Portugal},
series = {ICEGOV '14}
}

@article{10.14778/2735508.2735511,
author = {Yu, Xiangyao and Bezerra, George and Pavlo, Andrew and Devadas, Srinivas and Stonebraker, Michael},
title = {Staring into the Abyss: An Evaluation of Concurrency Control with One Thousand Cores},
year = {2014},
issue_date = {November 2014},
publisher = {VLDB Endowment},
volume = {8},
number = {3},
issn = {2150-8097},
url = {https://doi.org/10.14778/2735508.2735511},
doi = {10.14778/2735508.2735511},
abstract = {Computer architectures are moving towards an era dominated by many-core machines with dozens or even hundreds of cores on a single chip. This unprecedented level of on-chip parallelism introduces a new dimension to scalability that current database management systems (DBMSs) were not designed for. In particular, as the number of cores increases, the problem of concurrency control becomes extremely challenging. With hundreds of threads running in parallel, the complexity of coordinating competing accesses to data will likely diminish the gains from increased core counts.To better understand just how unprepared current DBMSs are for future CPU architectures, we performed an evaluation of concurrency control for on-line transaction processing (OLTP) workloads on many-core chips. We implemented seven concurrency control algorithms on a main-memory DBMS and using computer simulations scaled our system to 1024 cores. Our analysis shows that all algorithms fail to scale to this magnitude but for different reasons. In each case, we identify fundamental bottlenecks that are independent of the particular database implementation and argue that even state-of-the-art DBMSs suffer from these limitations. We conclude that rather than pursuing incremental solutions, many-core chips may require a completely redesigned DBMS architecture that is built from ground up and is tightly coupled with the hardware.},
journal = {Proc. VLDB Endow.},
month = nov,
pages = {209–220},
numpages = {12}
}

@inproceedings{10.5555/2691365.2691451,
author = {Shen, Chenguang and Choi, Haksoo and Chakraborty, Supriyo and Srivastava, Mani},
title = {Towards a Rich Sensing Stack for IoT Devices},
year = {2014},
isbn = {9781479962778},
publisher = {IEEE Press},
abstract = {The broad spectrum of interconnected sensors and actuators, available on various mobile devices and smartphones and collectively defined as the Internet of Things (IoT), have evolved into platforms with ability to both collect personal sensory data and also change the users' immediate environment. The continuous streams of richly annotated sensory data on these IoT devices have also enabled the emergence of a new class of context-aware apps that use the data to infer user context and accordingly customize their responses in real-time. However, this growth in the number of apps has not been complemented with adequate system support on the IoT devices resulting in monolithic apps that each implement and execute their own customized sensing pipelines. In this paper, we outline our vision of a sensing stack, akin to a networking stack, that can facilitate the development and execution of context-aware apps on IoT devices. There are several advantages to building a rich sensing stack. First, it allows apps to reuse stages of the sensing pipeline easing their development. Second, the layers of the stack allow for both in- and cross-layer resource optimization. Finally, it allows better control over the shared data as instead of raw-sensor data, higher-level semantic abstractions, such as inferences can now be shared with apps. We describe our initial efforts towards creating the different building blocks of such a sensing stack.},
booktitle = {Proceedings of the 2014 IEEE/ACM International Conference on Computer-Aided Design},
pages = {424–427},
numpages = {4},
keywords = {sensing, the internet of things, context inference},
location = {San Jose, California},
series = {ICCAD '14}
}

@inproceedings{10.1145/2665943.2665963,
author = {Shirazi, Fatemeh and Volkamer, Melanie},
title = {What Deters Jane from Preventing Identification and Tracking on the Web?},
year = {2014},
isbn = {9781450331487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2665943.2665963},
doi = {10.1145/2665943.2665963},
abstract = {Recent revelations about surveillance by several institutions and de-identification can be expected to have increased public awareness of identification- and tracking-related privacy threats. It is reasonable to expect that the general public has started using corresponding privacy protection mechanisms. Our goal with this research was to determine whether they actually do this. If not, we wanted to explore possible explanations for not uptaken such privacy-protecting countermeasures. We interviewed 20 (mainly lay) people and found that our interviewees did not proactively try to prevent being identified and tracked. We identified seven different types of explanations. Including a number of misconceptions which might explain this puzzling level of apathy. The participants demonstrated confusion between different kinds of sensitive data; and displayed a confusion between the semantics of `privacy' and `security'. The findings also indicate that security being compromised, resulting in losing money for example, is more concrete and more easily brought to mind than privacy-related problems. In terms of the consequences of surveillance, the most commonly cited outcome is the receipt of personalized advertisements, which many consider beneficial. Potentially negative impacts of identification and tracking is often assumed to not occur to them. Our interviews also pointed out a gap between passive and active knowledge about identification and tracking techniques, their impact on privacy and countermeasures against them.},
booktitle = {Proceedings of the 13th Workshop on Privacy in the Electronic Society},
pages = {107–116},
numpages = {10},
keywords = {mental models, concerns, identification, tracking, user behaviour analysis, privacy},
location = {Scottsdale, Arizona, USA},
series = {WPES '14}
}

@inproceedings{10.5555/2735522.2735528,
author = {Tourani, Parastou and Jiang, Yujuan and Adams, Bram},
title = {Monitoring Sentiment in Open Source Mailing Lists: Exploratory Study on the Apache Ecosystem},
year = {2014},
publisher = {IBM Corp.},
address = {USA},
abstract = {Large software projects, both open and closed source, are constructed and maintained collaboratively by teams of developers and testers, who are typically geographically dispersed. This dispersion creates a distance between team members, hiding feelings of distress or (un)happiness from their manager, which prevents him or her from using remediation techniques for those feelings. This paper evaluates the usage of automatic sentiment analysis to identify distress or happiness in a development team. Since mailing lists are one of the most popular media for discussion in distributed software projects, we extracted sentiment values of the user and developer mailing lists of two of the most successful and mature projects of the Apache software foundation. The results show that (1) user and developer mailing lists carry both positive and negative sentiment and have a slightly different focus, while (2) work is needed to customize automatic sentiment analysis techniques to the domain of software engineering, since they lack precision when facing technical terms},
booktitle = {Proceedings of 24th Annual International Conference on Computer Science and Software Engineering},
pages = {34–44},
numpages = {11},
keywords = {sentiment analysis, mining software repositories, mailing list data, empirical software engineering},
location = {Markham, Ontario, Canada},
series = {CASCON '14}
}

@inproceedings{10.1145/2661829.2661951,
author = {McCreadie, Richard and Macdonald, Craig and Ounis, Iadh},
title = {Incremental Update Summarization: Adaptive Sentence Selection Based on Prevalence and Novelty},
year = {2014},
isbn = {9781450325981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661829.2661951},
doi = {10.1145/2661829.2661951},
abstract = {The automatic summarization of long-running events from news steams is a challenging problem. A long-running event can contain hundreds of unique 'nuggets' of information to summarize, spread-out over its lifetime. Meanwhile, information reported about it can rapidly become outdated and is often highly redundant. Incremental update summarization (IUS) aims to select sentences from news streams to issue as updates to the user, summarising that event over time. The updates issued should cover all of the key nuggets concisely and before the information contained in those nuggets becomes outdated. Prior summarization approaches when applied to IUS can fail, since they define a fixed summary length that cannot effectively account for the different magnitudes and varying rate of development of such events. In this paper, we propose a novel IUS approach that adaptively alters the volume of content issued as updates over time with respect to the prevalence and novelty of discussions about the event. It incorporates existing state-of-the-art summarization techniques to rank candidate sentences, followed by a supervised regression model that balances novelty, nugget coverage and timeliness when selecting sentences from the top ranks. We empirically evaluate our approach using the TREC 2013 Temporal Summarization dataset extended with additional assessments. Our results show that by adaptively adjusting the number of sentences to select over time, our approach can nearly double the performance of effective summarization baselines.},
booktitle = {Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},
pages = {301–310},
numpages = {10},
keywords = {temporal summarization, machine learning, adaptive models},
location = {Shanghai, China},
series = {CIKM '14}
}

@inproceedings{10.1145/2668332.2668346,
author = {Cheng, Yun and Li, Xiucheng and Li, Zhijun and Jiang, Shouxu and Li, Yilong and Jia, Ji and Jiang, Xiaofan},
title = {AirCloud: A Cloud-Based Air-Quality Monitoring System for Everyone},
year = {2014},
isbn = {9781450331432},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2668332.2668346},
doi = {10.1145/2668332.2668346},
abstract = {We present the design, implementation, and evaluation of AirCloud -- a novel client-cloud system for pervasive and personal air-quality monitoring at low cost. At the frontend, we create two types of Internet-connected particulate matter (PM2:5) monitors -- AQM and miniAQM, with carefully designed mechanical structures for optimal air-flow. On the cloud-side, we create an air-quality analytics engine that learn and create models of air-quality based on a fusion of sensor data. This engine is used to calibrate AQMs and mini-AQMs in real-time, and infer PM2:5 concentrations. We evaluate AirCloud using 5 months of data and 2 month of continuous deployment, and show that AirCloud is able to achieve good accuracies at much lower cost than previous solutions. We also show three real applications built on top of AirCloud by 3rd party developers to further demonstrate the value of our system.},
booktitle = {Proceedings of the 12th ACM Conference on Embedded Network Sensor Systems},
pages = {251–265},
numpages = {15},
keywords = {air quality, client-cloud calibration system, PM2.5},
location = {Memphis, Tennessee},
series = {SenSys '14}
}

@inproceedings{10.1145/2661829.2661859,
author = {Lee, Pei and Lakshmanan, Laks V.S. and Milios, Evangelos},
title = {CAST: A Context-Aware Story-Teller for Streaming Social Content},
year = {2014},
isbn = {9781450325981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661829.2661859},
doi = {10.1145/2661829.2661859},
abstract = {Online social streams such as Twitter timelines, forum discussions and email threads have emerged as important channels for information propagation. Mining transient stories and their correlations implicit in social streams is a challenging task, since these streams are noisy and surge quickly. In this paper, we propose CAST, which is a context-aware story-teller that discovers new stories from social streams and tracks their structural context on the fly to build a vein of stories. More precisely, we model the social stream as a capillary network, and define stories by a new cohesive subgraph type called (k,d)-Core in the capillary network. We propose deterministic and randomized context search to support the iceberg query, which builds the story vein as social streams flow. We perform detailed experimental study on real Twitter streams and the results demonstrate the creativity and value of our approach.},
booktitle = {Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},
pages = {789–798},
numpages = {10},
keywords = {social content, context-aware, storyvein, story-teller},
location = {Shanghai, China},
series = {CIKM '14}
}

@inproceedings{10.1145/2676431.2676435,
author = {Wang, Wei and Chen, Zhilu and Xing, Baoyuan and Huang, Xiaochen and Han, S. and Agu, Emmanuel},
title = {A Smartphone-Based Digital Hearing Aid to Mitigate Hearing Loss at Specific Frequencies},
year = {2014},
isbn = {9781450331906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2676431.2676435},
doi = {10.1145/2676431.2676435},
abstract = {Hearing Loss is one of the three most common chronic conditions among the elderly. In many cases, an individuals hearing is only impaired at certain (not all) frequencies. Analog hearing aids boost all sound frequencies equally including frequencies in which the individuals hearing is good, causing discomfort to the user. Digital hearing aids can amplify only the specific frequencies at which a persons hearing is impaired. In this paper, we describe the design, implementation and evaluation of a smartphone digital hearing aid app. Our digital hearing aid implementation has two parts: speech processing in the frequency domain and sound classification. We used Weighted Over-Lap Add (WOLA) filter bank to decompose microphone sounds into different frequency bands that are then amplified in the frequency domain. Mel-frequency cepstral coefficients (MFCC) of input sounds are computed and used as features for sound classification by the Gaussian Mixture Model (GMM) machine learning model. Our digital hearing aid app amplifies select frequency bands and correctly classifies speech in quiet and noisy environments. The results of a small user evaluation of our prototype are also promising.},
booktitle = {Proceedings of the 1st Workshop on Mobile Medical Applications},
pages = {1–5},
numpages = {5},
keywords = {digital hearing aids, smartphone, sound classification},
location = {Memphis, Tennessee},
series = {MMA '14}
}

@inproceedings{10.1145/2663792.2663794,
author = {Panem, Sandeep and Gupta, Manish and Varma, Vasudeva},
title = {Structured Information Extraction from Natural Disaster Events on Twitter},
year = {2014},
isbn = {9781450316064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663792.2663794},
doi = {10.1145/2663792.2663794},
abstract = {As soon as natural disaster events happen, users are eager to know more about them. However, search engines currently provide a ten blue links interface for queries related to such events. Relevance of results for such queries can be significantly improved if users are shown a structured summary of the fresh events related to such queries. This would not just reduce the number of user clicks to get the relevant information but would also help users get updated with more fine grained attribute-level information. Twitter is a great source that can be exploited for obtaining such fine-grained structured information for fresh natural disaster events. Such events are often reported on Twitter much earlier than on other news media. However, extracting such structured information from tweets is challenging because: 1. tweets are noisy and ambiguous; 2. there is no well defined schema for various types of natural disaster events; 3. it is not trivial to extract attribute-value pairs and facts from unstructured text; and 4. it is difficult to find good mappings between extracted attributes and attributes in the event schema.We propose algorithms to extract attribute-value pairs, and also devise novel mechanisms to map such pairs to manually generated schemas for natural disaster events. Besides the tweet text, we also leverage text from URL links in the tweets to fill such schemas. Our schemas are temporal in nature and the values are updated whenever fresh information flows in from human sensors on Twitter. Evaluation on ~58000 tweets for 20 events shows that our system can fill such event schemas with an F1 of ~0.6.},
booktitle = {Proceedings of the 5th International Workshop on Web-Scale Knowledge Representation Retrieval &amp; Reasoning},
pages = {1–8},
numpages = {8},
keywords = {natural calamities, fact triplet extraction, natural disaster events, structured event mining, event infoboxes, twitter, attribute-value extraction},
location = {Shanghai, China},
series = {Web-KR '14}
}

@inproceedings{10.1145/2661829.2661946,
author = {Rokicki, Markus and Chelaru, Sergiu and Zerr, Sergej and Siersdorfer, Stefan},
title = {Competitive Game Designs for Improving the Cost Effectiveness of Crowdsourcing},
year = {2014},
isbn = {9781450325981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661829.2661946},
doi = {10.1145/2661829.2661946},
abstract = {Crowd based online work is leveraged in a variety of applications such as semantic annotation of images, translation of texts in foreign languages, and labeling of training data for machine learning models. However, annotating large amounts of data through crowdsourcing can be slow and costly. In order to improve both cost and time efficiency of crowdsourcing we examine alternative reward mechanisms compared to the "Pay-per-HIT" scheme commonly used in platforms such as Amazon Mechanical Turk. To this end, we explore a wide range of monetary reward schemes that are inspired by the success of competitions, lotteries, and games of luck. Our large-scale experimental evaluation with an overall budget of more than 1,000 USD and with 2,700 hours of work spent by crowd workers demonstrates that our alternative reward mechanisms are well accepted by online workers and lead to substantial performance boosts.},
booktitle = {Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},
pages = {1469–1478},
numpages = {10},
keywords = {crowdsourcing, lotteries, reward schemes, competitions},
location = {Shanghai, China},
series = {CIKM '14}
}

@inproceedings{10.1145/2647868.2654934,
author = {Kim, Yelin and Mower Provost, Emily},
title = {Say Cheese vs. Smile: Reducing Speech-Related Variability for Facial Emotion Recognition},
year = {2014},
isbn = {9781450330633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647868.2654934},
doi = {10.1145/2647868.2654934},
abstract = {Facial movement is modulated both by emotion and speech articulation. Facial emotion recognition systems aim to discriminate between emotions, while reducing the speech-related variability in facial cues. This aim is often achieved using two key features: (1) phoneme segmentation: facial cues are temporally divided into units with a single phoneme and (2) phoneme-specific classification: systems learn patterns associated with groups of visually similar phonemes (visemes), e.g. P, B, and M. In this work, we empirically compare the effects of different temporal segmentation and classification schemes for facial emotion recognition. We propose an unsupervised segmentation method that does not necessitate costly phonetic transcripts. We show that the proposed method bridges the accuracy gap between a traditional sliding window method and phoneme segmentation, achieving a statistically significant performance gain. We also demonstrate that the segments derived from the proposed unsupervised and phoneme segmentation strategies are similar to each other. This paper provides new insight into unsupervised facial motion segmentation and the impact of speech variability on emotion classification.},
booktitle = {Proceedings of the 22nd ACM International Conference on Multimedia},
pages = {27–36},
numpages = {10},
keywords = {speech, dynamics, emotion recognition, facial expression, viseme, dynamic time warping, phoneme, segmentation},
location = {Orlando, Florida, USA},
series = {MM '14}
}

@inproceedings{10.5555/2735522.2735583,
author = {Simmons, Bradley and Shtern, Mark and Litoiu, Marin and Smit, Michael},
title = {Toward a Solution for the Cloud Account Delegation Problem},
year = {2014},
publisher = {IBM Corp.},
address = {USA},
abstract = {Cloud account delegation refers to the situation in which a cloud account owner (delegator) allows one or more second parties (i.e., delegates) to acquire and use cloud infrastructure resources from the owner's account at the expense of the owner. This situation can exist in research groups, cloud testbeds, university courses, software development teams, and in general in cases where pooled resources are managed as software-defined infrastructure. The delegator assumes the risk of inefficient, wasted, or abused resources, and must rely on delegates, who are often not experienced cloud users, using the virtual infrastructure effectively and responsibly. This paper introduces the cloud account delegation problem, including three primary categories of risk, introduces a solution outline, and identifies research challenges.},
booktitle = {Proceedings of 24th Annual International Conference on Computer Science and Software Engineering},
pages = {359–362},
numpages = {4},
location = {Markham, Ontario, Canada},
series = {CASCON '14}
}

@inproceedings{10.1145/2668332.2668349,
author = {Georgiev, Petko and Lane, Nicholas D. and Rachuri, Kiran K. and Mascolo, Cecilia},
title = {DSP.Ear: Leveraging Co-Processor Support for Continuous Audio Sensing on Smartphones},
year = {2014},
isbn = {9781450331432},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2668332.2668349},
doi = {10.1145/2668332.2668349},
abstract = {The rapidly growing adoption of sensor-enabled smartphones has greatly fueled the proliferation of applications that use phone sensors to monitor user behavior. A central sensor among these is the microphone which enables, for instance, the detection of valence in speech, or the identification of speakers. Deploying multiple of these applications on a mobile device to continuously monitor the audio environment allows for the acquisition of a diverse range of sound-related contextual inferences. However, the cumulative processing burden critically impacts the phone battery.To address this problem, we propose DSP.Ear -- an integrated sensing system that takes advantage of the latest low-power DSP co-processor technology in commodity mobile devices to enable the continuous and simultaneous operation of multiple established algorithms that perform complex audio inferences. The system extracts emotions from voice, estimates the number of people in a room, identifies the speakers, and detects commonly found ambient sounds, while critically incurring little overhead to the device battery. This is achieved through a series of pipeline optimizations that allow the computation to remain largely on the DSP. Through detailed evaluation of our prototype implementation we show that, by exploiting a smartphone's co-processor, DSP.Ear achieves a 3 to 7 times increase in the battery lifetime compared to a solution that uses only the phone's main processor. In addition, DSP.Ear is 2 to 3 times more power efficient than a na\"{\i}ve DSP solution without optimizations. We further analyze a large-scale dataset from 1320 Android users to show that in about 80-90% of the daily usage instances DSP.Ear is able to sustain a full day of operation (even in the presence of other smartphone workloads) with a single battery charge.},
booktitle = {Proceedings of the 12th ACM Conference on Embedded Network Sensor Systems},
pages = {295–309},
numpages = {15},
keywords = {audio, energy, co-processor, DSP, mobile sensing},
location = {Memphis, Tennessee},
series = {SenSys '14}
}

@inproceedings{10.1145/2661829.2662081,
author = {Yin, Jiangtao and Gao, Lixin},
title = {Scalable Distributed Belief Propagation with Prioritized Block Updates},
year = {2014},
isbn = {9781450325981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661829.2662081},
doi = {10.1145/2661829.2662081},
abstract = {Belief propagation (BP) is a popular method for performing approximate inference on probabilistic graphical models. However, its message updates are time-consuming, and the schedule for updating messages is crucial to its running time and even convergence. In this paper, we propose a new scheduling scheme that selects a set of messages to update at a time and leverages a novel priority to determine which messages are selected. Additionally, an incremental update approach is introduced to accelerate the computation of the priority. As the size of the model grows, it is desirable to leverage the parallelism of a cluster of machines to reduce the inference time. Therefore, we design a distributed framework, Prom, to facilitate the implementation of BP algorithms. We evaluate the proposed scheduling scheme (supported by Prom) via extensive experiments on a local cluster as well as the Amazon EC2 cloud. The evaluation results show that our scheduling scheme outperforms the state-of-the-art counterpart.},
booktitle = {Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},
pages = {1209–1218},
numpages = {10},
keywords = {belief propagation, prioritized block updates, incremental updates, distributed framework},
location = {Shanghai, China},
series = {CIKM '14}
}

@inproceedings{10.1145/2661829.2662090,
author = {Li, Jiwei and Wang, Xun and Hovy, Eduard},
title = {What a Nasty Day: Exploring Mood-Weather Relationship from Twitter},
year = {2014},
isbn = {9781450325981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661829.2662090},
doi = {10.1145/2661829.2662090},
abstract = {While it has long been believed in psychology that weather somehow influences human's mood, the debates have been going on for decades about how they are correlated. In this paper, we try to study this long-lasting topic by harnessing a new source of data compared from traditional psychological researches: Twitter. We analyze 2 years' twitter data collected by twitter API which amounts to 10% of all postings and try to reveal the correlations between multiple dimensional structure of human mood with meteorological effects. Some of our findings confirm existing hypotheses, while others contradict them. We are hopeful that our approach, along with the new data source, can shed on the long-going debates on weather-mood correlation.},
booktitle = {Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},
pages = {1309–1318},
numpages = {10},
keywords = {mood, weather, twitter},
location = {Shanghai, China},
series = {CIKM '14}
}

@inproceedings{10.5555/2735522.2735539,
author = {Krizhanovsky, Alexander},
title = {Tempesta: A Framework for HTTP DDoS Attacks Mitigation},
year = {2014},
publisher = {IBM Corp.},
address = {USA},
abstract = {Modern application layer HTTP DDoS attacks employ complex techniques that make them difficult to detect. So modern DDoS defense approaches are also based on sophisticated methods to classify HTTP requests. Usually, these methods require exhaustive data on user activity from different layers of protocol stack, mainly from network, transport and application layers.Moreover, a typical DDoS attack puts a huge load onto a target Web cluster. That demands a DDoS mitigation solution that delivers higher performance and is able to significantly reduce the load on defended back-end systems.In this article we present Tempesta, a hybrid solution that combines a caching HTTP server and a firewall in one. It accelerates Web applications much efficiently than traditional Web accelerators and provides a high performance framework that offers easy access to data from all protocol layers. That facilitates the development and use of sophisticated DDoS classification and blocking algorithms.},
booktitle = {Proceedings of 24th Annual International Conference on Computer Science and Software Engineering},
pages = {148–162},
numpages = {15},
location = {Markham, Ontario, Canada},
series = {CASCON '14}
}

@inproceedings{10.1145/2647868.2654916,
author = {Sangineto, Enver and Zen, Gloria and Ricci, Elisa and Sebe, Nicu},
title = {We Are Not All Equal: Personalizing Models for Facial Expression Analysis with Transductive Parameter Transfer},
year = {2014},
isbn = {9781450330633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647868.2654916},
doi = {10.1145/2647868.2654916},
abstract = {Previous works on facial expression analysis have shown that person specific models are advantageous with respect to generic ones for recognizing facial expressions of new users added to the gallery set. This finding is not surprising, due to the often significant inter-individual variability: different persons have different morphological aspects and express their emotions in different ways. However, acquiring person-specific labeled data for learning models is a very time consuming process. In this work we propose a new transfer learning method to compute personalized models without labeled target data Our approach is based on learning multiple person-specific classifiers for a set of source subjects and then directly transfer knowledge about the parameters of these classifiers to the target individual. The transfer process is obtained by learning a regression function which maps the data distribution associated to each source subject to the corresponding classifier's parameters. We tested our approach on two different application domains, Action Units (AUs) detection and spontaneous pain recognition, using publicly available datasets and showing its advantages with respect to the state-of-the-art both in term of accuracy and computational cost.},
booktitle = {Proceedings of the 22nd ACM International Conference on Multimedia},
pages = {357–366},
numpages = {10},
keywords = {action unit detection, transductive transfer learning, learning from distributions, facial expression recognition},
location = {Orlando, Florida, USA},
series = {MM '14}
}

@inproceedings{10.1145/2647868.2654935,
author = {Chen, Tao and Yu, Felix X. and Chen, Jiawei and Cui, Yin and Chen, Yan-Ying and Chang, Shih-Fu},
title = {Object-Based Visual Sentiment Concept Analysis and Application},
year = {2014},
isbn = {9781450330633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647868.2654935},
doi = {10.1145/2647868.2654935},
abstract = {This paper studies the problem of modeling object-based visual concepts such as "crazy car" and "shy dog" with a goal to extract emotion related information from social multimedia content. We focus on detecting such adjective-noun pairs because of their strong co-occurrence relation with image tags about emotions. This problem is very challenging due to the highly subjective nature of the adjectives like "crazy" and "shy" and the ambiguity associated with the annotations. However, associating adjectives with concrete physical nouns makes the combined visual concepts more detectable and tractable. We propose a hierarchical system to handle the concept classification in an object specific manner and decompose the hard problem into object localization and sentiment related concept modeling. In order to resolve the ambiguity of concepts we propose a novel classification approach by modeling the concept similarity, leveraging on online commonsense knowledgebase. The proposed framework also allows us to interpret the classifiers by discovering discriminative features. The comparisons between our method and several baselines show great improvement in classification performance. We further demonstrate the power of the proposed system with a few novel applications such as sentiment-aware music slide shows of personal albums.},
booktitle = {Proceedings of the 22nd ACM International Conference on Multimedia},
pages = {367–376},
numpages = {10},
keywords = {affective computing, social multimedia, visual sentiment},
location = {Orlando, Florida, USA},
series = {MM '14}
}

@inproceedings{10.1145/2676629.2676637,
author = {Lan, Rongjian and Adelfio, Marco D. and Samet, Hanan},
title = {Spatio-Temporal Disease Tracking Using News Articles},
year = {2014},
isbn = {9781450331364},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2676629.2676637},
doi = {10.1145/2676629.2676637},
abstract = {Geographical Information Systems have been increasingly used to aid the prompt detection, tracking, and analysis of disease outbreaks. Web content which is full of health-related data also serves as a useful resource for disease outbreak analysis. News posts often report the initial outbreak of diseases and contain valuable information that aids in ascertaining the time and location of the disease outbreak. The locations mentioned in the news posts are specified textually rather than geometrically thereby requiring the use of geotagging methods to detect them and to map the textual specification to the corresponding actual geometric specification. The NewsStand system which aggregates news posts by topic and location while providing a map query interface to them is enhanced to enable disease tracking and analysis by geotagging disease-related web news posts. Besides the powerful functionalities of NewsStand for news exploration, enhancements of NewsStand with respect to the analysis of temporal information are described which include a well-designed time slider, a heatmap-based visualization tool for displaying disease distribution, and intuitive spatio-temporal querying methods. Future improvements to NewsStand are also discussed.},
booktitle = {Proceedings of the Third ACM SIGSPATIAL International Workshop on the Use of GIS in Public Health},
pages = {31–38},
numpages = {8},
keywords = {geotagging, disease tracking, GIS, spatio-temporal},
location = {Dallas, Texas},
series = {HealthGIS '14}
}

@inproceedings{10.1145/2675354.2675699,
author = {Truelove, Marie and Vasardani, Maria and Winter, Stephan},
title = {Testing a Model of Witness Accounts in Social Media},
year = {2014},
isbn = {9781450331357},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2675354.2675699},
doi = {10.1145/2675354.2675699},
abstract = {Identifying micro-bloggers who are likely witnesses to events is beneficial in numerous applications, including event detection and credibility assessment. This paper presents research in-progress on testing of a conceptual model, which defines witness and related accounts from micro-blogs about events. The case study events considered have varying spatial and temporal characteristics, and include a shark sighting, a music concert, a protest, and a cyclone. Results indicate that witnessing characteristics are influenced by numerous factors in addition to the spatial and temporal characteristics of the events, including the motivation of the witnesses themselves. Additionally, the results suggest enhancements to the conceptual model to provide a more sophisticated generic implementation, and insights for future automation approaches.},
booktitle = {Proceedings of the 8th Workshop on Geographic Information Retrieval},
articleno = {10},
numpages = {8},
keywords = {event characterization, witness accounts, geographic data mining, social media},
location = {Dallas, Texas},
series = {GIR '14}
}

@inproceedings{10.1145/2676467.2676481,
author = {Foster, Derek and Linehan, Conor and Lawson, Shaun},
title = {Effects of Group Performance Feedback and Goal-Setting in an Organisational Energy Intervention},
year = {2014},
isbn = {9781450330060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2676467.2676481},
doi = {10.1145/2676467.2676481},
abstract = {End-user energy demand (EUED) in the workplace is affected by a complex interaction between behavioural, social, technological, regulatory and organisational factors. Designing technology-led interventions to encourage pro-environmental behaviour that acknowledge and support this complexity is a significant challenge. This paper discusses the design and evaluation of an EUED intervention implemented in the corporate infrastructure of a UK university administration department. Two intervention types, group feedback and group goal-setting were implemented. 16 participants were recruited and engaged with a four stage study (baseline, group feedback, group goal setting, and baseline) for a duration of 4 months. This study design allowed us to track clearly any changes in mid-term energy usage behaviour during and beyond intervention. Findings suggest that, surprisingly, participant energy consumption increased during the intervention period compared to baseline conditions. These results demonstrate that simple group-based behaviour change methods can be counter-productive in the workplace, illustrating the complex and unpredictable nature of intervention in this design space.},
booktitle = {Proceedings of the 18th International Academic MindTrek Conference: Media Business, Management, Content &amp; Services},
pages = {57–65},
numpages = {9},
keywords = {organisations, sustainability, behaviour change},
location = {Tampere, Finland},
series = {AcademicMindTrek '14}
}

@inproceedings{10.1145/2666310.2666475,
author = {Oana, Cristina-Violeta and Vasile, Cristian and (Staiculescu), Simona Ipate},
title = {A Spatially Enabled Framework for Habitats and Species Management System: Architecture and Case Study},
year = {2014},
isbn = {9781450331319},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2666310.2666475},
doi = {10.1145/2666310.2666475},
abstract = {National Parks represent a natural heritage resource which is monitored through periodical observations of species in their territory and inventories of habitats and species within its boundaries. However, the management of the natural habitats and species is often critical, due to the difficulty of collecting data in a standard and interoperable form and dissemination to other available information systems. This paper is focused on the development of the geospatial architecture framework and applications required for an efficient inventory and mapping of natural habitats and wild species of community interest and undertaking special measures to conserve these species and habitats characteristic to the steppe bioregion. To show the usefulness, efficiency and effectiveness of this spatially enabled applications framework, we present a use case developed and implemented for the decision makers of the "Macin Mountains" National Park Administration and Natura2000 sites: SPA Macin-Niculitel and SCI Macin Mountains.},
booktitle = {Proceedings of the 22nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems},
pages = {445–448},
numpages = {4},
keywords = {GIS, SDI, geospatial web services, geoportal, database, metadata, biodiversity},
location = {Dallas, Texas},
series = {SIGSPATIAL '14}
}

@inproceedings{10.1145/2755492.2755498,
author = {Kim, Kyoung-Sook and Ogawa, Hirotaka and Nakamura, Akihito and Kojima, Isao},
title = {Sophy: A Morphological Framework for Structuring Geo-Referenced Social Media},
year = {2014},
isbn = {9781450331401},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2755492.2755498},
doi = {10.1145/2755492.2755498},
abstract = {Social networks have played a crucial role of information channels for understanding our daily lives beyond communication tools. In particular, their coupling with geographic location has boosted the worth of social media to detect, track, and predicate dynamic events and situations in the real world. While the amounts of geo-tagged social media are apparently increasing at every moment, we have few framework to handle spatiotemporal changes and analyze their relationships. In this paper, we propose a framework to understand dynamic social phenomena from the mountains of fragmented, noisy data flooding social media. First, we design a data model to describe morphological features of the populations of geo-location of social media and define a set of relationships by using differential measurements in spatial, temporal, and semantic dimensions. Then, we describe our real-time framework to extract morphometric features from streaming tweets, create the topological relationships, and store all features into a graph-based database. In the experiments, we show case studies related to two typhoons (Neoguri and Halong) and a landslide disaster (Hiroshima) with real tweet-sets in a visualization way.},
booktitle = {Proceedings of the 7th ACM SIGSPATIAL International Workshop on Location-Based Social Networks},
pages = {31–40},
numpages = {10},
keywords = {movement analysis, spatiotemporal phenomena, social geomorphology, morphological features},
location = {Dallas/Fort Worth, Texas},
series = {LBSN '14}
}

@inproceedings{10.1145/2676467.2676471,
author = {Paschali, Maria Eleni and Ampatzoglou, Apostolos and Chatzigeorgiou, Alexander and Stamelos, Ioannis},
title = {Non-Functional Requirements That Influence Gaming Experience: A Survey on Gamers Satisfaction Factors},
year = {2014},
isbn = {9781450330060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2676467.2676471},
doi = {10.1145/2676467.2676471},
abstract = {Requirements engineering is an extremely crucial phase in the software development lifecycle, because mishaps in this stage are usually expensive to fix in later development phases. In the domain of computer games, requirements engineering is a heavily studied research field (39.3% of published papers are dealing with requirements [1]), since it is considered substantially different from traditional software requirements engineering (see [1] and [14]). The main point of differentiation is that almost all computer games share a common key-driver as requirement, i.e. user satisfaction. In this paper, we investigate the most important user satisfaction factors from computer games, though a survey on regular gamers. The results of the study suggest that, user satisfaction factors are not uniform across different types of games (game genres), but are heavily dependent on them. Therefore, this study underlines the most important non-functional requirements that developers and researchers should focus on, while dealing with game engineering.},
booktitle = {Proceedings of the 18th International Academic MindTrek Conference: Media Business, Management, Content &amp; Services},
pages = {208–215},
numpages = {8},
keywords = {computer games, survey, user satisfaction factors},
location = {Tampere, Finland},
series = {AcademicMindTrek '14}
}

@inproceedings{10.1145/2663716.2663728,
author = {Wang, Gang and Wang, Bolun and Wang, Tianyi and Nika, Ana and Zheng, Haitao and Zhao, Ben Y.},
title = {Whispers in the Dark: Analysis of an Anonymous Social Network},
year = {2014},
isbn = {9781450332132},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663716.2663728},
doi = {10.1145/2663716.2663728},
abstract = {Social interactions and interpersonal communication has undergone significant changes in recent years. Increasing awareness of privacy issues and events such as the Snowden disclosures have led to the rapid growth of a new generation of anonymous social networks and messaging applications. By removing traditional concepts of strong identities and social links, these services encourage communication between strangers, and allow users to express themselves without fear of bullying or retaliation.Despite millions of users and billions of monthly page views, there is little empirical analysis of how services like Whisper have changed the shape and content of social interactions. In this paper, we present results of the first large-scale empirical study of an anonymous social network, using a complete 3-month trace of the Whisper network covering 24 million whispers written by more than 1 million unique users. We seek to understand how anonymity and the lack of social links affect user behavior. We analyze Whisper from a number of perspectives, including the structure of user interactions in the absence of persistent social links, user engagement and network stickiness over time, and content moderation in a network with minimal user accountability. Finally, we identify and test an attack that exposes Whisper users to detailed location tracking. We have notified Whisper and they have taken steps to address the problem.},
booktitle = {Proceedings of the 2014 Conference on Internet Measurement Conference},
pages = {137–150},
numpages = {14},
keywords = {graphs, anonymous social networks, user engagement, privacy},
location = {Vancouver, BC, Canada},
series = {IMC '14}
}

@inproceedings{10.1145/2668064.2668099,
author = {Costigan, Timothy and Prasad, Mukta and McDonnell, Rachel},
title = {Facial Retargeting Using Neural Networks},
year = {2014},
isbn = {9781450326230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2668064.2668099},
doi = {10.1145/2668064.2668099},
abstract = {Mapping the motion of an actor's face to a virtual model is a difficult but important problem, especially as fully animated characters are becoming more common in games and movies. Many methods have been proposed but most require the source and target to be structurally similar. Optical motion capture markers and blendshape weights are an example of topologically incongruous source and target examples that do not have a simple mapping between one another. In this paper, we created a system capable of determining this mapping through supervised learning of a small training dataset. Radial Basis Function Networks (RBFNs) have been used for retargeting markers to blendshape weights before but to our knowledge Multi-Layer Perceptron Artificial Neural Networks (referred to as ANNs) have not been employed in this way. We hypothesized that ANNs would result in a superior retargeting solution compared to the RBFN, due to their theoretically greater representational power. We implemented a retargeting system using ANNs and RBFNs for comparison. Our results found that both systems produced similar results (figure 1) and in some cases the ANN proved to be more expressive although the ANN was more difficult to work with.},
booktitle = {Proceedings of the Seventh International Conference on Motion in Games},
pages = {31–38},
numpages = {8},
keywords = {regression, facial retargeting, neural networks},
location = {Playa Vista, California},
series = {MIG '14}
}

@article{10.1145/2663355,
author = {White, Ryen W. and Hassan, Ahmed},
title = {Content Bias in Online Health Search},
year = {2014},
issue_date = {October 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
issn = {1559-1131},
url = {https://doi.org/10.1145/2663355},
doi = {10.1145/2663355},
abstract = {Search engines help people answer consequential questions. Biases in retrieved and indexed content (e.g., skew toward erroneous outcomes that represent deviations from reality), coupled with searchers' biases in how they examine and interpret search results, can lead people to incorrect answers. In this article, we seek to better understand biases in search and retrieval, and in particular those affecting the accuracy of content in search results, including the search engine index, features used for ranking, and the formulation of search queries. Focusing on the important domain of online health search, this research broadens previous work on biases in search to examine the role of search systems in contributing to biases. To assess bias, we focus on questions about medical interventions and employ reliable ground truth data from authoritative medical sources. In the course of our study, we utilize large-scale log analysis using data from a popular Web search engine, deep probes of result lists on that search engine, and crowdsourced human judgments of search result captions and landing pages. Our findings reveal bias in results, amplifying searchers' existing biases that appear evident in their search activity. We also highlight significant bias in indexed content and show that specific ranking signals and specific query terms support bias. Both of these can degrade result accuracy and increase skewness in search results. Our analysis has implications for bias mitigation strategies in online search systems, and we offer recommendations for search providers based on our findings.},
journal = {ACM Trans. Web},
month = nov,
articleno = {25},
numpages = {33},
keywords = {health search, Content biases}
}

@inproceedings{10.1145/2663715.2669609,
author = {Biega, Joanna and Mele, Ida and Weikum, Gerhard},
title = {Probabilistic Prediction of Privacy Risks in User Search Histories},
year = {2014},
isbn = {9781450315838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663715.2669609},
doi = {10.1145/2663715.2669609},
abstract = {This paper proposes a new model of user-centric, global, probabilistic privacy, geared for today's challenges of helping users to manage their privacy-sensitive information across a wide variety of social networks, online communities, QA forums, and search histories. Our approach anticipates an adversary that harnesses global background knowledge and rich statistics in order to make educated guesses, that is, probabilistic inferences at sensitive data. We aim for a tool that simulates such a powerful adversary, predicts privacy risks, and guides the user. In this paper, our framework is specialized for the case of Internet search histories. We present preliminary experiments that demonstrate how estimators of global correlations among sensitive and non-sensitive key-value items can be fed into a probabilistic graphical model in order to compute meaningful measures of privacy risk.},
booktitle = {Proceedings of the First International Workshop on Privacy and Secuirty of Big Data},
pages = {29–36},
numpages = {8},
keywords = {probabilistic privacy, privacy risk prediction, user-centric privacy, query logs},
location = {Shanghai, China},
series = {PSBD '14}
}

@inproceedings{10.1145/2666652.2666656,
author = {Miller, Brad and Kantchelian, Alex and Afroz, Sadia and Bachwani, Rekha and Dauber, Edwin and Huang, Ling and Tschantz, Michael Carl and Joseph, Anthony D. and Tygar, J.D.},
title = {Adversarial Active Learning},
year = {2014},
isbn = {9781450331531},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2666652.2666656},
doi = {10.1145/2666652.2666656},
abstract = {Active learning is an area of machine learning examining strategies for allocation of finite resources, particularly human labeling efforts and to an extent feature extraction, in situations where available data exceeds available resources. In this open problem paper, we motivate the necessity of active learning in the security domain, identify problems caused by the application of present active learning techniques in adversarial settings, and propose a framework for experimentation and implementation of active learning systems in adversarial contexts. More than other contexts, adversarial contexts particularly need active learning as ongoing attempts to evade and confuse classifiers necessitate constant generation of labels for new content to keep pace with adversarial activity. Just as traditional machine learning algorithms are vulnerable to adversarial manipulation, we discuss assumptions specific to active learning that introduce additional vulnerabilities, as well as present vulnerabilities that are amplified in the active learning setting. Lastly, we present a software architecture, Security-oriented Active Learning Testbed (SALT), for the research and implementation of active learning applications in adversarial contexts.},
booktitle = {Proceedings of the 2014 Workshop on Artificial Intelligent and Security Workshop},
pages = {3–14},
numpages = {12},
keywords = {secure machine learning, active learning, human in the loop},
location = {Scottsdale, Arizona, USA},
series = {AISec '14}
}

@inproceedings{10.1145/2661806.2661809,
author = {Williamson, James R. and Quatieri, Thomas F. and Helfer, Brian S. and Ciccarelli, Gregory and Mehta, Daryush D.},
title = {Vocal and Facial Biomarkers of Depression Based on Motor Incoordination and Timing},
year = {2014},
isbn = {9781450331197},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661806.2661809},
doi = {10.1145/2661806.2661809},
abstract = {In individuals with major depressive disorder, neurophysiological changes often alter motor control and thus affect the mechanisms controlling speech production and facial expression. These changes are typically associated with psychomotor retardation, a condition marked by slowed neuromotor output that is behaviorally manifested as altered coordination and timing across multiple motor-based properties. Changes in motor outputs can be inferred from vocal acoustics and facial movements as individuals speak. We derive novel multi-scale correlation structure and timing feature sets from audio-based vocal features and video-based facial action units from recordings provided by the 4th International Audio/Video Emotion Challenge (AVEC). The feature sets enable detection of changes in coordination, movement, and timing of vocal and facial gestures that are potentially symptomatic of depression. Combining complementary features in Gaussian mixture model and extreme learning machine classifiers, our multivariate regression scheme predicts Beck depression inventory ratings on the AVEC test set with a root-mean-square error of 8.12 and mean absolute error of 6.31. Future work calls for continued study into detection of neurological disorders based on altered coordination and timing across audio and video modalities.},
booktitle = {Proceedings of the 4th International Workshop on Audio/Visual Emotion Challenge},
pages = {65–72},
numpages = {8},
keywords = {major depressive disorder, facial biomarker, correlation structure, vocal biomarker, Gaussian mixture model, motor control, incoordination and timing, extreme learning machine},
location = {Orlando, Florida, USA},
series = {AVEC '14}
}

@inproceedings{10.1145/2660114.2660116,
author = {Abadi, Mojtaba Khomami and Abad, Azad and Subramanian, Ramanathan and Rostamzadeh, Negar and Ricci, Elisa and Varadarajan, Jagannadan and Sebe, Nicu},
title = {A Multi-Task Learning Framework for Time-Continuous Emotion Estimation from Crowd Annotations},
year = {2014},
isbn = {9781450331289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2660114.2660116},
doi = {10.1145/2660114.2660116},
abstract = {We propose Multi-task learning (MTL) for time-continuous or dynamic emotion (valence and arousal) estimation in movie scenes. Since compiling annotated training data for dynamic emotion prediction is tedious, we employ crowdsourcing for the same. Even though the crowdworkers come from various demographics, we demonstrate that MTL can effectively discover (1) consistent patterns in their dynamic emotion perception, and (2) the low-level audio and video features that contribute to their valence, arousal (VA) elicitation. Finally, we show that MTL-based regression models, which simultaneously learn the relationship between low-level audio-visual features and high-level VA ratings from a collection of movie scenes, can predict VA ratings for time-contiguous snippets from each scene more effectively than scene-specific models.},
booktitle = {Proceedings of the 2014 International ACM Workshop on Crowdsourcing for Multimedia},
pages = {17–23},
numpages = {7},
keywords = {multi-task learning, crowd annotation, time-continuous emotion estimation, movie clips},
location = {Orlando, Florida, USA},
series = {CrowdMM '14}
}

@inproceedings{10.1145/2661704.2661708,
author = {Guthier, Benjamin and Alharthi, Rajwa and Abaalkhail, Rana and El Saddik, Abdulmotaleb},
title = {Detection and Visualization of Emotions in an Affect-Aware City},
year = {2014},
isbn = {9781450331265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661704.2661708},
doi = {10.1145/2661704.2661708},
abstract = {Smart cities use various deployed sensors and aggregate their data to create a big picture of the live state of the city. This live state can be enhanced by incorporating the affective states of the citizens. In this work, we automatically detect the emotions of the city's inhabitants from geo-tagged posts on the social network Twitter. Emotions are represented as four-dimensional vectors of pleasantness, arousal, dominance and unpredictability. In a training phase, emotion-word hashtags in the messages are used as the ground truth emotion contained in a message. A neural network is trained by using the presence of words, hashtags and emoticons in the messages as features. During the live phase, these features are extracted from new geo-tagged Twitter messages and given as input to the neural network. This allows the estimation of a four-dimensional emotion vector for a new message. The detected emotions are aggregated over space and time and visualized on a map of the city.},
booktitle = {Proceedings of the 1st International Workshop on Emerging Multimedia Applications and Services for Smart Cities},
pages = {23–28},
numpages = {6},
keywords = {emotion detection, dimensional emotional model, affect-aware city, twitter, emotion-word hashtag},
location = {Orlando, Florida, USA},
series = {EMASC '14}
}

@inproceedings{10.1145/2659522.2659531,
author = {Alam, Firoj and Riccardi, Giuseppe},
title = {Predicting Personality Traits Using Multimodal Information},
year = {2014},
isbn = {9781450331296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2659522.2659531},
doi = {10.1145/2659522.2659531},
abstract = {Measuring personality traits has a long story in psychology where analysis has been done by asking sets of questions. These question sets (inventories) have been designed by investigating lexical terms that we use in our daily communications or by analyzing biological phenomena. Whether consciously or unconsciously we express our thoughts and behaviors when communicating with others, either verbally, non-verbally or using visual expressions. Recently, research in behavioral signal processing has focused on automatically measuring personality traits using different behavioral cues that appear in our daily communication. In this study, we present an approach to automatically recognize personality traits using a video-blog (vlog) corpus, consisting of transcription and extracted audio-visual features. We analyzed linguistic, psycholinguistic and emotional features in addition to the audio-visual features provided with the dataset. We also studied whether we can better predict a trait by identifying other traits. Using our best models we obtained very promising results compared to the official baseline.},
booktitle = {Proceedings of the 2014 ACM Multi Media on Workshop on Computational Personality Recognition},
pages = {15–18},
numpages = {4},
keywords = {behavioral signal processing, multimodal personality recognition},
location = {Orlando, Florida, USA},
series = {WCPR '14}
}

@inproceedings{10.1145/2667190.2667192,
author = {Line, Maria B. and Zand, Ali and Stringhini, Gianluca and Kemmerer, Richard},
title = {Targeted Attacks against Industrial Control Systems: Is the Power Industry Prepared?},
year = {2014},
isbn = {9781450331548},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2667190.2667192},
doi = {10.1145/2667190.2667192},
abstract = {Targeted cyber attacks are on the rise, and the power industry is an attractive target. Espionage and causing physical damage are likely goals of these targeted attacks. In the case of the power industry, the worst possible consequences are severe: large areas, including critical societal infrastructures, can suffer from power outages. In this paper, we try to measure the preparedness of the power industry against targeted attacks. To this end, we have studied well-known targeted attacks and created a taxonomy for them. Furthermore, we conduct a study, in which we interview six power distribution system operators (DSOs), to assess the level of cyber situation awareness among DSOs and to evaluate the efficiency and effectiveness of their currently deployed systems and practices for detecting and responding to targeted attacks. Our findings indicate that the power industry is very well prepared for traditional threats, such as physical attacks. However, cyber attacks, and especially sophisticated targeted attacks, where social engineering is one of the strategies used, have not been addressed appropriately so far. Finally, by understanding previous attacks and learning from them, we try to provide the industry with guidelines for improving their situation awareness and defense (both detection and response) capabilities.},
booktitle = {Proceedings of the 2nd Workshop on Smart Energy Grid Security},
pages = {13–22},
numpages = {10},
keywords = {power industry, preparedness, targeted attacks, industrial control systems, cyber situation awareness, interview study, information security, incident management},
location = {Scottsdale, Arizona, USA},
series = {SEGS '14}
}

@inproceedings{10.1145/2660398.2660404,
author = {Jahnke, Isa and Svendsen, Niels Vandel and Johansen, Simon Kristoffer and Zander, P\"{a}r-Ola},
title = {The Dream About the Magic Silver Bullet: The Complexity of Designing for Tablet-Mediated Learning},
year = {2014},
isbn = {9781450330435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2660398.2660404},
doi = {10.1145/2660398.2660404},
abstract = {In this paper, we report three cases of the integration of technology such as web-enabled media tablets in Scandinavian schools. Both qualitative and quantitative data have been applied. A daily challenge for teachers is to coordinate their group of students in a way that enables collaborative learning. We report the gaps and interrelations between the dreams and the practice of the teachers. They dream about an interconnected praxis -- the magic silver bullet -- and establish their visions of inter-connectivity because of their breakdown experiences of media tablets aiding complexity instead of reducing it. The teachers must learn how to navigate during the breakdowns before media tablets reduce complexity and reach a state in which the tablets take part in the classroom ecology as functional organs. The teachers have to deal with complex situations during class in situ. In order to be able to continue with the class, the teachers become jongleurs of different design elements including the handling of the didactical designs and the breakdowns caused by the integration of media tablets; the teaching practice in classrooms moves away from a common routine activity and turns into a design project.},
booktitle = {Proceedings of the 18th International Conference on Supporting Group Work},
pages = {100–110},
numpages = {11},
keywords = {schools, educational technology, cooperation, design, teacher practice, complexity, media tablets},
location = {Sanibel Island, Florida, USA},
series = {GROUP '14}
}

@inproceedings{10.1145/2660398.2660413,
author = {Esbensen, Morten and Bj\o{}rn, Pernille},
title = {Routine and Standardization in Global Software Development},
year = {2014},
isbn = {9781450330435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2660398.2660413},
doi = {10.1145/2660398.2660413},
abstract = {We present an ethnographic field study of a distributed software development team following the Scrum methodology. During a two-week period, we observed from both sites the collaboration between a Danish software company off-shoring part of their development to an Indian solution provider. Collaboration by its very definition is based on the notion of dependency in work between multiple people. Articulation work is the extra work required to handle these dependencies. In a globally distributed team, managing these dependencies is exacerbated due to the distances of time, space, and culture. To broaden our understanding of dependencies in a global context and how they influence work practices, we made them the focus of our analysis. The main contributions of this paper are (i) an empirical account of the dependencies that are part of the collaborative work in a global software development team, (ii) a discussion of the interlinked properties of dependencies, and (iii) an explanation of how the practices of standardization and routine are developed and used to manage these dependencies.},
booktitle = {Proceedings of the 18th International Conference on Supporting Group Work},
pages = {12–23},
numpages = {12},
keywords = {ethnographic study, global software development, routine, dependencies, standardization},
location = {Sanibel Island, Florida, USA},
series = {GROUP '14}
}

@inproceedings{10.1145/2669557.2669569,
author = {Blascheck, Tanja and Ertl, Thomas},
title = {Towards Analyzing Eye Tracking Data for Evaluating Interactive Visualization Systems},
year = {2014},
isbn = {9781450332095},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2669557.2669569},
doi = {10.1145/2669557.2669569},
abstract = {Eye tracking can be a suitable evaluation method for determining which regions and objects of a stimulus a human viewer perceived. Analysts can use eye tracking as a complement to other evaluation methods for a more holistic assessment of novel visualization techniques beyond time and error measures. Up to now, most stimuli in eye tracking are either static stimuli or videos. Since interaction is an integral part of visualization, an evaluation should include interaction. In this paper, we present an extensive literature review on evaluation methods for interactive visualizations. Based on the literature review we propose ideas for analyzing eye movement data from interactive stimuli. This requires looking critically at challenges induced by interactive stimuli. The first step is to collect data using different study methods. In our case, we look at using eye tracking, interaction logs, and thinking-aloud protocols. In addition, this requires a thorough synchronization of the mentioned study methods. To analyze the collected data new analysis techniques have to be developed. We investigate existing approaches and how we can adapt them to new data types as well as sketch ideas how new approaches can look like.},
booktitle = {Proceedings of the Fifth Workshop on Beyond Time and Errors: Novel Evaluation Methods for Visualization},
pages = {70–77},
numpages = {8},
keywords = {interaction, visualization, eye tracking},
location = {Paris, France},
series = {BELIV '14}
}

@inproceedings{10.1145/2671491.2671495,
author = {Fischer, Fabian and Keim, Daniel A.},
title = {NStreamAware: Real-Time Visual Analytics for Data Streams to Enhance Situational Awareness},
year = {2014},
isbn = {9781450328265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2671491.2671495},
doi = {10.1145/2671491.2671495},
abstract = {The analysis of data streams is important in many security-related domains to gain situational awareness. To provide monitoring and visual analysis of such data streams, we propose a system, called NStreamAware, that uses modern distributed processing technologies to analyze streams using stream slices, which are presented to analysts in a web-based visual analytics application, called NVisAware. Furthermore, we visually guide the user in the feature selection process to summarize the slices to focus on the most interesting parts of the stream based on introduced expert knowledge of the analyst. We show through case studies, how the system can be used to gain situational awareness and eventually enhance network security. Furthermore, we apply the system to a social media data stream to compete in an international challenge to evaluate the applicability of our approach to other domains.},
booktitle = {Proceedings of the Eleventh Workshop on Visualization for Cyber Security},
pages = {65–72},
numpages = {8},
keywords = {network security, real-time processing, situational awareness, data streams, visual analytics},
location = {Paris, France},
series = {VizSec '14}
}

@inproceedings{10.1145/2669557.2669579,
author = {Stasko, John},
title = {Value-Driven Evaluation of Visualizations},
year = {2014},
isbn = {9781450332095},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2669557.2669579},
doi = {10.1145/2669557.2669579},
abstract = {Existing evaluations of data visualizations often employ a series of low-level, detailed questions to be answered or benchmark tasks to be performed. While that methodology can be helpful to determine a visualization's usability, such evaluations overlook the key benefits that visualization uniquely provides over other data analysis methods. I propose a value-driven evaluation of visualizations in which a person illustrates a system's value through four important capabilities: minimizing the time to answer diverse questions, spurring the generation of insights and insightful questions, conveying the essence of the data, and generating confidence and knowledge about the data's domain and context. Additionally, I explain how interaction is instrumental in creating much of the value that can be found in visualizations.},
booktitle = {Proceedings of the Fifth Workshop on Beyond Time and Errors: Novel Evaluation Methods for Visualization},
pages = {46–53},
numpages = {8},
keywords = {value, interaction, evaluation, data visualization},
location = {Paris, France},
series = {BELIV '14}
}

@inproceedings{10.1145/2671491.2671492,
author = {Staheli, Diane and Yu, Tamara and Crouser, R. Jordan and Damodaran, Suresh and Nam, Kevin and O'Gwynn, David and McKenna, Sean and Harrison, Lane},
title = {Visualization Evaluation for Cyber Security: Trends and Future Directions},
year = {2014},
isbn = {9781450328265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2671491.2671492},
doi = {10.1145/2671491.2671492},
abstract = {The Visualization for Cyber Security research community (VizSec) addresses longstanding challenges in cyber security by adapting and evaluating information visualization techniques with application to the cyber security domain. This research effort has created many tools and techniques that could be applied to improve cyber security, yet the community has not yet established unified standards for evaluating these approaches to predict their operational validity. In this paper, we survey and categorize the evaluation metrics, components, and techniques that have been utilized in the past decade of VizSec research literature. We also discuss existing methodological gaps in evaluating visualization in cyber security, and suggest potential avenues for future research in order to help establish an agenda for advancing the state-of-the-art in evaluating cyber security visualizations.},
booktitle = {Proceedings of the Eleventh Workshop on Visualization for Cyber Security},
pages = {49–56},
numpages = {8},
keywords = {information visualization, cyber security, evaluation},
location = {Paris, France},
series = {VizSec '14}
}

@inproceedings{10.1145/2669557.2669564,
author = {Brehmer, Matthew and Carpendale, Sheelagh and Lee, Bongshin and Tory, Melanie},
title = {Pre-Design Empiricism for Information Visualization: Scenarios, Methods, and Challenges},
year = {2014},
isbn = {9781450332095},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2669557.2669564},
doi = {10.1145/2669557.2669564},
abstract = {Empirical study can inform visualization design, both directly and indirectly. Pre-design empirical methods can be used to characterize work practices and their associated problems in a specific domain, directly motivating design choices during the subsequent development of a specific application or technique. They can also be used to understand how individuals, existing tools, data, and contextual factors interact, indirectly informing later research in our community. Contexts for empirical study vary and practitioners should carefully consider finding the most appropriate methods for any given situation. This paper discusses some of the challenges associated with conducting pre-design studies by way of four illustrative scenarios, highlighting the methods as well as the challenges unique to the visualization domain. We encourage researchers and practitioners to conduct more pre-design empirical studies and describe in greater detail their use of empirical methods for informing design.},
booktitle = {Proceedings of the Fifth Workshop on Beyond Time and Errors: Novel Evaluation Methods for Visualization},
pages = {147–151},
numpages = {5},
keywords = {applied visualization design, empirical research},
location = {Paris, France},
series = {BELIV '14}
}

@inproceedings{10.1145/2635868.2666600,
author = {Kasi, Bakhtiar Khan},
title = {Minimizing Software Conflicts through Proactive Detection of Conflicts and Task Scheduling},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2666600},
doi = {10.1145/2635868.2666600},
abstract = { Software conflicts arising because of conflicting changes are a regular occurrence and delay projects. Workspace awareness tools have been proposed to facilitate task coordination among developers, enabling them to identify potential conflicts early, while conflicts are still easy to resolve. However, these tools have limitations, as they identify conflicts after conflicts have already occurred and therefore, are unable to prevent developers’ time and effort spent in resolving the conflicts. The goal of this Ph.D. research is to: (1) characterize the distribution of conflicts, their frequency and the factors within a project that affects the distribution and frequency of conflicts, (2) design and implement a conflict minimization technique that proactively identifies potential conflicts by analyzing developers’ tasks and avoids them by scheduling tasks in a conflict minimal manner and (3) evaluate the proposed approach using historic data from OSS projects and through user evaluations. Thus far, we have implemented our approach and evaluated it with historic data from four OSS projects and through simulated data. },
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {807–810},
numpages = {4},
keywords = {task scheduling, simulations, Collaborative software development},
location = {Hong Kong, China},
series = {FSE 2014}
}

@inproceedings{10.1145/2635868.2635871,
author = {Banerjee, Abhijeet and Chong, Lee Kee and Chattopadhyay, Sudipta and Roychoudhury, Abhik},
title = {Detecting Energy Bugs and Hotspots in Mobile Apps},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2635871},
doi = {10.1145/2635868.2635871},
abstract = { Over the recent years, the popularity of smartphones has increased dramatically. This has lead to a widespread availability of smartphone applications. Since smartphones operate on a limited amount of battery power, it is important to develop tools and techniques that aid in energy-efficient application development. Energy inefficiencies in smartphone applications can broadly be categorized into energy hotspots and energy bugs. An energy hotspot can be described as a scenario where executing an application causes the smartphone to consume abnormally high amount of battery power, even though the utilization of its hardware resources is low. In contrast, an energy bug can be described as a scenario where a malfunctioning application prevents the smartphone from becoming idle, even after it has completed execution and there is no user activity. In this paper, we present an automated test generation framework that detects energy hotspots/bugs in Android applications. Our framework systematically generates test inputs that are likely to capture energy hotspots/bugs. Each test input captures a sequence of user interactions (e.g. touches or taps on the smartphone screen) that leads to an energy hotspot/bug in the application. Evaluation with 30 freely-available Android applications from Google Play/F-Droid shows the efficacy of our framework in finding hotspots/bugs. Manual validation of the experimental results shows that our framework reports reasonably low number of false positives. Finally, we show the usage of the generated results by improving the energy-efficiency of some Android applications. },
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {588–598},
numpages = {11},
keywords = {Mobile apps, Non-functional testing, Energy consumption},
location = {Hong Kong, China},
series = {FSE 2014}
}

@inproceedings{10.1145/2635868.2635925,
author = {Pham, Raphael and Kiesling, Stephan and Liskin, Olga and Singer, Leif and Schneider, Kurt},
title = {Enablers, Inhibitors, and Perceptions of Testing in Novice Software Teams},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2635925},
doi = {10.1145/2635868.2635925},
abstract = { There are many different approaches to testing software, with different benefits for software quality and the development process. Yet, it is not well understood what developers struggle with when getting started with testing - and why some do not test at all or not as much as would be good for their project. This missing understanding keeps us from improving processes and tools to help novices adopt proper testing practices. We conducted a qualitative study with 97 computer science students. Through interviews, we explored their experiences and attitudes regarding testing in a collaborative software project. We found enabling and inhibiting factors for testing activities, the different testing strategies they used, and novices’ perceptions and attitudes of testing. Students push test automation to the end of the project, thus robbing themselves from the advantages of having a test suite during implementation. Students were not convinced of the return of investment in automated tests and opted for laborious manual tests - which they often regretted in the end. Understanding such challenges and opportunities novices face when confronted with adopting testing can help us improve testing processes, company policies, and tools. Our findings provide recommendations that can enable organizations to facilitate the adoption of testing practices by their members. },
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {30–40},
numpages = {11},
keywords = {Testing, Inhibitors, Enablers, Motivation, Adoption},
location = {Hong Kong, China},
series = {FSE 2014}
}

@inproceedings{10.1145/2693787.2693796,
author = {Westerlaken, Michelle and Gualeni, Stefano},
title = {Grounded Zoomorphism: An Evaluation Methodology for ACI Design},
year = {2014},
isbn = {9781450333146},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2693787.2693796},
doi = {10.1145/2693787.2693796},
abstract = {This paper proposes and evaluates a novel method for the analysis and the refinement of products and designs that participate in playful, digitally-mediated human-animal interactions. The proposed method relies on a Grounded Theory approach and aims at guiding design and research in the field of Animal Computer Interaction in a way that is better focused on the experience and needs of the animals interacting with playful, digital artefacts. In order to validate the proposed techniques, we designed a video game (Felino) in which cats and humans play together on a single tablet. Felino was then tested together with cats (N=19). Guidelines for the refinement of the game itself emerged from the process, and are presented as exemplary outputs of the proposed method at the end of this study.},
booktitle = {Proceedings of the 2014 Workshops on Advances in Computer Entertainment Conference},
articleno = {5},
numpages = {6},
keywords = {Method, Grounded Theory, User, Experience, Play, Zoomorphism, Animal Computer Interaction},
location = {Funchal, Portugal},
series = {ACE '14 Workshops}
}

@inproceedings{10.1145/2635868.2635877,
author = {Ying, Annie T. T. and Robillard, Martin P.},
title = {Selection and Presentation Practices for Code Example Summarization},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2635877},
doi = {10.1145/2635868.2635877},
abstract = { Code examples are an important source for answering questions about software libraries and applications. Many usage contexts for code examples require them to be distilled to their essence: e.g., when serving as cues to longer documents, or for reminding developers of a previously known idiom. We conducted a study to discover how code can be summarized and why. As part of the study, we collected 156 pairs of code examples and their summaries from 16 participants, along with over 26 hours of think-aloud verbalizations detailing the decisions of the participants during their summarization activities. Based on a qualitative analysis of this data we elicited a list of practices followed by the participants to summarize code examples and propose empirically-supported hypotheses justifying the use of specific practices. One main finding was that none of the participants exclusively extracted code verbatim for the summaries, motivating abstractive summarization. The results provide a grounded basis for the development of code example summarization and presentation technology. },
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {460–471},
numpages = {12},
location = {Hong Kong, China},
series = {FSE 2014}
}

@inproceedings{10.1145/2635868.2635892,
author = {Meyer, Andr\'{e} N. and Fritz, Thomas and Murphy, Gail C. and Zimmermann, Thomas},
title = {Software Developers' Perceptions of Productivity},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2635892},
doi = {10.1145/2635868.2635892},
abstract = { The better the software development community becomes at creating software, the more software the world seems to demand. Although there is a large body of research about measuring and investigating productivity from an organizational point of view, there is a paucity of research about how software developers, those at the front-line of software construction, think about, assess and try to improve their productivity. To investigate software developers' perceptions of software development productivity, we conducted two studies: a survey with 379 professional software developers to help elicit themes and an observational study with 11 professional software developers to investigate emergent themes in more detail. In both studies, we found that developers perceive their days as productive when they complete many or big tasks without significant interruptions or context switches. Yet, the observational data we collected shows our participants performed significant task and activity switching while still feeling productive. We analyze such apparent contradictions in our findings and use the analysis to propose ways to better support software developers in a retrospection and improvement of their productivity through the development of new tools and the sharing of best practices. },
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {19–29},
numpages = {11},
keywords = {goal setting, productivity, retrospection},
location = {Hong Kong, China},
series = {FSE 2014}
}

@inproceedings{10.1145/2671015.2671023,
author = {Covaci, Alexandra and Olivier, Anne-H\'{e}l\`{e}ne and Multon, Franck},
title = {Third Person View and Guidance for More Natural Motor Behaviour in Immersive Basketball Playing},
year = {2014},
isbn = {9781450332538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2671015.2671023},
doi = {10.1145/2671015.2671023},
abstract = {The use of Virtual Reality (VR) in sports training is now widely studied with the perspective to transfer motor skills learned in virtual environments (VEs) to real practice. However precision motor tasks that require high accuracy have been rarely studied in the context of VE, especially in Large Screen Image Display (LSID) platforms. An example of such a motor task is the basketball free throw, where the player has to throw a ball in a 46cm wide basket placed at 4.2m away from her. In order to determine the best VE training conditions for this type of skill, we proposed and compared three training paradigms. These training conditions were used to compare the combinations of different user perspectives: first (1PP) and third-person (3PP) perspectives, and the effectiveness of visual guidance. We analysed the performance of eleven amateur subjects who performed series of free throws in a real and immersive 1:1 scale environment under the proposed conditions. The results show that ball speed at the moment of the release in 1PP was significantly lower compared to real world, supporting the hypothesis that distance is underestimated in large screen VEs. However ball speed in 3PP condition was more similar to the real condition, especially if combined with guidance feedback. Moreover, when guidance information was proposed, the subjects released the ball at higher - and closer to optimal - position (5-7% higher compared to no-guidance conditions). This type of information contributes to better understand the impact of visual feedback on the motor performance of users who wish to train motor skills using immersive environments. Moreover, this information can be used by exergames designers who wish to develop coaching systems to transfer motor skills learned in VEs to real practice.},
booktitle = {Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology},
pages = {55–64},
numpages = {10},
keywords = {immersive room, visual feedback, perception of distance in VR, basketball training, performance},
location = {Edinburgh, Scotland},
series = {VRST '14}
}

@inproceedings{10.1145/2635868.2635882,
author = {Tsay, Jason and Dabbish, Laura and Herbsleb, James},
title = {Let's Talk about It: Evaluating Contributions through Discussion in GitHub},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2635882},
doi = {10.1145/2635868.2635882},
abstract = { Open source software projects often rely on code contributions from a wide variety of developers to extend the capabilities of their software. Project members evaluate these contributions and often engage in extended discussions to decide whether to integrate changes. These discussions have important implications for project management regarding new contributors and evolution of project requirements and direction. We present a study of how developers in open work environments evaluate and discuss pull requests, a primary method of contribution in GitHub, analyzing a sample of extended discussions around pull requests and interviews with GitHub developers. We found that developers raised issues around contributions over both the appropriateness of the problem that the submitter attempted to solve and the correctness of the implemented solution. Both core project members and third-party stakeholders discussed and sometimes implemented alternative solutions to address these issues. Different stakeholders also influenced the outcome of the evaluation by eliciting support from different communities such as dependent projects or even companies. We also found that evaluation outcomes may be more complex than simply acceptance or rejection. In some cases, although a submitter's contribution was rejected, the core team fulfilled the submitter's technical goals by implementing an alternative solution. We found that the level of a submitter's prior interaction on a project changed how politely developers discussed the contribution and the nature of proposed alternative solutions. },
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {144–154},
numpages = {11},
keywords = {open source, discussion, social media, contribution, GitHub, evaluation, social computing, transparency},
location = {Hong Kong, China},
series = {FSE 2014}
}

@inproceedings{10.1145/2663204.2663239,
author = {Marcos-Ramiro, Alvaro and Pizarro-Perez, Daniel and Marron-Romera, Marta and Pizarro-Perez, Daniel and Gatica-Perez, Daniel},
title = {Automatic Blinking Detection towards Stress Discovery},
year = {2014},
isbn = {9781450328852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663204.2663239},
doi = {10.1145/2663204.2663239},
abstract = {We present a robust method to automatically detect blinks in video sequences of conversations, aimed to discovering stress. Psychological studies have shown a relationship between blink frequency and dopamine levels, which in turn are affected by stress. Task performance correlates through an inverted U shape to both dopamine and stress levels. This shows the importance of automatic blink detection as a way of reducing human coding burden. We use an off-the-shelf face tracker in order to extract the eye region. Then, we perform per-pixel classification of the extracted eye images to later identify blinks through their dynamics. We evaluate the performance of our system with a job interview database with annotations of psychological variables, and show statistically significant correlation between perceived stress resistance and the automatically detected blink patterns.},
booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction},
pages = {307–310},
numpages = {4},
keywords = {stress discovery, blink detection, random forests},
location = {Istanbul, Turkey},
series = {ICMI '14}
}

@inproceedings{10.1145/2663204.2663257,
author = {Koldijk, Saskia and Sappelli, Maya and Verberne, Suzan and Neerincx, Mark A. and Kraaij, Wessel},
title = {The SWELL Knowledge Work Dataset for Stress and User Modeling Research},
year = {2014},
isbn = {9781450328852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663204.2663257},
doi = {10.1145/2663204.2663257},
abstract = {This paper describes the new multimodal SWELL knowledge work (SWELL-KW) dataset for research on stress and user modeling. The dataset was collected in an experiment, in which 25 people performed typical knowledge work (writing reports, making presentations, reading e-mail, searching for information). We manipulated their working conditions with the stressors: email interruptions and time pressure. A varied set of data was recorded: computer logging, facial expression from camera recordings, body postures from a Kinect 3D sensor and heart rate (variability) and skin conductance from body sensors. The dataset made available not only contains raw data, but also preprocessed data and extracted features. The participants' subjective experience on task load, mental effort, emotion and perceived stress was assessed with validated questionnaires as a ground truth. The resulting dataset on working behavior and affect is a valuable contribution to several research fields, such as work psychology, user modeling and context aware systems.},
booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction},
pages = {291–298},
numpages = {8},
keywords = {dataset, facial expressions, stress, body postures, computer interaction, mental state, physiology},
location = {Istanbul, Turkey},
series = {ICMI '14}
}

@inproceedings{10.1145/2666633.2666640,
author = {Chen, Lei and Leong, Chee Wee and Feng, Gary and Lee, Chong Min},
title = {Using Multimodal Cues to Analyze MLA'14 Oral Presentation Quality Corpus: Presentation Delivery and Slides Quality},
year = {2014},
isbn = {9781450304887},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2666633.2666640},
doi = {10.1145/2666633.2666640},
abstract = {The ability of making presentation slides and delivering them effectively to convey information to the audience is a task of increasing importance, particularly in the pursuit of both academic and professional career success. We envision that multimodal sensing and machine learning techniques can be employed to evaluate, and potentially help to improve the quality of the content and delivery of public presentations. To this end, we report a study using the Oral Presentation Quality Corpus provided by the 2014 Multimodal Learning Analytics (MLA) Grand Challenge. A set of multimodal features were extracted from slides, speech, posture and hand gestures, as well as head poses. We also examined the dimensionality of the human scores, which could be concisely represented by two Principal Component (PC) scores, comp1 for delivery skills and comp2 for slides quality. Several machine learning experiments were performed to predict the two PC scores using multimodal features. Our experiments suggest that multimodal cues can predict human scores on presentation tasks, and a scoring model comprising both verbal and visual features can outperform that using just a single modality.},
booktitle = {Proceedings of the 2014 ACM Workshop on Multimodal Learning Analytics Workshop and Grand Challenge},
pages = {45–52},
numpages = {8},
keywords = {educational applications, multimodal corpus, public speaking, body tracking, multimodal presentation assessment},
location = {Istanbul, Turkey},
series = {MLA '14}
}

@article{10.1145/2655691,
author = {Calabrese, Francesco and Ferrari, Laura and Blondel, Vincent D.},
title = {Urban Sensing Using Mobile Phone Network Data: A Survey of Research},
year = {2014},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2655691},
doi = {10.1145/2655691},
abstract = {The recent development of telecommunication networks is producing an unprecedented wealth of information and, as a consequence, an increasing interest in analyzing such data both from telecoms and from other stakeholders' points of view. In particular, mobile phone datasets offer access to insights into urban dynamics and human activities at an unprecedented scale and level of detail, representing a huge opportunity for research and real-world applications. This article surveys the new ideas and techniques related to the use of telecommunication data for urban sensing. We outline the data that can be collected from telecommunication networks as well as their strengths and weaknesses with a particular focus on urban sensing. We survey existing filtering and processing techniques to extract insights from this data and summarize them to provide recommendations on which datasets and techniques to use for specific urban sensing applications. Finally, we discuss a number of challenges and open research areas currently being faced in this field. We strongly believe the material and recommendations presented here will become increasingly important as mobile phone network datasets are becoming more accessible to the research community.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {25},
numpages = {20},
keywords = {Mobile phone data, data mining, urban planning, urban transportation}
}

@inproceedings{10.1145/2663204.2666271,
author = {Ringeval, Fabien and Amiriparian, Shahin and Eyben, Florian and Scherer, Klaus and Schuller, Bj\"{o}rn},
title = {Emotion Recognition in the Wild: Incorporating Voice and Lip Activity in Multimodal Decision-Level Fusion},
year = {2014},
isbn = {9781450328852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663204.2666271},
doi = {10.1145/2663204.2666271},
abstract = {In this paper, we investigate the relevance of using voice and lip activity to improve performance of audiovisual emotion recognition in unconstrained settings, as part of the 2014 Emotion Recognition in the Wild Challenge (EmotiW14). Indeed, the dataset provided by the organisers contains movie excerpts with highly challenging variability in terms of audiovisual content; e.g., speech and/or face of the subject expressing the emotion can be absent in the data. We therefore propose to tackle this issue by incorporating both voice and lip activity as additional features in a decision-level fusion. Results obtained on the blind test set show that the decision-level fusion can improve the best mono-modal approach, and that the addition of both voice and lip activity in the feature set leads to the best performance (UAR=35.27%), with an absolute improvement of 5.36% over the baseline.},
booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction},
pages = {473–480},
numpages = {8},
keywords = {multimedia, lip activity detection, emotion recognition, decision-level fusion, voice activity detection},
location = {Istanbul, Turkey},
series = {ICMI '14}
}

@inproceedings{10.1145/2663204.2666275,
author = {Dhall, Abhinav and Goecke, Roland and Joshi, Jyoti and Sikka, Karan and Gedeon, Tom},
title = {Emotion Recognition In The Wild Challenge 2014: Baseline, Data and Protocol},
year = {2014},
isbn = {9781450328852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663204.2666275},
doi = {10.1145/2663204.2666275},
abstract = {The Second Emotion Recognition In The Wild Challenge (EmotiW) 2014 consists of an audio-video based emotion classification challenge, which mimics the real-world conditions. Traditionally, emotion recognition has been performed on data captured in constrained lab-controlled like environment. While this data was a good starting point, such lab controlled data poorly represents the environment and conditions faced in real-world situations. With the exponential increase in the number of video clips being uploaded online, it is worthwhile to explore the performance of emotion recognition methods that work `in the wild'. The goal of this Grand Challenge is to carry forward the common platform defined during EmotiW 2013, for evaluation of emotion recognition methods in real-world conditions. The database in the 2014 challenge is the Acted Facial Expression In Wild (AFEW) 4.0, which has been collected from movies showing close-to-real-world conditions. The paper describes the data partitions, the baseline method and the experimental protocol.},
booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction},
pages = {461–466},
numpages = {6},
keywords = {emotiw challenge, audio-video data corpus, emotion recognition in the wild},
location = {Istanbul, Turkey},
series = {ICMI '14}
}

@inproceedings{10.1145/2663204.2666279,
author = {Sidorov, Maxim and Minker, Wolfgang},
title = {Emotion Recognition in Real-World Conditions with Acoustic and Visual Features},
year = {2014},
isbn = {9781450328852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663204.2666279},
doi = {10.1145/2663204.2666279},
abstract = {There is an enormous number of potential applications of the system which is capable to recognize human emotions. Such opportunity can be useful in various applications, e.g., improvement of Spoken Dialogue Systems (SDSs) or monitoring agents in call-centers. Therefore, the Emotion Recognition In The Wild Challenge 2014 (EmotiW 2014) is focused on estimating emotions in real-world situations. This study presents the results of multimodal emotion recognition based on support vector classifier. The described approach results in 41.77% of overall classification accuracy in the multimodal case. The obtained result is more than 17% higher than the baseline result for multimodal approach.},
booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction},
pages = {521–524},
numpages = {4},
keywords = {support vector machine, feature-based fusion, facial expression, audio-video data corpus},
location = {Istanbul, Turkey},
series = {ICMI '14}
}

@inproceedings{10.1145/2663204.2666270,
author = {Grosicki, Micha\l{}},
title = {Neural Networks for Emotion Recognition in the Wild},
year = {2014},
isbn = {9781450328852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663204.2666270},
doi = {10.1145/2663204.2666270},
abstract = {In this paper we present neural networks based method for emotion recognition. Proposed model was developed as part of 2014 Emotion Recognition in the Wild Challenge. It is composed of modality specific neural networks, which where trained separately on audio and video data extracted from short video clips taken from various movies. Each network was trained on frame-level data, which in later stages were aggregated by simple averaging of predicted class distributions for each clip. In the next stage various techniques for combining modalities where investigated with the best being support vector machine with RBF kernel. Our method achieved accuracy of 37.84%, which is better than 33.7% obtained by the best baseline model provided by organisers.},
booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction},
pages = {467–472},
numpages = {6},
keywords = {dropout, multimodal, denoising auto-encoders, neural networks},
location = {Istanbul, Turkey},
series = {ICMI '14}
}

@inproceedings{10.1145/2663204.2666278,
author = {Huang, Xiaohua and He, Qiuhai and Hong, Xiaopeng and Zhao, Guoying and Pietikainen, Matti},
title = {Improved Spatiotemporal Local Monogenic Binary Pattern for Emotion Recognition in The Wild},
year = {2014},
isbn = {9781450328852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663204.2666278},
doi = {10.1145/2663204.2666278},
abstract = {Local binary pattern from three orthogonal planes (LBP-TOP) has been widely used in emotion recognition in the wild. However, it suffers from illumination and pose changes. This paper mainly focuses on the robustness of LBP-TOP to unconstrained environment. Recent proposed method, spatiotemporal local monogenic binary pattern (STLMBP), was verified to work promisingly in different illumination conditions. Thus this paper proposes an improved spatiotemporal feature descriptor based on STLMBP. The improved descriptor uses not only magnitude and orientation, but also the phase information, which provide complementary information. In detail, the magnitude, orientation and phase images are obtained by using an effective monogenic filter, and multiple feature vectors are finally fused by multiple kernel learning. STLMBP and the proposed method are evaluated in the Acted Facial Expression in the Wild as part of the 2014 Emotion Recognition in the Wild Challenge. They achieve competitive results, with an accuracy gain of 6.35% and 7.65% above the challenge baseline (LBP-TOP) over video.},
booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction},
pages = {514–520},
numpages = {7},
keywords = {monogenic signal analysis, spatiotemporal feature, multiple kernel learning},
location = {Istanbul, Turkey},
series = {ICMI '14}
}

@inproceedings{10.1145/2663204.2663236,
author = {Mart\'{\i}nez, H\'{e}ctor P. and Yannakakis, Georgios N.},
title = {Deep Multimodal Fusion: Combining Discrete Events and Continuous Signals},
year = {2014},
isbn = {9781450328852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663204.2663236},
doi = {10.1145/2663204.2663236},
abstract = {Multimodal datasets often feature a combination of continuous signals and a series of discrete events. For instance, when studying human behaviour it is common to annotate actions performed by the participant over several other modalities such as video recordings of the face or physiological signals. These events are nominal, not frequent and are not sampled at a continuous rate while signals are numeric and often sampled at short fixed intervals. This fundamentally different nature complicates the analysis of the relation among these modalities which is often studied after each modality has been summarised or reduced. This paper investigates a novel approach to model the relation between such modality types bypassing the need for summarising each modality independently of each other. For that purpose, we introduce a deep learning model based on convolutional neural networks that is adapted to process multiple modalities at different time resolutions we name deep multimodal fusion. Furthermore, we introduce and compare three alternative methods (convolution, training and pooling fusion) to integrate sequences of events with continuous signals within this model. We evaluate deep multimodal fusion using a game user dataset where player physiological signals are recorded in parallel with game events. Results suggest that the proposed architecture can appropriately capture multimodal information as it yields higher prediction accuracies compared to single-modality models. In addition, it appears that pooling fusion, based on a novel filter-pooling method provides the more effective fusion approach for the investigated types of data.},
booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction},
pages = {34–41},
numpages = {8},
keywords = {physiology, convolutional neural networks, sequence fusion, deep learning, auto-encoders, multimodal fusion, pooling method, behaviour, sequence classification},
location = {Istanbul, Turkey},
series = {ICMI '14}
}

@inproceedings{10.1145/2663204.2663229,
author = {Abouelenien, Mohamed and P\'{e}rez-Rosas, Veronica and Mihalcea, Rada and Burzo, Mihai},
title = {Deception Detection Using a Multimodal Approach},
year = {2014},
isbn = {9781450328852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663204.2663229},
doi = {10.1145/2663204.2663229},
abstract = {In this paper we address the automatic identification of deceit by using a multimodal approach. We collect deceptive and truthful responses using a multimodal setting where we acquire data using a microphone, a thermal camera, as well as physiological sensors. Among all available modalities, we focus on three modalities namely, language use, physiological response, and thermal sensing. To our knowledge, this is the first work to integrate these specific modalities to detect deceit. Several experiments are carried out in which we first select representative features for each modality, and then we analyze joint models that integrate several modalities. The experimental results show that the combination of features from different modalities significantly improves the detection of deceptive behaviors as compared to the use of one modality at a time. Moreover, the use of non-contact modalities proved to be comparable with and sometimes better than existing contact-based methods. The proposed method increases the efficiency of detecting deceit by avoiding human involvement in an attempt to move towards a completely automated non-invasive deception detection process.},
booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction},
pages = {58–65},
numpages = {8},
keywords = {multimodal processing, deception detection},
location = {Istanbul, Turkey},
series = {ICMI '14}
}

@inproceedings{10.1145/2663204.2663264,
author = {Grafsgaard, Joseph F. and Wiggins, Joseph B. and Vail, Alexandria Katarina and Boyer, Kristy Elizabeth and Wiebe, Eric N. and Lester, James C.},
title = {The Additive Value of Multimodal Features for Predicting Engagement, Frustration, and Learning during Tutoring},
year = {2014},
isbn = {9781450328852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663204.2663264},
doi = {10.1145/2663204.2663264},
abstract = {Detecting learning-centered affective states is difficult, yet crucial for adapting most effectively to users. Within tutoring in particular, the combined context of student task actions and tutorial dialogue shape the student's affective experience. As we move toward detecting affect, we may also supplement the task and dialogue streams with rich sensor data. In a study of introductory computer programming tutoring, human tutors communicated with students through a text-based interface. Automated approaches were leveraged to annotate dialogue, task actions, facial movements, postural positions, and hand-to-face gestures. These dialogue, nonverbal behavior, and task action input streams were then used to predict retrospective student self-reports of engagement and frustration, as well as pretest/posttest learning gains. The results show that the combined set of multimodal features is most predictive, indicating an additive effect. Additionally, the findings demonstrate that the role of nonverbal behavior may depend on the dialogue and task context in which it occurs. This line of research identifies contextual and behavioral cues that may be leveraged in future adaptive multimodal systems.},
booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction},
pages = {42–49},
numpages = {8},
keywords = {engagement, gesture, tutorial dialogue, frustration, posture, facial expression, multimodal, affect},
location = {Istanbul, Turkey},
series = {ICMI '14}
}

@inproceedings{10.1145/2663204.2663260,
author = {Park, Sunghyun and Shim, Han Suk and Chatterjee, Moitreya and Sagae, Kenji and Morency, Louis-Philippe},
title = {Computational Analysis of Persuasiveness in Social Multimedia: A Novel Dataset and Multimodal Prediction Approach},
year = {2014},
isbn = {9781450328852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663204.2663260},
doi = {10.1145/2663204.2663260},
abstract = {Our lives are heavily influenced by persuasive communication, and it is essential in almost any types of social interactions from business negotiation to conversation with our friends and family. With the rapid growth of social multimedia websites, it is becoming ever more important and useful to understand persuasiveness in the context of social multimedia content online. In this paper, we introduce our newly created multimedia corpus of 1,000 movie review videos obtained from a social multimedia website called ExpoTV.com, which will be made freely available to the research community. Our research results presented here revolve around the following 3 main research hypotheses. Firstly, we show that computational descriptors derived from verbal and nonverbal behavior can be predictive of persuasiveness. We further show that combining descriptors from multiple communication modalities (audio, text and visual) improve the prediction performance compared to using those from single modality alone. Secondly, we investigate if having prior knowledge of a speaker expressing a positive or negative opinion helps better predict the speaker's persuasiveness. Lastly, we show that it is possible to make comparable prediction of persuasiveness by only looking at thin slices (shorter time windows) of a speaker's behavior.},
booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction},
pages = {50–57},
numpages = {8},
keywords = {persuasive opinion multimedia corpus, prediction, persuasion, multimodal, social multimedia, persuasiveness, pom corpus},
location = {Istanbul, Turkey},
series = {ICMI '14}
}

@inproceedings{10.1109/DataCloud.2014.8,
author = {Wu, Tak-Lon and Koppula, Abhilash and Qiu, Judy},
title = {Integrating Pig with Harp to Support Iterative Applications with Fast Cache and Customized Communication},
year = {2014},
isbn = {9781479970346},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/DataCloud.2014.8},
doi = {10.1109/DataCloud.2014.8},
abstract = {Use of high-level scripting languages to solve big data problems has become a mainstream approach for sophisticated machine learning data analysis. Often data must be used in several steps of a computation to complete a full task. Composing default data transformation operators with the standard Hadoop MapReduce runtime is very convenient. However, the current strategy of using high-level languages to support iterative applications with Hadoop MapReduce relies on an external wrapper script in other languages such as Python and Groovy, which causes significant performance loss when restarting mappers and reducers between jobs. In this paper, we reduce the extra job startup overheads by integrating Apache Pig with the high-performance Hadoop plug-in Harp developed at Indiana University. This provides fast data caching and customized communication patterns among iterations for data analysis. The results show performance improvements of factors from 2 to 5.},
booktitle = {Proceedings of the 5th International Workshop on Data-Intensive Computing in the Clouds},
pages = {33–39},
numpages = {7},
keywords = {iterative algorithms, Pig, big data, MapReduce, language},
location = {New Orleans, Louisiana},
series = {DataCloud '14}
}

@inproceedings{10.1109/SC.2014.18,
author = {Agelastos, Anthony and Allan, Benjamin and Brandt, Jim and Cassella, Paul and Enos, Jeremy and Fullop, Joshi and Gentile, Ann and Monk, Steve and Naksinehaboon, Nichamon and Ogden, Jeff and Rajan, Mahesh and Showerman, Michael and Stevenson, Joel and Taerat, Narate and Tucker, Tom},
title = {The Lightweight Distributed Metric Service: A Scalable Infrastructure for Continuous Monitoring of Large Scale Computing Systems and Applications},
year = {2014},
isbn = {9781479955008},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC.2014.18},
doi = {10.1109/SC.2014.18},
abstract = {Understanding how resources of High Performance Compute platforms are utilized by applications both individually and as a composite is key to application and platform performance. Typical system monitoring tools do not provide sufficient fidelity while application profiling tools do not capture the complex interplay between applications competing for shared resources. To gain new insights, monitoring tools must run continuously, system wide, at frequencies appropriate to the metrics of interest while having minimal impact on application performance.We introduce the Lightweight Distributed Metric Service for scalable, lightweight monitoring of large scale computing systems and applications. We describe issues and constraints guiding deployment in Sandia National Laboratories' capacity computing environment and on the National Center for Supercomputing Applications' Blue Waters platform including motivations, metrics of choice, and requirements relating to the scale and specialized nature of Blue Waters. We address monitoring overhead and impact on application performance and provide illustrative profiling results.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
pages = {154–165},
numpages = {12},
keywords = {monitoring, resource monitoring, resource management},
location = {New Orleans, Louisana},
series = {SC '14}
}

@inproceedings{10.1109/SC.2014.43,
author = {Misra, Sanchit and Md., Vasimuddin and Pamnany, Kiran and Chockalingam, Sriram P. and Dong, Yong and Xie, Min and Aluru, Maneesha R. and Aluru, Srinivas},
title = {Parallel Bayesian Network Structure Learning for Genome-Scale Gene Networks},
year = {2014},
isbn = {9781479955008},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC.2014.43},
doi = {10.1109/SC.2014.43},
abstract = {Learning Bayesian networks is NP-hard. Even with recent progress in heuristic and parallel algorithms, modeling capabilities still fall short of the scale of the problems encountered. In this paper, we present a massively parallel method for Bayesian network structure learning, and demonstrate its capability by constructing genome-scale gene networks of the model plant Arabidopsis thaliana from over 168.5 million gene expression values. We report strong scaling efficiency of 75% and demonstrate scaling to 1.57 million cores of the Tianhe-2 supercomputer. Our results constitute three and five orders of magnitude increase over previously published results in the scale of data analyzed and computations performed, respectively. We achieve this through algorithmic innovations, using efficient techniques to distribute work across all compute nodes, all available processors and coprocessors on each node, all available threads on each processor and coprocessor, and vectorization techniques to maximize single thread performance.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
pages = {461–472},
numpages = {12},
keywords = {bayesian networks, gene networks, systems biology, parallel machine learning},
location = {New Orleans, Louisana},
series = {SC '14}
}

@inproceedings{10.1145/2666253.2666257,
author = {Hammal, Zakia and Cohn, Jeffrey F.},
title = {Towards Multimodal Pain Assessment for Research and Clinical Use},
year = {2014},
isbn = {9781450306157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2666253.2666257},
doi = {10.1145/2666253.2666257},
abstract = {Pain is a complex phenomenon that requires consideration of individual differences in the index person, those with whom they interact, and the social context. Pain displays vary, with some patients highly expressive regarding their pain and others exhibiting minimal discomfort. Given myriad individual differences among patients, their families, and healthcare providers, pain is often poorly assessed, which can result in improper treatment. An automatic and reliable assessment of the onset, intensity, and pattern of occurrence of pain would help ensure the best possible treatment. Given these potential medical implications, increasing efforts are underway to develop intelligent systems to enable objective measurement and monitoring of pain.},
booktitle = {Proceedings of the 2014 Workshop on Roadmapping the Future of Multimodal Interaction Research Including Business Opportunities and Challenges},
pages = {13–17},
numpages = {5},
keywords = {Affective Computing, Pain, Pain Intensity},
location = {Istanbul, Turkey},
series = {RFMIR '14}
}

@inproceedings{10.1145/2666253.2666258,
author = {Hammal, Zakia and Cohn, Jeffrey F.},
title = {Intra- and Interpersonal Functions of Head Motion in Emotion Communication},
year = {2014},
isbn = {9781450306157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2666253.2666258},
doi = {10.1145/2666253.2666258},
abstract = {In affective computing, head motion too often has been considered only a nuisance variable, something to control when aligning face images for analysis of facial expression or identity. Yet, recent research suggests that head motion is critical to the communication of emotion and the regulation of face-to-face interaction. Using a generic head tracker, strong relationships between head motion and emotion at both the individual and dyadic levels were found in studies of distressed couples and mother-infant dyads. These findings raise key research questions about head motion and other nonverbal displays: How extensively do they communicate emotion and psychological distress or disorder? What is their temporal coordination with facial expression? How are they coordinated interpersonally? Windowed cross-correlation and actor-partner analysis are proposed for the latter.},
booktitle = {Proceedings of the 2014 Workshop on Roadmapping the Future of Multimodal Interaction Research Including Business Opportunities and Challenges},
pages = {19–22},
numpages = {4},
keywords = {interpersonal interaction, head motion, emotion communication},
location = {Istanbul, Turkey},
series = {RFMIR '14}
}

@inproceedings{10.1145/2668056.2668060,
author = {van Wingerden, Siewart and Uebbing, Tobias J. and Jung, Merel M. and Poel, Mannes},
title = {A Neural Network Based Approach to Social Touch Classification},
year = {2014},
isbn = {9781450301244},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2668056.2668060},
doi = {10.1145/2668056.2668060},
abstract = {Touch is an important interaction modality in social interaction, for instance touch can communicate emotions and can intensify emotions communicated by other modalities. In this paper we explore the use of Neural Networks for the classification of touch. The exploration and assessment of Neural Networks (NNs) is based on the Corpus of Social Touch established by Jung et al. This corpus was split in a train set (65%) and test set (35%), the train set was used to find the optimal parameters for the NN and for training the final model. Also different feature sets were investigated; the basic feature set included in the corpus, energy-histogram and dynamical features. Using all features led to the best performance of 64% on the test set, using a NN consisting of one hidden layer with 46 neurones. The confusion matrix showed the expected high confusion between pat-tap and grab-squeeze. A leave-one-subject-out approach lead to a performance of 54%, which is comparable with the results of Jung et al.},
booktitle = {Proceedings of the 2014 Workshop on Emotion Representation and Modelling in Human-Computer-Interaction-Systems},
pages = {7–12},
numpages = {6},
keywords = {neural networks, social touch, touch gesture recognition},
location = {Istanbul, Turkey},
series = {ERM4HCI '14}
}

@inproceedings{10.1145/2668056.2668058,
author = {Lee, Eunjung and Kim, Gyu-Wan and Kim, Byung-Soo and Kang, Mi-Ae},
title = {A Design Platform for Emotion-Aware User Interfaces},
year = {2014},
isbn = {9781450301244},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2668056.2668058},
doi = {10.1145/2668056.2668058},
abstract = {Machine recognition of emotion has become one of the main targets for developing next-generation user interaction in computer systems. While affect recognition technology has achieved substantial progress recently, the application of user emotion recognition to software user interface is in its early stages. In this paper, we describe the development of an emotion-aware user interface with a focus on visual appearance. Further, we propose an emotion-aware UI-authoring platform that helps designers create emotion-aware visual effects. In order to demonstrate its feasibility, we developed a prototype framework built with the authoring tool DAT4UX. The tool can integrate the resulting design into a mobile application equipped with emotion recognition facility. A proof-of-concept application featuring an emotion-aware interface is developed using the tool.},
booktitle = {Proceedings of the 2014 Workshop on Emotion Representation and Modelling in Human-Computer-Interaction-Systems},
pages = {19–24},
numpages = {6},
keywords = {design tool, mobile intelligence, emotion-aware, user interface},
location = {Istanbul, Turkey},
series = {ERM4HCI '14}
}

@inproceedings{10.1145/2666253.2666264,
author = {Potamianos, Alexandros},
title = {Cognitive Multimodal Processing: From Signal to Behavior},
year = {2014},
isbn = {9781450306157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2666253.2666264},
doi = {10.1145/2666253.2666264},
abstract = {Affective computing, social and behavioral signal processing are emerging research disciplines that attempt to automatically label the emotional, social and cognitive state of humans using features extracted from audio-visual streams. I argue that this monumental task cannot succeed unless the particularities of the human cognitive processing are incorporated into our models, especially given that often the quantities we are called to model are either biased cognitive abstractions of the real world or altogether fictional creations of our cognition. A variety of cognitive processes that make computational modeling especially challenging are outlined herein, notably: 1) (joint) attention and saliency, 2) common ground, conceptual semantic spaces and representation learning, 3) fusion across time, modalities and cognitive representation layers, and 4) dual-system processing (system one vs. system two) and cognitive decision non-linearities. The grand challenges are outlined and examples are given illustrating how to design models that are both high-performing and respect basic cognitive organization principles. It is shown that such models can achieve good generalization and representation power, as well as model cognitive biases, a prerequisite for modeling and predicting human behavior.},
booktitle = {Proceedings of the 2014 Workshop on Roadmapping the Future of Multimodal Interaction Research Including Business Opportunities and Challenges},
pages = {27–34},
numpages = {8},
keywords = {dual process theory, social signal processing, multimodal fusion, concept representations, cognitive models, behavioral signal processing, affective computing, distributional semantic models},
location = {Istanbul, Turkey},
series = {RFMIR '14}
}

@inproceedings{10.1145/2666253.2666260,
author = {Valstar, Michel},
title = {Automatic Behaviour Understanding in Medicine},
year = {2014},
isbn = {9781450306157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2666253.2666260},
doi = {10.1145/2666253.2666260},
abstract = {Now that Affective Computing and Social Signal Processing methods are becoming increasingly robust and accurate, novel areas of applications with significant societal impact are opening up for exploration. Perhaps one of the most promising areas is the application of automatic expressive behaviour understanding to help diagnose, monitor, and treat medical conditions that themselves alter a person's social and affective signals. This work argues that this is now essentially a new area of research, called behaviomedics. It gives a definition of the area, discusses the most important groups of medical conditions that could benefit from this, and makes suggestions for future directions.},
booktitle = {Proceedings of the 2014 Workshop on Roadmapping the Future of Multimodal Interaction Research Including Business Opportunities and Challenges},
pages = {57–60},
numpages = {4},
keywords = {social signal processing, medicine, affective computing},
location = {Istanbul, Turkey},
series = {RFMIR '14}
}

@inproceedings{10.1145/2668056.2668057,
author = {Chen, Lei and Yoon, Su-Youn and Leong, Chee Wee and Martin, Michelle and Ma, Min},
title = {An Initial Analysis of Structured Video Interviews by Using Multimodal Emotion Detection},
year = {2014},
isbn = {9781450301244},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2668056.2668057},
doi = {10.1145/2668056.2668057},
abstract = {Recently online video interviews have been increasingly used in the employment process. Though several automatic techniques have emerged to analyze the interview videos, so far, only simple emotion analyses have been attempted, e.g. counting the number of smiles on the face of an interviewee. In this paper, we report our initial study of employing advanced multimodal emotion detection approaches for the purpose of measuring performance on an interview task that elicits emotion. On an acted interview corpus we created, we performed our evaluations using a Speech-based Emotion Recognition (SER) system, as well as an off-the-shelf facial expression analysis toolkit (FACET). While the results obtained suggest the promise of using FACET for emotion detection, the benefits of employing the SER are somewhat limited.},
booktitle = {Proceedings of the 2014 Workshop on Emotion Representation and Modelling in Human-Computer-Interaction-Systems},
pages = {1–6},
numpages = {6},
keywords = {multimodal assessment, job applications, facial expression, employment interviews, speech, emotion},
location = {Istanbul, Turkey},
series = {ERM4HCI '14}
}

