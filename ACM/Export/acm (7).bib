@inproceedings{10.1145/2150976.2150982,
author = {Ferdman, Michael and Adileh, Almutaz and Kocberber, Onur and Volos, Stavros and Alisafaee, Mohammad and Jevdjic, Djordje and Kaynak, Cansu and Popescu, Adrian Daniel and Ailamaki, Anastasia and Falsafi, Babak},
title = {Clearing the Clouds: A Study of Emerging Scale-out Workloads on Modern Hardware},
year = {2012},
isbn = {9781450307598},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2150976.2150982},
doi = {10.1145/2150976.2150982},
abstract = {Emerging scale-out workloads require extensive amounts of computational resources. However, data centers using modern server hardware face physical constraints in space and power, limiting further expansion and calling for improvements in the computational density per server and in the per-operation energy. Continuing to improve the computational resources of the cloud while staying within physical constraints mandates optimizing server efficiency to ensure that server hardware closely matches the needs of scale-out workloads.In this work, we introduce CloudSuite, a benchmark suite of emerging scale-out workloads. We use performance counters on modern servers to study scale-out workloads, finding that today's predominant processor micro-architecture is inefficient for running these workloads. We find that inefficiency comes from the mismatch between the workload needs and modern processors, particularly in the organization of instruction and data memory systems and the processor core micro-architecture. Moreover, while today's predominant micro-architecture is inefficient when executing scale-out workloads, we find that continuing the current trends will further exacerbate the inefficiency in the future. In this work, we identify the key micro-architectural needs of scale-out workloads, calling for a change in the trajectory of server processors that would lead to improved computational density and power efficiency in data centers.},
booktitle = {Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {37–48},
numpages = {12},
keywords = {cloud computing, workload characterization, design insights, architectural evaluation},
location = {London, England, UK},
series = {ASPLOS XVII}
}

@article{10.1145/2189750.2150982,
author = {Ferdman, Michael and Adileh, Almutaz and Kocberber, Onur and Volos, Stavros and Alisafaee, Mohammad and Jevdjic, Djordje and Kaynak, Cansu and Popescu, Adrian Daniel and Ailamaki, Anastasia and Falsafi, Babak},
title = {Clearing the Clouds: A Study of Emerging Scale-out Workloads on Modern Hardware},
year = {2012},
issue_date = {March 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {1},
issn = {0163-5964},
url = {https://doi.org/10.1145/2189750.2150982},
doi = {10.1145/2189750.2150982},
abstract = {Emerging scale-out workloads require extensive amounts of computational resources. However, data centers using modern server hardware face physical constraints in space and power, limiting further expansion and calling for improvements in the computational density per server and in the per-operation energy. Continuing to improve the computational resources of the cloud while staying within physical constraints mandates optimizing server efficiency to ensure that server hardware closely matches the needs of scale-out workloads.In this work, we introduce CloudSuite, a benchmark suite of emerging scale-out workloads. We use performance counters on modern servers to study scale-out workloads, finding that today's predominant processor micro-architecture is inefficient for running these workloads. We find that inefficiency comes from the mismatch between the workload needs and modern processors, particularly in the organization of instruction and data memory systems and the processor core micro-architecture. Moreover, while today's predominant micro-architecture is inefficient when executing scale-out workloads, we find that continuing the current trends will further exacerbate the inefficiency in the future. In this work, we identify the key micro-architectural needs of scale-out workloads, calling for a change in the trajectory of server processors that would lead to improved computational density and power efficiency in data centers.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {37–48},
numpages = {12},
keywords = {design insights, workload characterization, architectural evaluation, cloud computing}
}

@article{10.1145/2248487.2150982,
author = {Ferdman, Michael and Adileh, Almutaz and Kocberber, Onur and Volos, Stavros and Alisafaee, Mohammad and Jevdjic, Djordje and Kaynak, Cansu and Popescu, Adrian Daniel and Ailamaki, Anastasia and Falsafi, Babak},
title = {Clearing the Clouds: A Study of Emerging Scale-out Workloads on Modern Hardware},
year = {2012},
issue_date = {April 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2248487.2150982},
doi = {10.1145/2248487.2150982},
abstract = {Emerging scale-out workloads require extensive amounts of computational resources. However, data centers using modern server hardware face physical constraints in space and power, limiting further expansion and calling for improvements in the computational density per server and in the per-operation energy. Continuing to improve the computational resources of the cloud while staying within physical constraints mandates optimizing server efficiency to ensure that server hardware closely matches the needs of scale-out workloads.In this work, we introduce CloudSuite, a benchmark suite of emerging scale-out workloads. We use performance counters on modern servers to study scale-out workloads, finding that today's predominant processor micro-architecture is inefficient for running these workloads. We find that inefficiency comes from the mismatch between the workload needs and modern processors, particularly in the organization of instruction and data memory systems and the processor core micro-architecture. Moreover, while today's predominant micro-architecture is inefficient when executing scale-out workloads, we find that continuing the current trends will further exacerbate the inefficiency in the future. In this work, we identify the key micro-architectural needs of scale-out workloads, calling for a change in the trajectory of server processors that would lead to improved computational density and power efficiency in data centers.},
journal = {SIGPLAN Not.},
month = mar,
pages = {37–48},
numpages = {12},
keywords = {workload characterization, architectural evaluation, design insights, cloud computing}
}

@inproceedings{10.1145/2150976.2150989,
author = {Hwang, Andy A. and Stefanovici, Ioan A. and Schroeder, Bianca},
title = {Cosmic Rays Don't Strike Twice: Understanding the Nature of DRAM Errors and the Implications for System Design},
year = {2012},
isbn = {9781450307598},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2150976.2150989},
doi = {10.1145/2150976.2150989},
abstract = {Main memory is one of the leading hardware causes for machine crashes in today's datacenters. Designing, evaluating and modeling systems that are resilient against memory errors requires a good understanding of the underlying characteristics of errors in DRAM in the field. While there have recently been a few first studies on DRAM errors in production systems, these have been too limited in either the size of the data set or the granularity of the data to conclusively answer many of the open questions on DRAM errors. Such questions include, for example, the prevalence of soft errors compared to hard errors, or the analysis of typical patterns of hard errors. In this paper, we study data on DRAM errors collected on a diverse range of production systems in total covering nearly 300 terabyte-years of main memory. As a first contribution, we provide a detailed analytical study of DRAM error characteristics, including both hard and soft errors. We find that a large fraction of DRAM errors in the field can be attributed to hard errors and we provide a detailed analytical study of their characteristics. As a second contribution, the paper uses the results from the measurement study to identify a number of promising directions for designing more resilient systems and evaluates the potential of different protection mechanisms in the light of realistic error patterns. One of our findings is that simple page retirement policies might be able to mask a large number of DRAM errors in production systems, while sacrificing only a negligible fraction of the total DRAM in the system.},
booktitle = {Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {111–122},
numpages = {12},
keywords = {uncorrectable errors, reliability, field study, correctable errors, DRAM errors},
location = {London, England, UK},
series = {ASPLOS XVII}
}

@article{10.1145/2189750.2150989,
author = {Hwang, Andy A. and Stefanovici, Ioan A. and Schroeder, Bianca},
title = {Cosmic Rays Don't Strike Twice: Understanding the Nature of DRAM Errors and the Implications for System Design},
year = {2012},
issue_date = {March 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {1},
issn = {0163-5964},
url = {https://doi.org/10.1145/2189750.2150989},
doi = {10.1145/2189750.2150989},
abstract = {Main memory is one of the leading hardware causes for machine crashes in today's datacenters. Designing, evaluating and modeling systems that are resilient against memory errors requires a good understanding of the underlying characteristics of errors in DRAM in the field. While there have recently been a few first studies on DRAM errors in production systems, these have been too limited in either the size of the data set or the granularity of the data to conclusively answer many of the open questions on DRAM errors. Such questions include, for example, the prevalence of soft errors compared to hard errors, or the analysis of typical patterns of hard errors. In this paper, we study data on DRAM errors collected on a diverse range of production systems in total covering nearly 300 terabyte-years of main memory. As a first contribution, we provide a detailed analytical study of DRAM error characteristics, including both hard and soft errors. We find that a large fraction of DRAM errors in the field can be attributed to hard errors and we provide a detailed analytical study of their characteristics. As a second contribution, the paper uses the results from the measurement study to identify a number of promising directions for designing more resilient systems and evaluates the potential of different protection mechanisms in the light of realistic error patterns. One of our findings is that simple page retirement policies might be able to mask a large number of DRAM errors in production systems, while sacrificing only a negligible fraction of the total DRAM in the system.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {111–122},
numpages = {12},
keywords = {reliability, uncorrectable errors, correctable errors, DRAM errors, field study}
}

@article{10.1145/2248487.2150989,
author = {Hwang, Andy A. and Stefanovici, Ioan A. and Schroeder, Bianca},
title = {Cosmic Rays Don't Strike Twice: Understanding the Nature of DRAM Errors and the Implications for System Design},
year = {2012},
issue_date = {April 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2248487.2150989},
doi = {10.1145/2248487.2150989},
abstract = {Main memory is one of the leading hardware causes for machine crashes in today's datacenters. Designing, evaluating and modeling systems that are resilient against memory errors requires a good understanding of the underlying characteristics of errors in DRAM in the field. While there have recently been a few first studies on DRAM errors in production systems, these have been too limited in either the size of the data set or the granularity of the data to conclusively answer many of the open questions on DRAM errors. Such questions include, for example, the prevalence of soft errors compared to hard errors, or the analysis of typical patterns of hard errors. In this paper, we study data on DRAM errors collected on a diverse range of production systems in total covering nearly 300 terabyte-years of main memory. As a first contribution, we provide a detailed analytical study of DRAM error characteristics, including both hard and soft errors. We find that a large fraction of DRAM errors in the field can be attributed to hard errors and we provide a detailed analytical study of their characteristics. As a second contribution, the paper uses the results from the measurement study to identify a number of promising directions for designing more resilient systems and evaluates the potential of different protection mechanisms in the light of realistic error patterns. One of our findings is that simple page retirement policies might be able to mask a large number of DRAM errors in production systems, while sacrificing only a negligible fraction of the total DRAM in the system.},
journal = {SIGPLAN Not.},
month = mar,
pages = {111–122},
numpages = {12},
keywords = {DRAM errors, correctable errors, reliability, field study, uncorrectable errors}
}

@article{10.1145/2134203.2134206,
author = {Kastanis, Iason and Slater, Mel},
title = {Reinforcement Learning Utilizes Proxemics: An Avatar Learns to Manipulate the Position of People in Immersive Virtual Reality},
year = {2012},
issue_date = {March 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
issn = {1544-3558},
url = {https://doi.org/10.1145/2134203.2134206},
doi = {10.1145/2134203.2134206},
abstract = {A reinforcement learning (RL) method was used to train a virtual character to move participants to a specified location. The virtual environment depicted an alleyway displayed through a wide field-of-view head-tracked stereo head-mounted display. Based on proxemics theory, we predicted that when the character approached within a personal or intimate distance to the participants, they would be inclined to move backwards out of the way. We carried out a between-groups experiment with 30 female participants, with 10 assigned arbitrarily to each of the following three groups: In the Intimate condition the character could approach within 0.38m and in the Social condition no nearer than 1.2m. In the Random condition the actions of the virtual character were chosen randomly from among the same set as in the RL method, and the virtual character could approach within 0.38m. The experiment continued in each case until the participant either reached the target or 7 minutes had elapsed. The distributions of the times taken to reach the target showed significant differences between the three groups, with 9 out of 10 in the Intimate condition reaching the target significantly faster than the 6 out of 10 who reached the target in the Social condition. Only 1 out of 10 in the Random condition reached the target. The experiment is an example of applied presence theory: we rely on the many findings that people tend to respond realistically in immersive virtual environments, and use this to get people to achieve a task of which they had been unaware. This method opens up the door for many such applications where the virtual environment adapts to the responses of the human participants with the aim of achieving particular goals.},
journal = {ACM Trans. Appl. Percept.},
month = mar,
articleno = {3},
numpages = {15},
keywords = {proxemics, virtual characters, avatars, Human-computer interaction}
}

@inproceedings{10.1145/2157689.2157811,
author = {Leite, Iolanda and Castellano, Ginevra and Pereira, Andr\'{e} and Martinho, Carlos and Paiva, Ana},
title = {Modelling Empathic Behaviour in a Robotic Game Companion for Children: An Ethnographic Study in Real-World Settings},
year = {2012},
isbn = {9781450310635},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2157689.2157811},
doi = {10.1145/2157689.2157811},
abstract = {The idea of autonomous social robots capable of assisting us in our daily lives is becoming more real every day. However, there are still many open issues regarding the social capabilities that those robots should have in order to make daily interactions with humans more natural. For example, the role of affective interactions is still unclear. This paper presents an ethnographic study conducted in an elementary school where 40 children interacted with a social robot capable of recognising and responding empathically to some of the children's affective states. The findings suggest that the robot's empathic behaviour affected positively how children perceived the robot. However, the empathic behaviours should be selected carefully, under the risk of having the opposite effect. The target application scenario and the particular preferences of children seem to influence the degree of empathy that social robots should be endowed with.},
booktitle = {Proceedings of the Seventh Annual ACM/IEEE International Conference on Human-Robot Interaction},
pages = {367–374},
numpages = {8},
keywords = {affect recognition, social robots, children, empathy},
location = {Boston, Massachusetts, USA},
series = {HRI '12}
}

@inproceedings{10.5555/2492708.2492755,
author = {Bartolini, Andrea and Sadri, MohammadSadegh and Furst, John-Nicholas and Coskun, Ayse Kivilcim and Benini, Luca},
title = {Quantifying the Impact of Frequency Scaling on the Energy Efficiency of the Single-Chip Cloud Computer},
year = {2012},
isbn = {9783981080186},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {Dynamic frequency and voltage scaling (DVFS) techniques have been widely used for meeting energy constraints. Single-chip many-core systems bring new challenges owing to the large number of operating points and the shift to message passing interface (MPI) from shared memory communication. DVFS, however, has been mostly studied on single-chip systems with one or few cores, without considering the impact of the communication among cores. This paper evaluates the impact of frequency scaling on the performance and power of many-core systems with MPI. We conduct experiments on the Single-Chip Cloud Computer (SCC), an experimental many-core processor developed by Intel. The paper first introduces the run-time monitoring infrastructure and the application suite we have designed for an in-depth evaluation of the SCC. We provide an extensive analysis quantifying the effects of frequency perturbations on performance and energy efficiency. Experimental results show that run-time communication patterns lead to significant differences in power/performance tradeoffs in many-core systems with MPI.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {181–186},
numpages = {6},
location = {Dresden, Germany},
series = {DATE '12}
}

@inproceedings{10.1145/2160673.2160679,
author = {Chongthammakun, Radaphat and Pal, Joyojeet},
title = {ICTs and Development in the Thai Bureaucracy: An Examination of Decentralization and Organizational Change},
year = {2012},
isbn = {9781450310451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2160673.2160679},
doi = {10.1145/2160673.2160679},
abstract = {ICTs are frequently looked to as a missing link between traditional bureaucracy and the modernization of public administration and service delivery. Through the empirical research in the Thai public sector, we find that there is a fundamental gap between the design and normative goal of ICTs and their real world implementation. The structures of power are frequently retained or even reinforced by those who hold budgetary administrative, and authoritative roles and consequently get to make decisions about the development and use of ICTs to facilitate their administrative and managerial goals. While on a discursive level ICTs in Thailand have been projected to counter traditional practices and streamline governance as part of a broader administrative reform since the 2000s, we find that the practice is far different. Situating our work in the theoretical traditions of organization studies and computer supported collaborative work, we discuss how the Thai computerization projects add a valuable case to the vast literature on technology adoption. We also use the case to illustrate the value of this literature in growing work on governance and technology adoption within ICTD circles.},
booktitle = {Proceedings of the Fifth International Conference on Information and Communication Technologies and Development},
pages = {36–45},
numpages = {10},
keywords = {organizational change, decentralization, centralization, bureaucracy, ICT development},
location = {Atlanta, Georgia, USA},
series = {ICTD '12}
}

@inproceedings{10.1145/2160673.2160696,
author = {Patel, Neil and Shah, Kapil and Savani, Krishna and Klemmer, Scott R. and Dave, Paresh and Parikh, Tapan S.},
title = {Power to the Peers: Authority of Source Effects for a Voice-Based Agricultural Information Service in Rural India},
year = {2012},
isbn = {9781450310451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2160673.2160696},
doi = {10.1145/2160673.2160696},
abstract = {Online communities enable people to easily connect and share knowledge across geographies. Mobile phones can enable billions of new users in emerging countries to participate in these online communities. In India, where social hierarchy is important, users may over-value institutionally-recognized authorities relative to peer-sourced content. We tested this hypothesis through a controlled experiment of source authority effects on a voice-based agricultural information service for farmers in Gujarat, India. 305 farmers were sent seven agricultural tips via automated phone calls over a two-week period. The same seven tips were each voice-recorded by two university scientists and two peer farmers. Participants received a preview of the tip from a randomly assigned source via the automated call, and played the remainder of the tip by calling a dedicated phone number. Participants called the follow-up number significantly more often when the tip preview was recorded by a peer than a scientist. On the other hand, in interviews conducted both before and after the experiment, a majority of farmers maintained that they preferred receiving information from scientists. This stated preference may have been expressing the more socially acceptable response. We interpret our experimental results as a demonstration of the demand for peer-based agricultural information dissemination. We conclude with design implications for peer-to-peer information services for rural communities in India.},
booktitle = {Proceedings of the Fifth International Conference on Information and Communication Technologies and Development},
pages = {169–178},
numpages = {10},
keywords = {online community, dissemination, India, mobile, source, authority, human-computer interaction, peer, rural development, agriculture},
location = {Atlanta, Georgia, USA},
series = {ICTD '12}
}

@inproceedings{10.1145/2160673.2160695,
author = {Mudliar, Preeti and Donner, Jonathan and Thies, William},
title = {Emergent Practices around CGNet Swara, Voice Forum for Citizen Journalism in Rural India},
year = {2012},
isbn = {9781450310451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2160673.2160695},
doi = {10.1145/2160673.2160695},
abstract = {Rural communities in India are often underserved by the mainstream media. While there is a public discourse surrounding the issues they face, this dialogue typically takes place on television, in newspaper editorials, and on the Internet. Unfortunately, participation in such forums is limited to the most privileged members of society, excluding those individuals who have the largest stake in the conversation.This paper examines an effort to foster a more inclusive dialogue by means of a simple technology: an interactive voice forum. Called CGNet Swara, the system enables callers to record messages of local interest, and listen to messages that others have recorded. Messages are also posted on the Internet, as a supplement to an existing discussion forum.In the first 21 months of its deployment in India, CGNet Swara has logged over 70,000 phone calls and released 1,100 messages. To understand the emergent practices surrounding this system, we conduct interviews with 42 diverse stakeholders, including callers, bureaucrats, and members of the media. Our analysis contributes to the understanding of voice-based media as a vehicle for social inclusion in remote and underprivileged populations.},
booktitle = {Proceedings of the Fifth International Conference on Information and Communication Technologies and Development},
pages = {159–168},
numpages = {10},
keywords = {citizen journalism, M4D, participation, interactive voice response, ICT4D, ICTD, socioeconomic development, IVR, journalism},
location = {Atlanta, Georgia, USA},
series = {ICTD '12}
}

@inproceedings{10.1145/2160673.2160677,
author = {DeRenzi, Brian and Findlater, Leah and Payne, Jonathan and Birnbaum, Benjamin and Mangilima, Joachim and Parikh, Tapan and Borriello, Gaetano and Lesh, Neal},
title = {Improving Community Health Worker Performance through Automated SMS},
year = {2012},
isbn = {9781450310451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2160673.2160677},
doi = {10.1145/2160673.2160677},
abstract = {Community health workers (CHWs) have been shown to be an effective and powerful intervention for improving community health. Routine visits, for example, can lower maternal and neonatal mortality rates. Despite these benefits, many challenges, including supervision and support, make CHW programs difficult to maintain. An increasing number of mHealth projects are providing CHWs with mobile phones to support their work, which opens up opportunities for real-time supervision of the program. Taking advantage of this potential, we evaluated the impact of SMS reminders to improve the promptness of routine CHW visits, first in a pilot study in Dodoma, Tanzania, followed by two larger studies with 87 CHWs in Dar es Salaam, Tanzania. The first Dar es Salaam study evaluated an escalating reminder system that sent SMS reminders directly to the CHW before notifying the CHW's supervisor after several overdue days. The reminders resulted in an 86% reduction in the average number of days a CHW's clients were overdue (9.7 to 1.4 days), with only a small number of cases ever escalating to the supervisor. However, when the step of escalating to the supervisor was removed in the second study, CHW performance significantly decreased.},
booktitle = {Proceedings of the Fifth International Conference on Information and Communication Technologies and Development},
pages = {25–34},
numpages = {10},
keywords = {reminder systems, mobile tools, public health, ICT4CHW, community health workers},
location = {Atlanta, Georgia, USA},
series = {ICTD '12}
}

@inproceedings{10.5555/2263019.2263059,
author = {Calma, Giampiero and Palazzi, Claudio E. and Bujari, Armir},
title = {Web Squared: Paradigms and Opportunities},
year = {2012},
isbn = {9781450315104},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
abstract = {In this article, we explore the technical implications related to Web Squared paradigm. Representing an evolution of Web 2.0 that emphasizes the interaction between the cyber world and the real world, Web Squared contemplates the use of sensors to share huge amounts of data and foster the creation of new services. In this context, we analyze the different approaches and opportunities related to the use sensor-equipped smartphones to generate and distribute context related data both automatically and through appealing user applications (e.g., games). We discuss a general methodology to adopt when devising smartphone-based distributed sensing applications and explore both the issues and adopted solutions in this context. Finally, we identify unresolved technical challenges limiting the widespread deployment of Web Squared services, which deserve future research effort.},
booktitle = {Proceedings of the 5th International ICST Conference on Simulation Tools and Techniques},
pages = {256–261},
numpages = {6},
keywords = {games, web squared, mobile sensing},
location = {Desenzano del Garda, Italy},
series = {SIMUTOOLS '12}
}

@inproceedings{10.5555/2263019.2263042,
author = {Dalle, Olivier and Mancini, Emilio P.},
title = {Integrated Tools for the Simulation Analysis of Peer-to-Peer Backup Systems},
year = {2012},
isbn = {9781450315104},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
abstract = {In order to evaluate the performance and estimate the resource usage of peer-to-peer backup systems, it is important to analyze the time they spend in storing, retrieving and keeping the redundancy of the stored files. The analysis of such systems is difficult due to the random behavior of the peers and the variations of network conditions. Simulations provide a unique means for reproducing such varying conditions in a controlled way. In this paper we describe a general meta-model for peer-to-peer backup systems and a tool-chain, based on SimGrid, to help in their analysis. We validated the meta-model and tool-chain through the analysis of a common scenario, and verified that they can be used, for example, for retrieving the relations between the storage size, the saved data fragment sizes and the induced network workload.},
booktitle = {Proceedings of the 5th International ICST Conference on Simulation Tools and Techniques},
pages = {178–183},
numpages = {6},
location = {Desenzano del Garda, Italy},
series = {SIMUTOOLS '12}
}

@article{10.1145/2133366.2133373,
author = {Yazdani, Ashkan and Lee, Jong-Seok and Vesin, Jean-Marc and Ebrahimi, Touradj},
title = {Affect Recognition Based on Physiological Changes during the Watching of Music Videos},
year = {2012},
issue_date = {March 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
issn = {2160-6455},
url = {https://doi.org/10.1145/2133366.2133373},
doi = {10.1145/2133366.2133373},
abstract = {Assessing emotional states of users evoked during their multimedia consumption has received a great deal of attention with recent advances in multimedia content distribution technologies and increasing interest in personalized content delivery. Physiological signals such as the electroencephalogram (EEG) and peripheral physiological signals have been less considered for emotion recognition in comparison to other modalities such as facial expression and speech, although they have a potential interest as alternative or supplementary channels. This article presents our work on: (1) constructing a dataset containing EEG and peripheral physiological signals acquired during presentation of music video clips, which is made publicly available, and (2) conducting binary classification of induced positive/negative valence, high/low arousal, and like/dislike by using the aforementioned signals. The procedure for the dataset acquisition, including stimuli selection, signal acquisition, self-assessment, and signal processing is described in detail. Especially, we propose a novel asymmetry index based on relative wavelet entropy for measuring the asymmetry in the energy distribution of EEG signals, which is used for EEG feature extraction. Then, the classification systems based on EEG and peripheral physiological signals are presented. Single-trial and single-run classification results indicate that, on average, the performance of the EEG-based classification outperforms that of the peripheral physiological signals. However, the peripheral physiological signals can be considered as a good alternative to EEG signals in the case of assessing a user's preference for a given music video clip (like/dislike) since they have a comparable performance to EEG signals while being more easily measured.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = mar,
articleno = {7},
numpages = {26},
keywords = {signal processing, physiological signals, pattern classification, affective computing, Emotion classification, EEG}
}

@inproceedings{10.1145/2393091.2393104,
author = {Marvel, Jeremy A. and Hong, Tsai-Hong and Messina, Elena},
title = {2011 Solutions in Perception Challenge Performance Metrics and Results},
year = {2012},
isbn = {9781450311267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2393091.2393104},
doi = {10.1145/2393091.2393104},
abstract = {The 2011 Solutions in Perception Challenge presented an international collection of teams with the opportunity to develop algorithms that could accurately detect, recognize, and locate in space an arbitrary collection of artifacts. Researchers at the National Institute of Standards and Technology (NIST) generated a series of artifacts synonymous with parts found in industrial settings, a modular fixturing system capable of accurately and precisely positioning the artifacts within a work volume, and a relative pose scoring metric to quantify an algorithm's performance. Teams were presented with training and validation data sets consisting of red-green-blue color images and 3D point cloud data of the artifacts, and the top performers achieved over 70 % accuracy in translation and pose estimation. In this paper we discuss the design of NIST's contributions, and present the teams' results from the Challenge.},
booktitle = {Proceedings of the Workshop on Performance Metrics for Intelligent Systems},
pages = {59–63},
numpages = {5},
keywords = {laser tracker, fixtures, 6DOF metrology, ground truth},
location = {College Park, Maryland},
series = {PerMIS '12}
}

@inproceedings{10.1145/2393091.2393096,
author = {Sattar, Junaed and Dudek, Gregory},
title = {On the Performance Evaluation of a Vision-Based Human-Robot Interaction Framework},
year = {2012},
isbn = {9781450311267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2393091.2393096},
doi = {10.1145/2393091.2393096},
abstract = {This paper describes the performance evaluation of a machine vision-based human-robot interaction framework, particularly those involving human-interface studies. We describe a visual programming language called RoboChat, and a complimentary dialog engine which evaluates the need for confirmation based on utility and risk. Together, RoboChat and the dialog mechanism enable a human operator to send a series of complex instructions to a robot, with the assurance of confirmations in case of high task-cost or command uncertainty, or both. We have performed extensive human-interface studies to evaluate the usability of this framework, both in controlled laboratory conditions and in a variety of outdoors environments. One specific goal for the RoboChat scheme was to aid a scuba diver to operate and program an underwater robot in a variety of deployment scenarios, and the real-world validations were thus performed on-board the Aqua amphibious robot [4], in both underwater and terrestrial environments. The paper describes the details of the visual human-robot interaction framework, with an emphasis on the RoboChat language and the confirmation system, and presents a summary of the set of performance evaluation experiments performed both on- and off-board the Aqua vehicle.},
booktitle = {Proceedings of the Workshop on Performance Metrics for Intelligent Systems},
pages = {21–28},
numpages = {8},
location = {College Park, Maryland},
series = {PerMIS '12}
}

@inproceedings{10.1145/2160881.2160898,
author = {Zimmermann, Angelika},
title = {Offshoring Attitudes and Relational Behaviours in German-Indian Offshoring Collaborations: Reflections from a Field Study},
year = {2012},
isbn = {9781450308182},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2160881.2160898},
doi = {10.1145/2160881.2160898},
abstract = {Offshoring arrangements have become a common setting for intercultural collaborations. There is ample evidence that the success of these offshoring arrangements is influenced on the relational behaviours between offshore and onshore colleagues. However, it has not been questioned whether and how the attitudes that onshore colleagues hold towards offshoring affect their relational behaviours towards offshore colleagues. This paper draws together the literatures on offshoring and transnational teams, to argue for the importance of offshoring attitudes. It presents a qualitative case study examining the offshoring attitudes of German IT developers working with Indian colleagues in an Indian subsidiary of the firm. The inquiry revealed that respondent's offshoring attitudes were associated with their relational behaviours towards Indian offshore colleagues, namely whether Germans treated their Indian colleagues as fellow team members or as mere suppliers, how much effort they spent in communicating and transferring knowledge, and whether they supported or avoided the transfer of tasks to India. Importantly, these relational behaviours also had a reverse effect on the German's offshoring attitudes, creating vicious and virtuous circles of offshoring attitudes and relational behaviours. Certain departmental context factors were identified to explain the differences in offshoring attitudes and resulting vicious and virtuous circles. The findings demonstrate that researchers and practitioners have to pay more attention to offshoring attitudes in order to better understand relational behaviours between onshore and offshore members, and thereby achieve more successful offshoring collaborations.},
booktitle = {Proceedings of the 4th International Conference on Intercultural Collaboration},
pages = {107–118},
numpages = {12},
keywords = {attitudes, global teams, offshoring, transnational teams, vicious circle},
location = {Bengaluru, India},
series = {ICIC '12}
}

@inproceedings{10.1145/2160881.2160886,
author = {Korver Michan, Ren\'{e}e and Bj\o{}orn, Pernille},
title = {Sources of Miscommunication in Email: Searching for Contextual Information in Communication between Chinese and Danish Collaborators},
year = {2012},
isbn = {9781450308182},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2160881.2160886},
doi = {10.1145/2160881.2160886},
abstract = {Based on an interpretative case study investigating the communication between Danish and Chinese engineers in a global medical engineering company, we identified four key sources of miscommunication: 1) lack of common communication protocols; 2) exclusion of participants; 3) political motives; and 4) misinterpretation of common terms. This paper posits that all four challenges are related to a lack of contextual information due to geographical dislocation and not, as initially assumed, to cultural differences. This finding is essential when investigating cross-cultural communication, because it suggests that we should not forget to examine ordinary communication issues when researching communication between people from different cultural backgrounds.},
booktitle = {Proceedings of the 4th International Conference on Intercultural Collaboration},
pages = {21–30},
numpages = {10},
keywords = {intercultural collaboration, virtual teams, global engineering, distributed collaboration, miscommunication},
location = {Bengaluru, India},
series = {ICIC '12}
}

@inproceedings{10.1145/2160881.2160895,
author = {Li, Ye and Li, Hui and M\"{a}dche, Alexander and Rau, Pei-Luen Patrick},
title = {Are You a Trustworthy Partner in a Cross-Cultural Virtual Environment? Behavioral Cultural Intelligence and Receptivity-Based Trust in Virtual Collaboration},
year = {2012},
isbn = {9781450308182},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2160881.2160895},
doi = {10.1145/2160881.2160895},
abstract = {Globally distributed work has been prevalent in organizations. However, cultural issues in distributed work are still challenging team performance. Cultural intelligence, defined as individuals' capability to perform in cross-cultural settings, has great potential in untangling these issues. The present study examines three individual capabilities (behavioral cultural intelligence, language proficiency and technical skills) and their effects on partners' receptivity-based trust and satisfaction in a cross-cultural virtual environment. We develop a theoretical model based on the extended adaptive structuration theory (EAST) and verify the model in a cross-border experiment. The result suggests that focal members' behavioral cultural intelligence strongly influences their remote partners' receptivity/trust. This effect is moderated by language proficiency; 57% of the variance of partners' satisfaction is predicted by receptivity/trust and the focal members' technical skills.},
booktitle = {Proceedings of the 4th International Conference on Intercultural Collaboration},
pages = {87–96},
numpages = {10},
keywords = {receptivity, collaboration, virtual teams, satisfaction, trust, cultural intelligence},
location = {Bengaluru, India},
series = {ICIC '12}
}

@inproceedings{10.1145/2245276.2245455,
author = {Eggink, Jana and Allen, Penelope and Bland, Denise},
title = {A Pilot Study for Mood-Based Classification of TV Programmes},
year = {2012},
isbn = {9781450308571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2245276.2245455},
doi = {10.1145/2245276.2245455},
abstract = {We report results from a pilot study on mood-based classification of TV programmes. Short video clips from various programmes were labelled on three mood axes, giving the subjects opinion of how happy, serious and exciting each clip was. This data was used for mood classification based on automatically extracted audio and video features in a machine learning framework. Attention was given to the challenges of dealing with a small dataset as commonly obtained from pilot studies, showing that a thorough evaluation was possible and produced useful results. Introducing a new feature based on face detection and combining it with other signal processing features led to good classification accuracies. These lay between 85% and 100% for the most simple setting, and still reached more than 70% accuracy when a finer three point mood scale was used. Overall, the results were promising and showed that automatic mood classification of video material is possible. Moods can therefore be used as additional metadata to facilitate search in large archives.},
booktitle = {Proceedings of the 27th Annual ACM Symposium on Applied Computing},
pages = {918–922},
numpages = {5},
keywords = {multimedia classification, mood classification, machine learning},
location = {Trento, Italy},
series = {SAC '12}
}

@inproceedings{10.1145/2245276.2245373,
author = {Inzinger, Christian and Satzger, Benjamin and Hummer, Waldemar and Leitner, Philipp and Dustdar, Schahram},
title = {Non-Intrusive Policy Optimization for Dependable and Adaptive Service-Oriented Systems},
year = {2012},
isbn = {9781450308571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2245276.2245373},
doi = {10.1145/2245276.2245373},
abstract = {The Service-Oriented Architecture paradigm facilitates the creation of distributed, composite applications. Services are usually simple to integrate, but often encapsulate complex and dynamic business logic with multiple variations and configurations. The fact that these services typically execute in a dynamic, unpredictable environment additionally complicates manageability and calls for adaptable management strategies. Current system control strategies mostly rely on static approaches, such as predefined policies. In this paper we propose a novel technique to improve management policies for complex service-based systems during runtime. This allows systems to adapt to changing environments, to circumvent unforeseen events and errors, and to resolve incompatibilities of composed services. Our approach requires no knowledge about the internals of services or service platforms, but analyzes log output to realize adaptive policies in a non-intrusive and generic way. Experiments in our testbed show that the approach is highly effective in avoiding incompatibilities and reducing the impact of defects in service implementations.},
booktitle = {Proceedings of the 27th Annual ACM Symposium on Applied Computing},
pages = {504–510},
numpages = {7},
keywords = {SOA, adaptation, autonomic management, dependability},
location = {Trento, Italy},
series = {SAC '12}
}

@inproceedings{10.1145/2168556.2168560,
author = {Pfeiffer, Thies},
title = {Measuring and Visualizing Attention in Space with 3D Attention Volumes},
year = {2012},
isbn = {9781450312219},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2168556.2168560},
doi = {10.1145/2168556.2168560},
abstract = {Knowledge about the point of regard is a major key for the analysis of visual attention in areas such as psycholinguistics, psychology, neurobiology, computer science and human factors. Eye tracking is thus an established methodology in these areas, e. g., for investigating search processes, human communication behavior, product design or human-computer interaction. As eye tracking is a process which depends heavily on technology, the progress of gaze use in these scientific areas is tied closely to the advancements of eye-tracking technology. It is thus not surprising that in the last decades, research was primarily based on 2D stimuli and rather static scenarios, regarding both content and observer.Only with the advancements in mobile and robust eye-tracking systems, the observer is freed to physically interact in a 3D target scenario. Measuring and analyzing the point of regards in 3D space, however, requires additional techniques for data acquisition and scientific visualization. We describe the process for measuring the 3D point of regard and provide our own implementation of this process, which extends recent approaches of combining eye tracking with motion capturing, including holistic estimations of the 3D point of regard. In addition, we present a refined version of 3D attention volumes for representing and visualizing attention in 3D space.},
booktitle = {Proceedings of the Symposium on Eye Tracking Research and Applications},
pages = {29–36},
numpages = {8},
keywords = {motion tracking, visualization, visual attention, gaze tracking, 3d},
location = {Santa Barbara, California},
series = {ETRA '12}
}

@inproceedings{10.1145/2168556.2168559,
author = {Egawa, Akira and Shirayama, Susumu},
title = {A Method to Construct an Importance Map of an Image Using the Saliency Map Model and Eye Movement Analysis},
year = {2012},
isbn = {9781450312219},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2168556.2168559},
doi = {10.1145/2168556.2168559},
abstract = {Interpretability and recognizability of images have played important roles in applications such as the analysis of surveillance images, medical image diagnosis, and visual communication in education. In order to make an image as interpretable and recognizable as possible, unimportant visual information is removed or minimized, and regions that are of higher importance than others are clearly identified. Several methods have been developed to identify the important regions in an image. Most of these methods consist of two stages: segmentation of the image and ordering the segments hierarchically according to their relative importance. In the present paper, we propose a new method by which an importance map of a source image can be constructed. First, the source image is divided into segments based on a saliency map model that indicates high-saliency regions. Second, the segments are ordered according to the attention shift induced by the saliency map. Third, eye movement data is acquired and mapped into the segments. A network for the eye movements is generated by regarding the segments as nodes. The importance score can be calculated by the PageRank algorithm. Finally, an importance map of the image is constructed by combining the attention shift among the segments and the scores determined from eye movements. The usefulness of the proposed method is then investigated through several experiments.},
booktitle = {Proceedings of the Symposium on Eye Tracking Research and Applications},
pages = {21–28},
numpages = {8},
keywords = {PageRank algorithm, image importance map, image segmentation, eye movement analysis, saliency map model},
location = {Santa Barbara, California},
series = {ETRA '12}
}

@inproceedings{10.1145/2168556.2168635,
author = {Tula, Antonio Diaz and de Campos, Filipe M. S. and Morimoto, Carlos H.},
title = {Dynamic Context Switching for Gaze Based Interaction},
year = {2012},
isbn = {9781450312219},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2168556.2168635},
doi = {10.1145/2168556.2168635},
abstract = {This paper introduces Dynamic Context Switching (DCS) as an extension of the Context Switching (CS) paradigm for gaze-based interaction. CS replicates information in each context. The user can freely explore one context without worrying about the Midas touch problem, and a saccade to the other context triggers the selection of the item under focus. Because CS has to display two contexts simultaneously, the amount of useful screen space is limited. DCS dynamically adjusts the context sizes, where the context that has the focus is displayed in full size, while the other is minimized, thus improving useful screen space. A saccade to the minimized context triggers selection, and properly readjusts the sizes of the contexts. Results from a pilot user experiment show that DCS improves user performance and do not cause disorientation due to the dynamic context resizing.},
booktitle = {Proceedings of the Symposium on Eye Tracking Research and Applications},
pages = {353–356},
numpages = {4},
keywords = {selection by gaze, gaze based interaction, dynamic context switching},
location = {Santa Barbara, California},
series = {ETRA '12}
}

@article{10.14778/2212351.2212354,
author = {Low, Yucheng and Bickson, Danny and Gonzalez, Joseph and Guestrin, Carlos and Kyrola, Aapo and Hellerstein, Joseph M.},
title = {Distributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud},
year = {2012},
issue_date = {April 2012},
publisher = {VLDB Endowment},
volume = {5},
number = {8},
issn = {2150-8097},
url = {https://doi.org/10.14778/2212351.2212354},
doi = {10.14778/2212351.2212354},
abstract = {While high-level data parallel frameworks, like MapReduce, simplify the design and implementation of large-scale data processing systems, they do not naturally or efficiently support many important data mining and machine learning algorithms and can lead to inefficient learning systems. To help fill this critical void, we introduced the GraphLab abstraction which naturally expresses asynchronous, dynamic, graph-parallel computation while ensuring data consistency and achieving a high degree of parallel performance in the shared-memory setting. In this paper, we extend the GraphLab framework to the substantially more challenging distributed setting while preserving strong data consistency guarantees.We develop graph based extensions to pipelined locking and data versioning to reduce network congestion and mitigate the effect of network latency. We also introduce fault tolerance to the GraphLab abstraction using the classic Chandy-Lamport snapshot algorithm and demonstrate how it can be easily implemented by exploiting the GraphLab abstraction itself. Finally, we evaluate our distributed implementation of the GraphLab abstraction on a large Amazon EC2 deployment and show 1-2 orders of magnitude performance gains over Hadoop-based implementations.},
journal = {Proc. VLDB Endow.},
month = apr,
pages = {716–727},
numpages = {12}
}

@article{10.1145/2188379.2188381,
author = {Antonie, Luiza and Bessonov, Kyrylo},
title = {Biologically Relevant Association Rules for Classification of Microarray Data},
year = {2012},
issue_date = {Spring 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {1559-6915},
url = {https://doi.org/10.1145/2188379.2188381},
doi = {10.1145/2188379.2188381},
abstract = {In this paper we investigate a method for classifying microarray data using association rules. Associative classifiers, classification systems based on association rules, show good performance level while being easy to read and understand. This feature is especially attractive for biological data where experts can read and validate the association rules. Relevant features are selected using Support Vector Machines with Recursive Feature Elimination. These features are discretized according to their relative expression levels (upregulated, downregulated or no change) and then they are used to build an associative classifier. The proposed combination proves highly accurate for the studied microarray data collection. In addition, the classification rules discovered and employed in the classification process prove to be biologically relevant.},
journal = {SIGAPP Appl. Comput. Rev.},
month = apr,
pages = {12–23},
numpages = {12},
keywords = {microarray data, association rules, classification}
}

@article{10.1145/2160547.2160551,
author = {Taub, Rivka and Armoni, Michal and Ben-Ari, Mordechai},
title = {CS Unplugged and Middle-School Students’ Views, Attitudes, and Intentions Regarding CS},
year = {2012},
issue_date = {April 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
url = {https://doi.org/10.1145/2160547.2160551},
doi = {10.1145/2160547.2160551},
abstract = {Many students hold incorrect ideas and negative attitudes about computer science (CS). In order to address these difficulties, a series of learning activities called Computer Science Unplugged was developed by Tim Bell and his colleagues. These activities expose young people to central concepts in CS in an entertaining way without requiring a computer. The CS Unplugged activities have become more and more popular among CS educators and several activities are recommended in the ACM K-12 curriculum for elementary schools. CS Unplugged is used worldwide and has been translated into many languages.We examined the effect of the CS Unplugged activities on middle-school students’ ideas about CS and their desire to consider and study it in high school. The results indicate that following the activities the ideas of the students on what CS is about were partially improved, but their desire to study CS lessened.In order to provide possible explanations to these results, we analyzed the CS Unplugged activities to determine to what extent the objectives of CS Unplugged were addressed in the activities. In addition, we checked whether the activities were designed according to constructivist principles and whether they were explicitly linked to central concepts in CS. We found that only some of the objectives were addressed in the activities, that the activities do not engage with the students’ prior knowledge and that most of the activities are not explicitly linked to central concepts in CS. We offer suggestions for modifying the CS Unplugged activities so that they will be more likely to achieve their objectives.},
journal = {ACM Trans. Comput. Educ.},
month = apr,
articleno = {8},
numpages = {29},
keywords = {views, K-12 instruction, Computer science unplugged, attitudes}
}

@inproceedings{10.1145/2168836.2168842,
author = {Chen, Yanpei and Alspaugh, Sara and Borthakur, Dhruba and Katz, Randy},
title = {Energy Efficiency for Large-Scale MapReduce Workloads with Significant Interactive Analysis},
year = {2012},
isbn = {9781450312233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2168836.2168842},
doi = {10.1145/2168836.2168842},
abstract = {MapReduce workloads have evolved to include increasing amounts of time-sensitive, interactive data analysis; we refer to such workloads as MapReduce with Interactive Analysis (MIA). Such workloads run on large clusters, whose size and cost make energy efficiency a critical concern. Prior works on MapReduce energy efficiency have not yet considered this workload class. Increasing hardware utilization helps improve efficiency, but is challenging to achieve for MIA workloads. These concerns lead us to develop BEEMR (Berkeley Energy Efficient MapReduce), an energy efficient MapReduce workload manager motivated by empirical analysis of real-life MIA traces at Facebook. The key insight is that although MIA clusters host huge data volumes, the interactive jobs operate on a small fraction of the data, and thus can be served by a small pool of dedicated machines; the less time-sensitive jobs can run on the rest of the cluster in a batch fashion. BEEMR achieves 40-50% energy savings under tight design constraints, and represents a first step towards improving energy efficiency for an increasingly important class of datacenter workloads.},
booktitle = {Proceedings of the 7th ACM European Conference on Computer Systems},
pages = {43–56},
numpages = {14},
keywords = {MapReduce, energy efficiency},
location = {Bern, Switzerland},
series = {EuroSys '12}
}

@inproceedings{10.1145/2169090.2169093,
author = {Schwarzkopf, Malte and Hand, Steven},
title = {A Down-to-Earth Look at the Cloud Host OS},
year = {2012},
isbn = {9781450311625},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2169090.2169093},
doi = {10.1145/2169090.2169093},
abstract = {Current cloud programming models have opened up new opportunities, but the platforms they run on are still rooted in the legacy of single machine-centric computing. This leads to inefficiency that both costs money and offends scientific sensibilities. In this position paper, we make a passionate and necessarily opinionated argument for a research agenda that challenges fundamental assumptions about operating systems and "cloud" application software. We present a set of ideas for possible directions, and hope to elicit fruitful discussion within the community.},
booktitle = {Proceedings of the 1st International Workshop on Hot Topics in Cloud Data Processing},
articleno = {3},
numpages = {5},
location = {Bern, Switzerland},
series = {HotCDP '12}
}

@inproceedings{10.1145/2189736.2189743,
author = {Orgaz, Gema Bello and R-Moreno, Mar\'{\i}a D. and Camacho, David and Barrero, David F.},
title = {Clustering Avatars Behaviours from Virtual Worlds Interactions},
year = {2012},
isbn = {9781450311892},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2189736.2189743},
doi = {10.1145/2189736.2189743},
abstract = {Virtual Worlds (VWs) platforms and applications provide a practical implementation of the Metaverse concept. These applications, as highly inmersive and interactive 3D environments, have become very popular in social networks and games domains. The existence of a set of open platforms like OpenSim or OpenCobalt have played a major role in the popularization of this technology and they open new exciting research areas. One of these areas is behaviour analysis. In virtual world, the user (or avatar) can move and interact within an artificial world with a high degree of freedom. The movements and iterations of the avatar can be monitorized, and hence this information can be analysed to obtain interesting behavioural patterns. Usually, only the information related to the avatars conversations (textual chat logs) are directly available for processing. However, these open platforms allow to capture other kind of information like the exact position of an avatar in the VW, what they are looking at (eye-gazing) or which actions they perform inside these worlds. This paper studies how this information, can be extracted, processed and later used by clustering methods to detect behaviour or group formations in the world. To detect the behavioural patterns of the avatars considered, clustering techniques have been used. These techniques, using the correct data preprocessing and modelling, can be used to automatically detect hidden patterns from data.},
booktitle = {Proceedings of the 4th International Workshop on Web Intelligence &amp; Communities},
articleno = {4},
numpages = {7},
keywords = {hierarchical clustering, clustering techniques, virtual worlds, behavioral patterns, data processing, graph and overlapping clustering},
location = {Lyon, France},
series = {WI&amp;C '12}
}

@inproceedings{10.1145/2187836.2187955,
author = {Zhai, Ke and Boyd-Graber, Jordan and Asadi, Nima and Alkhouja, Mohamad L.},
title = {Mr. LDA: A Flexible Large Scale Topic Modeling Package Using Variational Inference in MapReduce},
year = {2012},
isbn = {9781450312295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187836.2187955},
doi = {10.1145/2187836.2187955},
abstract = {Latent Dirichlet Allocation (LDA) is a popular topic modeling technique for exploring document collections. Because of the increasing prevalence of large datasets, there is a need to improve the scalability of inference for LDA. In this paper, we introduce a novel and flexible large scale topic modeling package in MapReduce (Mr. LDA). As opposed to other techniques which use Gibbs sampling, our proposed framework uses variational inference, which easily fits into a distributed environment. More importantly, this variational implementation, unlike highly tuned and specialized implementations based on Gibbs sampling, is easily extensible. We demonstrate two extensions of the models possible with this scalable framework: informed priors to guide topic discovery and extracting topics from a multilingual corpus. We compare the scalability of Mr. LDA against Mahout, an existing large scale topic modeling package. Mr. LDA out-performs Mahout both in execution speed and held-out likelihood.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {879–888},
numpages = {10},
keywords = {scalability, topic models, mapreduce},
location = {Lyon, France},
series = {WWW '12}
}

@inproceedings{10.1145/2185677.2185741,
author = {Ali, Amin Ahsan and Hossain, Syed Monowar and Hovsepian, Karen and Rahman, Md. Mahbubur and Plarre, Kurt and Kumar, Santosh},
title = {MPuff: Automated Detection of Cigarette Smoking Puffs from Respiration Measurements},
year = {2012},
isbn = {9781450312271},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2185677.2185741},
doi = {10.1145/2185677.2185741},
abstract = {Smoking has been conclusively proved to be the leading cause of mortality that accounts for one in five deaths in the United States. Extensive research is conducted on developing effective smoking cessation programs. Most smoking cessation programs achieve low success rate because they are unable to intervene at the right moment. Identification of high-risk situations that may lead an abstinent smoker to relapse involve discovering the associations among various contexts that precede a smoking session or a smoking lapse. In the absence of an automated method, detection of smoking events still relies on subject self-report that is prone to failure to report and involves subject burden. Automated detection of smoking events in the natural environment can revolutionize smoking research and lead to effective intervention.In this paper, we present mpuff, a novel system to automatically detect smoking puffs from respiration measurements, using which a model can be developed to automatically detect entire smoking episodes in the field. We introduce several new features from respiration that can help classify individual respiration cycles into smoking puffs or non-puffs. We then propose supervised and semi-supervised support vector models to detect smoking puffs. We train our models on data collected from 10 daily smokers and find that smoking puffs can be detected with an accuracy of 91% within a smoking session. We then consider respiration measurements during confounding events such as stress, speaking, and walking, and show that our model can still identify smoking puffs with an accuracy of 86.7%. The smoking detector presented here opens the opportunity to develop effective interventions that can be delivered on a mobile phone when and where smoking urges may occur, thereby improving the abysmal low rate of success in smoking cessation.},
booktitle = {Proceedings of the 11th International Conference on Information Processing in Sensor Networks},
pages = {269–280},
numpages = {12},
keywords = {smoking detection, respiration, wearable sensors},
location = {Beijing, China},
series = {IPSN '12}
}

@inproceedings{10.1145/2187836.2187944,
author = {Reischuk, Raphael M. and Backes, Michael and Gehrke, Johannes},
title = {SAFE Extensibility of Data-Driven Web Applications},
year = {2012},
isbn = {9781450312295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187836.2187944},
doi = {10.1145/2187836.2187944},
abstract = {This paper presents a novel method for enabling fast development and easy customization of interactive data-intensive web applications. Our approach is based on a high-level hierarchical programming model that results in both a very clean semantics of the application while at the same time creating well-defined interfaces for customization of application components. A prototypical implementation of a conference management system shows the efficacy of our approach.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {799–808},
numpages = {10},
keywords = {extensibility, customization, data management, software-as-a-service},
location = {Lyon, France},
series = {WWW '12}
}

@inproceedings{10.1145/2187980.2187982,
author = {Aly, Mohamed and Hatch, Andrew and Josifovski, Vanja and Narayanan, Vijay K.},
title = {Web-Scale User Modeling for Targeting},
year = {2012},
isbn = {9781450312301},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187980.2187982},
doi = {10.1145/2187980.2187982},
abstract = {We present the experiences from building a web-scale user modeling platform for optimizing display advertising targeting at Yahoo!. The platform described in this paper allows for per-campaign maximization of conversions representing purchase activities or transactions. Conversions directly translate to advertiser's revenue, and thus provide the most relevant metrics of return on advertising investment. We focus on two major challenges: how to efficiently process histories of billions of users on a daily basis, and how to build per-campaign conversion models given the extremely low conversion rates (compared to click rates in a traditional setting). We first present mechanisms for building web-scale user profiles in a daily incremental fashion. Second, we show how to reduce the latency through in-memory processing of billions of user records. Finally, we discuss a technique for scaling the number of handled campaigns/models by introducing an efficient labeling technique that allows for sharing negative training examples across multiple campaigns.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {3–12},
numpages = {10},
keywords = {behavioral targeting, advertising, user modeling},
location = {Lyon, France},
series = {WWW '12 Companion}
}

@inproceedings{10.1145/2187836.2187879,
author = {Chia, Pern Hui and Yamamoto, Yusuke and Asokan, N.},
title = {Is This App Safe? A Large Scale Study on Application Permissions and Risk Signals},
year = {2012},
isbn = {9781450312295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187836.2187879},
doi = {10.1145/2187836.2187879},
abstract = {Third-party applications (apps) drive the attractiveness of web and mobile application platforms. Many of these platforms adopt a decentralized control strategy, relying on explicit user consent for granting permissions that the apps request. Users have to rely primarily on community ratings as the signals to identify the potentially harmful and inappropriate apps even though community ratings typically reflect opinions about perceived functionality or performance rather than about risks. With the arrival of HTML5 web apps, such user-consent permission systems will become more widespread. We study the effectiveness of user-consent permission systems through a large scale data collection of Facebook apps, Chrome extensions and Android apps. Our analysis confirms that the current forms of community ratings used in app markets today are not reliable indicators of privacy risks of an app. We find some evidence indicating attempts to mislead or entice users into granting permissions: free applications and applications with mature content request more permissions than is typical; 'look-alike' applications which have names similar to popular applications also request more permissions than is typical. We also find that across all three platforms popular applications request more permissions than average.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {311–320},
numpages = {10},
keywords = {privacy, facebook apps, chrome extensions, application permissions, android apps},
location = {Lyon, France},
series = {WWW '12}
}

@inproceedings{10.1145/2187836.2187957,
author = {Shahaf, Dafna and Guestrin, Carlos and Horvitz, Eric},
title = {Trains of Thought: Generating Information Maps},
year = {2012},
isbn = {9781450312295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187836.2187957},
doi = {10.1145/2187836.2187957},
abstract = {When information is abundant, it becomes increasingly difficult to fit nuggets of knowledge into a single coherent picture. Complex stories spaghetti into branches, side stories, and intertwining narratives. In order to explore these stories, one needs a map to navigate unfamiliar territory. We propose a methodology for creating structured summaries of information, which we call metro maps. Our proposed algorithm generates a concise structured set of documents maximizing coverage of salient pieces of information. Most importantly, metro maps explicitly show the relations among retrieved pieces in a way that captures story development. We first formalize characteristics of good maps and formulate their construction as an optimization problem. Then we provide efficient methods with theoretical guarantees for generating maps. Finally, we integrate user interaction into our framework, allowing users to alter the maps to better reflect their interests. Pilot user studies with a real-world dataset demonstrate that the method is able to produce maps which help users acquire knowledge efficiently.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {899–908},
numpages = {10},
keywords = {metro maps, information, summarization},
location = {Lyon, France},
series = {WWW '12}
}

@inproceedings{10.1145/2188286.2188319,
author = {de Gooijer, Thijmen and Jansen, Anton and Koziolek, Heiko and Koziolek, Anne},
title = {An Industrial Case Study of Performance and Cost Design Space Exploration},
year = {2012},
isbn = {9781450312028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2188286.2188319},
doi = {10.1145/2188286.2188319},
abstract = {Determining the trade-off between performance and costs of a distributed software system is important as it enables fulfilling performance requirements in a cost-efficient way. The large amount of design alternatives for such systems often leads software architects to select a suboptimal solution, which may either waste resources or cannot cope with future workloads. Recently, several approaches have appeared to assist software architects with this design task. In this paper, we present a case study applying one of these approaches, i.e. PerOpteryx, to explore the design space of an existing industrial distributed software system from ABB. To facilitate the design exploration, we created a highly detailed performance and cost model, which was instrumental in determining a cost-efficient architecture solution using an evolutionary algorithm. The case study demonstrates the capabilities of various modern performance modeling tools and a design space exploration tool in an industrial setting,provides lessons learned, and helps other software architects in solving similar problems.},
booktitle = {Proceedings of the 3rd ACM/SPEC International Conference on Performance Engineering},
pages = {205–216},
numpages = {12},
keywords = {industrial case study, software architecture, performance modeling},
location = {Boston, Massachusetts, USA},
series = {ICPE '12}
}

@inproceedings{10.1145/2188286.2188344,
author = {Nguyen, Thanh H.D. and Adams, Bram and Jiang, Zhen Ming and Hassan, Ahmed E. and Nasser, Mohamed and Flora, Parminder},
title = {Automated Detection of Performance Regressions Using Statistical Process Control Techniques},
year = {2012},
isbn = {9781450312028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2188286.2188344},
doi = {10.1145/2188286.2188344},
abstract = {The goal of performance regression testing is to check for performance regressions in a new version of a software system. Performance regression testing is an important phase in the software development process. Performance regression testing is very time consuming yet there is usually little time assigned for it. A typical test run would output thousands of performance counters. Testers usually have to manually inspect these counters to identify performance regressions. In this paper, we propose an approach to analyze performance counters across test runs using a statistical process control technique called control charts. We evaluate our approach using historical data of a large software team as well as an open-source software project. The results show that our approach can accurately identify performance regressions in both software systems. Feedback from practitioners is very promising due to the simplicity and ease of explanation of the results.},
booktitle = {Proceedings of the 3rd ACM/SPEC International Conference on Performance Engineering},
pages = {299–310},
numpages = {12},
keywords = {performance engineering, statistical control technique, load testing},
location = {Boston, Massachusetts, USA},
series = {ICPE '12}
}

@inproceedings{10.5555/2388632.2388639,
author = {G\'{e}n\'{e}reux, Michel and Martinez, William},
title = {Contrasting Objective and Subjective Portuguese Texts from Heterogeneous Sources},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {This paper contrasts the content and form of objective versus subjective texts. A collection of on-line newspaper news items serve as objective texts, while parliamentary speeches (debates) and blog posts form the basis of our subjective texts, all in Portuguese. The aim is to provide general linguistic patterns as used in objective written media and subjective speeches and blog posts, to help construct domain-independent templates for information extraction and opinion mining. Our hybrid approach combines statistical data along with linguistic knowledge to filter out irrelevant patterns. As resources for subjective classification are still limited for Portuguese, we use a parallel corpus and tools developed for English to build our subjective spoken corpus, through annotations produced for English projected onto a parallel corpus in Portuguese. A measure for the saliency of n-grams is used to extract relevant linguistic patterns deemed "objective" and "subjective". Perhaps unsurprisingly, our contrastive approach shows that, in Portuguese at least, subjective texts are characterized by markers such as descriptive, reactive and opinionated terms, while objective texts are characterized mainly by the absence of subjective markers.},
booktitle = {Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data},
pages = {46–51},
numpages = {6},
location = {Avignon, France},
series = {HYBRID '12}
}

@inproceedings{10.5555/2380816.2380855,
author = {Volkova, Svitlana and Dolan, William B. and Wilson, Theresa},
title = {CLex: A Lexicon for Exploring Color, Concept and Emotion Associations in Language},
year = {2012},
isbn = {9781937284190},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Existing concept-color-emotion lexicons limit themselves to small sets of basic emotions and colors, which cannot capture the rich pallet of color terms that humans use in communication. In this paper we begin to address this problem by building a novel, color-emotion-concept association lexicon via crowdsourcing. This lexicon, which we call CLEX, has over 2,300 color terms, over 3,000 affect terms and almost 2,000 concepts. We investigate the relation between color and concept, and color and emotion, reinforcing results from previous studies, as well as discovering new associations. We also investigate cross-cultural differences in color-emotion associations between US and India-based annotators.},
booktitle = {Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics},
pages = {306–314},
numpages = {9},
location = {Avignon, France},
series = {EACL '12}
}

@inproceedings{10.5555/2388655.2388658,
author = {Heylen, Kris and Speelman, Dirk and Geeraerts, Dirk},
title = {Looking at Word Meaning: An Interactive Visualization of Semantic Vector Spaces for Dutch Synsets},
year = {2012},
isbn = {9781937284190},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {In statistical NLP, Semantic Vector Spaces (SVS) are the standard technique for the automatic modeling of lexical semantics. However, it is largely unclear how these black-box techniques exactly capture word meaning. To explore the way an SVS structures the individual occurrences of words, we use a non-parametric MDS solution of a token-by-token similarity matrix. The MDS solution is visualized in an interactive plot with the Google Chart Tools. As a case study, we look at the occurrences of 476 Dutch nouns grouped in 214 synsets.},
booktitle = {Proceedings of the EACL 2012 Joint Workshop of LINGVIS &amp; UNCLH},
pages = {16–24},
numpages = {9},
location = {Avignon, France},
series = {EACL 2012}
}

@inproceedings{10.5555/2380816.2380826,
author = {Farkas, Rich\'{a}rd and Vincze, Veronika and Schmid, Helmut},
title = {Dependency Parsing of Hungarian: Baseline Results and Challenges},
year = {2012},
isbn = {9781937284190},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Hungarian is a stereotype of morphologically rich and non-configurational languages. Here, we introduce results on dependency parsing of Hungarian that employ a 80K, multi-domain, fully manually annotated corpus, the Szeged Dependency Treebank. We show that the results achieved by state-of-the-art data-driven parsers on Hungarian and English (which is at the other end of the configurational-non-configurational spectrum) are quite similar to each other in terms of attachment scores. We reveal the reasons for this and present a systematic and comparative linguistically motivated error analysis on both languages. This analysis highlights that addressing the language-specific phenomena is required for a further remarkable error reduction.},
booktitle = {Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics},
pages = {55–65},
numpages = {11},
location = {Avignon, France},
series = {EACL '12}
}

@inproceedings{10.1145/2330601.2330645,
author = {Garc\'{\i}a-Sol\'{o}rzano, David and Cobo, Germ\'{a}n and Santamar\'{\i}a, Eug\`{e}nia and Mor\'{a}n, Jose Antonio and Monzo, Carlos and Melench\'{o}n, Javier},
title = {Educational Monitoring Tool Based on Faceted Browsing and Data Portraits},
year = {2012},
isbn = {9781450311113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2330601.2330645},
doi = {10.1145/2330601.2330645},
abstract = {Due to the idiosyncrasy of online education, students may become disoriented, frustrated or confused if they do not receive the support, feedback or guidance needed to be successful. To avoid this, the role of teachers is essential. In this regard, instructors should be facilitators who guide students throughout the teaching-learning process and arrange meaningful learner-centered experiences. However, unlike face-to-face classes, teachers have difficulty in monitoring their learners in an online environment, since a lot of learning management systems provide faculty with student tracking data in a poor tabular format that is difficult to understand. In order to overcome this drawback, this paper presents a novel graphical educational monitoring tool based on faceted browsing that helps instructors to gain an insight into their classrooms' performance. Moreover, this tool depicts information of each individual student by using a data portrait. Thanks to this monitoring tool, teachers can, on the one hand, track their students during the teaching-learning process and, on the other, detect potential problems in time.},
booktitle = {Proceedings of the 2nd International Conference on Learning Analytics and Knowledge},
pages = {170–178},
numpages = {9},
keywords = {learning analytics, instructor support, faceted browsing, information visualization, data portraits, student monitoring},
location = {Vancouver, British Columbia, Canada},
series = {LAK '12}
}

@inproceedings{10.1145/2330601.2330650,
author = {Ammari, Ahmad and Lau, Lydia and Dimitrova, Vania},
title = {Deriving Group Profiles from Social Media to Facilitate the Design of Simulated Environments for Learning},
year = {2012},
isbn = {9781450311113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2330601.2330650},
doi = {10.1145/2330601.2330650},
abstract = {Simulated environments for learning are becoming increasingly popular to support experiential learning in complex domains. A key challenge when designing simulated learning environments is how to align the experience in the simulated world with real world experiences. Social media resources provide user-generated content that is rich in digital traces of real world experiences. People comments, tweets, and blog posts in social spaces can reveal interesting aspects of real world situations or can show what particular group of users is interested in or aware of. This paper examines a systematic way to analyze user-generated content in social media resources to provide useful information for learning simulator design. A hybrid framework exploiting Machine Learning and Semantics for social group profiling is presented. The framework has five stages: (1) Retrieval of user-generated content from the social resource (2) Content noise filtration, removing spam, abuse, and content irrelevant to the learning domain; (3) Deriving individual social profiles for the content authors; (4) Clustering of individuals into groups of similar authors; and (5) Deriving group profiles, where interesting concepts suitable for the use in simulated learning systems are extracted from the aggregated content authored by each group. The framework is applied to derive group profiles by mining user comments on YouTube videos. The application is evaluated in an experimental study within the context of learning interpersonal skills in job interviews. The paper discusses how the YouTube-based group profiles can be used to facilitate the design of a job interview skills learning simulator, considering: (1) identifying learning needs based on digital traces of real world experiences; and (2) augmenting learner models in simulators based on group characteristics derived from social media.},
booktitle = {Proceedings of the 2nd International Conference on Learning Analytics and Knowledge},
pages = {198–207},
numpages = {10},
keywords = {learning analytics, data mining for learning, augmented user models, social profiles, mining social media, learning needs},
location = {Vancouver, British Columbia, Canada},
series = {LAK '12}
}

@inproceedings{10.1145/2330601.2330634,
author = {Drachsler, Hendrik and Greller, Wolfgang},
title = {The Pulse of Learning Analytics Understandings and Expectations from the Stakeholders},
year = {2012},
isbn = {9781450311113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2330601.2330634},
doi = {10.1145/2330601.2330634},
abstract = {While there is currently much buzz about the new field of learning analytics [19] and the potential it holds for benefiting teaching and learning, the impression one currently gets is that there is also much uncertainty and hesitation, even extending to scepticism. A clear common understanding and vision for the domain has not yet formed among the educator and research community. To investigate this situation, we distributed a stakeholder survey in September 2011 to an international audience from different sectors of education. The findings provide some further insights into the current level of understanding and expectations toward learning analytics among stakeholders. The survey was scaffolded by a conceptual framework on learning analytics that was developed based on a recent literature review. It divides the domain of learning analytics into six critical dimensions. The preliminary survey among 156 educational practitioners and researchers mostly from the higher education sector reveals substantial uncertainties in learning analytics.In this article, we first briefly introduce the learning analytics framework and its six domains that formed the backbone structure to our survey. Afterwards, we describe the method and key results of the learning analytics questionnaire and draw further conclusions for the field in research and practice. The article finishes with plans for future research on the questionnaire and the publication of both data and the questions for others to utilize.},
booktitle = {Proceedings of the 2nd International Conference on Learning Analytics and Knowledge},
pages = {120–129},
numpages = {10},
keywords = {understanding, privacy, survey, innovation, learning analytics, attitude, expectations, learning technologies},
location = {Vancouver, British Columbia, Canada},
series = {LAK '12}
}

@inproceedings{10.1145/2330601.2330631,
author = {Rivera-Pelayo, Ver\'{o}nica and Zacharias, Valentin and M\"{u}ller, Lars and Braun, Simone},
title = {Applying Quantified Self Approaches to Support Reflective Learning},
year = {2012},
isbn = {9781450311113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2330601.2330631},
doi = {10.1145/2330601.2330631},
abstract = {This paper presents a framework for technical support of reflective learning, derived from a unification of reflective learning theory with a conceptual framework of Quantified Self tools -- tools for collecting personally relevant information for gaining self-knowledge. Reflective learning means returning to and evaluating past experiences in order to promote continuous learning and improve future experiences. Whilst the reflective learning theories do not sufficiently consider technical support, Quantified Self (QS) approaches are rather experimental and the many emergent tools are disconnected from the goals and benefits of their use. This paper brings these two strands into one unified framework that shows how QS approaches can support reflective learning processes on the one hand and how reflective learning can inform the design of new QS tools for informal learning purposes on the other hand.},
booktitle = {Proceedings of the 2nd International Conference on Learning Analytics and Knowledge},
pages = {111–114},
numpages = {4},
keywords = {quantified self, reflective learning, mobile applications, learning analytics, framework},
location = {Vancouver, British Columbia, Canada},
series = {LAK '12}
}

@article{10.1145/2168931.2168943,
author = {Fisher, Danyel and DeLine, Rob and Czerwinski, Mary and Drucker, Steven},
title = {Interactions with Big Data Analytics},
year = {2012},
issue_date = {May + June 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1072-5520},
url = {https://doi.org/10.1145/2168931.2168943},
doi = {10.1145/2168931.2168943},
journal = {Interactions},
month = may,
pages = {50–59},
numpages = {10}
}

@article{10.1145/2168752.2168764,
author = {Estlin, Tara A. and Bornstein, Benjamin J. and Gaines, Daniel M. and Anderson, Robert C. and Thompson, David R. and Burl, Michael and Casta\~{n}o, Rebecca and Judd, Michele},
title = {AEGIS Automated Science Targeting for the MER Opportunity Rover},
year = {2012},
issue_date = {May 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/2168752.2168764},
doi = {10.1145/2168752.2168764},
abstract = {The Autonomous Exploration for Gathering Increased Science (AEGIS) system enables automated data collection by planetary rovers. AEGIS software was uploaded to the Mars Exploration Rover (MER) mission’s Opportunity rover in December 2009 and has successfully demonstrated automated onboard targeting based on scientist-specified objectives. Prior to AEGIS, images were transmitted from the rover to the operations team on Earth; scientists manually analyzed the images, selected geological targets for the rover’s remote-sensing instruments, and then generated a command sequence to execute the new measurements. AEGIS represents a significant paradigm shift---by using onboard data analysis techniques, the AEGIS software uses scientist input to select high-quality science targets with no human in the loop. This approach allows the rover to autonomously select and sequence targeted observations in an opportunistic fashion, which is particularly applicable for narrow field-of-view instruments (such as the MER Mini-TES spectrometer, the MER Panoramic camera, and the 2011 Mars Science Laboratory (MSL) ChemCam spectrometer). This article provides an overview of the AEGIS automated targeting capability and describes how it is currently being used onboard the MER mission Opportunity rover.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
articleno = {50},
numpages = {19},
keywords = {spacecraft autonomy, autonomous science, Data analysis}
}

@article{10.1145/2168752.2168771,
author = {Rendle, Steffen},
title = {Factorization Machines with LibFM},
year = {2012},
issue_date = {May 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/2168752.2168771},
doi = {10.1145/2168752.2168771},
abstract = {Factorization approaches provide high accuracy in several important prediction problems, for example, recommender systems. However, applying factorization approaches to a new prediction problem is a nontrivial task and requires a lot of expert knowledge. Typically, a new model is developed, a learning algorithm is derived, and the approach has to be implemented.Factorization machines (FM) are a generic approach since they can mimic most factorization models just by feature engineering. This way, factorization machines combine the generality of feature engineering with the superiority of factorization models in estimating interactions between categorical variables of large domain. libFM is a software implementation for factorization machines that features stochastic gradient descent (SGD) and alternating least-squares (ALS) optimization, as well as Bayesian inference using Markov Chain Monto Carlo (MCMC). This article summarizes the recent research on factorization machines both in terms of modeling and learning, provides extensions for the ALS and MCMC algorithms, and describes the software tool libFM.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
articleno = {57},
numpages = {22},
keywords = {matrix factorization, tensor factorization, Factorization model, factorization machine, recommender system, collaborative filtering}
}

@article{10.1145/2168752.2168754,
author = {Yang, Yi-Hsuan and Chen, Homer H.},
title = {Machine Recognition of Music Emotion: A Review},
year = {2012},
issue_date = {May 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/2168752.2168754},
doi = {10.1145/2168752.2168754},
abstract = {The proliferation of MP3 players and the exploding amount of digital music content call for novel ways of music organization and retrieval to meet the ever-increasing demand for easy and effective information access. As almost every music piece is created to convey emotion, music organization and retrieval by emotion is a reasonable way of accessing music information. A good deal of effort has been made in the music information retrieval community to train a machine to automatically recognize the emotion of a music signal. A central issue of machine recognition of music emotion is the conceptualization of emotion and the associated emotion taxonomy. Different viewpoints on this issue have led to the proposal of different ways of emotion annotation, model training, and result visualization. This article provides a comprehensive review of the methods that have been proposed for music emotion recognition. Moreover, as music emotion recognition is still in its infancy, there are many open issues. We review the solutions that have been proposed to address these issues and conclude with suggestions for further research.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
articleno = {40},
numpages = {30},
keywords = {Music emotion recognition}
}

@article{10.1145/2168931.2168939,
author = {Morris, Margaret E.},
title = {Motivating Change with Mobile: Seven Guidelines},
year = {2012},
issue_date = {May + June 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1072-5520},
url = {https://doi.org/10.1145/2168931.2168939},
doi = {10.1145/2168931.2168939},
abstract = {This forum is dedicated to personal health in all its many facets: decision-making, goal setting, celebration, discovery, reflection, coordination---even entertainment. We'll look at innovations in interactive technologies and how they help address current critical healthcare challenges. Elizabeth D. Mynatt, Editor},
journal = {Interactions},
month = may,
pages = {26–31},
numpages = {6}
}

@article{10.14778/2311906.2311907,
author = {Sun, Zhao and Wang, Hongzhi and Wang, Haixun and Shao, Bin and Li, Jianzhong},
title = {Efficient Subgraph Matching on Billion Node Graphs},
year = {2012},
issue_date = {May 2012},
publisher = {VLDB Endowment},
volume = {5},
number = {9},
issn = {2150-8097},
url = {https://doi.org/10.14778/2311906.2311907},
doi = {10.14778/2311906.2311907},
abstract = {The ability to handle large scale graph data is crucial to an increasing number of applications. Much work has been dedicated to supporting basic graph operations such as subgraph matching, reachability, regular expression matching, etc. In many cases, graph indices are employed to speed up query processing. Typically, most indices require either super-linear indexing time or super-linear indexing space. Unfortunately, for very large graphs, super-linear approaches are almost always infeasible. In this paper, we study the problem of subgraph matching on billion-node graphs. We present a novel algorithm that supports efficient subgraph matching for graphs deployed on a distributed memory store. Instead of relying on super-linear indices, we use efficient graph exploration and massive parallel computing for query processing. Our experimental results demonstrate the feasibility of performing subgraph matching on web-scale graph data.},
journal = {Proc. VLDB Endow.},
month = may,
pages = {788–799},
numpages = {12}
}

@article{10.1145/2180905.2180907,
author = {Adams, Ian F. and Storer, Mark W. and Miller, Ethan L.},
title = {Analysis of Workload Behavior in Scientific and Historical Long-Term Data Repositories},
year = {2012},
issue_date = {May 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {1553-3077},
url = {https://doi.org/10.1145/2180905.2180907},
doi = {10.1145/2180905.2180907},
abstract = {The scope of archival systems is expanding beyond cheap tertiary storage: scientific and medical data is increasingly digital, and the public has a growing desire to digitally record their personal histories. Driven by the increase in cost efficiency of hard drives, and the rise of the Internet, content archives have become a means of providing the public with fast, cheap access to long-term data. Unfortunately, designers of purpose-built archival systems are either forced to rely on workload behavior obtained from a narrow, anachronistic view of archives as simply cheap tertiary storage, or extrapolate from marginally related enterprise workload data and traditional library access patterns.To close this knowledge gap and provide relevant input for the design of effective long-term data storage systems, we studied the workload behavior of several systems within this expanded archival storage space. Our study examined several scientific and historical archives, covering a mixture of purposes, media types, and access models---that is, public versus private. Our findings show that, for more traditional private scientific archival storage, files have become larger, but update rates have remained largely unchanged. However, in the public content archives we observed, we saw behavior that diverges from the traditional “write-once, read-maybe” behavior of tertiary storage. Our study shows that the majority of such data is modified---sometimes unnecessarily---relatively frequently, and that indexing services such as Google and internal data management processes may routinely access large portions of an archive, accounting for most of the accesses. Based on these observations, we identify areas for improving the efficiency and performance of archival storage systems.},
journal = {ACM Trans. Storage},
month = may,
articleno = {6},
numpages = {27},
keywords = {tertiary storage, Archival storage, trace analysis}
}

@article{10.1145/2147783.2147789,
author = {Leong, Tuck W. and Vetere, Frank and Howard, Steve},
title = {Experiencing Coincidence during Digital Music Listening},
year = {2012},
issue_date = {March 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1073-0516},
url = {https://doi.org/10.1145/2147783.2147789},
doi = {10.1145/2147783.2147789},
abstract = {People have reported encountering coincidences when using particular technologies to interact with personal digital content. However, to date, there is a paucity of research to understand these experiences. This article applies McCarthy and Wright's [2004; 2005] experiential framework to analyze these kinds of technology-mediated coincidences. By focusing upon encounters of coincidence during people's digital music listening, we identified the elements at play, elucidated the properties of the individual elements, their inter-relationships, and an understanding of how coincidences can arise. We also reveal how, under particular conditions, such elements provide people with opportunities to encounter coincidence. This understanding of coincidence demonstrates how McCarthy and Wright's [2004; 2005] framework can be usefully applied to an empirical investigation of user experience.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = may,
articleno = {6},
numpages = {19},
keywords = {dialogical sensemaking, Coincidence, the whole person, felt life, McCarthy and Wright experience framework, music listening, user experience}
}

@inproceedings{10.1145/2247569.2247576,
author = {Blanchard, Katharine and Soltys, Michael},
title = {Perceptions of Foundational Knowledge by Computer Science Students},
year = {2012},
isbn = {9781450314077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2247569.2247576},
doi = {10.1145/2247569.2247576},
abstract = {In this paper we are concerned with computer science students' perceptions of foundational knowledge, understood as the mathematical underpinnings of the field. We review recent literature on the subject, propose an approach for teaching foundational knowledge, and finally present a case study where we analyze the merits of our approach. We make our observations based on experience and on a student survey.},
booktitle = {Proceedings of the Seventeenth Western Canadian Conference on Computing Education},
pages = {19–23},
numpages = {5},
keywords = {perceptions, satisfaction, foundations, curriculum, theory},
location = {Vancouver, British Columbia, Canada},
series = {WCCCE '12}
}

@article{10.1145/2147783.2147787,
author = {Koulouri, Theodora and Lauria, Stanislao and Macredie, Robert D. and Chen, Sherry},
title = {Are We There yet? The Role of Gender on the Effectiveness and Efficiency of User-Robot Communication in Navigational Tasks},
year = {2012},
issue_date = {March 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1073-0516},
url = {https://doi.org/10.1145/2147783.2147787},
doi = {10.1145/2147783.2147787},
abstract = {Many studies have identified gender differences in communication related to spatial navigation in real and virtual worlds. Most of this research has focused on single-party communication (monologs), such as the way in which individuals either give or follow route instructions. However, very little work has been reported on spatial navigation dialogs and whether there are gender differences in the way that they are conducted. This article will address the lack of research evidence by exploring the dialogs between partners of the same and of different gender in a simulated Human-Robot Interaction study. In the experiments discussed in this article, pairs of participants communicated remotely; in each pair, one participant (the instructor) was under the impression that s/he was giving route instructions to a robot (the follower), avoiding any perception of gendered communication. To ensure the naturalness of the interaction, the followers were given no guidelines on what to say, however, each had to control a robot based on the user's instructions. While many monologe-based studies suggest male superiority in a multitude of spatial activities and domains, this study of dialogs highlights a more complex pattern of results. As anticipated, gender influences task performance and communication. However, the findings suggest that it is the interaction—the combination of gender and role (i.e., instructor or follower)—that has the most significant impact. In particular, pairs of female users/instructors and male “robots”/followers are associated with the fastest and most accurate completion of the navigation tasks. Moreover, dialoge-based analysis illustrates how pairs of male users/instructors and female “robots”/followers achieved successful communication through “alignment” of spatial descriptions. In particular, males seem to adapt the content of their instructions when interacting with female “robots”/followers and employ more landmark references compared to female users/instructors or when addressing males (in male-male pairings). This study describes the differences in how males and females interact with the system, and proposes that any female “disadvantage” in spatial communication can disappear through interactive mechanisms. Such insights are important for the design of navigation systems that are equally effective for users of either gender.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = may,
articleno = {4},
numpages = {29}
}

@inproceedings{10.1145/2207676.2208525,
author = {McDuff, Daniel and Karlson, Amy and Kapoor, Ashish and Roseway, Asta and Czerwinski, Mary},
title = {AffectAura: An Intelligent System for Emotional Memory},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208525},
doi = {10.1145/2207676.2208525},
abstract = {We present AffectAura, an emotional prosthetic that allows users to reflect on their emotional states over long periods of time. We designed a multimodal sensor set-up for continuous logging of audio, visual, physiological and contextual data, a classification scheme for predicting user affective state and an interface for user reflection. The system continuously predicts a user's valence, arousal and engage-ment, and correlates this with information on events, communications and data interactions. We evaluate the interface through a user study consisting of six users and over 240 hours of data, and demonstrate the utility of such a reflection tool. We show that users could reason forward and backward in time about their emotional experiences using the interface, and found this useful.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {849–858},
numpages = {10},
keywords = {visualization, machine learning, affect},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207727,
author = {Barkhuus, Louise},
title = {The Mismeasurement of Privacy: Using Contextual Integrity to Reconsider Privacy in HCI},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207727},
doi = {10.1145/2207676.2207727},
abstract = {Privacy is a widely studied concept in relation to social computing and sensor-based technologies; scores of research papers have investigated people's "privacy preferences" and apparent reluctance to share personal data. In this paper we explore how Ubicomp and HCI studies have approached the notion of privacy, often as a quantifiable concept. Leaning on several theoretical frameworks, but in particular Nissenbaum's notion of contextual integrity, we question the viability of obtaining universal answers in terms of people's "general" privacy practices and apply elements of Nissenbaum's theory to our own data in order to illustrate its relevance. We then suggest restructuring inquiries into information sharing in studies of state-of-the-art technologies and analyze contextually grounded issues using a different, more specific vocabulary. Finally, we provide the first building blocks to such vocabulary.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {367–376},
numpages = {10},
keywords = {online social networks, user studies, location-based services, ubiquitous computing, privacy},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207679,
author = {Szafir, Daniel and Mutlu, Bilge},
title = {Pay Attention! Designing Adaptive Agents That Monitor and Improve User Engagement},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207679},
doi = {10.1145/2207676.2207679},
abstract = {Embodied agents hold great promise as educational assistants, exercise coaches, and team members in collaborative work. These roles require agents to closely monitor the behavioral, emotional, and mental states of their users and provide appropriate, effective responses. Educational agents, for example, will have to monitor student attention and seek to improve it when student engagement decreases. In this paper, we draw on techniques from brain-computer interfaces (BCI) and knowledge from educational psychology to design adaptive agents that monitor student attention in real time using measurements from electroencephalography (EEG) and recapture diminishing attention levels using verbal and nonverbal cues. An experimental evaluation of our approach showed that an adaptive robotic agent employing behavioral techniques to regain attention during drops in engagement improved student recall abilities 43% over the baseline regardless of student gender and significantly improved female motivation and rapport. Our findings offer guidelines for developing effective adaptive agents, particularly for educational settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {11–20},
numpages = {10},
keywords = {immediacy, adaptive agents, electroencephalography (eeg), passive brain-computer interfaces (bci), educational agents, human-robot interaction},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208532,
author = {Haque, Md and Kawsar, Ferdaus and Adibuzzaman, Mohammad and Ahamed, Sheikh and Love, Richard and Dowla, Rumana and Roe, David and Hossain, Syed and Selim, Reza},
title = {Findings of E-ESAS: A Mobile Based Symptom Monitoring System for Breast Cancer Patients in Rural Bangladesh},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208532},
doi = {10.1145/2207676.2208532},
abstract = {Breast cancer (BC) patients need traditional treatment as well as long term monitoring through an adaptive feedback-oriented treatment mechanism. Here, we present the findings of our 31-week long field study and deployment of e-ESAS - the first mobile-based remote symptom monitoring system (RSMS) developed for rural BC patients where patients are the prime users rather than just the source of data collection at some point of time. We have also shown how 'motivation' and 'automation' have been integrated in e-ESAS and creating a unique motivation-persuasion-motivation cycle where the motivated patients become proactive change agents by persuading others. Though in its early deployment stages (2 months), e-ESAS demonstrates the potential to positively impact the cancer care by (1) helping the doctors with graphical charts of long symptom history (automation), (2) facilitating timely interventions through alert generation (automation) and (3) improving three way communications (doctor-patient-attendant) for a better decision making process (motivation) and thereby improving the quality of life of BC patients.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {899–908},
numpages = {10},
keywords = {symptom monitoring, breast cancer, mobile computing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208392,
author = {Zhang, Hong and Yang, Xing-Dong and Ens, Barrett and Liang, Hai-Ning and Boulanger, Pierre and Irani, Pourang},
title = {See Me, See You: A Lightweight Method for Discriminating User Touches on Tabletop Displays},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208392},
doi = {10.1145/2207676.2208392},
abstract = {Tabletop systems provide a versatile space for collaboration, yet, in many cases, are limited by the inability to differentiate the interactions of simultaneous users. We present See Me, See You, a lightweight approach for discriminating user touches on a vision-based tabletop. We contribute a valuable characterization of finger orientation distributions of tabletop users. We exploit this biometric trait with a machine learning approach to allow the system to predict the correct position of users as they touch the surface. We achieve accuracies as high as 98% in simple situations and above 92% in more challenging conditions, such as two-handed tasks. We show high acceptance from users, who can self-correct prediction errors without significant costs. See Me, See You is a viable solution for providing simple yet effective support for multi-user application features on tabletops.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2327–2336},
numpages = {10},
keywords = {tabletop interaction, touch discrimination, position aware system, multi-user application},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208693,
author = {L\"{u}, Hao and Li, Yang},
title = {Gesture Coder: A Tool for Programming Multi-Touch Gestures by Demonstration},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208693},
doi = {10.1145/2207676.2208693},
abstract = {Multi-touch gestures have become popular on a wide range of touchscreen devices, but the programming of these gestures remains an art. It is time-consuming and error-prone for a developer to handle the complicated touch state transitions that result from multiple fingers and their simultaneous movements. In this paper, we present Gesture Coder, which by learning from a few examples given by the developer automatically generates code that recognizes multi-touch gestures, tracks their state changes and invokes corresponding application actions. Developers can easily test the generated code in Gesture Coder, refine it by adding more examples, and once they are satisfied with its performance integrate the code into their applications. We evaluated our learning algorithm exhaustively with various conditions over a large set of noisy data. Our results show that it is sufficient for rapid prototyping and can be improved with higher quality and more training data. We also evaluated Gesture Coder's usability through a within-subject study in which we asked participants to implement a set of multi-touch interactions with and without Gesture Coder. The results show overwhelmingly that Gesture Coder significantly lowers the threshold of programming multi-touch gestures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2875–2884},
numpages = {10},
keywords = {multi-touch gestures, programming by demonstration, decision trees, state machines, eclipse plug-in.},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207741,
author = {Endert, Alex and Fiaux, Patrick and North, Chris},
title = {Semantic Interaction for Visual Text Analytics},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207741},
doi = {10.1145/2207676.2207741},
abstract = {Visual analytics emphasizes sensemaking of large, complex datasets through interactively exploring visualizations generated by statistical models. For example, dimensionality reduction methods use various similarity metrics to visualize textual document collections in a spatial metaphor, where similarities between documents are approximately represented through their relative spatial distances to each other in a 2D layout. This metaphor is designed to mimic analysts' mental models of the document collection and support their analytic processes, such as clustering similar documents together. However, in current methods, users must interact with such visualizations using controls external to the visual metaphor, such as sliders, menus, or text fields, to directly control underlying model parameters that they do not understand and that do not relate to their analytic process occurring within the visual metaphor. In this paper, we present the opportunity for a new design space for visual analytic interaction, called semantic interaction, which seeks to enable analysts to spatially interact with such models directly within the visual metaphor using interactions that derive from their analytic process, such as searching, highlighting, annotating, and repositioning documents. Further, we demonstrate how semantic interactions can be implemented using machine learning techniques in a visual analytic tool, called ForceSPIRE, for interactive analysis of textual data within a spatial visualization. Analysts can express their expert domain knowledge about the documents by simply moving them, which guides the underlying model to improve the overall layout, taking the user's feedback into account.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {473–482},
numpages = {10},
keywords = {visual analytics, visualization, interaction},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207754,
author = {Mark, Gloria and Voida, Stephen and Cardello, Armand},
title = {"A Pace Not Dictated by Electrons": An Empirical Study of Work without Email},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207754},
doi = {10.1145/2207676.2207754},
abstract = {We report on an empirical study where we cut off email usage for five workdays for 13 information workers in an organization. We employed both quantitative measures such as computer log data and ethnographic methods to compare a baseline condition (normal email usage) with our experimental manipulation (email cutoff). Our results show that without email, people multitasked less and had a longer task focus, as measured by a lower frequency of shifting between windows and a longer duration of time spent working in each computer window. Further, we directly measured stress using wearable heart rate monitors and found that stress, as measured by heart rate variability, was lower without email. Interview data were consistent with our quantitative measures, as participants reported being able to focus more on their tasks. We discuss the implications for managing email better in organizations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {555–564},
numpages = {10},
keywords = {sensors, empirical study, multitasking, email, interruptions},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208291,
author = {Ziemkiewicz, Caroline and Gomez, Steven and Laidlaw, David},
title = {Analysis within and between Graphs: Observed User Strategies in Immunobiology Visualization},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208291},
doi = {10.1145/2207676.2208291},
abstract = {We present an analysis of two user strategies in interactive data analysis, based on an observational study of four researchers in the immunology domain. Screen captures, video records, interviews, and verbal protocols are used to analyze common procedures in this type of visual data analysis, as well as how these procedures differ among these users. Our findings present a case where skilled users can approach a similar problem with diverging analysis strategies. In the group we observed, strategies fell within two broad categories: within-graph analysis, in which a user generates a few graph layouts and interacts heavily within them, and between-graph analysis, in which a user generates a series of graphs and switches between them in sequence. Differences in strategies lead to distinct interaction patterns, and are likely to be best supported by different interface designs. We characterize these observed strategies and discuss their implications for scientific visualization design and evaluation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1655–1658},
numpages = {4},
keywords = {visualization, immunology, task analysis},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208372,
author = {Solovey, Erin and Schermerhorn, Paul and Scheutz, Matthias and Sassaroli, Angelo and Fantini, Sergio and Jacob, Robert},
title = {Brainput: Enhancing Interactive Systems with Streaming Fnirs Brain Input},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208372},
doi = {10.1145/2207676.2208372},
abstract = {This paper describes the Brainput system, which learns to identify brain activity patterns occurring during multitasking. It provides a continuous, supplemental input stream to an interactive human-robot system, which uses this information to modify its behavior to better support multitasking. This paper demonstrates that we can use non-invasive methods to detect signals coming from the brain that users naturally and effortlessly generate while using a computer system. If used with care, this additional information can lead to systems that respond appropriately to changes in the user's state. Our experimental study shows that Brainput significantly improves several performance metrics, as well as the subjective NASA-Task Load Index scores in a dual-task human-robot activity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2193–2202},
numpages = {10},
keywords = {multitasking, brain computer interface, human-robot interaction, fnirs, near-infrared spectroscopy},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207743,
author = {Sato, Munehiko and Poupyrev, Ivan and Harrison, Chris},
title = {Touch\'{e}: Enhancing Touch Interaction on Humans, Screens, Liquids, and Everyday Objects},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207743},
doi = {10.1145/2207676.2207743},
abstract = {Touch\'{e} proposes a novel Swept Frequency Capacitive Sensing technique that can not only detect a touch event, but also recognize complex configurations of the human hands and body. Such contextual information significantly enhances touch interaction in a broad range of applications, from conventional touchscreens to unique contexts and materials. For example, in our explorations we add touch and gesture sensitivity to the human body and liquids. We demonstrate the rich capabilities of Touch\'{e} with five example setups from different application domains and conduct experimental studies that show gesture classification accuracies of 99% are achievable with our technology.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {483–492},
numpages = {10},
keywords = {mobile devices, touch, on-body computing, ubiquitous interfaces, sensors, gestures},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208612,
author = {Jamison-Powell, Sue and Linehan, Conor and Daley, Laura and Garbett, Andrew and Lawson, Shaun},
title = {"I Can't Get No Sleep": Discussing #insomnia on Twitter},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208612},
doi = {10.1145/2207676.2208612},
abstract = {Emerging research has shown that social media services are being used as tools to disclose a range of personal health information. To explore the role of social media in the discussion of mental health issues, and with particular reference to insomnia and sleep disorders, a corpus of 18,901 messages - or Tweets - posted to the microblogging social media service Twitter were analysed using a mixed methods approach. We present a content analysis which revealed that Tweets that contained the word "insomnia" contained significantly more negative health information than a random sample, strongly suggesting that individuals were making disclosures about their sleep disorder. A subsequent thematic analysis then revealed two themes: coping with insomnia, and describing the experience of insomnia. We discuss these themes as well as the implications of our research for those in the interaction design community interested in integrating online social media systems in health interventions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1501–1510},
numpages = {10},
keywords = {microblogging, twitter, health, mental health, insomnia, self-disclosure},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208601,
author = {Pfeifer Vardoulakis, Laura and Karlson, Amy and Morris, Dan and Smith, Greg and Gatewood, Justin and Tan, Desney},
title = {Using Mobile Phones to Present Medical Information to Hospital Patients},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208601},
doi = {10.1145/2207676.2208601},
abstract = {The awareness that hospital patients have of the people and events surrounding their care has a dramatic impact on satisfaction and clinical outcomes. However, patients are often under-informed about even basic aspects of their care. In this work, we hypothesize that mobile devices - which are increasingly available to patients - can be used as real-time information conduits to improve patient awareness and consequently improve patient care. To better understand the unique affordances that mobile devices offer in the hospital setting, we provided twenty-five patients with mobile phones that presented a dynamic, interactive report on their progress, care plan, and care team throughout their emergency department stay. Through interviews with these patients, their visitors, and hospital staff, we explore the benefits and challenges of using the mobile phone as an information display, finding overall that this is a promising approach to improving patient awareness. Furthermore, we demonstrate that only a small number of technology challenges remain before such a system could be deployed without researcher intervention.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1411–1420},
numpages = {10},
keywords = {mobile phone, health information, patient awareness},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208348,
author = {Ferreira, Pedro and H\"{o}\"{o}k, Kristina},
title = {Appreciating Plei-Plei around Mobiles: Playfulness in Rah Island},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208348},
doi = {10.1145/2207676.2208348},
abstract = {We set out to explore and understand the ways in which mobiles made their way into an environment--Rah Island in Vanuatu--for the first time. We were struck by their playful use, especially given the very limited infrastructure and inexpensive devices that were available. Based on our findings, we discuss tensions between playfulness and utility, in particular relating to socio-economic benefits, and conclude that playfulness in these settings needs to be taken as seriously as in any other setting. Additionally, we formulated three challenges when designing for play in similar settings: (1) engage intimately with the materials of inexpensive ICT; (2) revisit design recommendations for playfulness to ensure that they can travel/translate into other cultures; and (3) alleviate existing tensions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2015–2024},
numpages = {10},
keywords = {playfulness, ICT4D, third wave hci},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208718,
author = {Tabard, Aur\'{e}lien and Hincapi\'{e} Ramos, Juan David and Bardram, Jakob},
title = {The ELabBench in the Wild: Supporting Exploration in a Molecular Biology Lab},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208718},
doi = {10.1145/2207676.2208718},
abstract = {In this paper we present a field trial of the eLabBench, a digital tabletop-based laboratory bench designed to support the exploratory practices of molecular biologists in the laboratory. The eLabBench supports the organization of personal information, capture of experimental work for later access, and the use of a variety of computational resources directly at the lab bench. We deployed the eLabBench in a biology laboratory for 16 weeks, and invited seven molecular biologists to run experiments on it. We report on how they used the bench and how it fitted within their larger experimental process. The main impact of the eLabBench lies in the changes it sparked off in preparing, running, and documenting lab experiments. By supporting computation at the bench and management of physical objects in the office, the eLabBench blurred the separation between office and laboratory work. Based on our observations, we discuss how interactive systems for laboratories such as the eLabBench can support a more exploratory or design-oriented way of 'doing' science.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3051–3060},
numpages = {10},
keywords = {field study, laboratory, design, life-sciences, digital bench, research practices, tabletop, elabbench, experiment, biology},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208397,
author = {Froehlich, Jon and Findlater, Leah and Ostergren, Marilyn and Ramanathan, Solai and Peterson, Josh and Wragg, Inness and Larson, Eric and Fu, Fabia and Bai, Mazhengmin and Patel, Shwetak and Landay, James A.},
title = {The Design and Evaluation of Prototype Eco-Feedback Displays for Fixture-Level Water Usage Data},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208397},
doi = {10.1145/2207676.2208397},
abstract = {Few means currently exist for home occupants to learn about their water consumption: e.g., where water use occurs, whether such use is excessive and what steps can be taken to conserve. Emerging water sensing systems, however, can provide detailed usage data at the level of individual water fixtures (i.e., disaggregated usage data). In this paper, we perform formative evaluations of two sets of novel eco-feedback displays that take advantage of this disaggregated data. The first display set isolates and examines specific elements of an eco-feedback design space such as data and time granularity. Displays in the second set act as design probes to elicit reactions about competition, privacy, and integration into domestic space. The displays were evaluated via an online survey of 651 North American respondents and in-home, semi-structured interviews with 10 families (20 adults). Our findings are relevant not only to the design of future water eco-feedback systems but also for other types of consumption (e.g., electricity and gas).},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2367–2376},
numpages = {10},
keywords = {eco-feedback, sustainability, water, iterative design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207689,
author = {Cox, Anna and Cairns, Paul and Shah, Pari and Carroll, Michael},
title = {Not Doing but Thinking: The Role of Challenge in the Gaming Experience},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207689},
doi = {10.1145/2207676.2207689},
abstract = {Previous research into the experience of videogames has shown the importance of the role of challenge in producing a good experience. However, defining exactly which challenges are important and which aspects of gaming experience are affected is largely under-explored. In this paper, we investigate if altering the level of challenge in a videogame influences people's experience of immersion. Our first study demonstrates that simply increasing the physical demands of the game by requiring gamers to interact more with the game does not result in increased immersion. In a further two studies, we use time pressure to make games more physically and cognitively challenging. We find that the addition of time pressure increases immersion as predicted. We argue that the level of challenge experienced is an interaction between the level of expertise of the gamer and the cognitive challenge encompassed within the game.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {79–88},
numpages = {10},
keywords = {immersion, challenge, games},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207728,
author = {Klemperer, Peter and Liang, Yuan and Mazurek, Michelle and Sleeper, Manya and Ur, Blase and Bauer, Lujo and Cranor, Lorrie Faith and Gupta, Nitin and Reiter, Michael},
title = {Tag, You Can See It! Using Tags for Access Control in Photo Sharing},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207728},
doi = {10.1145/2207676.2207728},
abstract = {Users often have rich and complex photo-sharing preferences, but properly configuring access control can be difficult and time-consuming. In an 18-participant laboratory study, we explore whether the keywords and captions with which users tag their photos can be used to help users more intuitively create and maintain access-control policies. We find that (a) tags created for organizational purposes can be repurposed to create efficient and reasonably accurate access-control rules; (b) users tagging with access control in mind develop coherent strategies that lead to significantly more accurate rules than those associated with organizational tags alone; and (c) participants can understand and actively engage with the concept of tag-based access control.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {377–386},
numpages = {10},
keywords = {human factors, tagging, access control, privacy},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208686,
author = {Woelfer, Jill Palzkill and Hendry, David G.},
title = {Homeless Young People on Social Network Sites},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208686},
doi = {10.1145/2207676.2208686},
abstract = {This paper reports on the use of social network sites (MySpace and Facebook) by homeless young people, an extraordinary user population, made so in part by its vulnerability. Twenty-three participants of diverse ethnicities, 11 women and 12 men (mean age, 21.7 years), were interviewed in same-sex discussion groups of four participants each. The interviews consisted of questions about the uses, benefits, and harms of social network sites and how people present themselves online. Qualitative analysis of the discussion group transcripts shows how young people explore their identities, cultivate and exploit social ties, experience interpersonal tensions, manage incompatible audiences, and respond to shifting affiliations and transitions. From this analysis, implications for social intervention and technical design are presented, focused on maintaining ties with pro-social family and friends and with maintaining separation between communication spheres of incompatible audiences. This work contributes to the growing literature on vital, deeply human experiences that have become associated with social network sites.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2825–2834},
numpages = {10},
keywords = {social and technical design, homeless young people, vulnerability, myspace, facebook, social network sites},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208550,
author = {Cheema, Salman and Gulwani, Sumit and LaViola, Joseph},
title = {QuickDraw: Improving Drawing Experience for Geometric Diagrams},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208550},
doi = {10.1145/2207676.2208550},
abstract = {We present QuickDraw, a prototype sketch-based drawing tool, that facilitates drawing of precise geometry diagrams that are often drawn by students and academics in several scientific disciplines. Quickdraw can recognize sketched diagrams containing components such as line segments and circles, infer geometric constraints relating recognized components, and use this information to beautify the sketched diagram. Beautification is based on a novel algorithm that iteratively computes various sub-components of the components using an extensible set of deductive rules. We conducted a user study comparing QuickDraw with four state-of-the-art diagramming tools: Microsoft PowerPoint, Cabri II Plus, Geometry Expressions and Geometer's SketchPad. Our study demonstrates a strong interest among participants for the use of sketch-based software for drawing geometric diagrams. We also found that QuickDraw enables users to draw precise diagrams faster than the majority of existing tools in some cases, while having them make fewer corrections.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1037–1064},
numpages = {28},
keywords = {geometry constraint solving, sketch-based interfaces, sketch recognition, sketch beautification},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207745,
author = {Holz, Christian and Grossman, Tovi and Fitzmaurice, George and Agur, Anne},
title = {Implanted User Interfaces},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207745},
doi = {10.1145/2207676.2207745},
abstract = {We investigate implanted user interfaces that small devices provide when implanted underneath human skin. Such devices always stay with the user, making their implanted user interfaces available at all times. We discuss four core challenges of implanted user interfaces: how to sense input through the skin, how to produce output, how to communicate amongst one another and with external infrastructure, and how to remain powered. We investigate these four challenges in a technical evaluation where we surgically implant study devices into a specimen arm. We find that traditional interfaces do work through skin. We then demonstrate how to deploy a prototype device on participants, using artificial skin to simulate implantation. We close with a discussion of medical considerations of implanted user interfaces, risks and limitations, and project into the future.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {503–512},
numpages = {10},
keywords = {implantables, disappearing mobile devices, wearable computing, wireless power, augmented humans, mobile devices, implanted interfaces, implanted devices},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208322,
author = {Mueller, Florian and Vetere, Frank and Gibbs, Martin and Edge, Darren and Agamanolis, Stefan and Sheridan, Jennifer and Heer, Jeffrey},
title = {Balancing Exertion Experiences},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208322},
doi = {10.1145/2207676.2208322},
abstract = {Exercising with others, such as jogging in pairs, can be socially engaging. However, if exercise partners have different fitness levels then the activity can be too strenuous for one and not challenging enough for the other, compromising engagement and health benefits. Our system, Jogging over a Distance, uses heart rate data and spatialized sound to create an equitable, balanced experience between joggers of different fitness levels who are geographically distributed. We extend this prior work by analyzing the experience of 32 joggers to detail how specific design features facilitated, and hindered, an engaging and balanced exertion experience. With this knowledge, we derive four dimensions that describe a design space for balancing exertion experiences: Measurement, Adjustment, Presentation and Control. We also present six design tactics for creating balanced exertion experiences described by these dimensions. By aiding designers in supporting participants of different physical abilities, we hope to increase participation and engagement with physical activity and facilitate the many benefits it brings about.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1853–1862},
numpages = {10},
keywords = {running, whole-body interaction, dynamic difficulty adjustment, handicap, exertion interface, exergame, jogging, dynamic game balancing, heart rate scaling, sport},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208395,
author = {Kjeldskov, Jesper and Skov, Mikael B. and Paay, Jeni and Pathmanathan, Rahuvaran},
title = {Using Mobile Phones to Support Sustainability: A Field Study of Residential Electricity Consumption},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208395},
doi = {10.1145/2207676.2208395},
abstract = {Recent focus on sustainability has made consumers more aware of our joint responsibility for conserving energy resources such as electricity. However, reducing electricity use can be difficult with only a meter and a monthly or annual electricity bill. With the emergence of new power meters units, information on electricity consumption is now available digitally and wirelessly. This enables the design and deployment of a new class of persuasive systems giving consumers insight into their use of energy resources and means for reducing it. In this paper, we explore the design and use of one such system, Power Advisor, promoting electricity conservation through tailored information on a mobile phone or tablet. The use of the system in 10 households was studied over 7 weeks. Findings provide insight into peoples awareness of electricity consumption in their home and how this may be influenced through design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2347–2356},
numpages = {10},
keywords = {households, sustainability, electricity consumption},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208530,
author = {Van Kleek, Max and Smith, Daniel and Stranders, Ruben and schraefel, m.c.},
title = {Twiage: A Game for Finding Good Advice on Twitter},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208530},
doi = {10.1145/2207676.2208530},
abstract = {Millions of recommendations, opinions and experiences are shared across popular microblogging platforms and services each day. Yet much of this content becomes quickly lost in the stream shortly after being posted. This paper looks at the feasibility of identifying useful content in microblog streams so that it might be archived to facilitate wider access and reference. Towards this goal, we present an experiment with a game-with-a-purpose called Twiage that we designed to determine how well the deluge of content in "raw" microblog streams could be turned into filtered and ranked collections using ratings from players. Experiments with Twiage validate the feasibility of applying human-computation to this problem, finding strong agreement about what constitutes the "most useful" content in our test dataset. Second, we compare the effectiveness of various methods of eliciting such ratings, finding that a "choose-best" interface and Elo rating ranking scheme yield the greatest agreement in the fewest rounds. External validation of resulting top-rated twitter content with a domain expert found that while the top Twiage-ranked "tweets" were among the best of the set, there was a tendency for players to also select what we term "weak spam" - e.g., promotional content disguised as articles or reviews, indicating a need for more stringent content filtering.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {889–898},
numpages = {10},
keywords = {social information filtering, microblogs, human-computation, games with a purpose, crowdsourcing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208716,
author = {Yardi, Sarita and Bruckman, Amy},
title = {Income, Race, and Class: Exploring Socioeconomic Differences in Family Technology Use},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208716},
doi = {10.1145/2207676.2208716},
abstract = {Minorities are the fastest growing demographic in the U.S. and the poverty level in the U.S. is the highest it has been in 50 years. We interviewed middle to upper class, suburban, white American parents and low-income, urban, African-American parents to understand how each group incorporates technology into their lives. Participants had teens in their homes and devices like computers and cell phones played a powerful and preeminent role in family life. Our results show that socioeconomic differences both reflect and reinforce technology use at home. Specifically, low socioeconomic status families share devices more often and low socioeconomic status teens have more responsibility and independence in their technology use. We argue that that as low socioeconomic status families become the majority demographic, the CHI community needs to better understand how to design for these groups.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3041–3050},
numpages = {10},
keywords = {class, race, families, social computing, african american, income, socioeconomic status., parents, teens},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208409,
author = {Diakopoulos, Nicholas and De Choudhury, Munmun and Naaman, Mor},
title = {Finding and Assessing Social Media Information Sources in the Context of Journalism},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208409},
doi = {10.1145/2207676.2208409},
abstract = {Social media is already a fixture for reporting for many journalists, especially around breaking news events where non-professionals may already be on the scene to share an eyewitness report, photo, or video of the event. At the same time, the huge amount of content posted in conjunction with such events serves as a challenge to finding interesting and trustworthy sources in the din of the stream. In this paper we develop and investigate new methods for filtering and assessing the verity of sources found through social media by journalists. We take a human centered design approach to developing a system, SRSR ("Seriously Rapid Source Review"), informed by journalistic practices and knowledge of information production in events. We then used the system, together with a realistic reporting scenario, to evaluate the filtering and visual cue features that we developed. Our evaluation offers insights into social media information sourcing practices and challenges, and highlights the role technology can play in the solution.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2451–2460},
numpages = {10},
keywords = {news events, computational journalism, social media},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208611,
author = {Zilouchian Moghaddam, Roshanak and Bailey, Brian and Fu, Wai-Tat},
title = {Consensus Building in Open Source User Interface Design Discussions},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208611},
doi = {10.1145/2207676.2208611},
abstract = {We report results of a study which examines consensus building in user interface design discussions in open source software communities. Our methodology consisted of conducting interviews with designers and developers from the Drupal and Ubuntu communities (N=17) and analyzing a large corpus of interaction data collected from Drupal. The interviews captured user perspectives on the challenges of reaching consensus, techniques employed for building consensus, and the consequences of not reaching consensus. We analyzed the interaction data to determine how different elements of the content, process, and user relationships in the design discussions affect consensus. Our main result shows that design discussions engaging participants with more experience and prior interaction history are more likely to reach consensus. Based on all of our results, we formulated design implications for promoting consensus in distributed discussions of user interface design issues.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1491–1500},
numpages = {10},
keywords = {consensus, design discussion, open source software},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208288,
author = {Elias, Micheline and Bezerianos, Anastasia},
title = {Annotating BI Visualization Dashboards: Needs &amp; Challenges},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208288},
doi = {10.1145/2207676.2208288},
abstract = {Annotations have been identified as an important aid in analysis record-keeping and recently data discovery. In this paper we discuss the use of annotations on visualization dashboards, with a special focus on business intelligence (BI) analysis. In-depth interviews with experts lead to new annotation needs for multi-chart visualization systems, on which we based the design of a dashboard prototype that supports data and context aware annotations. We focus particularly on novel annotation aspects, such as multi-target annotations, annotation transparency across charts and data dimension levels, as well as annotation properties such as lifetime and validity. Moreover, our prototype is built on a data layer shared among different data-sources and BI applications, allowing cross application annotations. We discuss challenges in supporting context aware annotations in dashboards and other visualizations, such as dealing with changing annotated data, and provide design solutions. Finally we report reactions and recommendations from a different set of expert users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1641–1650},
numpages = {10},
keywords = {business intelligence, visualization dashboards, annotation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207722,
author = {Odom, William and Zimmerman, John and Forlizzi, Jodi and Choi, Hajin and Meier, Stephanie and Park, Angela},
title = {Investigating the Presence, Form and Behavior of Virtual Possessions in the Context of a Teen Bedroom},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207722},
doi = {10.1145/2207676.2207722},
abstract = {Over the past several years, people have acquired more and more virtual possessions. While virtual possessions have become ubiquitous, little work exists to inform designers on how these growing collections should be displayed and how they should behave. We generated four design concepts that changed the form and behavior of these digital things, making them more present within a teen bedroom. We then conducted speed dating sessions to investigate how these new forms and behaviors influence perceptions of value. Sessions revealed how new technologies might better support self-exploration and reflection, as well as how they could complicate identity construction processes. Findings are interpreted to detail opportunities and tensions that can guide future research and practice in this emerging space.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {327–336},
numpages = {10},
keywords = {research through design, virtual possessions, teenagers, home, speed dating, bedroom, user enactments, design methods, design research, design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208727,
author = {Lee, Bhoram and Lee, Hyunjeong and Lim, Soo-Chul and Lee, Hyungkew and Han, Seungju and Park, Joonah},
title = {Evaluation of Human Tangential Force Input Performance},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208727},
doi = {10.1145/2207676.2208727},
abstract = {While interacting with mobile devices, users may press against touch screens and also exert tangential force to the display in a sliding manner. We seek to guide UI design based on the tangential force applied by a user to the surface of a hand-held device. A prototype of an interface using tangential force input was implemented utilizing a force sensitive layer and an elastic layer and used for the user experiment. We investigated user controllability to reach and maintain target force levels and considered the effects of hand pose and direction of force input. Our results imply no significant difference in performance when applying force holding the device in one hand and in two hands. We also observed that users have more physical and perceived loads when applying tangential force in the left-right direction compared to the up-down direction. Based on the experimental results, we discuss considerations for user interface applications of tangential-force-based interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3121–3130},
numpages = {10},
keywords = {input devices, force-based interface, mobile interaction},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208655,
author = {M\"{u}ller, Claudia and Neufeldt, Cornelius and Randall, David and Wulf, Volker},
title = {ICT-Development in Residential Care Settings: Sensitizing Design to the Life Circumstances of the Residents of a Care Home},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208655},
doi = {10.1145/2207676.2208655},
abstract = {In this paper we wish to contribute to the recent ICT-design for and reflection of the application field of residential care homes. In doing so, the contribution of the paper is twofold: we wish to highlight some aspects of the every-day life of institutionalized elderly people - trust, sociality, and memory - which not only provoke reflection on design ideas but also on the socio-technical nexus in which design for the elderly has to take place. This domain, we suggest, is one where the 'parachuting in' of technology is unlikely to prove successful, for reasons we examine below. Further, we suggest that design for and with the elderly carries with it some specific problems. We illustrate our methodological reflections by means of an ongoing empirical research project which aims at the development of a large-screen display for a residential care home.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2639–2648},
numpages = {10},
keywords = {methodology, residential care, large-screen display, elderly people, design, action research},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208665,
author = {Xie, Jing and Lipford, Heather and Chu, Bei-Tseng},
title = {Evaluating Interactive Support for Secure Programming},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208665},
doi = {10.1145/2207676.2208665},
abstract = {Implementing secure code is an important and oft-overlooked non-functional requirement. Secure programming errors are a subset of program errors that result in many common privacy and security breaches in commercial software. We are seeking to provide interactive support for secure programming in the development environment. In this paper, we have evaluated our prototype tool, ASIDE, which provides real-time warnings and code generation to reduce secure programming errors introduced by programmers. We evaluate the potential use and effectiveness of ASIDE on both novice and professional developers in two comparison user studies. Our results demonstrate that the interactive support can help address this important non-functional requirement, and suggest guidelines for such tools to support programmers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2707–2716},
numpages = {10},
keywords = {secure programming, software security, software developers},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@article{10.1145/2212757.2212764,
author = {Ives, Blake and Adams, Dennis},
title = {Shaping the Future of IT within the Academy},
year = {2012},
issue_date = {May 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {2},
issn = {0095-0033},
url = {https://doi.org/10.1145/2212757.2212764},
doi = {10.1145/2212757.2212764},
abstract = {We summarize the problems and potential solutions put forward in the four articles by the Deans and then offer three lenses to consider as we reimagine the future of IT education and research. These lenses include major disruptions in education that are already emerging, the need to harness the huge, ever, payoff from the rapid, but predictable, growth in information technology, and, what seems likely to be, a painful transition from an economy based largely on labor and material goods to one based on software and information goods.},
journal = {SIGMIS Database},
month = may,
pages = {33–43},
numpages = {11},
keywords = {perspectives on the is field, moore's law, future of it, khan academy, it research, disruptive technology, it education, information abundance}
}

@inproceedings{10.1145/2222436.2222438,
author = {Cinque, Marcello and Cotroneo, Domenico and Testa, Alessandro},
title = {A Logging Framework for the On-Line Failure Analysis of Android Smart Phones},
year = {2012},
isbn = {9781450311502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2222436.2222438},
doi = {10.1145/2222436.2222438},
abstract = {This paper introduces the design of a logging framework for the on-line failure analysis of Android Smart Phones. The framework enables the collection of failure data at runtime, useful to assess the dependability of smart phones, to deeply investigate the causes of failures, and to reduce maintenance efforts. Existing tools mainly focus on the collection of failure data about application crashes. The aim of the proposed framework is to extend the collection to other types of failures, such as, application hang, phone freeze and phone self-reboot. The paper describes the main design choices behind the components of the framework, and investigates advantages and disadvantages of different solutions.},
booktitle = {Proceedings of the 1st European Workshop on AppRoaches to MObiquiTous Resilience},
articleno = {2},
numpages = {6},
location = {Sibiu, Romania},
series = {ARMOR '12}
}

@inproceedings{10.1145/2212908.2212928,
author = {Min, Alexander W. and Wang, Ren and Tsai, James and Ergin, Mesut A. and Tai, Tsung-Yuan Charlie},
title = {Improving Energy Efficiency for Mobile Platforms by Exploiting Low-Power Sleep States},
year = {2012},
isbn = {9781450312158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2212908.2212928},
doi = {10.1145/2212908.2212928},
abstract = {Reducing energy consumption is one of the most important design aspects for small form-factor mobile platforms, such as smartphones and tablets. Despite its potential for power savings, optimally leveraging system low-power sleep states during active mobile workloads, such as video streaming and web browsing, has not been fully explored. One major challenge is to make intelligent power management decisions based on, among other things, accurate system idle duration prediction, which is difficult due to the non-deterministic system interrupt behavior. In this paper, we propose a novel framework, called E2S3 (Energy Efficient Sleep-State Selection), that dynamically enters the optimal low-power sleep state to minimize the system power consumption. In particular, E2S3 detects and exploits short idle durations during active mobile workloads by, (i) finding optimal thresholds (i.e., energy break-even times) for multiple low-power sleep states, (ii) predicting the sleep-state selection error probabilities heuristically, and by (iii) selecting the optimal sleep state based on the expected reward, e.g., power consumption, which incorporates the risks of making a wrong decision We implemented and evaluated E2S3 on Android-based smartphones, demonstrating the effectiveness of the algorithm. The evaluation results show that E2S3 significantly reduces the platform energy consumption, by up to 50% (hence extending battery life), without compromising system performance.},
booktitle = {Proceedings of the 9th Conference on Computing Frontiers},
pages = {133–142},
numpages = {10},
keywords = {low-power sleep states, idle duration prediction, mobile platform, energy efficiency, reward-based sleep-state selection},
location = {Cagliari, Italy},
series = {CF '12}
}

@inproceedings{10.1145/2212908.2212915,
author = {Chang, Jichuan and Ranganathan, Parthasarathy and Mudge, Trevor and Roberts, David and Shah, Mehul A. and Lim, Kevin T.},
title = {A Limits Study of Benefits from Nanostore-Based Future Data-Centric System Architectures},
year = {2012},
isbn = {9781450312158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2212908.2212915},
doi = {10.1145/2212908.2212915},
abstract = {The adoption of non-volatile memories (NVMs) in system architecture and the growth in data-centric workloads offer exciting opportunities for new designs. In this paper, we examine the potential and limit of designs that move compute in close proximity to NVM-based data stores. To address the challenges in evaluating such system architectures for distributed systems, we develop and validate a new methodology for large-scale data-centric workloads. We then study "nanostores" as an example design that constructs distributed systems from building blocks with 3D-stacked compute and NVM layers on the same chip, replacing both traditional storage and memory with NVM. Our limits study demonstrates significant potential of this approach (3-162X improvement in energy delay product) over 2015 baselines, particularly for IO-intensive workloads. We also discuss and quantify the impact of network bandwidth, software scalability, and power density, and design tradeoffs for future NVM-based data-centric architectures.},
booktitle = {Proceedings of the 9th Conference on Computing Frontiers},
pages = {33–42},
numpages = {10},
keywords = {data-centric data centers, non-volatile memory, system architectures, limits study, nanostores},
location = {Cagliari, Italy},
series = {CF '12}
}

@inproceedings{10.1145/2213836.2213950,
author = {Pavlidis, Yannis and Mathihalli, Madhusudan and Chakravarty, Indrani and Batra, Arvind and Benson, Ron and Raj, Ravi and Yau, Robert and McKiernan, Mike and Harinarayan, Venky and Rajaraman, Anand},
title = {Anatomy of a Gift Recommendation Engine Powered by Social Media},
year = {2012},
isbn = {9781450312479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2213836.2213950},
doi = {10.1145/2213836.2213950},
abstract = {More and more people conduct their shopping online [1], especially during the holiday season [2]. Shopping online offers a lot of convenience, including the luxury of shopping from home, the ease of research, better prices, and in many cases access to unique products not available in stores.One of the facets of shopping is gifting. Gifting may be the act of giving a present to somebody because of an event (e.g., birthday) or occasion (e.g., house warming party). People may also treat themselves or loved ones to a gift. Regardless of the occasion or the reason for gifting, there is often one common denominator: delight the receiver. The pursuit of delight can cause a great deal of stress and also be extremely time consuming as many people today either already have everything, or have easy access to everything.The @WalmartLabs Gift Recommendation Engine and its first application, Shopycat, which is a gift finder application on Facebook, aim to find the right and "wow" gifts much easier and quicker than ever before, by taking into account social media interactions. In this paper we will begin by describing the Shopycat Social Gift Finder Facebook application. Next, we describe the components of the engine. Finally, we discuss the metrics used to evaluate the engine.Building such a gift recommendation engine raises many challenges, in inferring user interests, computing the giftability of a product and an interest, and processing the big and fast data associated with social media. We briefly discuss our solutions to these challenges. Overall, our gift recommendation engine is an example that illustrates social commerce, a powerful emerging trend in e-commerce, and a major focus of @WalmartLabs.},
booktitle = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},
pages = {757–764},
numpages = {8},
keywords = {semantic analysis, social genome, information extraction, data integration, recommendation engine, social media, gift},
location = {Scottsdale, Arizona, USA},
series = {SIGMOD '12}
}

@inproceedings{10.1145/2443416.2443417,
author = {Albrecht, Michael and Donnelly, Patrick and Bui, Peter and Thain, Douglas},
title = {Makeflow: A Portable Abstraction for Data Intensive Computing on Clusters, Clouds, and Grids},
year = {2012},
isbn = {9781450318761},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2443416.2443417},
doi = {10.1145/2443416.2443417},
abstract = {In recent years, there has been a renewed interest in languages and systems for large scale distributed computing. Unfortunately, most systems available to the end user use a custom description language tightly coupled to a specific runtime implementation, making it difficult to transfer applications between systems. To address this problem we introduce Makeflow, a simple system for expressing and running a data-intensive workflow across multiple execution engines without requiring changes to the application or workflow description. Makeflow allows any user familiar with basic Unix Make syntax to generate a workflow and run it on one of many supported execution systems. Furthermore, in order to assess the performance characteristics of the various execution engines available to users and assist them in selecting one for use we introduce Workbench, a suite of benchmarks designed for analyzing common workflow patterns. We evaluate Workbench on two physical architectures -- the first a storage cluster with local disks and a slower network and the second a high performance computing cluster with a central parallel filesystem and fast network -- using a variety of execution engines. We conclude by demonstrating three applications that use Makeflow to execute data intensive applications consisting of thousands of jobs.},
booktitle = {Proceedings of the 1st ACM SIGMOD Workshop on Scalable Workflow Execution Engines and Technologies},
articleno = {1},
numpages = {13},
location = {Scottsdale, Arizona, USA},
series = {SWEET '12}
}

@inproceedings{10.1145/2443416.2443420,
author = {Islam, Mohammad and Huang, Angelo K. and Battisha, Mohamed and Chiang, Michelle and Srinivasan, Santhosh and Peters, Craig and Neumann, Andreas and Abdelnur, Alejandro},
title = {Oozie: Towards a Scalable Workflow Management System for Hadoop},
year = {2012},
isbn = {9781450318761},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2443416.2443420},
doi = {10.1145/2443416.2443420},
abstract = {Hadoop is a massively scalable parallel computation platform capable of running hundreds of jobs concurrently, and many thousands of jobs per day. Managing all these computations demands for a workflow and scheduling system. In this paper, we identify four indispensable qualities that a Hadoop workflow management system must fulfill namely Scalability, Security, Multi-tenancy, and Operability. We find that conventional workflow management tools lack at least one of these qualities, and therefore present Apache Oozie, a workflow management system specialized for Hadoop. We discuss the architecture of Oozie, share our production experience over the last few years at Yahoo, and evaluate Oozie's scalability and performance.},
booktitle = {Proceedings of the 1st ACM SIGMOD Workshop on Scalable Workflow Execution Engines and Technologies},
articleno = {4},
numpages = {10},
keywords = {Oozie, workflow management, scalability, Hadoop},
location = {Scottsdale, Arizona, USA},
series = {SWEET '12}
}

@inproceedings{10.1145/2213836.2213843,
author = {Consens, Mariano P. and Ioannidou, Kleoni and LeFevre, Jeff and Polyzotis, Neoklis},
title = {Divergent Physical Design Tuning for Replicated Databases},
year = {2012},
isbn = {9781450312479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2213836.2213843},
doi = {10.1145/2213836.2213843},
abstract = {We introduce divergent designs as a novel tuning paradigm for database systems that employ replication. A divergent design installs a different physical configuration (e.g., indexes and materialized views) with each database replica, specializing replicas for different subsets of the workload. At runtime, queries are routed to the subset of the replicas configured to yield the most efficient execution plans. When compared to uniformly designed replicas, divergent replicas can potentially execute their subset of the queries significantly faster, and their physical configurations could be initialized and maintained(updated) in less time. However, the specialization of divergent replicas limits the ability to load-balance the workload at runtime.We formalize the divergent design problem, characterize the properties of good designs, and analyze the complexity of identifying the optimal divergent design. Our paradigm captures the trade-off between load balancing among all n replicas vs. load balancing among m ≤ n specialized replicas. We develop an effective algorithm (leveraging single-node-tuning functionality) to compute good divergent designs for all the points of this trade-off. Experimental results validate the effectiveness of the algorithm and demonstrate that divergent designs can substantially improve workload performance.},
booktitle = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},
pages = {49–60},
numpages = {12},
keywords = {physical design tuning, replicated databases, divergence},
location = {Scottsdale, Arizona, USA},
series = {SIGMOD '12}
}

@inproceedings{10.1145/2213836.2213840,
author = {Kwon, YongChul and Balazinska, Magdalena and Howe, Bill and Rolia, Jerome},
title = {SkewTune: Mitigating Skew in Mapreduce Applications},
year = {2012},
isbn = {9781450312479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2213836.2213840},
doi = {10.1145/2213836.2213840},
abstract = {We present an automatic skew mitigation approach for user-defined MapReduce programs and present SkewTune, a system that implements this approach as a drop-in replacement for an existing MapReduce implementation. There are three key challenges: (a) require no extra input from the user yet work for all MapReduce applications, (b) be completely transparent, and (c) impose minimal overhead if there is no skew. The SkewTune approach addresses these challenges and works as follows: When a node in the cluster becomes idle, SkewTune identifies the task with the greatest expected remaining processing time. The unprocessed input data of this straggling task is then proactively repartitioned in a way that fully utilizes the nodes in the cluster and preserves the ordering of the input data so that the original output can be reconstructed by concatenation. We implement SkewTune as an extension to Hadoop and evaluate its effectiveness using several real applications. The results show that SkewTune can significantly reduce job runtime in the presence of skew and adds little to no overhead in the absence of skew.},
booktitle = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},
pages = {25–36},
numpages = {12},
keywords = {user-defined operator, skew, partitioning, mapreduce},
location = {Scottsdale, Arizona, USA},
series = {SIGMOD '12}
}

@inproceedings{10.1145/2254556.2254659,
author = {Kandel, Sean and Parikh, Ravi and Paepcke, Andreas and Hellerstein, Joseph M. and Heer, Jeffrey},
title = {Profiler: Integrated Statistical Analysis and Visualization for Data Quality Assessment},
year = {2012},
isbn = {9781450312875},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254556.2254659},
doi = {10.1145/2254556.2254659},
abstract = {Data quality issues such as missing, erroneous, extreme and duplicate values undermine analysis and are time-consuming to find and fix. Automated methods can help identify anomalies, but determining what constitutes an error is context-dependent and so requires human judgment. While visualization tools can facilitate this process, analysts must often manually construct the necessary views, requiring significant expertise. We present Profiler, a visual analysis tool for assessing quality issues in tabular data. Profiler applies data mining methods to automatically flag problematic data and suggests coordinated summary visualizations for assessing the data in context. The system contributes novel methods for integrated statistical and visual analysis, automatic view suggestion, and scalable visual summaries that support real-time interaction with millions of data points. We present Profiler's architecture --- including modular components for custom data types, anomaly detection routines and summary visualizations --- and describe its application to motion picture, natural disaster and water quality data sets.},
booktitle = {Proceedings of the International Working Conference on Advanced Visual Interfaces},
pages = {547–554},
numpages = {8},
keywords = {anomaly detection, data quality, data analysis, visualization},
location = {Capri Island, Italy},
series = {AVI '12}
}

@inproceedings{10.1145/2213556.2213571,
author = {Kifer, Daniel and Machanavajjhala, Ashwin},
title = {A Rigorous and Customizable Framework for Privacy},
year = {2012},
isbn = {9781450312486},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2213556.2213571},
doi = {10.1145/2213556.2213571},
abstract = {In this paper we introduce a new and general privacy framework called Pufferfish. The Pufferfish framework can be used to create new privacy definitions that are customized to the needs of a given application. The goal of Pufferfish is to allow experts in an application domain, who frequently do not have expertise in privacy, to develop rigorous privacy definitions for their data sharing needs. In addition to this, the Pufferfish framework can also be used to study existing privacy definitions.We illustrate the benefits with several applications of this privacy framework: we use it to formalize and prove the statement that differential privacy assumes independence between records, we use it to define and study the notion of composition in a broader context than before, we show how to apply it to protect unbounded continuous attributes and aggregate information, and we show how to use it to rigorously account for prior data releases.},
booktitle = {Proceedings of the 31st ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems},
pages = {77–88},
numpages = {12},
keywords = {differential privacy, privacy},
location = {Scottsdale, Arizona, USA},
series = {PODS '12}
}

@inproceedings{10.1145/2254556.2254664,
author = {Ardito, C. and Costabile, M. F. and Lanzilotti, R. and De Angeli, A. and Desolda, G.},
title = {A Field Study of a Multi-Touch Display at a Conference},
year = {2012},
isbn = {9781450312875},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254556.2254664},
doi = {10.1145/2254556.2254664},
abstract = {Large interactive displays are increasingly used in public spaces. Yet, it is still a challenge to understand how people behave when faced with such displays in their real life, not only when they are used for entertainment (or advertising), but also when they mediate more purposeful tasks. Do people feel shy? Are they willing to interact? Are they satisfied with the services offered and will they come back to use them again? To answer such questions, these systems have to be evaluated in the field so as to understand their actual impact on users in the real life. This paper first introduces an initial evaluation framework, aimed at highlighting some of the variables involved in understanding the impact of large display installations. Then, it applies the framework to analyze users' behavior and their experience with a large display installed at an international conference. Results highlighted that people showed greater interest in those services that, despite a lower appeal, supported them in carrying out useful tasks.},
booktitle = {Proceedings of the International Working Conference on Advanced Visual Interfaces},
pages = {580–587},
numpages = {8},
keywords = {multi-touch display, field study, evaluation},
location = {Capri Island, Italy},
series = {AVI '12}
}

@inproceedings{10.1145/2422604.2422610,
author = {Auer, S\"{o}ren and Dalamagas, Theodore and Parkinson, Helen and Bancilhon, Fran\c{c}ois and Flouris, Giorgos and Sacharidis, Dimitris and Buneman, Peter and Kotzinos, Dimitris and Stavrakas, Yannis and Christophides, Vassilis and Papastefanatos, George and Thiveos, Kostas},
title = {Diachronic Linked Data: Towards Long-Term Preservation of Structured Interrelated Information},
year = {2012},
isbn = {9781450314046},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2422604.2422610},
doi = {10.1145/2422604.2422610},
abstract = {The Linked Data Paradigm is a promising technology for publishing, sharing, and connecting data on the Web, which provides new perspectives for data integration and interoperability. However, the proliferation of distributed, interconnected linked data sources on the Web poses significant new challenges for consistently managing the vast number of potentially large datasets and their interdependencies. In this article we focus on the key problem of preserving evolving structured interlinked data. We argue that a number of issues, which hinder applications and users, are related to the temporal aspect that is intrinsic in Linked Data. We present three use cases to motivate our approach, we discuss problems that occur, and propose a direction for a solution.},
booktitle = {Proceedings of the First International Workshop on Open Data},
pages = {31–39},
numpages = {9},
keywords = {data preservation, data evolution, linked data lifecycle, data provenance},
location = {Nantes, France},
series = {WOD '12}
}

@inproceedings{10.5555/2325676.2325689,
author = {Rozzi, Simone and Amaldi, Paola},
title = {Organizational and Inter-Organizational Precursors to Problematic Automation in Safety Critical Domains},
year = {2012},
isbn = {9782917490204},
publisher = {IRIT Press},
address = {Toulouse, FRA},
abstract = {Automation brings the potential for safety and capacity improvements in virtually any domain. However, such potential, is often compromised by those unintended and undesirable effects resulting from the interaction of automation with operational practices. This study inquires into the organizational and inter-organizational precursors to such effects in safety critical domains. While drawing on organizational safety literature, the study consists of an interpretive case centered on an alarm system from the Air Traffic Management domain. The history and adoption of the alarm have been investigated within the European Air Traffic Management System through the historical ethnographic method. Findings indicated that the main organizational precursors to problematic set up of the alarm included: (i) a tendency to frame implementation as an engineering routine project rather than an innovative safety effort; (ii) a commitment to implementation without an assessment of the organizational capability to implement the alarm; (iii) flawed service provider-software vendor integration; (iv) underspecified international standards. Implications for policy makers and managers of automation programmes are discussed.},
booktitle = {Proceedings of the 2nd International Conference on Application and Theory of Automation in Command and Control Systems},
pages = {98–106},
numpages = {9},
keywords = {organizational safety, problematic automation, nuisance alarms, resilience engineering, automation management},
location = {London, United Kingdom},
series = {ATACCS '12}
}

