@inproceedings{10.1145/2517899.2517927,
author = {Sabiescu, Amalia and van Zyl, Izak and Pucciarelli, Marta and Cantoni, Lorenzo and Bytheway, Andy and Chigona, Wallace and Tardini, Stefano},
title = {Changing Mindsets: The Attitude of Pre-Service Teachers on Technology for Teaching},
year = {2013},
isbn = {9781450319072},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517899.2517927},
doi = {10.1145/2517899.2517927},
abstract = {In a context where there has only been limited success with Information and Communication Technologies (ICTs) in education, this paper explores attitudes towards the use of ICTs in South African pre-service teacher education. In particular, it looks at how cognitive and affective attitudes towards technology determine visions and scenarios of technology integration into teaching and learning practice. This note presents the results of an in-depth qualitative study involving exceptionally motivated pre-service teachers from two higher education institutions. Findings indicate strong intentions to integrate ICT in future teaching and the constant inclination to keep updated with technological evolution. Pre-service teachers view themselves as users of technology in order to keep up with what they perceive to be a technologisation of life and education. The integration scenarios envisioned by participants demonstrate a changing mindset where technology is not only an additional tool, but enables the advancement of new teaching and learning models centred on the active role of the student. A critical look at the study findings compels us to give accrued importance to how living and learning in a developing area determines meaningful articulations of pro-technology attitudes.},
booktitle = {Proceedings of the Sixth International Conference on Information and Communications Technologies and Development: Notes - Volume 2},
pages = {136–139},
numpages = {4},
keywords = {technology imperative, attitude toward technology, technology in education, pre-service teacher education},
location = {Cape Town, South Africa},
series = {ICTD '13}
}

@inproceedings{10.1145/2516604.2516629,
author = {Mudliar, Preeti and Pal, Joyojeet},
title = {ICTD in the Popular Press: Media Discourse around Aakash, the 'World's Cheapest Tablet'},
year = {2013},
isbn = {9781450319065},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2516604.2516629},
doi = {10.1145/2516604.2516629},
abstract = {The quest for the low-cost computer has been among the primal motivations of innovation and practice in the ICTD world from its very beginnings. We discuss continuing developments in case of the low-cost Indian tablet, Aakash, publicized as the world's cheapest computer, and situate these within a history of India's quest for development through technology in the past two decades. We analyze 212 articles on Aakash and find four dominant themes in the way the device has been discussed in the popular media. These include the cult of a technocratic leadership, the discourse of indigenous technology, the recreation of the Silicon Valley dream, and the face of the marginal user. We argue that Aakash has gone beyond being a technology artifact to a device that represents Indian aspirations at several levels -- as a forward thinking state, an ingenious entrepreneurial class, and an energetic population that needs nothing but access to technology to succeed.},
booktitle = {Proceedings of the Sixth International Conference on Information and Communication Technologies and Development: Full Papers - Volume 1},
pages = {43–54},
numpages = {12},
keywords = {India, low-cost tablet, ICTD discourse, Aakash},
location = {Cape Town, South Africa},
series = {ICTD '13}
}

@inproceedings{10.5555/2675983.2676189,
author = {undefinedatek, Maciej M. and Rizi, Seyed M. Mussavi and Geller, Armando},
title = {Verification through Calibration: An Approach and a Case Study of a Model of Conflict in Syria},
year = {2013},
isbn = {9781479920778},
publisher = {IEEE Press},
abstract = {In this paper we introduce a workflow for multiagent modeling that relies on piecemeal calibration to verify the model, and discuss how modelers can organize this workflow to accelerate model building, improve the quality and technical soundness of the final model and be able to attribute dynamics of model outputs to causal mechanisms represented in the model. To this end, we apply the proposed workflow step by step to the development process of a multiagent model of the civil war in Syria, and visualize model validity and dynamics across individual development sprints.},
booktitle = {Proceedings of the 2013 Winter Simulation Conference: Simulation: Making Decisions in a Complex World},
pages = {1649–1660},
numpages = {12},
location = {Washington, D.C.},
series = {WSC '13}
}

@inproceedings{10.5555/2675983.2676150,
author = {Middleton, Victor},
title = {Distortion of "Mental Maps" as an Exemplar of Imperfect Situation Awareness},
year = {2013},
isbn = {9781479920778},
publisher = {IEEE Press},
abstract = {This paper provides the first results of dissertation research that seeks to develop and apply an experimental milieu for the study of imperfect Situation Awareness/Situation Understanding (SA/SU) and of decision-making based on that SA/SU. It describes an agent-based simulation and initial results of simulation experiments conducted with that framework. The simulation experiments explore a specific, easily understood, and quantifiable example of human behavior: intelligent agents being spatially "lost" while trying to navigate in a simulation world. The paper concludes with a discussion of on-going and planned research based on modifications to that simulation and conduct of additional experiments.},
booktitle = {Proceedings of the 2013 Winter Simulation Conference: Simulation: Making Decisions in a Complex World},
pages = {1316–1326},
numpages = {11},
location = {Washington, D.C.},
series = {WSC '13}
}

@inproceedings{10.5555/2675983.2675821,
author = {Klaas, Alexander and Laroque, Christoph and Renken, Hendrik and Dangelmaier, Wilhelm},
title = {Simulation Aided, Self-Adapting Knowledge Based Control of Material Handling Systems},
year = {2013},
isbn = {9781479920778},
publisher = {IEEE Press},
abstract = {Knowledge based methods have recently been applied to the control of material handling systems, specifically using simulation as a source of knowledge. Little research has been done however on ensuring a consistently high quality of the data generated by the simulation, especially under changing circumstances such as differing load patterns in the system. We propose a self-adapting control that is able to automatically generate knowledge according to current circumstances using a parametrized simulation model, which uses observed system parameters as input. The control automatically triggers generation when necessary, detects changes in the system and also proactively anticipates them, resulting in consistently high performance. For the problem of knowledge generation (determining an optimal control action to a given situation), we present a look ahead simulation method that considers uncertainties. We validated our approach in a real world material handling system, developed by L\"{o}dige Industries GmbH.},
booktitle = {Proceedings of the 2013 Winter Simulation Conference: Simulation: Making Decisions in a Complex World},
pages = {3418–3429},
numpages = {12},
location = {Washington, D.C.},
series = {WSC '13}
}

@inproceedings{10.5555/2675983.2676173,
author = {Barrett, Christopher and Bisset, Keith and Chandan, Shridhar and Chen, Jiangzhuo and Chungbaek, Youngyun and Eubank, Stephen and Evrenoso\u{g}lu, Yaman and Lewis, Bryan and Lum, Kristian and Marathe, Achla and Marathe, Madhav and Mortveit, Henning and Parikh, Nidhi and Phadke, Arun and Reed, Jeffrey and Rivers, Caitlin and Saha, Sudip and Stretz, Paula and Swarup, Samarth and Thorp, James and Vullikanti, Anil and Xie, Dawen},
title = {Planning and Response in the Aftermath of a Large Crisis: An Agent-Based Informatics Framework},
year = {2013},
isbn = {9781479920778},
publisher = {IEEE Press},
abstract = {We present a synthetic information and modeling environment that can allow policy makers to study various counter-factual experiments in the event of a large human-initiated crisis. The specific scenario we consider is a ground detonation caused by an improvised nuclear device in a large urban region.In contrast to earlier work in this area that focuses largely on the prompt effects on human health and injury, we focus on co-evolution of individual and collective behavior and its interaction with the differentially damaged infrastructure. This allows us to study short term secondary and tertiary effects. The present environment is suitable for studying the dynamical outcomes over a two week period after the initial blast.A novel computing and data processing architecture is described; the architecture allows us to represent multiple co-evolving infrastructures and social networks at a highly resolved temporal, spatial, and individual scale. The representation allows us to study the emergent behavior of individuals as well as specific strategies to reduce casualties and injuries that exploit the spatial and temporal nature of the secondary and tertiary effects.A number of important conclusions are obtained using the modeling environment. For example, the studies decisively show that deploying ad hoc communication networks to reach individuals in the affected area is likely to have a significant impact on the overall casualties and injuries.},
booktitle = {Proceedings of the 2013 Winter Simulation Conference: Simulation: Making Decisions in a Complex World},
pages = {1515–1526},
numpages = {12},
location = {Washington, D.C.},
series = {WSC '13}
}

@inproceedings{10.1145/2541596.2541601,
author = {Rusitschka, Sebnem and Doblander, Christoph and Goebel, Christoph and Jacobsen, Hans-Arno},
title = {Adaptive Middleware for Real-Time Prescriptive Analytics in Large Scale Power Systems},
year = {2013},
isbn = {9781450325509},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2541596.2541601},
doi = {10.1145/2541596.2541601},
abstract = {The increased digitalization of power systems poses both opportunities and challenges for system operators. GPS time-synchronized high-resolution data streams emanating from measurement devices distributed over a wide area enable the detection of disturbances and the real-time monitoring of consequences as they are evolving, such as undamped oscillations. Processing these data streams is not possible with state-of-the-art SCADA systems that poll data asynchronously at much lower time intervals. Moreover, real-time analysis on fresh streaming data at the enterprise level is an unresolved challenge. In this paper we propose an adaptive middleware concept that can make better use of available data processing resources by enabling distributed computation both on the enterprise and on the field level. We apply the concept of linked data to provide a map for moving the computation to the data it requires for analysis. If based on the IEC 61850 standard semantic data model, the linked data concept additionally yields location and domain awareness that can be leveraged for real-time prescriptive analytics in the field. Another advantage of the proposed adaptive middleware is the abstraction of computational resources: Analytical programs can be written once and then be used to process historical data residing on servers on the enterprise level as well on the distributed devices that originated the data to enable fast analysis of events as they are unfolding.},
booktitle = {Proceedings of the Industrial Track of the 13th ACM/IFIP/USENIX International Middleware Conference},
articleno = {5},
numpages = {6},
keywords = {data analytics, IEC 61850, middleware, distributed computing, power system automation},
location = {Beijing, China},
series = {Middleware Industry '13}
}

@inproceedings{10.1145/2522848.2531740,
author = {Day, Matthew},
title = {Emotion Recognition with Boosted Tree Classifiers},
year = {2013},
isbn = {9781450321297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2522848.2531740},
doi = {10.1145/2522848.2531740},
abstract = {In this paper, we describe a simple system to recognize emotions from short video sequences, developed for the Emotion Recognition in the Wild Challenge (EmotiW 2013). Performance matches the challenge baseline whilst being significantly faster and lower in complexity. Our experiments and subsequent discussion provide a number of insights into the problem.},
booktitle = {Proceedings of the 15th ACM on International Conference on Multimodal Interaction},
pages = {531–534},
numpages = {4},
keywords = {gradient boosting, machine learning, emotion recognition},
location = {Sydney, Australia},
series = {ICMI '13}
}

@inproceedings{10.1145/2522848.2531743,
author = {Meudt, Sascha and Zharkov, Dimitri and K\"{a}chele, Markus and Schwenker, Friedhelm},
title = {Multi Classifier Systems and Forward Backward Feature Selection Algorithms to Classify Emotional Coloured Speech},
year = {2013},
isbn = {9781450321297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2522848.2531743},
doi = {10.1145/2522848.2531743},
abstract = {Systems for the recognition of psychological characteristics such as the emotional state in real world scenarios have to deal with several difficulties. Amongst those are unconstrained environments and uncertainties in one or several input channels. However a more crucial aspect is the content of the data itself. Psychological states are highly person-dependent and often even humans are not able to determine the correct state a person is in. A successful recognition system thus has to deal with data, that is not very discriminative and often simply misleading. In order to succeed, a critical view on features and decisions is essential to select only the most valuable ones. This work presents a comparison of a common multi classifier system approach based on state of the art features and a modified forward backward feature selection algorithm with a long term stopping criteria. The second approach takes also features of the voice quality family into account. Both approaches are based on the audio modality only. The dataset used in the challenge is an in between dataset of real world datasets which are still very hard to handle and over acted datasets which were famous in the past and today are well understood.},
booktitle = {Proceedings of the 15th ACM on International Conference on Multimodal Interaction},
pages = {551–556},
numpages = {6},
keywords = {emotion recognition, multi classifier systems, feature selection, human computer interaction, affective computing},
location = {Sydney, Australia},
series = {ICMI '13}
}

@inproceedings{10.1145/2522848.2522896,
author = {Jraidi, Im\`{e}ne and Chaouachi, Maher and Frasson, Claude},
title = {A Dynamic Multimodal Approach for Assessing Learners' Interaction Experience},
year = {2013},
isbn = {9781450321297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2522848.2522896},
doi = {10.1145/2522848.2522896},
abstract = {In this paper we seek to model the users' experience within an interactive learning environment. More precisely, we are interested in assessing three extreme trends in the interaction experience, namely flow (a perfect immersion within the task), stuck (a difficulty to maintain focused attention) and off-task (a drop out from the task). We propose a hierarchical probabilistic framework using a dynamic Bayesian network to simultaneously assess the probability of experiencing each trend, as well as the emotional responses occurring subsequently. The framework combines three-modality diagnostic variables that sense the learner's experience including physiology, behavior and performance, predictive variables that represent the current context and the learner's profile, and a dynamic structure that tracks the temporal evolution of the learner's experience. We describe the experimental study conducted to validate our approach. A protocol was established to elicit the three target trends as 44 participants interacted with three learning environments involving different cognitive tasks. Physiological activities (electroencephalography, skin conductance and blood volume pulse), patterns of the interaction, and performance during the task were recorded. We demonstrate that the proposed framework outperforms conventional non-dynamic modeling approaches such as static Bayesian networks, as well as three non-hierarchical formalisms including naive Bayes classifiers, decision trees and support vector machines.},
booktitle = {Proceedings of the 15th ACM on International Conference on Multimodal Interaction},
pages = {271–278},
numpages = {8},
keywords = {flow, biofeedback sensing, stuck, emotional responses, interaction experience, off-task, dynamic bayesian networks},
location = {Sydney, Australia},
series = {ICMI '13}
}

@inproceedings{10.1145/2541596.2541600,
author = {Rivetti, Nicolo and Corsaro, Angelo},
title = {State Based Paxos},
year = {2013},
isbn = {9781450325509},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2541596.2541600},
doi = {10.1145/2541596.2541600},
abstract = {Paxos is an algorithm that provides an elegant and optimal solution to the consensus problem in distributed systems. Despite its conceptual simplicity, industrial strength and high performance implementations of Paxos are very hard. This paper presents and evaluates the performance of State Paxos, a novel variation of the Paxos consensus algorithm that exploits overwrite semantics to eliminate most of the complexities and inefficiencies introduced by state management. This variation is suitable in applications where the current state depends only on the last update as opposed to the entire history, such as group management and distributed key-value stores.},
booktitle = {Proceedings of the Industrial Track of the 13th ACM/IFIP/USENIX International Middleware Conference},
articleno = {4},
numpages = {6},
keywords = {zookeeper, middleware, performance evaluation, group management, Paxos, DDS},
location = {Beijing, China},
series = {Middleware Industry '13}
}

@inproceedings{10.1145/2522848.2531741,
author = {Sikka, Karan and Dykstra, Karmen and Sathyanarayana, Suchitra and Littlewort, Gwen and Bartlett, Marian},
title = {Multiple Kernel Learning for Emotion Recognition in the Wild},
year = {2013},
isbn = {9781450321297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2522848.2531741},
doi = {10.1145/2522848.2531741},
abstract = {We propose a method to automatically detect emotions in unconstrained settings as part of the 2013 Emotion Recognition in the Wild Challenge [16], organized in conjunction with the ACM International Conference on Multimodal Interaction (ICMI 2013). Our method combines multiple visual descriptors with paralinguistic audio features for multimodal classification of video clips. Extracted features are combined using Multiple Kernel Learning and the clips are classified using an SVM into one of the seven emotion categories: Anger, Disgust, Fear, Happiness, Neutral, Sadness and Surprise. The proposed method achieves competitive results, with an accuracy gain of approximately 10% above the challenge baseline.},
booktitle = {Proceedings of the 15th ACM on International Conference on Multimodal Interaction},
pages = {517–524},
numpages = {8},
keywords = {bag of words, support vector machine, multiple kernel learning, multimodal, feature fusion},
location = {Sydney, Australia},
series = {ICMI '13}
}

@inproceedings{10.1145/2522848.2522895,
author = {Mahmoud, Marwa and Morency, Louis-Philippe and Robinson, Peter},
title = {Automatic Multimodal Descriptors of Rhythmic Body Movement},
year = {2013},
isbn = {9781450321297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2522848.2522895},
doi = {10.1145/2522848.2522895},
abstract = {Prolonged durations of rhythmic body gestures were proved to be correlated with different types of psychological disorders. To-date, there is no automatic descriptor that can robustly detect those behaviours. In this paper, we propose a cyclic gestures descriptor that can detect and localise rhythmic body movements by taking advantage of both colour and depth modalities. We show experimentally how our rhythmic descriptor can successfully localise the rhythmic gestures as: hands fidgeting, legs fidgeting or rocking, significantly higher than the majority vote classification baseline. Our experiments also demonstrate the importance of fusing both modalities, with a significant increase in performance when compared to individual modalities.},
booktitle = {Proceedings of the 15th ACM on International Conference on Multimodal Interaction},
pages = {429–436},
numpages = {8},
keywords = {multimodal fusion, multidimensional tracklets, rhythmic body movements},
location = {Sydney, Australia},
series = {ICMI '13}
}

@inproceedings{10.1145/2522848.2531745,
author = {Kahou, Samira Ebrahimi and Pal, Christopher and Bouthillier, Xavier and Froumenty, Pierre and G\"{u}l\c{c}ehre, \c{C}aglar and Memisevic, Roland and Vincent, Pascal and Courville, Aaron and Bengio, Yoshua and Ferrari, Raul Chandias and Mirza, Mehdi and Jean, S\'{e}bastien and Carrier, Pierre-Luc and Dauphin, Yann and Boulanger-Lewandowski, Nicolas and Aggarwal, Abhishek and Zumer, Jeremie and Lamblin, Pascal and Raymond, Jean-Philippe and Desjardins, Guillaume and Pascanu, Razvan and Warde-Farley, David and Torabi, Atousa and Sharma, Arjun and Bengio, Emmanuel and C\^{o}t\'{e}, Myriam and Konda, Kishore Reddy and Wu, Zhenzhou},
title = {Combining Modality Specific Deep Neural Networks for Emotion Recognition in Video},
year = {2013},
isbn = {9781450321297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2522848.2531745},
doi = {10.1145/2522848.2531745},
abstract = {In this paper we present the techniques used for the University of Montr\'{e}al's team submissions to the 2013 Emotion Recognition in the Wild Challenge. The challenge is to classify the emotions expressed by the primary human subject in short video clips extracted from feature length movies. This involves the analysis of video clips of acted scenes lasting approximately one-two seconds, including the audio track which may contain human voices as well as background music. Our approach combines multiple deep neural networks for different data modalities, including: (1) a deep convolutional neural network for the analysis of facial expressions within video frames; (2) a deep belief net to capture audio information; (3) a deep autoencoder to model the spatio-temporal information produced by the human actions depicted within the entire scene; and (4) a shallow network architecture focused on extracted features of the mouth of the primary human subject in the scene. We discuss each of these techniques, their performance characteristics and different strategies to aggregate their predictions. Our best single model was a convolutional neural network trained to predict emotions from static frames using two large data sets, the Toronto Face Database and our own set of faces images harvested from Google image search, followed by a per frame aggregation strategy that used the challenge training data. This yielded a test set accuracy of 35.58%. Using our best strategy for aggregating our top performing models into a single predictor we were able to produce an accuracy of 41.03% on the challenge test set. These compare favorably to the challenge baseline test set accuracy of 27.56%.},
booktitle = {Proceedings of the 15th ACM on International Conference on Multimodal Interaction},
pages = {543–550},
numpages = {8},
keywords = {emotion recognition},
location = {Sydney, Australia},
series = {ICMI '13}
}

@inproceedings{10.1145/2522848.2531746,
author = {Krishna, Tarun and Rai, Ayush and Bansal, Shubham and Khandelwal, Shubham and Gupta, Shubham and Goyal, Dushyant},
title = {Emotion Recognition Using Facial and Audio Features},
year = {2013},
isbn = {9781450321297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2522848.2531746},
doi = {10.1145/2522848.2531746},
abstract = {Human Computer Interaction is an upcoming scientific field which aims at inter-communication between humans and computers. A major element of this field is Human Emotion Recognition. The most expressive way humans display emotions is through facial expressions. Traditionally, emotion recognition has been performed on laboratory controlled data. While undoubtedly worthwhile at the time, such lab controlled data poorly represents the environment and conditions faced in real-world situations. With the increase in the number of video clips online, it is worthwhile to explore the performance of emotion recognition methods that work 'in the wild' .This work mainly focuses on automatic emotion recognition in a wild video sample. In this task, we have worked on the problem of human emotion recognition using a combination of video features and audio features. The technique that we have utilized for emotion detection involves a blend of Optical flow, Gabor Filtering, few other facial features and audio features. Training and Classification is performed using Support Vector Machine-Hidden Markov Model (HMM). The unique thing about our methodology is that it produces better results for some particular class of emotions as compared to the baseline score in the case of wild emotion dataset with an overall accuracy of 20.51% on the test set.},
booktitle = {Proceedings of the 15th ACM on International Conference on Multimodal Interaction},
pages = {557–564},
numpages = {8},
keywords = {speech tool, support vector machine, hidden markov model, optical flow, gabor filtering},
location = {Sydney, Australia},
series = {ICMI '13}
}

@inproceedings{10.1145/2522848.2533789,
author = {Ochoa, Xavier and Chiluiza, Katherine and M\'{e}ndez, Gonzalo and Luzardo, Gonzalo and Guam\'{a}n, Bruno and Castells, James},
title = {Expertise Estimation Based on Simple Multimodal Features},
year = {2013},
isbn = {9781450321297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2522848.2533789},
doi = {10.1145/2522848.2533789},
abstract = {Multimodal Learning Analytics is a field that studies how to process learning data from dissimilar sources in order to automatically find useful information to give feedback to the learning process. This work processes video, audio and pen strokes information included in the Math Data Corpus, a set of multimodal resources provided to the participants of the Second International Workshop on Multimodal Learning Analytics. The result of this processing is a set of simple features that could discriminate between experts and non-experts in groups of students solving mathematical problems. The main finding is that several of those simple features, namely the percentage of time that the students use the calculator, the speed at which the student writes or draws and the percentage of time that the student mentions numbers or mathematical terms, are good discriminators be- tween experts and non-experts students. Precision levels of 63% are obtained for individual problems and up to 80% when full sessions (aggregation of 16 problems) are analyzed. While the results are specific for the recorded settings, the methodology used to obtain and analyze the features could be used to create discriminations models for other contexts.},
booktitle = {Proceedings of the 15th ACM on International Conference on Multimodal Interaction},
pages = {583–590},
numpages = {8},
keywords = {math data corpus, multimodal learning analytics},
location = {Sydney, Australia},
series = {ICMI '13}
}

@inproceedings{10.1145/2541583.2541588,
author = {Shi, Weiming and Hong, Bo},
title = {Clotho: An Elastic MapReduce Workload/Runtime Co-Design},
year = {2013},
isbn = {9781450325530},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2541583.2541588},
doi = {10.1145/2541583.2541588},
abstract = {The resource management of a multi-tenant MapReduce cluster can be hard given unpredictable user demands. Conventional resource management scheme would inevitably create a fair amount of spare resource fragments in the system. On the other hand, MapReduce workloads are prone to have a bottleneck stage in the execution pipeline.To address these two issues under a coherent framework, this paper presents Clotho, a MapReduce workload and runtime co-design that can opportunistically utilize the spare resource fragments in the system to alleviate the bottleneck stage of MapReduce workloads while honoring the SLAs of existing systems. We describe the design and the implementation of Clotho, evaluate it with benchmarks drawn from real MapReduce applications, and demonstrate that it can effectively utilize the spare CPU resource fragments and meanwhile improve the performance of user programs if there is potential to speed up the bottleneck stage of the entire MapReduce execution pipeline.},
booktitle = {Proceedings of the 12th International Workshop on Adaptive and Reflective Middleware},
articleno = {5},
numpages = {6},
keywords = {workload/runtime co-design, elastic resource management and performance, MapReduce},
location = {Beijing, China},
series = {ARM '13}
}

@inproceedings{10.1145/2535948.2535954,
author = {Lim, Kai Keat and Friedrich, Max and Radun, Jenni and Jokinen, Kristiina},
title = {Lying through the Eyes: Detecting Lies through Eye Movements},
year = {2013},
isbn = {9781450325639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2535948.2535954},
doi = {10.1145/2535948.2535954},
abstract = {In this pilot study, we investigated if it is possible to detect lies through eye gaze behavior. Earlier research suggests that lying increases the cognitive load, resulting in less eye -movements and shorter saccade amplitudes. To investigate these findings further, a structured interview was conducted with three subjects. During the interview, subjects were supposed to lie in half of their answers. The subjects' eye gazes were tracked during the interview session. We hypothesized that people show shorter saccade amplitudes and tend to engage in less eye movements when lying. A significant difference could be observed for saccade amplitudes between the truth telling and lie telling situations. The overall results support the theory that cognitive load decreases the number of eye movements, but our analysis also revealed significant individual differences. This raised the question whether different individuals have different ways of handling deception and whether different viewing behavior patterns could be found for different groups of individuals.},
booktitle = {Proceedings of the 6th Workshop on Eye Gaze in Intelligent Human Machine Interaction: Gaze in Multimodal Interaction},
pages = {51–56},
numpages = {6},
keywords = {lie detection, eye tracking},
location = {Sydney, Australia},
series = {GazeIn '13}
}

@inproceedings{10.1145/2534688.2534691,
author = {Ranner, Veronica},
title = {UISilk: Towards Interfacing the Body},
year = {2013},
isbn = {9781450325622},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2534688.2534691},
doi = {10.1145/2534688.2534691},
abstract = {This paper examines transient electronics, ubiquitous biosensing and design in the context of the biodegradable material silk. The intersection of these disciplines will be demonstrated with the hypothetical application scenario You, I, Silk (UISilk). This design probe furthers the possibilities and probabilities of silken high- tech applications, which might soon enter the human body, for example in form of transient electronics. The speculation on potential impact of silk through the lens of organic and non-digital sensing offers hereby an extended perspective on programmable biomarkers, their potential for Citizen Science and current sensing paradigms.},
booktitle = {Proceedings of the Second International Workshop on Smart Material Interfaces: Another Step to a Material Future},
pages = {13–18},
numpages = {6},
keywords = {silk, smart material interface, MUI, body interface, transient electronics, biodigital},
location = {Sydney, Australia},
series = {SMI '13}
}

@article{10.1145/2556583,
author = {Delimitrou, Christina and Kozyrakis, Christos},
title = {QoS-Aware Scheduling in Heterogeneous Datacenters with Paragon},
year = {2013},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {4},
issn = {0734-2071},
url = {https://doi.org/10.1145/2556583},
doi = {10.1145/2556583},
abstract = {Large-scale datacenters (DCs) host tens of thousands of diverse applications each day. However, interference between colocated workloads and the difficulty of matching applications to one of the many hardware platforms available can degrade performance, violating the quality of service (QoS) guarantees that many cloud workloads require. While previous work has identified the impact of heterogeneity and interference, existing solutions are computationally intensive, cannot be applied online, and do not scale beyond a few applications.We present Paragon, an online and scalable DC scheduler that is heterogeneity- and interference-aware. Paragon is derived from robust analytical methods, and instead of profiling each application in detail, it leverages information the system already has about applications it has previously seen. It uses collaborative filtering techniques to quickly and accurately classify an unknown incoming workload with respect to heterogeneity and interference in multiple shared resources. It does so by identifying similarities to previously scheduled applications. The classification allows Paragon to greedily schedule applications in a manner that minimizes interference and maximizes server utilization. After the initial application placement, Paragon monitors application behavior and adjusts the scheduling decisions at runtime to avoid performance degradations. Additionally, we design ARQ, a multiclass admission control protocol that constrains application waiting time. ARQ queues applications in separate classes based on the type of resources they need and avoids long queueing delays for easy-to-satisfy workloads in highly-loaded scenarios. Paragon scales to tens of thousands of servers and applications with marginal scheduling overheads in terms of time or state.We evaluate Paragon with a wide range of workload scenarios, on both small and large-scale systems, including 1,000 servers on EC2. For a 2,500-workload scenario, Paragon enforces performance guarantees for 91% of applications, while significantly improving utilization. In comparison, heterogeneity-oblivious, interference-oblivious, and least-loaded schedulers only provide similar guarantees for 14%, 11%, and 3% of workloads. The differences are more striking in oversubscribed scenarios where resource efficiency is more critical.},
journal = {ACM Trans. Comput. Syst.},
month = dec,
articleno = {12},
numpages = {34},
keywords = {cloud computing, scheduling, QoS, heterogeneity, Datacenter, resource-efficiency, interference}
}

@article{10.1145/2543581.2543584,
author = {Castro, Pablo Samuel and Zhang, Daqing and Chen, Chao and Li, Shijian and Pan, Gang},
title = {From Taxi GPS Traces to Social and Community Dynamics: A Survey},
year = {2013},
issue_date = {November 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2543581.2543584},
doi = {10.1145/2543581.2543584},
abstract = {Vehicles equipped with GPS localizers are an important sensory device for examining people’s movements and activities. Taxis equipped with GPS localizers serve the transportation needs of a large number of people driven by diverse needs; their traces can tell us where passengers were picked up and dropped off, which route was taken, and what steps the driver took to find a new passenger. In this article, we provide an exhaustive survey of the work on mining these traces. We first provide a formalization of the data sets, along with an overview of different mechanisms for preprocessing the data. We then classify the existing work into three main categories: social dynamics, traffic dynamics and operational dynamics. Social dynamics refers to the study of the collective behaviour of a city’s population, based on their observed movements; Traffic dynamics studies the resulting flow of the movement through the road network; Operational dynamics refers to the study and analysis of taxi driver’s modus operandi. We discuss the different problems currently being researched, the various approaches proposed, and suggest new avenues of research. Finally, we present a historical overview of the research work in this field and discuss which areas hold most promise for future research.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {17},
numpages = {34},
keywords = {urban computing, smart cities, Taxi GPS}
}

@article{10.1145/2567561.2567563,
author = {Elmokashfi, Ahmed and Dhamdhere, Amogh},
title = {Revisiting BGP Churn Growth},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {1},
issn = {0146-4833},
url = {https://doi.org/10.1145/2567561.2567563},
doi = {10.1145/2567561.2567563},
abstract = {In the mid 2000s there was some concern in the research and operational communities over the scalability of BGP, the Internet's interdomain routing protocol. The focus was on update churn (the number of routing protocol messages that are exchanged when the network undergoes routing changes) and whether churn was growing too fast for routers to handle. Recent work somewhat allayed those fears, showing that update churn grows slowly in IPv4, but the question of routing scalability has re-emerged with IPv6.In this work, we develop a model that expresses BGP churn in terms of four measurable properties of the routing system. We show why the number of updates normalized by the size of the topology is constant, and why routing dynamics are qualitatively similar in IPv4 and IPv6. We also show that the exponential growth of IPv6 churn is entirely expected, as the underlying IPv6 topology is also growing exponentially.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = dec,
pages = {5–12},
numpages = {8},
keywords = {bgp, scalability, routing dynamics}
}

@article{10.1145/2499621,
author = {Bulling, Andreas and Blanke, Ulf and Schiele, Bernt},
title = {A Tutorial on Human Activity Recognition Using Body-Worn Inertial Sensors},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2499621},
doi = {10.1145/2499621},
abstract = {The last 20 years have seen ever-increasing research activity in the field of human activity recognition. With activity recognition having considerably matured, so has the number of challenges in designing, implementing, and evaluating activity recognition systems. This tutorial aims to provide a comprehensive hands-on introduction for newcomers to the field of human activity recognition. It specifically focuses on activity recognition using on-body inertial sensors. We first discuss the key research challenges that human activity recognition shares with general pattern recognition and identify those challenges that are specific to human activity recognition. We then describe the concept of an Activity Recognition Chain (ARC) as a general-purpose framework for designing and evaluating activity recognition systems. We detail each component of the framework, provide references to related research, and introduce the best practice methods developed by the activity recognition research community. We conclude with the educational example problem of recognizing different hand gestures from inertial sensors attached to the upper and lower arm. We illustrate how each component of this framework can be implemented for this specific activity recognition problem and demonstrate how different implementations compare and how they impact overall recognition performance.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {33},
numpages = {33},
keywords = {Activity recognition, gesture recognition, Activity Recognition Chain (ARC), on-body inertial sensors}
}

@article{10.1145/2499672,
author = {Kumar, Rohit and Ros\'{e}, Carolyn P.},
title = {Triggering Effective Social Support for Online Groups},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
issn = {2160-6455},
url = {https://doi.org/10.1145/2499672},
doi = {10.1145/2499672},
abstract = {Conversational agent technology is an emerging paradigm for creating a social environment in online groups that is conducive to effective teamwork. Prior work has demonstrated advantages in terms of learning gains and satisfaction scores when groups learning together online have been supported by conversational agents that employ Balesian social strategies. This prior work raises two important questions that are addressed in this article. The first question is one of generality. Specifically, are the positive effects of the designed support specific to learning contexts? Or are they in evidence in other collaborative task domains as well? We present a study conducted within a collaborative decision-making task where we see that the positive effects of the Balesian social strategies extend to this new context. The second question is whether it is possible to increase the effectiveness of the Balesian social strategies by increasing the context sensitivity with which the social strategies are triggered. To this end, we present technical work that increases the sensitivity of the triggering. Next, we present a user study that demonstrates an improvement in performance of the support agent with the new, more sensitive triggering policy over the baseline approach from prior work.The technical contribution of this article is that we extend prior work where such support agents were modeled using a composition of conversational behaviors integrated within an event-driven framework. Within the present approach, conversation is orchestrated through context-sensitive triggering of the composed behaviors. The core effort involved in applying this approach involves building a set of triggering policies that achieve this orchestration in a time-sensitive and coherent manner. In line with recent developments in data-driven approaches for building dialog systems, we present a novel technique for learning behavior-specific triggering policies, deploying it as part of our efforts to improve a socially capable conversational tutor agent that supports collaborative learning.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = jan,
articleno = {24},
numpages = {32},
keywords = {collaborative learning, triggering policy, sequence modeling, large-margin learner, Conversational agents, social ratio filtering, social behaviors}
}

@article{10.1145/2543921,
author = {Zamborlin, Bruno and Bevilacqua, Frederic and Gillies, Marco and D'inverno, Mark},
title = {Fluid Gesture Interaction Design: Applications of Continuous Recognition for the Design of Modern Gestural Interfaces},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
issn = {2160-6455},
url = {https://doi.org/10.1145/2543921},
doi = {10.1145/2543921},
abstract = {This article presents Gesture Interaction DEsigner (GIDE), an innovative application for gesture recognition. Instead of recognizing gestures only after they have been entirely completed, as happens in classic gesture recognition systems, GIDE exploits the full potential of gestural interaction by tracking gestures continuously and synchronously, allowing users to both control the target application moment to moment and also receive immediate and synchronous feedback about system recognition states. By this means, they quickly learn how to interact with the system in order to develop better performances. Furthermore, rather than learning the predefined gestures of others, GIDE allows users to design their own gestures, making interaction more natural and also allowing the applications to be tailored by users' specific needs. We describe our system that demonstrates these new qualities—that combine to provide fluid gesture interaction design—through evaluations with a range of performers and artists.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = jan,
articleno = {22},
numpages = {30},
keywords = {continuous and synchronous control, meaningful feedback, Gesture interaction, design and application of gesture interaction systems, personalisation}
}

@article{10.1145/2555611,
author = {Yuan, Eric and Esfahani, Naeem and Malek, Sam},
title = {A Systematic Survey of Self-Protecting Software Systems},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
issn = {1556-4665},
url = {https://doi.org/10.1145/2555611},
doi = {10.1145/2555611},
abstract = {Self-protecting software systems are a class of autonomic systems capable of detecting and mitigating security threats at runtime. They are growing in importance, as the stovepipe static methods of securing software systems have been shown to be inadequate for the challenges posed by modern software systems. Self-protection, like other self-* properties, allows the system to adapt to the changing environment through autonomic means without much human intervention, and can thereby be responsive, agile, and cost effective. While existing research has made significant progress towards autonomic and adaptive security, gaps and challenges remain. This article presents a significant extension of our preliminary study in this area. In particular, unlike our preliminary study, here we have followed a systematic literature review process, which has broadened the scope of our study and strengthened the validity of our conclusions. By proposing and applying a comprehensive taxonomy to classify and characterize the state-of-the-art research in this area, we have identified key patterns, trends and challenges in the existing approaches, which reveals a number of opportunities that will shape the focus of future research efforts.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = jan,
articleno = {17},
numpages = {41},
keywords = {Self-protection, self-* properties, autonomic computing, adaptive security, self-adaptive systems}
}

@article{10.1145/2542182.2542192,
author = {Fire, Michael and Tenenboim-Chekina, Lena and Puzis, Rami and Lesser, Ofrit and Rokach, Lior and Elovici, Yuval},
title = {Computationally Efficient Link Prediction in a Variety of Social Networks},
year = {2014},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/2542182.2542192},
doi = {10.1145/2542182.2542192},
abstract = {Online social networking sites have become increasingly popular over the last few years. As a result, new interdisciplinary research directions have emerged in which social network analysis methods are applied to networks containing hundreds of millions of users. Unfortunately, links between individuals may be missing either due to an imperfect acquirement process or because they are not yet reflected in the online network (i.e., friends in the real world did not form a virtual connection). The primary bottleneck in link prediction techniques is extracting the structural features required for classifying links. In this article, we propose a set of simple, easy-to-compute structural features that can be analyzed to identify missing links. We show that by using simple structural features, a machine learning classifier can successfully identify missing links, even when applied to a predicament of classifying links between individuals with at least one common friend. We also present a method for calculating the amount of data needed in order to build more accurate classifiers. The new Friends measure and Same community features we developed are shown to be good predictors for missing links. An evaluation experiment was performed on ten large social networks datasets: Academia.edu, DBLP, Facebook, Flickr, Flixster, Google+, Gowalla, TheMarker, Twitter, and YouTube. Our methods can provide social network site operators with the capability of helping users to find known, offline contacts and to discover new friends online. They may also be used for exposing hidden links in online social networks.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
articleno = {10},
numpages = {25},
keywords = {social networks, Academia.edu, training set size, Facebook, Flixster, hidden links, Twitter, Google+, Link prediction, Flickr, TheMarker Cafe, supervised learning, DBLP, imbalanced dataset, YouTube}
}

@article{10.1145/2537046,
author = {O'shea, James and Bandar, Zuhair and Crockett, Keeley},
title = {A New Benchmark Dataset with Production Methodology for Short Text Semantic Similarity Algorithms},
year = {2014},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {1550-4875},
url = {https://doi.org/10.1145/2537046},
doi = {10.1145/2537046},
abstract = {This research presents a new benchmark dataset for evaluating Short Text Semantic Similarity (STSS) measurement algorithms and the methodology used for its creation. The power of the dataset is evaluated by using it to compare two established algorithms, STASIS and Latent Semantic Analysis. This dataset focuses on measures for use in Conversational Agents; other potential applications include email processing and data mining of social networks. Such applications involve integrating the STSS algorithm in a complex system, but STSS algorithms must be evaluated in their own right and compared with others for their effectiveness before systems integration. Semantic similarity is an artifact of human perception; therefore its evaluation is inherently empirical and requires benchmark datasets derived from human similarity ratings. The new dataset of 64 sentence pairs, STSS-131, has been designed to meet these requirements drawing on a range of resources from traditional grammar to cognitive neuroscience. The human ratings are obtained from a set of trials using new and improved experimental methods, with validated measures and statistics. The results illustrate the increased challenge and the potential longevity of the STSS-131 dataset as the Gold Standard for future STSS algorithm evaluation.},
journal = {ACM Trans. Speech Lang. Process.},
month = jan,
articleno = {19},
numpages = {63},
keywords = {text processing, similarity measures, Evaluation/methodology, semantic similarity, text analysis, conversational agents}
}

@article{10.1145/2542182.2542190,
author = {Arias, Marta and Arratia, Argimiro and Xuriguera, Ramon},
title = {Forecasting with Twitter Data},
year = {2014},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/2542182.2542190},
doi = {10.1145/2542182.2542190},
abstract = {The dramatic rise in the use of social network platforms such as Facebook or Twitter has resulted in the availability of vast and growing user-contributed repositories of data. Exploiting this data by extracting useful information from it has become a great challenge in data mining and knowledge discovery. A recently popular way of extracting useful information from social network platforms is to build indicators, often in the form of a time series, of general public mood by means of sentiment analysis. Such indicators have been shown to correlate with a diverse variety of phenomena.In this article we follow this line of work and set out to assess, in a rigorous manner, whether a public sentiment indicator extracted from daily Twitter messages can indeed improve the forecasting of social, economic, or commercial indicators. To this end we have collected and processed a large amount of Twitter posts from March 2011 to the present date for two very different domains: stock market and movie box office revenue. For each of these domains, we build and evaluate forecasting models for several target time series both using and ignoring the Twitter-related data. If Twitter does help, then this should be reflected in the fact that the predictions of models that use Twitter-related data are better than the models that do not use this data. By systematically varying the models that we use and their parameters, together with other tuning factors such as lag or the way in which we build our Twitter sentiment index, we obtain a large dataset that allows us to test our hypothesis under different experimental conditions. Using a novel decision-tree-based technique that we call summary tree we are able to mine this large dataset and obtain automatically those configurations that lead to an improvement in the prediction power of our forecasting models. As a general result, we have seen that nonlinear models do take advantage of Twitter data when forecasting trends in volatility indices, while linear ones fail systematically when forecasting any kind of financial time series. In the case of predicting box office revenue trend, it is support vector machines that make best use of Twitter data. In addition, we conduct statistical tests to determine the relation between our Twitter time series and the different target time series.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
articleno = {8},
numpages = {24},
keywords = {Twitter, forecasting, Box office, stock market, sentiment index}
}

@article{10.1145/2513563,
author = {Cai, Xiaoyan and Li, Wenjie and Zhang, Renxian},
title = {Combining Co-Clustering with Noise Detection for Theme-Based Summarization},
year = {2014},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {1550-4875},
url = {https://doi.org/10.1145/2513563},
doi = {10.1145/2513563},
abstract = {To overcome the fact that the length of sentences is short and their content is limited, we regard words as independent text objects rather than features of sentences in sentence clustering and develop two co-clustering frameworks, namely integrated clustering and interactive clustering, to cluster sentences and words simultaneously. Since real-world datasets always contain noise, we incorporate noise detection and removal to enhance clustering of sentences and words. Meanwhile, a semisupervised approach is explored to incorporate the query information (and the sentence information in early document sets) in theme-based summarization. Thorough experimental studies are conducted. When evaluated on the DUC2005-2007 datasets and TAC 2008-2009 datasets, the performance of the two noise-detecting co-clustering approaches is comparable with that of the top three systems. The results also demonstrate that the interactive with noise detection algorithm is more effective than the noise-detecting integrated algorithm.},
journal = {ACM Trans. Speech Lang. Process.},
month = jan,
articleno = {16},
numpages = {27},
keywords = {sentence and word co-clustering, theme-based summarization, Document analysis, noise detection}
}

@article{10.1145/2514689,
author = {Kifer, Daniel and Machanavajjhala, Ashwin},
title = {Pufferfish: A Framework for Mathematical Privacy Definitions},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0362-5915},
url = {https://doi.org/10.1145/2514689},
doi = {10.1145/2514689},
abstract = {In this article, we introduce a new and general privacy framework called Pufferfish. The Pufferfish framework can be used to create new privacy definitions that are customized to the needs of a given application. The goal of Pufferfish is to allow experts in an application domain, who frequently do not have expertise in privacy, to develop rigorous privacy definitions for their data sharing needs. In addition to this, the Pufferfish framework can also be used to study existing privacy definitions.We illustrate the benefits with several applications of this privacy framework: we use it to analyze differential privacy and formalize a connection to attackers who believe that the data records are independent; we use it to create a privacy definition called hedging privacy, which can be used to rule out attackers whose prior beliefs are inconsistent with the data; we use the framework to define and study the notion of composition in a broader context than before; we show how to apply the framework to protect unbounded continuous attributes and aggregate information; and we show how to use the framework to rigorously account for prior data releases.},
journal = {ACM Trans. Database Syst.},
month = jan,
articleno = {3},
numpages = {36},
keywords = {Privacy, differential privacy}
}

@inproceedings{10.1145/2557977.2558020,
author = {Alam, Md. Golam Rabiul and Cho, Eung Jun and Huh, Eui-Nam and Hong, Choong Seon},
title = {Cloud Based Mental State Monitoring System for Suicide Risk Reconnaissance Using Wearable Bio-Sensors},
year = {2014},
isbn = {9781450326445},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2557977.2558020},
doi = {10.1145/2557977.2558020},
abstract = {Development of wireless body- and bio-sensor network opens a new horizon of healthcare especially to measure the vital physical signs of personnel for disease diagnosis and patient monitoring. And the cloud computing technology has enabled patient monitoring service dynamically scalable and ubiquitously accessible. The success of suicide risk reconnaissance is depends on effective prediction of mental states. This paper proposes a suicide risk scouting prototype by predicting mental states in cloud environment. In this system, patients' real-time vital diseases symptoms are collected through wireless body area network (WBAN) and then analyzed the collected data in healthcare cloud platform with patient's historical repository of diseases, habits, rehabilitations and genetics. Here, the mental statuses of patients have been modeled as the discrete set of states of hidden Markov model (HMM), where WBANs annotations and stored facts of patients in cloud are considered as the observations of HMM. Subsequently, the Viterbi, a machine learning algorithm has been applied to generate the most probable mental state sequence to monitor suicide risk of mentally disordered patients. Finally, the proposed system is validated by deploying this model on mental patients dataset.},
booktitle = {Proceedings of the 8th International Conference on Ubiquitous Information Management and Communication},
articleno = {56},
numpages = {6},
keywords = {suicide, cloud computing, hidden Markov model, mental health, mental state monitoring},
location = {Siem Reap, Cambodia},
series = {ICUIMC '14}
}

@inproceedings{10.1145/2557977.2558042,
author = {Kodirov, Elyor and Han, Sejin and Lee, Guee-Sang and Kim, YoungChul},
title = {Music with Harmony: Chord Separation and Recognition in Printed Music Score Images},
year = {2014},
isbn = {9781450326445},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2557977.2558042},
doi = {10.1145/2557977.2558042},
abstract = {Optical music recognition systems are in the general interest recently. These systems achieve accurate symbol recognition at some level. However, chords are not considered in these systems yet they play a role in music. Therefore, we aimed to develop an algorithm that can deal with separation and recognition of chords in music score images. Separation is necessary because the chords can be touched, overlapped or/and broken due to noise and other reasons. By considering these problems, we propose top-down based separation using domain information and characteristics of the chords. To handle recognition, we propose a modified zoning method with k-nearest neighbor classifier. Also, we analyzed several classifiers with different features to see which method is reliable for the chord recognition. Since this topic is not considered with special focus before, there is not a standard benchmark to evaluate performance of the algorithm. Thus, we introduce a new dataset, namely OMR-ChSR6306, which includes a wide range of chords such as single chords, touched chords, and overlapped chords. Experiments on the proposed dataset demonstrate that our algorithm can separate and recognize the chords, with 100% separation and 98.98% recognition accuracy respectively.},
booktitle = {Proceedings of the 8th International Conference on Ubiquitous Information Management and Communication},
articleno = {50},
numpages = {8},
keywords = {zoning, k-nearest neighbor, separation, chord, recognition, music score images},
location = {Siem Reap, Cambodia},
series = {ICUIMC '14}
}

@article{10.1145/2539118,
author = {Zhao, Jing and Jin, Yuliang and Trivedi, Kishor S. and Jr., Rivalino Matias and Wang, Yanbin},
title = {Software Rejuvenation Scheduling Using Accelerated Life Testing},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
issn = {1550-4832},
url = {https://doi.org/10.1145/2539118},
doi = {10.1145/2539118},
abstract = {A number of studies have reported the phenomenon of “Software aging”, caused by resource exhaustion and characterized by progressive software performance degradation. In this article, we carry out an experimental study of software aging and rejuvenation for an on-line bookstore application, following the standard configuration of TPC-W benchmark. While real website is used for the bookstore, the clients are emulated. In order to reduce the time to application failures caused by memory leaks, we use the accelerated life testing (ALT) approach. We then select the Weibull time to failure distribution at normal level, to be used in a semi-Markov process, to compute the optimal software rejuvenation trigger interval. Since the validation of optimal rejuvenation trigger interval with emulated browsers will take an inordinate long time, we develop a simulation model to validate the ALT experimental results, and also estimate the steady-state availability to cross-validate the results of the semi-Markov availability model.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = jan,
articleno = {9},
numpages = {23},
keywords = {memory leaks, Accelerated life tests, simulation, semi-markov process, optimal software rejuvenation}
}

@inproceedings{10.1145/2556863.2556868,
author = {Massari, Giuseppe and Caffarri, Chiara and Bellasi, Patrick and Fornaciari, William},
title = {Extending a Run-Time Resource Management Framework to Support OpenCL and Heterogeneous Systems},
year = {2014},
isbn = {9781450326070},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556863.2556868},
doi = {10.1145/2556863.2556868},
abstract = {From Mobile to High-Performance Computing (HPC) systems, performance and energy efficiency are becoming always more challenging requirements. In this regard, heterogeneous systems, made by a general-purpose processor and one or more hardware accelerators, are emerging as affordable solutions. However, the effective exploitation of such platforms requires specific programming languages, like for instance OpenCL, and suitable run-time software layers. This work illustrates the extension of a run-time resource management (RTRM) framework, to support the execution of OpenCL applications on systems featuring a multi-core CPU and multiple GPUs. Early results show how this solution leads to benefits both for the applications, in terms of performance, and for the system, in terms of resource utilization, i.e. load balancing and thermal leveling over the computing devices.},
booktitle = {Proceedings of Workshop on Parallel Programming and Run-Time Management Techniques for Many-Core Architectures and Design Tools and Architectures for Multicore Embedded Computing Platforms},
pages = {21–26},
numpages = {6},
keywords = {OpenCL, Graphical Processing Units (GPUs), Runtime, Profiling, Multicore, Heterogeneous systems, Parallel programming},
location = {Vienna, Austria},
series = {PARMA-DITAM '14}
}

@inproceedings{10.5555/2667473.2667489,
author = {Mayan, Omar and Sheard, Judy and Carbone, Angela},
title = {Understanding Saudi Arabian Students' Engagement in e-Learning 2.0 in Australian Higher Education},
year = {2014},
isbn = {9781921770302},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {This paper focuses on understanding Saudi Arabian students' engagement in e-learning 2.0 in Australian higher education. Eight Saudi students enrolled in the Australian Higher Education were interviewed to discuss their experiences and attitudes towards e-learning 2.0 using Semi-structured interviews. A qualitative approach was adopted to analyse the gathered data. The approach was based largely upon Charmaz's constructivist grounded theory.Key findings indicated that Saudi Arabian students were able to utilise the e-learning 2.0 settings in their respective universities as tools in which they interacted with other people while preparing themselves to become more interactive in their classes. At the same time, e-learning 2.0 served as a means for these students to steadily get over the socio-cultural barriers that might hinder them from making the most out of their education in Australia. However, it was also found that the language barrier that persisted even in the e-learning 2.0 environment made it more challenging for students to break through other barriers. Furthermore, it was found that the gender segregation culture that Saudi Arabian students have been used to still affected them in Australia, even in taking advantage of the e-learning 2.0 opportunities. This paper presents a discussion of four axial codes/categories that were identified that shape the Saudi students' attitudes, experiences and their engagement with e-learning 2.0. Specific attention is given to the 'Engaging in learning through technology' axis.},
booktitle = {Proceedings of the Thirty-Seventh Australasian Computer Science Conference - Volume 147},
pages = {135–143},
numpages = {9},
keywords = {Saudi Arabian students, web 2.0, Australian higher education, qualitative research, grounded theory, engaging in e-learning 2.0, educational technology, e-learning 2.0},
location = {Auckland, New Zealand},
series = {ACSC '14}
}

@article{10.1145/2530290,
author = {Khan, Mohammad Maifi Hasan and Le, Hieu Khac and Ahmadi, Hossein and Abdelzaher, Tarek F. and Han, Jiawei},
title = {Troubleshooting Interactive Complexity Bugs in Wireless Sensor Networks Using Data Mining Techniques},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {2},
issn = {1550-4859},
url = {https://doi.org/10.1145/2530290},
doi = {10.1145/2530290},
abstract = {This article presents a tool for uncovering bugs due to interactive complexity in networked sensing applications. Such bugs are not localized to one component that is faulty, but rather result from complex and unexpected interactions between multiple often individually nonfaulty components. Moreover, the manifestations of these bugs are often not repeatable, making them particularly hard to find, as the particular sequence of events that invokes the bug may not be easy to reconstruct. Because of the distributed nature of failure scenarios, our tool looks for sequences of events that may be responsible for faulty behavior, as opposed to localized bugs such as a bad pointer in a module. We identified several challenges in applying discriminative sequence mining for root cause analysis when the system fails to perform as expected and presented our solutions to those challenges. We also present two alternative schemes, namely, two-stage mining and the progressive discriminative sequence mining to address the scalability challenge. An extensible framework is developed where a front-end collects runtime data logs of the system being debugged and an offline back-end uses frequent discriminative pattern mining to uncover likely causes of failure. We provided several case studies where we applied our tool successfully to troubleshoot the cause of the problem. We uncovered a kernel-level race condition bug in the LiteOS operating system and a protocol design bug in the directed diffusion protocol. We also presented a case study of debugging a multichannel MAC protocol that was found to exhibit corner cases of poor performance (worse than single-channel MAC). The tool helped to uncover event sequences that lead to a highly degraded mode of operation. Fixing the problem significantly improved the performance of the protocol. We also evaluated the extensions presented in this article. Finally, we provided a detailed analysis of tool overhead in terms of memory requirements and impact on the running application.},
journal = {ACM Trans. Sen. Netw.},
month = jan,
articleno = {31},
numpages = {35},
keywords = {wireless sensor networks, Distributed protocol debugging}
}

@article{10.1145/2513179,
author = {Lederman, Reeva and Wadley, Greg and Gleeson, John and Bendall, Sarah and \'{A}lvarez-Jim\'{e}nez, Mario},
title = {Moderated Online Social Therapy: Designing and Evaluating Technology for Mental Health},
year = {2014},
issue_date = {February 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1073-0516},
url = {https://doi.org/10.1145/2513179},
doi = {10.1145/2513179},
abstract = {Although the use and prevalence of Web-based mental health applications have grown over the past decade, many of these services suffer high rates of attrition. This is problematic, as face-to-face support for mental health is limited. To determine appropriate design guidelines for increasing engagement, we conducted a study of First-Episode Psychosis (FEP) patients and reviewed theories on the use of existing online services. We produced a set of design goals, developed an online application that combined social networking and online therapy within a clinician-moderated site, and conducted a 6-week trial with a group of young FEP patients. The design goals, based on existing theory including Supportive Accountability and Positive Psychology, are operationlised through a model we call Moderated Online Social Therapy (MOST). The trial results indicate that our implementation achieved the design goals and that the MOST model can inform the development of more effective and engaging online therapies.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = feb,
articleno = {5},
numpages = {26},
keywords = {positive computing, online therapy, user-appropriate design, Mental health interventions, user experience, supportive accountability}
}

@article{10.1145/2544066,
author = {Truschin, Sergej and Schermann, Michael and Goswami, Suparna and Krcmar, Helmut},
title = {Designing Interfaces for Multiple-Goal Environments: Experimental Insights from in-Vehicle Speech Interfaces},
year = {2014},
issue_date = {February 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1073-0516},
url = {https://doi.org/10.1145/2544066},
doi = {10.1145/2544066},
abstract = {Designing computer-human interfaces for multiple-goal environments is challenging because people pursue multiple goals with conflicting priorities. Safety-critical environments, such as driving, aggravate the need for a more nuanced understanding of interfaces that may reconcile conflicting tasks. Speech interfaces are prime examples of such interfaces. In this article, we investigate how design variations of an in-vehicle speech interface influence performance of a primary task (driving safely) and a secondary task (e-mailing). In a controlled experiment, we test the performance implications of using single computer-generated Text-To-Speech (TTS) voice and multiple matching TTS voices while users respond to e-mails with varying levels of complexity during driving. Our results indicate that the number of voices used has a significant effect on both driving performance and handling e-mail--related activities. We discuss potentially unintended consequences of making the interface too naturalistic and too engaging for the driver and conclude with theoretical and practical implications.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = feb,
articleno = {7},
numpages = {24},
keywords = {user engagement, task prioritization, distraction, driving simulator, text complexity, Interface design, e-mailing, text-to-speech, driving, multiple voices, in-vehicle speech interfaces}
}

@inproceedings{10.1145/2555243.2555245,
author = {Tardieu, Olivier and Herta, Benjamin and Cunningham, David and Grove, David and Kambadur, Prabhanjan and Saraswat, Vijay and Shinnar, Avraham and Takeuchi, Mikio and Vaziri, Mandana},
title = {X10 and APGAS at Petascale},
year = {2014},
isbn = {9781450326568},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2555243.2555245},
doi = {10.1145/2555243.2555245},
abstract = {X10 is a high-performance, high-productivity programming language aimed at large-scale distributed and shared-memory parallel applications. It is based on the Asynchronous Partitioned Global Address Space (APGAS) programming model, supporting the same fine-grained concurrency mechanisms within and across shared-memory nodes.We demonstrate that X10 delivers solid performance at petascale by running (weak scaling) eight application kernels on an IBM Power 775 supercomputer utilizing up to 55,680 Power7 cores (for 1.7 Pflop/s of theoretical peak performance). We detail our advances in distributed termination detection, distributed load balancing, and use of high-performance interconnects that enable X10 to scale out to tens of thousands of cores.For the four HPC Class 2 Challenge benchmarks, X10 achieves 41% to 87% of the system's potential at scale (as measured by IBM's HPCC Class 1 optimized runs). We also implement K-Means, Smith-Waterman, Betweenness Centrality, and Unbalanced Tree Search (UTS) for geometric trees. Our UTS implementation is the first to scale to petaflop systems.},
booktitle = {Proceedings of the 19th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
pages = {53–66},
numpages = {14},
keywords = {APGAS, scalability, performance, X10},
location = {Orlando, Florida, USA},
series = {PPoPP '14}
}

@article{10.1145/2692916.2555245,
author = {Tardieu, Olivier and Herta, Benjamin and Cunningham, David and Grove, David and Kambadur, Prabhanjan and Saraswat, Vijay and Shinnar, Avraham and Takeuchi, Mikio and Vaziri, Mandana},
title = {X10 and APGAS at Petascale},
year = {2014},
issue_date = {August 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {8},
issn = {0362-1340},
url = {https://doi.org/10.1145/2692916.2555245},
doi = {10.1145/2692916.2555245},
abstract = {X10 is a high-performance, high-productivity programming language aimed at large-scale distributed and shared-memory parallel applications. It is based on the Asynchronous Partitioned Global Address Space (APGAS) programming model, supporting the same fine-grained concurrency mechanisms within and across shared-memory nodes.We demonstrate that X10 delivers solid performance at petascale by running (weak scaling) eight application kernels on an IBM Power 775 supercomputer utilizing up to 55,680 Power7 cores (for 1.7 Pflop/s of theoretical peak performance). We detail our advances in distributed termination detection, distributed load balancing, and use of high-performance interconnects that enable X10 to scale out to tens of thousands of cores.For the four HPC Class 2 Challenge benchmarks, X10 achieves 41% to 87% of the system's potential at scale (as measured by IBM's HPCC Class 1 optimized runs). We also implement K-Means, Smith-Waterman, Betweenness Centrality, and Unbalanced Tree Search (UTS) for geometric trees. Our UTS implementation is the first to scale to petaflop systems.},
journal = {SIGPLAN Not.},
month = feb,
pages = {53–66},
numpages = {14},
keywords = {scalability, X10, performance, APGAS}
}

@inproceedings{10.1145/2555243.2555248,
author = {Cunningham, David and Grove, David and Herta, Benjamin and Iyengar, Arun and Kawachiya, Kiyokuni and Murata, Hiroki and Saraswat, Vijay and Takeuchi, Mikio and Tardieu, Olivier},
title = {Resilient X10: Efficient Failure-Aware Programming},
year = {2014},
isbn = {9781450326568},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2555243.2555248},
doi = {10.1145/2555243.2555248},
abstract = {Scale-out programs run on multiple processes in a cluster. In scale-out systems, processes can fail. Computations using traditional libraries such as MPI fail when any component process fails. The advent of Map Reduce, Resilient Data Sets and MillWheel has shown dramatic improvements in productivity are possible when a high-level programming framework handles scale-out and resilience automatically.We are concerned with the development of general-purpose languages that support resilient programming. In this paper we show how the X10 language and implementation can be extended to support resilience. In Resilient X10, places may fail asynchronously, causing loss of the data and tasks at the failed place. Failure is exposed through exceptions. We identify a {em Happens Before Invariance Principle} and require the runtime to automatically repair the global control structure of the program to maintain this principle. We show this reduces much of the burden of resilient programming. The programmer is only responsible for continuing execution with fewer computational resources and the loss of part of the heap, and can do so while taking advantage of domain knowledge.We build a complete implementation of the language, capable of executing benchmark applications on hundreds of nodes. We describe the algorithms required to make the language runtime resilient. We then give three applications, each with a different approach to fault tolerance (replay, decimation, and domain-level checkpointing). These can be executed at scale and survive node failure. We show that for these programs the overhead of resilience is a small fraction of overall runtime by comparing to equivalent non-resilient X10 programs. On one program we show end-to-end performance of Resilient X10 is ~100x faster than Hadoop.},
booktitle = {Proceedings of the 19th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
pages = {67–80},
numpages = {14},
keywords = {resilience, parallel, X10, distributed},
location = {Orlando, Florida, USA},
series = {PPoPP '14}
}

@article{10.1145/2692916.2555248,
author = {Cunningham, David and Grove, David and Herta, Benjamin and Iyengar, Arun and Kawachiya, Kiyokuni and Murata, Hiroki and Saraswat, Vijay and Takeuchi, Mikio and Tardieu, Olivier},
title = {Resilient X10: Efficient Failure-Aware Programming},
year = {2014},
issue_date = {August 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {8},
issn = {0362-1340},
url = {https://doi.org/10.1145/2692916.2555248},
doi = {10.1145/2692916.2555248},
abstract = {Scale-out programs run on multiple processes in a cluster. In scale-out systems, processes can fail. Computations using traditional libraries such as MPI fail when any component process fails. The advent of Map Reduce, Resilient Data Sets and MillWheel has shown dramatic improvements in productivity are possible when a high-level programming framework handles scale-out and resilience automatically.We are concerned with the development of general-purpose languages that support resilient programming. In this paper we show how the X10 language and implementation can be extended to support resilience. In Resilient X10, places may fail asynchronously, causing loss of the data and tasks at the failed place. Failure is exposed through exceptions. We identify a {em Happens Before Invariance Principle} and require the runtime to automatically repair the global control structure of the program to maintain this principle. We show this reduces much of the burden of resilient programming. The programmer is only responsible for continuing execution with fewer computational resources and the loss of part of the heap, and can do so while taking advantage of domain knowledge.We build a complete implementation of the language, capable of executing benchmark applications on hundreds of nodes. We describe the algorithms required to make the language runtime resilient. We then give three applications, each with a different approach to fault tolerance (replay, decimation, and domain-level checkpointing). These can be executed at scale and survive node failure. We show that for these programs the overhead of resilience is a small fraction of overall runtime by comparing to equivalent non-resilient X10 programs. On one program we show end-to-end performance of Resilient X10 is ~100x faster than Hadoop.},
journal = {SIGPLAN Not.},
month = feb,
pages = {67–80},
numpages = {14},
keywords = {X10, resilience, distributed, parallel}
}

@inproceedings{10.1145/2531602.2531712,
author = {Cobb, Camille and McCarthy, Ted and Perkins, Annuska and Bharadwaj, Ankitha and Comis, Jared and Do, Brian and Starbird, Kate},
title = {Designing for the Deluge: Understanding &amp; Supporting the Distributed, Collaborative Work of Crisis Volunteers},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531712},
doi = {10.1145/2531602.2531712},
abstract = {Social media are a potentially valuable source of situational awareness information during crisis events. Consistently, "digital volunteers" and others are coming together to filter and process this data into usable resources, often coordinating their work within distributed online groups. However, current tools and practices are frequently unable to keep up with the speed and volume of incoming data during large events. Through contextual interviews with emergency response professionals and digital volunteers, this research examines the ad hoc, collaborative practices that have emerged to help process this data and outlines strategies for supporting and leveraging these efforts in future designs. We argue for solutions that align with current group values, work practices, volunteer motivations, and organizational structures, but also allow these groups to increase the scale and efficiency of their operations.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {888–899},
numpages = {12},
keywords = {machine learning, natural language processing, civic participation, digital volunteers, disaster response, crowdsourcing, social computing, crisis informatics},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2531602.2531645,
author = {Jacobs, Maia and Clawson, James and Mynatt, Elizabeth D.},
title = {Cancer Navigation: Opportunities and Challenges for Facilitating the Breast Cancer Journey},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531645},
doi = {10.1145/2531602.2531645},
abstract = {Cancer navigation programs help patients overcome emotional, financial, and logistical challenges not typically addressed by the medical system. In this paper, we provide a detailed description of a rural cancer navigation organization, specifically detailing the roles collaboration and technology play in supporting navigation work. Examining navigation from a CSCW perspective, we see that navigation is a collaborative care system requiring coordination with patients, providers, and other navigators. Our study reveals a number of design opportunities for supporting navigation in the areas of resource monitoring, knowledge transfer, case management, long term navigation, and development of best practices. Supporting cancer navigation will be a critical step towards improving the healthcare experience for cancer patients.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {1467–1478},
numpages = {12},
keywords = {implications for design, cancer, healthcare, navigation},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2568326.2568327,
author = {Kim, Nikolai and Krall, Andreas},
title = {Integrated modulo Scheduling and Cluster Assignment for TI TMS320C64x+ Architecture},
year = {2014},
isbn = {9781450325950},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568326.2568327},
doi = {10.1145/2568326.2568327},
abstract = {For the exploitation of the available parallelism clustered Very Long Instruction Word (VLIW) processors rely on highly optimizing compilers. Aiming this parallelism, many advanced compiler concepts have been developed and proposed in the past. Many of them concentrate on loops only as most of the execution time is usually spent executing repeating patterns of code. Software pipelining techniques, such as modulo scheduling, try to speed up the execution of loops by simultaneous initiation of multiple iterations, thus additionally exploiting parallelism across loop iteration boundaries. This increases processor utilization at the cost of higher complexity which is especially true for architectures featuring multiple clusters and distributed register files. Additional scheduling constraints need to be considered in order to produce valid schedules. Targeting TI's TMS320C64x+ clustered VLIW architecture, we describe a code generation approach that adapts an iterative modulo scheduling scheme, and also propose two heuristics for cluster assignment, all together implemented within the popular LLVM compiler framework. We cover implementation of developed algorithms, present evaluation results for a selection of benchmarks popular for embedded system development and discuss gained insights on the topics of integrated modulo scheduling and cluster assignment in this paper.},
booktitle = {Proceedings of the 11th Workshop on Optimizations for DSP and Embedded Systems},
pages = {25–32},
numpages = {8},
keywords = {integer linear programming, instruction level parallelism, VLIW, cluster assignment, modulo scheduling, LLVM, phase ordering},
location = {Orlando, Florida, USA},
series = {ODES '14}
}

@inproceedings{10.1145/2531602.2531659,
author = {Vasilescu, Bogdan and Serebrenik, Alexander and Devanbu, Prem and Filkov, Vladimir},
title = {How Social Q&amp;A Sites Are Changing Knowledge Sharing in Open Source Software Communities},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531659},
doi = {10.1145/2531602.2531659},
abstract = {Historically, mailing lists have been the preferred means for coordinating development and user support activities. With the emergence and popularity growth of social Q&amp;A sites such as the StackExchange network (e.g., StackOverflow), this is beginning to change. Such sites offer different socio-technical incentives to their participants than mailing lists do, e.g., rich web environments to store and manage content collaboratively, or a place to showcase their knowledge and expertise more vividly to peers or potential recruiters. A key difference between StackExchange and mailing lists is gamification, i.e., StackExchange participants compete to obtain reputation points and badges. In this paper, we use a case study of R (a widely-used tool for data analysis) to investigate how mailing list participation has evolved since the launch of StackExchange. Our main contribution is the assembly of a joint data set from the two sources, in which participants in both the texttt{r-help} mailing list and StackExchange are identifiable. This permits their activities to be linked across the two resources and also over time. With this data set we found that user support activities show a strong shift away from texttt{r-help}. In particular, mailing list experts are migrating to StackExchange, where their behaviour is different. First, participants active both on texttt{r-help} and on StackExchange are more active than those who focus exclusively on only one of the two. Second, they provide faster answers on StackExchange than on texttt{r-help}, suggesting they are motivated by the emph{gamified} environment. To our knowledge, our study is the first to directly chart the changes in behaviour of specific contributors as they migrate into gamified environments, and has important implications for knowledge management in software engineering.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {342–354},
numpages = {13},
keywords = {mailing lists, gamification., open source, social q&amp;a, crowdsourced knowledge},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2531602.2531719,
author = {Maruyama, Misa T. and Robertson, Scott P. and Douglas, Sara K. and Semaan, Bryan C. and Faucett, Heather A.},
title = {Hybrid Media Consumption: How Tweeting during a Televised Political Debate Influences the Vote Decision},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531719},
doi = {10.1145/2531602.2531719},
abstract = {An increasing number of people are using microblogs to broadcast their thoughts in real time as they watch televised political events. Microblogging social network sites (SNSs) such as Twitter generate a parallel stream of information and opinion. It is presumed that the additional content enhances the viewing experience, but our experiment explores the validity of this assumption. We studied how tweeting, or passively observing Twitter during a debate, influenced affect, recall and vote decision. For most measures, participants' average feeling and recall toward the candidates did not depend on Twitter activity, but Twitter activity did matter for vote choice. People who actively tweeted changed their voting choice to reflect the majority sentiment on Twitter. Results are discussed in terms of the possibility that active tweeting leads to greater engagement but that it may also make people more susceptible to social influence.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {1422–1432},
numpages = {11},
keywords = {e-participation, social networking, microblogging, digital democracy, social media, ecitizenship},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2531602.2531696,
author = {Wisniewski, Pamela J. and Xu, Heng and Rosson, Mary Beth and Carroll, John M.},
title = {Adolescent Online Safety: The "Moral" of the Story},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531696},
doi = {10.1145/2531602.2531696},
abstract = {Adolescence is characterized by heightened risk-taking and independence from parents; these tendencies seem to be magnified by the opportunities afforded through online interactions. Drawing on Kohlberg's Cognitive Moral Development (CMD) theory, we conduct a qualitative study of 12 parent-adolescent dyads that examines the interplay between parenting behaviors and adolescent moral development. We show an association between adolescent moral judgment and online behavior, and we illustrate how parenting style and mediation strategies influence the teen's moral growth and decision making about online behaviors. We also note that parental mediation strategies are moderated by parents' digital literacy: reduced digital literacy is associated with more restrictive or indulgent strategies; while more digitally competent parents are more likely to monitor and mediate their teen's behaviors as they engage online. We also found that experience, not restriction, facilitates the teen's moral growth.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {1258–1271},
numpages = {14},
keywords = {adolescent online safety, parenting, moral development},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2531602.2531715,
author = {Hui, Julie S. and Greenberg, Michael D. and Gerber, Elizabeth M.},
title = {Understanding the Role of Community in Crowdfunding Work},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531715},
doi = {10.1145/2531602.2531715},
abstract = {Crowdfunding provides a new opportunity for entrepre-neurs to launch ventures without having to rely on traditional funding mechanisms, such as banks and angel investing. Despite its rapid growth, we understand little about how crowdfunding users build ad hoc online communities to undertake this new way of performing entrepreneurial work. To better understand this phenomenon, we performed a qualitative study of 47 entrepreneurs who use crowdfunding platforms to raise funds for their projects. We identify community efforts to support crowdfunding work, such as providing mentorship to novices, giving feedback on campaign presentation, and building a repository of example projects to serve as models. We also identify where community efforts and technologies succeed and fail at support-ing the work in order to inform the design of crowdfunding support tools and systems.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {62–74},
numpages = {13},
keywords = {crowd work, community, entrepreneurship, rowdfunding, support tools, distributed work},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2531602.2531631,
author = {Ferguson, Robert Douglas and Massimi, Michael and Crist, Emily Anne and Moffatt, Karyn Anne},
title = {Craving, Creating, and Constructing Comfort: Insights and Opportunities for Technology in Hospice},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531631},
doi = {10.1145/2531602.2531631},
abstract = {Hospice is a medical setting for patients with terminal illnesses where active treatment is withdrawn in favor of providing comfort and dignity at the end of life. Providing comfort extends beyond managing physical pain to include social, emotional, spiritual, and environmental aspects of care. We studied technology's role in achieving these multifaceted dimensions of comfort through interviews with 16 family members of past hospice patients. Comfort was an ongoing pursuit, requiring the involvement of diverse stakeholders; communication technologies were selectively chosen in service of this achievement. We provide opportunities and recommendations for technologies in hospice, including the need for varying degrees of richness and symmetry, and for support for life-affirming acts. To our knowledge, this constitutes the first study, in the CSCW and HCI literatures, of communication technology use during the final days of a person's life, with implications both for hospice and for the end of life more broadly.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {1479–1490},
numpages = {12},
keywords = {palliative, comfort, family communication., and end of life care, computer-mediated communication, hospice},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2531602.2531687,
author = {Johri, Aditya and Srinivasan, Janaki},
title = {The Role of Data in Aligning the 'unique Identity' Infrastructure in India},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531687},
doi = {10.1145/2531602.2531687},
abstract = {We present findings from a qualitative field study of a national e-infrastructure project currently underway in India. We study how this large and complex infrastructure for issuing unique biometric-based identification numbers to the 1.2 billion residents of India was aligned across various stakeholders engaged in the project. We find that the focus on 'data' kept the entire infrastructure together and working. However, this narrow focus also made the design team view the people applying for IDs as numbers whose management could be standardized. In reality, the infrastructure encountered people with differing experiences and expectations of state-issued IDs, expectations that had to be managed by agents on the ground. With our focus on the nation state as a site for studying e-infrastructure, we extend the domains in which CSCW research takes place and contribute to the theory of infrastructure building in a context where state-citizen relations are at stake.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {697–709},
numpages = {13},
keywords = {qualitative field study, ictd., alignment, infrastructure},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2531602.2531656,
author = {Mitra, Tanushree and Gilbert, Eric},
title = {The Language That Gets People to Give: Phrases That Predict Success on Kickstarter},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531656},
doi = {10.1145/2531602.2531656},
abstract = {Crowdfunding sites like Kickstarter--where entrepreneurs and artists look to the internet for funding--have quickly risen to prominence. However, we know very little about the factors driving the 'crowd' to take projects to their funding goal. In this paper we explore the factors which lead to successfully funding a crowdfunding project. We study a corpus of 45K crowdfunded projects, analyzing 9M phrases and 59 other variables commonly present on crowdfunding sites. The language used in the project has surprising predictive power accounting for 58.56% of the variance around successful funding. A closer look at the phrases shows they exhibit general persuasion principles. For example, also receive two reflects the principle of Reciprocity and is one of the top predictors of successful funding. We conclude this paper by announcing the release of the predictive phrases along with the control variables as a public dataset, hoping that our work can enable new features on crowdfunding sites--tools to help both backers and project creators make the best use of their time and money.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {49–61},
numpages = {13},
keywords = {crowdfunding, cmc, natural language processing (nlp)},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2531602.2531624,
author = {Ribes, David},
title = {Ethnography of Scaling, or, How to a Fit a National Research Infrastructure in the Room},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531624},
doi = {10.1145/2531602.2531624},
abstract = {Ethnographers have traditionally studied people in particular times and places. However, sociotechnical systems are often long-term enterprises, spanning the globe and serving vast communities. Drawing from three cases of research infrastructure development, this paper demonstrates a methodology in which the ethnographer examines scalar devices: actors' techniques and technologies for knowing and managing large-scale enterprises. Such devices are enacted in and across concrete times and places; for the ethnographer they are observable as activities of scaling. By examining the enactment of scale we can better investigate diverse kinds of size and growth within sociotechnical systems.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {158–170},
numpages = {13},
keywords = {grounded theory, large-scale, actor-network theory, methodology, ethnography, infrastructure},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2531602.2531684,
author = {Desjardins, Audrey and Neustaedter, Carman and Greenberg, Saul and Wakkary, Ron},
title = {Collaboration Surrounding Beacon Use during Companion Avalanche Rescue},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531684},
doi = {10.1145/2531602.2531684},
abstract = {When facing an avalanche, backcountry skiers need to work effectively both individually and as a group to rescue buried victims. If they don't, death is likely. One of the tools used by each person is a digital beacon that transmits an electromagnetic signal. If buried, others use their beacons to locate victims by searching for their signals, and then dig them out. This study focuses on the collaborative practices of avalanche rescue and the interactions with beacons while backcountry skiing. We conducted interviews with backcountry recreationists and experts, and we observed avalanche rescue practice scenarios. Our results highlight aspects and challenges of mental representation, trust, distributed cognition, and practice. Implications include three considerations for the redesign of beacons: simplicity, visibility and practice.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {877–887},
numpages = {11},
keywords = {snowboard, communication, avalanche, collaboration, ski, transceiver, beacon, distributed cognition, backcountry},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2531602.2531693,
author = {Lingel, Jessica and Naaman, Mor and boyd, danah m.},
title = {City, Self, Network: Transnational Migrants and Online Identity Work},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531693},
doi = {10.1145/2531602.2531693},
abstract = {This paper uses qualitative interviews with 26 transnational migrants in New York City to analyze socio-technical practices related to online identity work. We focus specifically on the use of Facebook, where benefits included keeping in touch with friends and family abroad and documenting everyday urban life. At the same time, many participants also reported experiences of fatigue, socio-cultural tensions and concerns about maintaining a sense of personal privacy. These experiences highlight how transnational practices complicate context collapse, where the geographic dispersal of participants' personal networks renders visible conflicts of 'flattened' online networks. Our findings also suggest a kind of technology-enabled code-switching, where transnational migrants leverage social media to perform identities that alternate between communities, nationalities and geographies. This analysis informs HCI research on transnationalism and technological practices, as well as the complexities of online identity work in terms of shifting social and spatial contexts.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {1502–1510},
numpages = {9},
keywords = {urban informatics, identity work, transnationalism, social media},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2531602.2531697,
author = {Heinrich, Peter and Kilic, Mehmet and Aschoff, Felix-Robinson and Schwabe, Gerhard},
title = {Enabling Relationship Building in Tabletop-Supported Advisory Settings},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531697},
doi = {10.1145/2531602.2531697},
abstract = {Recent research has shown that financial advisory encounters can successfully be supported with IT-artifacts. Tabletop scenarios, for example, can increase the transparency of the advisory process for customers. However, we have also had the experience that the relationship quality as experienced by customers can suffer severely when IT-artifacts are introduced. Based on these experiences, we developed guidelines for both, the artifact- design itself as well as for the environment in order to avoid this effect, and implemented them in one of our prototypes. The evaluation reveals that these measures proved to be effective. With the reported study, we seek to enhance our design knowledge of IT-supported advisory scenarios with a special focus on relationship building. In a larger context, we argue that the use of IT during sensitive face-to-face encounters will be of growing significance in the future but, as yet, is hardly understood. We make a contribution in this area with our generic requirements, design principles and evaluation.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {171–183},
numpages = {13},
keywords = {advisory scenario, relationship building, tabletop},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2531602.2531717,
author = {Duysburgh, Pieter and Elprama, Shirley A. and Jacobs, An},
title = {Exploring the Social-Technological Gap in Telesurgery: Collaboration within Distributed or Teams},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531717},
doi = {10.1145/2531602.2531717},
abstract = {While its technical feasibility has been illustrated over a decade ago, today, robot-assisted telesurgery is not a part of everyday surgical practice. The thresholds for adoption of telesurgery are mostly seen as technical, legal and financial challenges. However, the aim of this paper is to understand collaboration within distributed OR teams, which seems to be under examined in research on telesurgery. By means of a proxy-technology assessment and a series of interviews, collaborative challenges for telesurgery have been identified. These include the unfamiliarity of the remote surgeon with the practices of the local operating room team and the patient. In addition, verbal and non-verbal communication have to be mediated in a telesurgery setting, making it difficult for the remote surgeon to have an overview and stay in control during surgery. With this research, we illustrate how trust issues in distributed teams manifest in OR teams in a telesurgery setting.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {1537–1548},
numpages = {12},
keywords = {robot- assisted telesurgery, robot-assisted surgery, surgical teams., distributed teams, team work, telesurgery},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2531602.2531722,
author = {Xiao, Shundan and Witschey, Jim and Murphy-Hill, Emerson},
title = {Social Influences on Secure Development Tool Adoption: Why Security Tools Spread},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531722},
doi = {10.1145/2531602.2531722},
abstract = {Security tools can help developers build more secure software systems by helping developers detect or fix security vulnerabilities in source code. However, developers do not always use these tools. In this paper, we investigate a number of social factors that impact developers' adoption decisions, based on a multidisciplinary field of research called diffusion of innovations. We conducted 42 one-on-one interviews with professional software developers, and our results suggest a number of ways in which security tool adoption depends on developers' social environments and on the channels through which information about tools is communicated. For example, some participants trusted developers with strong reputations on the Internet as much as they trust their colleagues for information about security tools.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {1095–1106},
numpages = {12},
keywords = {adoption, security tools, social factors},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@inproceedings{10.1145/2531602.2531701,
author = {Procyk, Jason and Neustaedter, Carman},
title = {GEMS: The Design and Evaluation of a Location-Based Storytelling Game},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531701},
doi = {10.1145/2531602.2531701},
abstract = {It is now possible to capture geotagged photos and videos and share them with family and friends. Yet the reality is that applications for capturing and viewing this information are not particularly rich offering little more than maps and simple textual information about a location. Given this, we wanted to explore this design space to find new and exciting ways for people to document and share their experiences. We designed a location-based game called GEMS to support storytelling amongst family members and close friends. The game narrative and mechanics prompt players to reflect on meaningful places from their past and create geolocated digital memory. Other players can then visit the locations to collect and view the records. A user study revealed that location can provide a rich foundation for storytelling activities. We learned that location-based storytelling strategies often elicit a sense of discovery through exploration, sharing, and conscious reflection.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {1156–1166},
numpages = {11},
keywords = {pervasive games, location-based games, family storytelling},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@article{10.1145/2559936,
author = {Tappenden, Andrew F. and Miller, James},
title = {Automated Cookie Collection Testing},
year = {2014},
issue_date = {February 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/2559936},
doi = {10.1145/2559936},
abstract = {Cookies are used by over 80% of Web applications utilizing dynamic Web application frameworks. Applications deploying cookies must be rigorously verified to ensure that the application is robust and secure. Given the intense time-to-market pressures faced by modern Web applications, testing strategies that are low cost and automatable are required. Automated Cookie Collection Testing (CCT) is presented, and is empirically demonstrated to be a low-cost and highly effective automated testing solution for modern Web applications. Automatable test oracles and evaluation metrics specifically designed for Web applications are presented, and are shown to be significant diagnostic tests. Automated CCT is shown to detect faults within five real-world Web applications. A case study of over 580 test results for a single application is presented demonstrating that automated CCT is an effective testing strategy. Moreover, CCT is found to detect security bugs in a Web application released into full production.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
articleno = {3},
numpages = {40},
keywords = {automated testing, Web application testing, test generation, software testing, Cookies, adaptive random testing, test strategies}
}

@inproceedings{10.1145/2556195.2556261,
author = {Guerra, Pedro Calais and Meira, Wagner and Cardie, Claire},
title = {Sentiment Analysis on Evolving Social Streams: How Self-Report Imbalances Can Help},
year = {2014},
isbn = {9781450323512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556195.2556261},
doi = {10.1145/2556195.2556261},
abstract = {Real-time sentiment analysis is a challenging machine learning task, due to scarcity of labeled data and sudden changes in sentiment caused by real-world events that need to be instantly interpreted. In this paper we propose solutions to acquire labels and cope with concept drift in this setting, by using findings from social psychology on how humans prefer to disclose some types of emotions. In particular, we use findings that humans are more motivated to report positive feelings rather than negative feelings and also prefer to report extreme feelings rather than average feelings.We map each of these self-report imbalances on two machine learning sub-tasks. The preference on the disclosure of positive feelings can be explored to generate labeled data on polarizing topics, where a positive event for one group usually induces negative feelings from the opposing group, generating an imbalance on user activity that unveils the current dominant sentiment.Based on the knowledge that extreme experiences are more reported than average experiences, we propose a feature representation strategy that focus on terms which appear at spikes in the social stream. When comparing to a static text representation (TF-IDF), we found that our feature representation is more capable of detecting new informative features that capture the sudden changes on sentiment stream caused by real-world events.We show that our social psychology-inspired framework produces accuracies up to 84% while analyzing live reactions in the debate of two popular sports on Twitter - soccer and football - despite requiring no human effort in generating supervisory labels.},
booktitle = {Proceedings of the 7th ACM International Conference on Web Search and Data Mining},
pages = {443–452},
numpages = {10},
keywords = {stream data mining, social media analytics, sentiment analysis},
location = {New York, New York, USA},
series = {WSDM '14}
}

@inproceedings{10.1145/2556195.2556244,
author = {Quattrone, Giovanni and Mashhadi, Afra and Quercia, Daniele and Smith-Clarke, Chris and Capra, Licia},
title = {Modelling Growth of Urban Crowd-Sourced Information},
year = {2014},
isbn = {9781450323512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556195.2556244},
doi = {10.1145/2556195.2556244},
abstract = {Urban crowd-sourcing has become a popular paradigm to harvest spatial information about our evolving cities directly from citizens. OpenStreetMap is a successful example of such paradigm, with an accuracy of its user-generated content comparable to that of curated databases (e.g., Ordnance Survey). Coverage is however low and most importantly non-uniformly distributed across the city. Being able to model the spontaneous growth of digital information in these domains is required, so to be able to plan interventions aimed at gathering content about areas that would otherwise be neglected. Inspired by models of physical urban growth developed by urban planners, we build a model of digital growth of crowd-sourced spatial information that is both easy to interpret and dynamic, so to be able to determine what factors impact growth and how these change over time. We build and test the model against five years of OpenStreetMap data for the city of London, UK. We then run the model against two other cities, chosen for their different physical and digital growth's characteristics, so to stress-test the model. We conclude with a discussion of the implications of this work on both developers and users of urban crowd-sourcing applications.},
booktitle = {Proceedings of the 7th ACM International Conference on Web Search and Data Mining},
pages = {563–572},
numpages = {10},
keywords = {crowd-sourcing, cellular automata, modelling},
location = {New York, New York, USA},
series = {WSDM '14}
}

@inproceedings{10.1145/2556195.2556251,
author = {Lu, Chun-Ta and Xie, Sihong and Kong, Xiangnan and Yu, Philip S.},
title = {Inferring the Impacts of Social Media on Crowdfunding},
year = {2014},
isbn = {9781450323512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556195.2556251},
doi = {10.1145/2556195.2556251},
abstract = {Crowdfunding -- in which people can raise funds through collaborative contributions of general public (i.e., crowd) -- has emerged as a billion dollars business for supporting more than one million ventures. However, very few research works have examined the process of crowdfunding. In particular, none has studied how social networks help crowdfunding projects to succeed. To gain insights into the effects of social networks in crowdfunding, we analyze the hidden connections between the fundraising results of projects on crowdfunding websites and the corresponding promotion campaigns in social media. Our analysis considers the dynamics of crowdfunding from two aspects: how fundraising activities and promotional activities on social media simultaneously evolve over time, and how the promotion campaigns influence the final outcomes. From our investigation, we identify a number of important principles that provide a useful guide for devising effective campaigns. For example, we observe temporal distribution of customer interest, strong correlations between a crowdfunding project's early promotional activities and the final outcomes, and the importance of concurrent promotion from multiple sources. We then show that these discoveries can help predict several important quantities, including overall popularity and the success rate of the project. Finally, we show how to use these discoveries to help design crowdfunding sites.},
booktitle = {Proceedings of the 7th ACM International Conference on Web Search and Data Mining},
pages = {573–582},
numpages = {10},
keywords = {crowdfunding, social media, early prediction},
location = {New York, New York, USA},
series = {WSDM '14}
}

@inproceedings{10.1145/2557500.2557524,
author = {Toker, Dereck and Steichen, Ben and Gingerich, Matthew and Conati, Cristina and Carenini, Giuseppe},
title = {Towards Facilitating User Skill Acquisition: Identifying Untrained Visualization Users through Eye Tracking},
year = {2014},
isbn = {9781450321846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2557500.2557524},
doi = {10.1145/2557500.2557524},
abstract = {A key challenge for information visualization designers lies in developing systems that best support users in terms of their individual abilities, needs, and preferences. However, most visualizations require users to first gather a certain set of skills before they can efficiently process the displayed information. This paper presents a first step towards designing visualizations that provide personalized support in order to ease the so-called 'learning curve' during a user's skill acquisition phase. We present prediction models, trained on users' gaze data, that can identify if users are still in the skill acquisition phase or if they have gained the necessary abilities. The paper first reveals that users exhibit the learning curve even during the usage of simple information visualizations, and then shows that we can generate reasonably accurate predictions about a user's skill acquisition using solely their eye gaze behavior.},
booktitle = {Proceedings of the 19th International Conference on Intelligent User Interfaces},
pages = {105–114},
numpages = {10},
keywords = {information visualization, eye-tracking, skill acquisition, adaptation, machine learning},
location = {Haifa, Israel},
series = {IUI '14}
}

@inproceedings{10.1145/2557500.2557537,
author = {L\'{e}cu\'{e}, Freddy and Tallevi-Diotallevi, Simone and Hayes, Jer and Tucker, Robert and Bicer, Veli and Sbodio, Marco Luca and Tommasi, Pierpaolo},
title = {STAR-CITY: Semantic Traffic Analytics and Reasoning for CITY},
year = {2014},
isbn = {9781450321846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2557500.2557537},
doi = {10.1145/2557500.2557537},
abstract = {This paper presents STAR-CITY, a system supporting semantic traffic analytics and reasoning for city. STAR-CITY, which integrates (human and machine-based) sensor data using variety of formats, velocities and volumes, has been designed to provide insight on historical and real-time traffic conditions, all supporting efficient urban planning. Our system demonstrates how the severity of road traffic congestion can be smoothly analyzed, diagnosed, explored and predicted using semantic web technologies. We present how semantic diagnosis and predictive reasoning, both using and interpreting semantics of data to deliver useful, accurate and consistent inferences, have been exploited and adapted systematized in an intelligent user interface. Our prototype of semantics-aware traffic analytics and reasoning, experimented in Dublin City Ireland, works and scales efficiently with historical together with real live and heterogeneous stream data.},
booktitle = {Proceedings of the 19th International Conference on Intelligent User Interfaces},
pages = {179–188},
numpages = {10},
keywords = {intelligent user interfaces, semantic web, transportation, semantic reasoning, automated system},
location = {Haifa, Israel},
series = {IUI '14}
}

@inproceedings{10.1145/2541940.2541942,
author = {Pichai, Bharath and Hsu, Lisa and Bhattacharjee, Abhishek},
title = {Architectural Support for Address Translation on GPUs: Designing Memory Management Units for CPU/GPUs with Unified Address Spaces},
year = {2014},
isbn = {9781450323055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2541940.2541942},
doi = {10.1145/2541940.2541942},
abstract = {The proliferation of heterogeneous compute platforms, of which CPU/GPU is a prevalent example, necessitates a manageable programming model to ensure widespread adoption. A key component of this is a shared unified address space between the heterogeneous units to obtain the programmability benefits of virtual memory.To this end, we are the first to explore GPU Memory Management Units(MMUs) consisting of Translation Lookaside Buffers (TLBs) and page table walkers (PTWs) for address translation in unified heterogeneous systems. We show the performance challenges posed by GPU warp schedulers on TLBs accessed in parallel with L1 caches, which provide many well-known programmability benefits. In response, we propose modest TLB and PTW augmentations that recover most of the performance lost by introducing L1 parallel TLB access. We also show that a little TLB-awareness can make other GPU performance enhancements (e.g., cache-conscious warp scheduling and dynamic warp formation on branch divergence) feasible in the face of cache-parallel address translation, bringing overheads in the range deemed acceptable for CPUs (10-15% of runtime). We presume this initial design leaves room for improvement but anticipate that our bigger insight, that a little TLB-awareness goes a long way in GPUs, will spur further work in this fruitful area.},
booktitle = {Proceedings of the 19th International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {743–758},
numpages = {16},
keywords = {unified address space, tlbs, mmus, gpus},
location = {Salt Lake City, Utah, USA},
series = {ASPLOS '14}
}

@article{10.1145/2654822.2541942,
author = {Pichai, Bharath and Hsu, Lisa and Bhattacharjee, Abhishek},
title = {Architectural Support for Address Translation on GPUs: Designing Memory Management Units for CPU/GPUs with Unified Address Spaces},
year = {2014},
issue_date = {March 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {1},
issn = {0163-5964},
url = {https://doi.org/10.1145/2654822.2541942},
doi = {10.1145/2654822.2541942},
abstract = {The proliferation of heterogeneous compute platforms, of which CPU/GPU is a prevalent example, necessitates a manageable programming model to ensure widespread adoption. A key component of this is a shared unified address space between the heterogeneous units to obtain the programmability benefits of virtual memory.To this end, we are the first to explore GPU Memory Management Units(MMUs) consisting of Translation Lookaside Buffers (TLBs) and page table walkers (PTWs) for address translation in unified heterogeneous systems. We show the performance challenges posed by GPU warp schedulers on TLBs accessed in parallel with L1 caches, which provide many well-known programmability benefits. In response, we propose modest TLB and PTW augmentations that recover most of the performance lost by introducing L1 parallel TLB access. We also show that a little TLB-awareness can make other GPU performance enhancements (e.g., cache-conscious warp scheduling and dynamic warp formation on branch divergence) feasible in the face of cache-parallel address translation, bringing overheads in the range deemed acceptable for CPUs (10-15% of runtime). We presume this initial design leaves room for improvement but anticipate that our bigger insight, that a little TLB-awareness goes a long way in GPUs, will spur further work in this fruitful area.},
journal = {SIGARCH Comput. Archit. News},
month = feb,
pages = {743–758},
numpages = {16},
keywords = {mmus, gpus, unified address space, tlbs}
}

@article{10.1145/2644865.2541942,
author = {Pichai, Bharath and Hsu, Lisa and Bhattacharjee, Abhishek},
title = {Architectural Support for Address Translation on GPUs: Designing Memory Management Units for CPU/GPUs with Unified Address Spaces},
year = {2014},
issue_date = {April 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2644865.2541942},
doi = {10.1145/2644865.2541942},
abstract = {The proliferation of heterogeneous compute platforms, of which CPU/GPU is a prevalent example, necessitates a manageable programming model to ensure widespread adoption. A key component of this is a shared unified address space between the heterogeneous units to obtain the programmability benefits of virtual memory.To this end, we are the first to explore GPU Memory Management Units(MMUs) consisting of Translation Lookaside Buffers (TLBs) and page table walkers (PTWs) for address translation in unified heterogeneous systems. We show the performance challenges posed by GPU warp schedulers on TLBs accessed in parallel with L1 caches, which provide many well-known programmability benefits. In response, we propose modest TLB and PTW augmentations that recover most of the performance lost by introducing L1 parallel TLB access. We also show that a little TLB-awareness can make other GPU performance enhancements (e.g., cache-conscious warp scheduling and dynamic warp formation on branch divergence) feasible in the face of cache-parallel address translation, bringing overheads in the range deemed acceptable for CPUs (10-15% of runtime). We presume this initial design leaves room for improvement but anticipate that our bigger insight, that a little TLB-awareness goes a long way in GPUs, will spur further work in this fruitful area.},
journal = {SIGPLAN Not.},
month = feb,
pages = {743–758},
numpages = {16},
keywords = {unified address space, mmus, tlbs, gpus}
}

@inproceedings{10.1145/2565585.2565589,
author = {Chen, Zhuo and Hu, Wenlu and Ha, Kiryong and Harkes, Jan and Gilbert, Benjamin and Hong, Jason and Smailagic, Asim and Siewiorek, Dan and Satyanarayanan, Mahadev},
title = {QuiltView: A Crowd-Sourced Video Response System},
year = {2014},
isbn = {9781450327428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2565585.2565589},
doi = {10.1145/2565585.2565589},
abstract = {Effortless one-touch capture of video is a unique capability of wearable devices such as Google Glass. We use this capability to create a new type of crowd-sourced system in which users receive queries relevant to their current location and opt-in preferences. In response, they can send back live video snippets of their surroundings. A system of result caching, geolocation and query similarity detection shields users from being overwhelmed by a flood of queries.},
booktitle = {Proceedings of the 15th Workshop on Mobile Computing Systems and Applications},
articleno = {13},
numpages = {6},
location = {Santa Barbara, California},
series = {HotMobile '14}
}

@article{10.1145/2523819,
author = {Rodr\'{\i}guez, Natalia D\'{\i}az and Cu\'{e}llar, M. P. and Lilius, Johan and Calvo-Flores, Miguel Delgado},
title = {A Survey on Ontologies for Human Behavior Recognition},
year = {2014},
issue_date = {April 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2523819},
doi = {10.1145/2523819},
abstract = {Describing user activity plays an essential role in ambient intelligence. In this work, we review different methods for human activity recognition, classified as data-driven and knowledge-based techniques. We focus on context ontologies whose ultimate goal is the tracking of human behavior. After studying upper and domain ontologies, both useful for human activity representation and inference, we establish an evaluation criterion to assess the suitability of the different candidate ontologies for this purpose. As a result, any missing features, which are relevant for modeling daily human behaviors, are identified as future challenges.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {43},
numpages = {33},
keywords = {activity recognition, context awareness, Human behavior recognition}
}

@inproceedings{10.1145/2576195.2576196,
author = {Hizver, Jennia and Chiueh, Tzi-cker},
title = {Real-Time Deep Virtual Machine Introspection and Its Applications},
year = {2014},
isbn = {9781450327640},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2576195.2576196},
doi = {10.1145/2576195.2576196},
abstract = {Virtual Machine Introspection (VMI) provides the ability to monitor virtual machines (VM) in an agentless fashion by gathering VM execution states from the hypervisor and analyzing those states to extract information about a running operating system (OS) without installing an agent inside the VM. VMI's main challenge lies in the difficulty in converting low-level byte string values into high-level semantic states of the monitored VM's OS. In this work, we tackle this challenge by developing a real-time kernel data structure monitoring (RTKDSM) system that leverages the rich OS analysis capabilities of Volatility, an open source computer forensics framework, to significantly simplify and automate analysis of VM execution states. The RTKDSM system is designed as an extensible software framework that is meant to be extended to perform application-specific VM state analysis. In addition, the RTKDSM system is able to perform real-time monitoring of any changes made to the extracted OS states of guest VMs. This real-time monitoring capability is especially important for VMI-based security applications. To minimize the performance overhead associated with real-time kernel data structure monitoring, the RTKDSM system has incorporated several optimizations whose effectiveness is reported in this paper.},
booktitle = {Proceedings of the 10th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments},
pages = {3–14},
numpages = {12},
keywords = {security monitoring, virtual machine introspection, forensics, performance},
location = {Salt Lake City, Utah, USA},
series = {VEE '14}
}

@article{10.1145/2674025.2576196,
author = {Hizver, Jennia and Chiueh, Tzi-cker},
title = {Real-Time Deep Virtual Machine Introspection and Its Applications},
year = {2014},
issue_date = {July 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {7},
issn = {0362-1340},
url = {https://doi.org/10.1145/2674025.2576196},
doi = {10.1145/2674025.2576196},
abstract = {Virtual Machine Introspection (VMI) provides the ability to monitor virtual machines (VM) in an agentless fashion by gathering VM execution states from the hypervisor and analyzing those states to extract information about a running operating system (OS) without installing an agent inside the VM. VMI's main challenge lies in the difficulty in converting low-level byte string values into high-level semantic states of the monitored VM's OS. In this work, we tackle this challenge by developing a real-time kernel data structure monitoring (RTKDSM) system that leverages the rich OS analysis capabilities of Volatility, an open source computer forensics framework, to significantly simplify and automate analysis of VM execution states. The RTKDSM system is designed as an extensible software framework that is meant to be extended to perform application-specific VM state analysis. In addition, the RTKDSM system is able to perform real-time monitoring of any changes made to the extracted OS states of guest VMs. This real-time monitoring capability is especially important for VMI-based security applications. To minimize the performance overhead associated with real-time kernel data structure monitoring, the RTKDSM system has incorporated several optimizations whose effectiveness is reported in this paper.},
journal = {SIGPLAN Not.},
month = mar,
pages = {3–14},
numpages = {12},
keywords = {performance, security monitoring, forensics, virtual machine introspection}
}

@article{10.1145/2542049,
author = {Mitchell, Robert and Chen, Ing-Ray},
title = {A Survey of Intrusion Detection Techniques for Cyber-Physical Systems},
year = {2014},
issue_date = {April 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2542049},
doi = {10.1145/2542049},
abstract = {Pervasive healthcare systems, smart grids, and unmanned aircraft systems are examples of Cyber-Physical Systems (CPSs) that have become highly integrated in the modern world. As this integration deepens, the importance of securing these systems increases. In order to identify gaps and propose research directions in CPS intrusion detection research, we survey the literature of this area. Our approach is to classify modern CPS Intrusion Detection System (IDS) techniques based on two design dimensions: detection technique and audit material. We summarize advantages and drawbacks of each dimension’s options. We also summarize the most and least studied CPS IDS techniques in the literature and provide insight on the effectiveness of IDS techniques as they apply to CPSs. Finally, we identify gaps in CPS IDS research and suggest future research areas.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {55},
numpages = {29},
keywords = {intrusion detection, classification, Cyber-physical systems, security}
}

@article{10.1145/2590599,
author = {Woldt, Wayne and Frew, Eric and Meyer, George},
title = {Feeding a Hungry World: The Potential for Unmanned Aircraft Systems},
year = {2014},
issue_date = {Spring 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {3},
issn = {1528-4972},
url = {https://doi.org/10.1145/2590599},
doi = {10.1145/2590599},
abstract = {The fusion of next generation sensors and advanced information systems, combined with advances in unmanned aircraft systems that have emerged through aerospace engineering technologies, will contribute to the challenge of feeding our future world in a sustainable manner. Without these advances, the world may find itself short of food and perhaps on the brink of global conflict.},
journal = {XRDS},
month = mar,
pages = {24–27},
numpages = {4}
}

@article{10.1145/2500875,
author = {Yang, Junfeng and Cui, Heming and Wu, Jingyue and Tang, Yang and Hu, Gang},
title = {Making Parallel Programs Reliable with Stable Multithreading},
year = {2014},
issue_date = {March 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/2500875},
doi = {10.1145/2500875},
abstract = {Stable multithreading dramatically simplifies the interleaving behaviors of parallel programs, offering new hope for making parallel programming easier.},
journal = {Commun. ACM},
month = mar,
pages = {58–69},
numpages = {12}
}

@article{10.14778/2732286.2732290,
author = {Wang, Sheng and Maier, David and Ooi, Beng Chin},
title = {Lightweight Indexing of Observational Data in Log-Structured Storage},
year = {2014},
issue_date = {March 2014},
publisher = {VLDB Endowment},
volume = {7},
number = {7},
issn = {2150-8097},
url = {https://doi.org/10.14778/2732286.2732290},
doi = {10.14778/2732286.2732290},
abstract = {Huge amounts of data are being generated by sensing devices every day, recording the status of objects and the environment. Such observational data is widely used in scientific research. As the capabilities of sensors keep improving, the data produced are drastically expanding in precision and quantity, making it a write-intensive domain. Log-structured storage is capable of providing high write throughput, and hence is a natural choice for managing large-scale observational data.In this paper, we propose an approach to indexing and querying observational data in log-structured storage. Based on key traits of observational data, we design a novel index approach called the CR-index (Continuous Range Index), which provides fast query performance without compromising write throughput. It is a lightweight structure that is fast to construct and often small enough to reside in RAM. Our experimental results show that the CR-index is superior in handling observational data compared to other indexing techniques. While our focus is scientific data, we believe our index will be effective for other applications with similar properties, such as process monitoring in manufacturing.},
journal = {Proc. VLDB Endow.},
month = mar,
pages = {529–540},
numpages = {12}
}

@inproceedings{10.1145/2576195.2576205,
author = {Kalibera, Tomas and Maj, Petr and Morandat, Floreal and Vitek, Jan},
title = {A Fast Abstract Syntax Tree Interpreter for R},
year = {2014},
isbn = {9781450327640},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2576195.2576205},
doi = {10.1145/2576195.2576205},
abstract = {Dynamic languages have been gaining popularity to the point that their performance is starting to matter. The effort required to develop a production-quality, high-performance runtime is, however, staggering and the expertise required to do so is often out of reach of the community maintaining a particular language. Many domain specific languages remain stuck with naive implementations, as they are easy to write and simple to maintain for domain scientists. In this paper, we try to see how far one can push a naive implementation while remaining portable and not requiring expertise in compilers and runtime systems. We choose the R language, a dynamic language used in statistics, as the target of our experiment and adopt the simplest possible implementation strategy, one based on evaluation of abstract syntax trees. We build our interpreter on top of a Java virtual machine and use only facilities available to all Java programmers. We compare our results to other implementations of R.},
booktitle = {Proceedings of the 10th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments},
pages = {89–102},
numpages = {14},
keywords = {r language, specialization, lazy evaluation},
location = {Salt Lake City, Utah, USA},
series = {VEE '14}
}

@article{10.1145/2674025.2576205,
author = {Kalibera, Tomas and Maj, Petr and Morandat, Floreal and Vitek, Jan},
title = {A Fast Abstract Syntax Tree Interpreter for R},
year = {2014},
issue_date = {July 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {7},
issn = {0362-1340},
url = {https://doi.org/10.1145/2674025.2576205},
doi = {10.1145/2674025.2576205},
abstract = {Dynamic languages have been gaining popularity to the point that their performance is starting to matter. The effort required to develop a production-quality, high-performance runtime is, however, staggering and the expertise required to do so is often out of reach of the community maintaining a particular language. Many domain specific languages remain stuck with naive implementations, as they are easy to write and simple to maintain for domain scientists. In this paper, we try to see how far one can push a naive implementation while remaining portable and not requiring expertise in compilers and runtime systems. We choose the R language, a dynamic language used in statistics, as the target of our experiment and adopt the simplest possible implementation strategy, one based on evaluation of abstract syntax trees. We build our interpreter on top of a Java virtual machine and use only facilities available to all Java programmers. We compare our results to other implementations of R.},
journal = {SIGPLAN Not.},
month = mar,
pages = {89–102},
numpages = {14},
keywords = {lazy evaluation, specialization, r language}
}

@article{10.1145/2579990,
author = {Su, Ao-Jan and Hu, Y. Charlie and Kuzmanovic, Aleksandar and Koh, Cheng-Kok},
title = {How to Improve Your Search Engine Ranking: Myths and Reality},
year = {2014},
issue_date = {March 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {1559-1131},
url = {https://doi.org/10.1145/2579990},
doi = {10.1145/2579990},
abstract = {Search engines have greatly influenced the way people access information on the Internet, as such engines provide the preferred entry point to billions of pages on the Web. Therefore, highly ranked Web pages generally have higher visibility to people and pushing the ranking higher has become the top priority for Web masters. As a matter of fact, Search Engine Optimization (SEO) has became a sizeable business that attempts to improve their clients’ ranking. Still, the lack of ways to validate SEO’s methods has created numerous myths and fallacies associated with ranking algorithms.In this article, we focus on two ranking algorithms, Google’s and Bing’s, and design, implement, and evaluate a ranking system to systematically validate assumptions others have made about these popular ranking algorithms. We demonstrate that linear learning models, coupled with a recursive partitioning ranking scheme, are capable of predicting ranking results with high accuracy. As an example, we manage to correctly predict 7 out of the top 10 pages for 78% of evaluated keywords. Moreover, for content-only ranking, our system can correctly predict 9 or more pages out of the top 10 ones for 77% of search terms. We show how our ranking system can be used to reveal the relative importance of ranking features in a search engine’s ranking function, provide guidelines for SEOs and Web masters to optimize their Web pages, validate or disprove new ranking features, and evaluate search engine ranking results for possible ranking bias.},
journal = {ACM Trans. Web},
month = mar,
articleno = {8},
numpages = {25},
keywords = {learning, search engine optimization, Search engine, ranking algorithm}
}

@article{10.1145/2579700,
author = {Peters, Christian and Hermann, Thomas and Wachsmuth, Sven and Hoey, Jesse},
title = {Automatic Task Assistance for People with Cognitive Disabilities in Brushing Teeth - A User Study with the TEBRA System},
year = {2014},
issue_date = {March 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {1936-7228},
url = {https://doi.org/10.1145/2579700},
doi = {10.1145/2579700},
abstract = {People with cognitive disabilities such as dementia and intellectual disabilities tend to have problems in coordinating steps in the execution of Activities of Daily Living (ADLs) due to limited capabilities in cognitive functioning. To successfully perform ADLs, these people are reliant on the assistance of human caregivers. This leads to a decrease of independence for care recipients and imposes a high burden on caregivers. Assistive Technology for Cognition (ATC) aims to compensate for decreased cognitive functions. ATC systems provide automatic assistance in task execution by delivering appropriate prompts which enable the user to perform ADLs without any assistance of a human caregiver. This leads to an increase of the user’s independence and to a relief of caregiver’s burden. In this article, we describe the design, development and evaluation of a novel ATC system. The TEBRA (TEeth BRushing Assistance) system supports people with moderate cognitive disabilities in the execution of brushing teeth. A main requirement for the acceptance of ATC systems is context awareness: explicit feedback from the user is not necessary to provide appropriate assistance. Furthermore, an ATC system needs to handle spatial and temporal variance in the execution of behaviors such as different movement characteristics and different velocities. The TEBRA system handles spatial variance in a behavior recognition component based on a Bayesian network classifier. A dynamic timing model deals with temporal variance by adapting to different velocities of users during a trial. We evaluate a fully functioning prototype of the TEBRA system in a study with people with cognitive disabilities. The main aim of the study is to analyze the technical performance of the system and the user’s behavior in the interaction with the system with regard to the main hypothesis: is the TEBRA system able to increase the user’s independence in the execution of brushing teeth?},
journal = {ACM Trans. Access. Comput.},
month = mar,
articleno = {10},
numpages = {34},
keywords = {cognitive disabilities, Automatic task assistance, user study}
}

@article{10.14778/2732286.2732287,
author = {Ntarmos, Nikos and Patlakas, Ioannis and Triantafillou, Peter},
title = {Rank Join Queries in NoSQL Databases},
year = {2014},
issue_date = {March 2014},
publisher = {VLDB Endowment},
volume = {7},
number = {7},
issn = {2150-8097},
url = {https://doi.org/10.14778/2732286.2732287},
doi = {10.14778/2732286.2732287},
abstract = {Rank (i.e., top-k) join queries play a key role in modern analytics tasks. However, despite their importance and unlike centralized settings, they have been completely overlooked in cloud NoSQL settings. We attempt to fill this gap: We contribute a suite of solutions and study their performance comprehensively. Baseline solutions are offered using SQL-like languages (like Hive and Pig), based on MapReduce jobs. We first provide solutions that are based on specialized indices, which may themselves be accessed using either MapReduce or coordinator-based strategies. The first index-based solution is based on inverted indices, which are accessed with MapReduce jobs. The second index-based solution adapts a popular centralized rank-join algorithm. We further contribute a novel statistical structure comprising histograms and Bloom filters, which forms the basis for the third index-based solution. We provide (i) MapReduce algorithms showing how to build these indices and statistical structures, (ii) algorithms to allow for online updates to these indices, and (iii) query processing algorithms utilizing them. We implemented all algorithms in Hadoop (HDFS) and HBase and tested them on TPC-H datasets of various scales, utilizing different queries on tables of various sizes and different score-attribute distributions. We ported our implementations to Amazon EC2 and "in-house" lab clusters of various scales. We provide performance results for three metrics: query execution time, network bandwidth consumption, and dollar-cost for query execution.},
journal = {Proc. VLDB Endow.},
month = mar,
pages = {493–504},
numpages = {12}
}

@article{10.1145/2535933,
author = {Navarro, Gonzalo},
title = {Spaces, Trees, and Colors: The Algorithmic Landscape of Document Retrieval on Sequences},
year = {2014},
issue_date = {April 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2535933},
doi = {10.1145/2535933},
abstract = {Document retrieval is one of the best-established information retrieval activities since the ’60s, pervading all search engines. Its aim is to obtain, from a collection of text documents, those most relevant to a pattern query. Current technology is mostly oriented to “natural language” text collections, where inverted indexes are the preferred solution. As successful as this paradigm has been, it fails to properly handle various East Asian languages and other scenarios where the “natural language” assumptions do not hold. Inthis survey, we cover the recent research in extending the document retrieval techniques to a broader class of sequence collections, which has applications in bioinformatics, data and web mining, chemoinformatics, software engineering, multimedia information retrieval, and many other fields. We focus on the algorithmic aspects of the techniques, uncovering a rich world of relations between document retrieval challenges and fundamental problems on trees, strings, range queries, discrete geometry, and other areas.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {52},
numpages = {47},
keywords = {Text indexing, colored range queries, information retrieval, compact data structures, orthogonal range searches, string searching}
}

@article{10.1145/2555595,
author = {Duarte Torres, Sergio and Weber, Ingmar and Hiemstra, Djoerd},
title = {Analysis of Search and Browsing Behavior of Young Users on the Web},
year = {2014},
issue_date = {March 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {1559-1131},
url = {https://doi.org/10.1145/2555595},
doi = {10.1145/2555595},
abstract = {The Internet is increasingly used by young children for all kinds of purposes. Nonetheless, there are not many resources especially designed for children on the Internet and most of the content online is designed for grown-up users. This situation is problematic if we consider the large differences between young users and adults since their topic interests, computer skills, and language capabilities evolve rapidly during childhood. There is little research aimed at exploring and measuring the difficulties that children encounter on the Internet when searching for information and browsing for content. In the first part of this work, we employed query logs from a commercial search engine to quantify the difficulties children of different ages encounter on the Internet and to characterize the topics that they search for. We employed query metrics (e.g., the fraction of queries posed in natural language), session metrics (e.g., the fraction of abandoned sessions), and click activity (e.g., the fraction of ad clicks). The search logs were also used to retrace stages of child development. Concretely, we looked for changes in interests (e.g., the distribution of topics searched) and language development (e.g., the readability of the content accessed and the vocabulary size).In the second part of this work, we employed toolbar logs from a commercial search engine to characterize the browsing behavior of young users, particularly to understand the activities on the Internet that trigger search. We quantified the proportion of browsing and search activity in the toolbar sessions and we estimated the likelihood of a user to carry out search on the Web vertical and multimedia verticals (i.e., videos and images) given that the previous event is another search event or a browsing event.We observed that these metrics clearly demonstrate an increased level of confusion and unsuccessful search sessions among children. We also found a clear relation between the reading level of the clicked pages and characteristics of the users such as age and educational attainment.In terms of browsing behavior, children were found to start their activities on the Internet with a search engine (instead of directly browsing content) more often than adults. We also observed a significantly larger amount of browsing activity for the case of teenager users. Interestingly we also found that if children visit knowledge-related Web sites (i.e., information-dense pages such as Wikipedia articles), they subsequently do more Web searches than adults. Additionally, children and especially teenagers were found to have a greater tendency to engage in multimedia search, which calls to improve the aggregation of multimedia results into the current search result pages.},
journal = {ACM Trans. Web},
month = mar,
articleno = {7},
numpages = {54},
keywords = {query logs, Web search, session analysis, Yahoo! Search, topic classification, Children, browsing behavior, search behavior, Yahoo! Answers, toolbar logs, young adults, adults}
}

@article{10.1109/TASLP.2014.2300339,
author = {Wei, Wen-Li and Wu, Chung-Hsien and Lin, Jen-Chun and Li, Han},
title = {Exploiting Psychological Factors for Interaction Style Recognition in Spoken Conversation},
year = {2014},
issue_date = {March 2014},
publisher = {IEEE Press},
volume = {22},
number = {3},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2014.2300339},
doi = {10.1109/TASLP.2014.2300339},
abstract = {Determining how a speaker is engaged in a conversation is crucial for achieving harmonious interaction between computers and humans. In this study, a fusion approach was developed based on psychological factors to recognize Interaction Style ($IS$ ) in spoken conversation, which plays a key role in creating natural dialogue agents. The proposed Fused Cross-Correlation Model (FCCM) provides a unified probabilistic framework to model the relationships among the psychological factors of emotion, personality trait ($PT$), transient  $IS$, and  $IS$ history, for recognizing $IS$. An emotional arousal-dependent speech recognizer was used to obtain the recognized spoken text for extracting linguistic features to estimate transient  $IS$ likelihood and recognize $PT$. A temporal course modeling approach and an emotional sub-state language model, based on the temporal phases of an emotional expression, were employed to obtain a better emotion recognition result. The experimental results indicate that the proposed FCCM yields satisfactory results in  $IS$ recognition and also demonstrate that combining psychological factors effectively improves  $IS$ recognition accuracy.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = mar,
pages = {659–671},
numpages = {13}
}

@article{10.1145/2577386,
author = {Elerath, Jon G. and Schindler, Jiri},
title = {Beyond MTTDL: A Closed-Form RAID 6 Reliability Equation},
year = {2014},
issue_date = {March 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {2},
issn = {1553-3077},
url = {https://doi.org/10.1145/2577386},
doi = {10.1145/2577386},
abstract = {We introduce a new closed-form equation for estimating the number of data-loss events for a redundant array of inexpensive disks in a RAID-6 configuration. The equation expresses operational failures, their restorations, latent (sector) defects, and disk media scrubbing by time-based distributions that can represent non-homogeneous Poisson processes. It uses two-parameter Weibull distributions that allows the distributions to take on many different shapes, modeling increasing, decreasing, or constant occurrence rates. This article focuses on the statistical basis of the equation. It also presents time-based distributions of the four processes based on an extensive analysis of field data collected over several years from 10,000s of commercially available systems with 100,000s of disk drives. Our results for RAID-6 groups of size 16 indicate that the closed-form expression yields much more accurate results compared to the MTTDL reliability equation and matching computationally-intensive Monte Carlo simulations.},
journal = {ACM Trans. Storage},
month = mar,
articleno = {7},
numpages = {21},
keywords = {Storage systems, RAID reliability}
}

@inproceedings{10.1145/2556325.2566246,
author = {Stephens-Martinez, Kristin and Hearst, Marti A. and Fox, Armando},
title = {Monitoring MOOCs: Which Information Sources Do Instructors Value?},
year = {2014},
isbn = {9781450326698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556325.2566246},
doi = {10.1145/2556325.2566246},
abstract = {For an instructor who is teaching a massive open online course (MOOC), what is the best way to understand their class? What is the best way to view how the students are interacting with the content while the course is running? To help prepare for the next iteration, how should the course's data be best analyzed after the fact? How do these instructional monitoring needs differ between online courses with tens of thousands of students and courses with only tens? This paper reports the results of a survey of 92 MOOC instructors who answered questions about which information they find useful in their course, with the end goal of creating an information display for MOOC instructors.The main findings are: (i) quantitative data sources such as grades, although useful, are not sufficient; understanding the activity in discussion forums and student surveys was rated useful for all use cases by a large majority of respondents, (ii) chat logs were not seen as useful, (iii) for the most part, the same sources of information were seen as useful as found in surveys of smaller online courses, (iv) mockups of existing and novel visualization techniques were responded to positively for use both while the course is running and for planning a revision of the course, and (v) a wide range of views was expressed about other details.},
booktitle = {Proceedings of the First ACM Conference on Learning @ Scale Conference},
pages = {79–88},
numpages = {10},
keywords = {instructor support, moocs, visualizations, e-learning, massive open online courses},
location = {Atlanta, Georgia, USA},
series = {L@S '14}
}

@inproceedings{10.1145/2556325.2566244,
author = {Konstan, Joseph A. and Walker, J.D. and Brooks, D. Christopher and Brown, Keith and Ekstrand, Michael D.},
title = {Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC},
year = {2014},
isbn = {9781450326698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556325.2566244},
doi = {10.1145/2556325.2566244},
abstract = {In Fall 2013 we offered an open online Introduction to Recommender Systems through Coursera, while simultaneously offering a for-credit version of the course on-campus using the Coursera platform and a flipped classroom instruction model. As the goal of offering this course was to experiment with this type of instruction, we performed extensive evaluation including surveys of demographics, self-assessed skills, and learning intent; we also designed a knowledge-assessment tool specifically for the subject matter in this course, administering it before and after the course to measure learning. We also tracked students through the course, including separating out students enrolled for credit from those enrolled only for the free, open course. This article reports on our findings.},
booktitle = {Proceedings of the First ACM Conference on Learning @ Scale Conference},
pages = {61–70},
numpages = {10},
keywords = {mooc, distance learning, evaluation, open learning},
location = {Atlanta, Georgia, USA},
series = {L@S '14}
}

@inproceedings{10.1145/2538862.2538949,
author = {Buffum, Philip Sheridan and Martinez-Arocho, Allison G. and Frankosky, Megan Hardy and Rodriguez, Fernando J. and Wiebe, Eric N. and Boyer, Kristy Elizabeth},
title = {CS Principles Goes to Middle School: Learning How to Teach "Big Data"},
year = {2014},
isbn = {9781450326056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2538862.2538949},
doi = {10.1145/2538862.2538949},
abstract = {Spurred by evidence that students' future studies are highly influenced during middle school, recent efforts have seen a growing emphasis on introducing computer science to middle school learners. This paper reports on the in-progress development of a new middle school curricular module for Big Data, situated as part of a new CS Principles-based middle school curriculum. Big Data is of widespread societal importance and holds increasing implications for the computer science workforce. It also has appeal as a focus for middle school computer science because of its rich interplay with other important computer science principles. This paper examines three key aspects of a Big Data unit for middle school: its alignment with emerging curricular standards; the perspectives of middle school classroom teachers in mathematics, science, and language arts; and student feedback as explored during a middle school pilot study with a small subset of the planned curriculum. The results indicate that a Big Data unit holds great promise as part of a middle school computer science curriculum.},
booktitle = {Proceedings of the 45th ACM Technical Symposium on Computer Science Education},
pages = {151–156},
numpages = {6},
keywords = {middle school, computer science education, big data},
location = {Atlanta, Georgia, USA},
series = {SIGCSE '14}
}

@inproceedings{10.1145/2538862.2538962,
author = {Kranch, Douglas A.},
title = {Remediation and Student Success in CIS Programs},
year = {2014},
isbn = {9781450326056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2538862.2538962},
doi = {10.1145/2538862.2538962},
abstract = {This retrospective study of the performance of Computer Information Systems (CIS) students from between 1987 and 2010 found evidence that remedial math, reading, and writing courses can significantly increase student mean GPA, persistence, and completion in a CIS program. Remediation was most effective when verbal as well as mathematical deficiencies were addressed, and the performance of fully remediated students was indistinguishable as a group from students not requiring remediation.},
booktitle = {Proceedings of the 45th ACM Technical Symposium on Computer Science Education},
pages = {689–694},
numpages = {6},
keywords = {remediation, computer science readiness, novice learner},
location = {Atlanta, Georgia, USA},
series = {SIGCSE '14}
}

@inproceedings{10.1145/2538862.2538970,
author = {Exter, Marisa},
title = {Comparing Educational Experiences and On-the-Job Needs of Educational Software Designers},
year = {2014},
isbn = {9781450326056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2538862.2538970},
doi = {10.1145/2538862.2538970},
abstract = {This paper reports on part of the findings of a mixed-methods study which explored the educational experiences of Computing Professionals who design and develop educational software. A particular focus is given on the gaps professionals perceive between what was covered in their formal (university) education and the skills and knowledge that have been most important to them in their professional roles. Discrepancies were found particularly in areas related to practical skills (such as testing, maintaining code over time, use of source code control and development tools), communication, critical thinking and problem solving, and strategies used to continue learning on-the-job. Participant suggestions for improving university programs focused largely on the use of large scale, complex, authentic projects of significant duration. The author recommends further consideration be given to explicitly teaching the type of self-learning skills and strategies used by experienced professionals.},
booktitle = {Proceedings of the 45th ACM Technical Symposium on Computer Science Education},
pages = {355–360},
numpages = {6},
keywords = {curriculum, computing education, non-formal education, informal education, computer science education, pedagogy},
location = {Atlanta, Georgia, USA},
series = {SIGCSE '14}
}

@inproceedings{10.1145/2538862.2538956,
author = {Van Dyne, Michele and Braun, Jeffrey},
title = {Effectiveness of a Computational Thinking (CS0) Course on Student Analytical Skills},
year = {2014},
isbn = {9781450326056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2538862.2538956},
doi = {10.1145/2538862.2538956},
abstract = {: In this paper, we describe the content and evaluation of a Computational Thinking (CS0) course developed to improve the analytical problem solving of students participating in the course. The course is targeted to students who are mathematically under-prepared to enter our introductory programming sequence; however, it has recently been included in the University's general education curriculum so that students majoring in any discipline may take the course. Using the Whimbey Analytical Skills Inventory (WASI) students in the CS0 class, along with students in an analogous level engineering class (FESP), were tested at the beginning of the course and again at the end, using different versions of the test. The improvement in scores was statistically significant when measured by both the student t-test and the Cohen d (effect size) for CS0 students but not for the FESP students, providing support that the course does, in fact, increase student analytical problem solving skills. Courses in Computational Thinking have demonstrated success in many schools; however, this research demonstrates its effectiveness in improving analytical skills in majors as well as non-majors.},
booktitle = {Proceedings of the 45th ACM Technical Symposium on Computer Science Education},
pages = {133–138},
numpages = {6},
keywords = {critical thinking, computational thinking, problem solving, course effectiveness, analytical skills, CS0},
location = {Atlanta, Georgia, USA},
series = {SIGCSE '14}
}

@inproceedings{10.1145/2557642.2579372,
author = {Shah, Rajiv Ratn and Yu, Yi and Zimmermann, Roger},
title = {User Preference-Aware Music Video Generation Based on Modeling Scene Moods},
year = {2014},
isbn = {9781450327053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2557642.2579372},
doi = {10.1145/2557642.2579372},
abstract = {Due to technical advances in mobile devices (e.g., smartphones, tablets) and wireless communications, people now can easily capture user-generated videos (UGVs) anywhere, anytime and instantly share their real-life experiences via social web sites. Enjoying videos has become very popular entertainment. One challenge is that many mobile videos do not have very appealing audio that was captured with the video. In this demonstration, to overcome this issue we propose a music video generation/creation system (Android app and backend system) that aims to make UGVs more attractive by generating scene-adaptive and user-preference aware music tracks. In our system, we take geographic categories, visual content and user listening history into account. In particular, the sequences of geographic categories and visual features are integrated into a SVMhmm model to predict video scene moods. The music genre, as a user preference is also exploited to personalize the recommended songs. We believe this is the first work that predicts scene moods from a real-world video dataset collected by users' daily outdoor recordings to facilitate user-preference aware music video generation. Our experiments confirm that our system can effectively combine objective scene moods and individual music tastes to recommend appealing soundtracks for videos. Our Android app only sends recorded sensor data and a few keyframes of a UGV to a cloud service (backend system) to retrieve recommended music tracks, therefore it is bandwidth efficient since the transmission of video data is not required for analysis.},
booktitle = {Proceedings of the 5th ACM Multimedia Systems Conference},
pages = {156–159},
numpages = {4},
keywords = {user preference, scene mood prediction, geographic category, video soundtrack generation},
location = {Singapore, Singapore},
series = {MMSys '14}
}

@inproceedings{10.1145/2567688.2567690,
author = {Gera, Abhishek and Bhattacharya, Arnab},
title = {Emotion Recognition from Audio and Visual Data Using F-Score Based Fusion},
year = {2014},
isbn = {9781450324755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567688.2567690},
doi = {10.1145/2567688.2567690},
abstract = {Emotion recognition has been one of the cornerstones of human-computer interaction. Although decades of work has attacked the problem of automatic emotion recognition from either audio or video signals, the fusion of the two modalities is more recent. In this paper, we aim to tackle the problem when both audio and video data are available in a synchronized manner. We address the six basic human emotions, namely, anger, disgust, fear, happiness, sadness, and surprise. We employ an automatic face tracker to extract the different facial points of interest from a video. We then compute feature vectors for each video frame using distances and angles between the tracked points. For audio data, we use the pitch, energy and MFCC to derive feature vectors for each window as well as the entire audio signal. We use two standard techniques, GMM-based HMM and SVM, as the base classifiers. We then design a novel fusion method using the F-score of the base classifiers. We first demonstrate that our fusion approach can increase the accuracy of the base classifiers by as much as 5%. Finally, we show that our fusion-based bi-modal emotion recognition method achieves an overall accuracy of 54% on a publicly available database, which is an improvement upon the current state-of-the-art by 9%.},
booktitle = {Proceedings of the 1st IKDD Conference on Data Sciences},
pages = {1–10},
numpages = {10},
keywords = {Multi-class fusion, Emotion recognition, Audio-visual data, F-score},
location = {Delhi, India},
series = {CoDS '14}
}

@inproceedings{10.1145/2568088.2568104,
author = {Yan, Feng and Hughes, Shannon and Riska, Alma and Smirni, Evgenia},
title = {Agile Middleware for Scheduling: Meeting Competing Performance Requirements of Diverse Tasks},
year = {2014},
isbn = {9781450327336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568088.2568104},
doi = {10.1145/2568088.2568104},
abstract = {As the need for scaled-out systems increases, it is paramount to architect them as large distributed systems consisting of off-the-shelf basic computing components known as compute or data nodes. These nodes are expected to handle their work independently, and often utilize off-the-shelf management tools, like those offered by Linux, to differentiate priorities of tasks. While prioritization of background tasks in server nodes takes center stage in scaled-out systems, with many tasks associated with salient features such as eventual consistency, data analytics, and garbage collection, the standard Linux tools such as nice and ionice fail to adapt to the dynamic behavior of high priority tasks in order to achieve the best trade-off between protecting the performance of high priority workload and completing as much low priority work as possible. In this paper, we provide a solution by proposing a priority scheduling middleware that employs different policies to schedule background tasks based on the instantaneous resource requirements of the high priority applications running on the server node. The selection of policies is based on off-line and on-line learning of the high priority workload characteristics and the imposed performance impact due to low priority work. In effect, this middleware uses a {em hybrid} approach to scheduling rather than a monolithic policy. We prototype and evaluate it via measurements on a test-bed and show that this scheduling middleware is robust as it effectively and autonomically changes the relative priorities between high and low priority tasks, consistently meeting their competing performance targets.},
booktitle = {Proceedings of the 5th ACM/SPEC International Conference on Performance Engineering},
pages = {185–196},
numpages = {12},
keywords = {workload characterization, priority scheduling, linux priority utilities, decision map, performance guarantee, learning performance patterns, background throughput},
location = {Dublin, Ireland},
series = {ICPE '14}
}

@inproceedings{10.1145/2649563.2649577,
author = {Al Ali, Rima and Gerostathopoulos, Ilias and Gonzalez-Herrera, Inti and Juan-Verdejo, Adrian and Kit, Michal and Surajbali, Bholanathsingh},
title = {An Architecture-Based Approach for Compute-Intensive Pervasive Systems in Dynamic Environments},
year = {2014},
isbn = {9781450330596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2649563.2649577},
doi = {10.1145/2649563.2649577},
abstract = {Distributed systems have continued to evolve and we note two important trends: the dramatically increasing level of dynamism in contemporary distributed systems and the convergence of mobile computing with cloud computing. The end result is that it is very difficult to achieve the required level of scalability and dependability in a systematic way when considering pervasive systems that are software- and compute-intensive and whose functionality is typically augmented by static cloud infrastructure resources. This work discusses relevant challenges and requirements for integrating cloud computing with pervasive systems operating in dynamic environments. We present a set of requirements using a holistic case study and describe a framework approach to address these requirements.},
booktitle = {Proceedings of the 2nd International Workshop on Hot Topics in Cloud Service Scalability},
articleno = {3},
numpages = {6},
location = {Dublin, Ireland},
series = {HotTopiCS '14}
}

@inproceedings{10.1145/2554850.2554867,
author = {Pessin, Gustavo and Os\'{o}rio, Fernando S. and Ueyama, J\'{o} and Wolf, Denis F. and Moioli, Renan C. and Vargas, Patr\'{\i}cia A.},
title = {Self-Localisation in Indoor Environments Combining Learning and Evolution with Wireless Networks},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2554867},
doi = {10.1145/2554850.2554867},
abstract = {This work combines wireless networks (WLAN) (Wireless LAN IEEE 802.11 b/g) with learning and evolution of artificial neural networks. Our main objective is to propose an architecture for a self-adaptive system, addressing alternative methods to the usage of GPS for self-localisation in autonomous mobile robots either in indoor or outdoor environments. We seek to describe alternatives and evaluation methods for localisation of mobile agents using the strength signal from Access Points (APs). The results show that the proposed method used with autonomous mobile robots does not require the use of special hardware, and hence is low cost, easy to operate, and fully autonomous.},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {661–666},
numpages = {6},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@inproceedings{10.5555/2616606.2616648,
author = {Chang, Doohwang and Ozev, Sule and Sinanoglu, Ozgur and Karri, Ramesh},
title = {Approximating the Age of RF/Analog Circuits through Re-Characterization and Statistical Estimation},
year = {2014},
isbn = {9783981537024},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Counterfeit ICs have become an issue for semiconductor manufacturers due to impacts on their reputation and lost revenue. Counterfeit ICs are either products that are intentionally mislabeled or legitimate products that are extracted from electronic waste. The former is easier to detect whereas the latter is harder since they are identical to new devices but display degraded performance due to environmental and use stress conditions. Detecting counterfeit ICs that are extracted from electronic waste requires an approach that can approximate the age of manufactured devices based on their parameters. In this paper, we present a methodology that uses information on both fresh and aged ICs and tries to distinguish between the fresh and aged population based on an estimate of the age. Since analog devices age mainly due to their bias stress, input signals play less of a role. Hence, it is possible to use simulation models to approximate the aging process, which would give us access to a large population of aged devices. Using this information, we can construct a statistical model that approximates the age of a given circuit. We use a Low noise amplifier (LNA) and an NMOS LC oscillator to demonstrate that individual aged devices can be accurately classified using the proposed method.},
booktitle = {Proceedings of the Conference on Design, Automation &amp; Test in Europe},
articleno = {35},
numpages = {4},
location = {Dresden, Germany},
series = {DATE '14}
}

@inproceedings{10.1145/2554850.2554932,
author = {Noureddine, Adel and Rouvoy, Romain and Seinturier, Lionel},
title = {Unit Testing of Energy Consumption of Software Libraries},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2554932},
doi = {10.1145/2554850.2554932},
abstract = {The development of energy-efficient software has become a key requirement for a large number of devices, from smartphones to data centers. However, measuring accurately this consumption is a major challenge that state-of-the-art approaches have tried to tackle with a limited success. While monitoring applications' consumption offers a clear insight on where the energy is being spent, it does not help in understanding how the energy is consumed. In this paper, we therefore introduce JalenUnit, a software framework that infers the energy consumption model of software libraries from execution traces. This model can then be used to diagnose application code for detecting energy bugs, understanding energy distribution, establishing energy profiles and classifications, and comparing software libraries against their energy consumption.},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {1200–1205},
numpages = {6},
keywords = {power modeling, empirical benchmarking, software metrics, energy, energy measurement, modeling, benchmarks},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@inproceedings{10.5555/2616606.2616718,
author = {Jin, Yier and Sullivan, Dean},
title = {Real-Time Trust Evaluation in Integrated Circuits},
year = {2014},
isbn = {9783981537024},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {The use of side-channel measurements and fingerprinting, in conjunction with statistical analysis, has proven to be the most effective method for accurately detecting hardware Trojans in fabricated integrated circuits. However, these post-fabrication trust evaluation methods overlook the capabilities of advanced design skills that attackers can use in designing sophisticated Trojans. To this end, we have designed a Trojan using power-gating techniques and demonstrate that it can be masked from advanced side-channel fingerprinting detection while dormant. We then propose a real-time trust evaluation framework that continuously monitors the on-board global power consumption to monitor chip trustworthiness. The measurements obtained corroborate our frameworks effectiveness for detecting Trojans. Finally, the results presented are experimentally verified by performing measurements on fabricated Trojan-free and Trojan-infected variants of a reconfigurable linear feedback shift register (LFSR) array.},
booktitle = {Proceedings of the Conference on Design, Automation &amp; Test in Europe},
articleno = {91},
numpages = {6},
location = {Dresden, Germany},
series = {DATE '14}
}

@inproceedings{10.1145/2567574.2567617,
author = {Drachsler, Hendrik and Stoyanov, Slavi and Specht, Marcus},
title = {The Impact of Learning Analytics on the Dutch Education System},
year = {2014},
isbn = {9781450326643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567574.2567617},
doi = {10.1145/2567574.2567617},
abstract = {The article reports the findings of a Group Concept Mapping study that was conducted within the framework of the Learning Analytics Summer Institute (LASI) in the Netherlands. Learning Analytics are expected to be beneficial for students and teacher empowerment, personalization, research on learning design, and feedback for performance. The study depicted some management and economics issues and identified some possible treats. No differences were found between novices and experts on how important and feasible are changes in education triggered by Learning Analytics.},
booktitle = {Proceedings of the Fourth International Conference on Learning Analytics And Knowledge},
pages = {158–162},
numpages = {5},
keywords = {learning analytics, group concept mapping, focus group, community building},
location = {Indianapolis, Indiana, USA},
series = {LAK '14}
}

@inproceedings{10.1145/2567574.2567590,
author = {Ga\v{s}evi\'{c}, Dragan and Mirriahi, Negin and Dawson, Shane},
title = {Analytics of the Effects of Video Use and Instruction to Support Reflective Learning},
year = {2014},
isbn = {9781450326643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567574.2567590},
doi = {10.1145/2567574.2567590},
abstract = {Although video annotation software is no longer considered as a new innovation, its application in promoting student self-regulated learning and reflection skills has only begun to emerge in the research literature. Advances in text and video analytics provide the capability of investigating students' use of the tool and the psychometrics and linguistic processes evident in their written annotations. This paper reports on a study exploring students' use of a video annotation tool when two different instructional approaches were deployed -- graded and non-graded self-reflection annotations within two courses in the performing arts. In addition to counts and temporal locations of self-reflections, the Linguistic Inquiry and Word Counts (LIWC) framework was used for the extraction of variables indicative of the linguistic and psychological processes associated with self-reflection annotations of videos. The results indicate that students in the course with graded self-reflections adopted more linguistic and psychological related processes in comparison to the course with non-graded self-reflections. In general, the effect size of the graded reflections was lower for students who took both courses in parallel. Consistent with prior research, the study identified that students tend to make the majority of their self-reflection annotations early in the video time line. The paper also provides several suggestions for future research to better understand the application of video annotations in facilitating student learning.},
booktitle = {Proceedings of the Fourth International Conference on Learning Analytics And Knowledge},
pages = {123–132},
numpages = {10},
keywords = {text analysis, self-reflections, metacognition, learning analytics},
location = {Indianapolis, Indiana, USA},
series = {LAK '14}
}

@inproceedings{10.1145/2554850.2555082,
author = {Tesfay, Teklemariam Tsegay and Hubaux, Jean-Pierre and Le Boudec, Jean-Yves and Oechslin, Philippe},
title = {Cyber-Secure Communication Architecture for Active Power Distribution Networks},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2555082},
doi = {10.1145/2554850.2555082},
abstract = {Active power distribution networks require sophisticated monitoring and control strategies for efficient energy management and automatic adaptive reconfiguration of the power infrastructure. Such requirements are realised by deploying a large number of various electronic automation and communication field devices, such as Phasor Measurement Units (PMUs) or Intelligent Electronic Devices (IEDs), and a reliable two-way communication infrastructure that facilitates transfer of sensor data and control signals. In this paper, we perform a detailed threat analysis in a typical active distribution network's automation system. We also propose mechanisms by which we can design a secure and reliable communication network for an active distribution network that is resilient to insider and outsider malicious attacks, natural disasters, and other unintended failure. The proposed security solution also guarantees that an attacker is not able to install a rogue field device by exploiting an emergency situation during islanding.},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {545–552},
numpages = {8},
keywords = {islanding, smart grid, PKI, unauthorised access, smart grid security, active distribution network, authentication},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@inproceedings{10.1145/2554850.2555020,
author = {K\v{r}ikava, Filip and Collet, Philippe and France, Robert B.},
title = {ACTRESS: Domain-Specific Modeling of Self-Adaptive Software Architectures},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2555020},
doi = {10.1145/2554850.2555020},
abstract = {A common approach for engineering self-adaptive software systems is to use Feedback Control Loops (FCLs). Advances have led to more explicit and safer design of some control architectures, however, there is a need for more integrated and systematic approaches that support end-to-end integration of FCLs into software systems.In this paper, we propose a tooled approach that enables researchers and engineers to design and integrate adaptation mechanisms into software systems through FCLs. It consists of a domain-specific modeling language that raises the level of abstraction on which FCLs are defined, making them amenable to automated analysis and implementation code synthesis. The language supports composition, distribution and reflection, thereby enabling coordination and composition of multiple distributed FCLs. Its use is facilitated by a modeling environment, Actress, that provides support for modeling, verification and complete code generation. We report on its application to a concrete adaptation case study and also discuss resulting properties.},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {391–398},
numpages = {8},
keywords = {domain-specific modeling, model-driven engineering, self-adaptive software systems, domain-specific languages},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@inproceedings{10.1145/2609876.2609891,
author = {Elm, William C.},
title = {User Evaluation Methodology Framework in Big Data Environments},
year = {2014},
isbn = {9781450329385},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2609876.2609891},
doi = {10.1145/2609876.2609891},
abstract = {From an initial discussion of "analytic tradecraft will be different when enabled with Big Data and Big Data enabled tools", this HCBDR breakout group framed an initial context to ground the discussions to follow. The evaluation methodology must cover the triple of Organizational Context, Analyst(s) and Data/Tools all surrounding the Mission Needs. The instrumentation and measurement methodology must consider the holistic combination of all of these elements. Further, it must both measure what *is* occurring at those elements, as well as what is missing from each (felt to be a much more difficult task). The final recommendations include a blend of technical indicators (e.g. system session log information) as well as a sophisticated mix of ethnographic observations important to fully understanding the cognitive performance of the analyst and technology together. Several key issues (such as analysis quality assessment) remain unanswered.},
booktitle = {Proceedings of the 2014 Workshop on Human Centered Big Data Research},
pages = {59–63},
numpages = {5},
keywords = {Cognitive Systems Engineering, Human Centered, Workshop, Ethnographic, Analysis, Big Data, User Evaluation, Technology Enabled Tradecraft, Joint Cognitive System, Methodology},
location = {Raleigh, NC, USA},
series = {HCBDR '14}
}

@inproceedings{10.1145/2609876.2609880,
author = {Mushi, Magreth and Dutta, Rudra},
title = {Data-Driven Study of Network Administration in the Evolving Landscape of Software Defined Networking},
year = {2014},
isbn = {9781450329385},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2609876.2609880},
doi = {10.1145/2609876.2609880},
abstract = {In this paper, we make an initial attempt to employ Grounded Theory approach to gather the corpus of common human errors in the current process of network administration and management over a large variety of organizations and working environments; categorize such errors regarding their potential impact on the security of future script-based management of SDN and analyze these impacts to produce a scientific basis for the design of future resilient networks with adaptive automated device management. Our main contribution is to start introducing a more data-driven scientific approach to solving the misconfiguration problem by studying the effect of network administrators' actions and decisions in configuration of network devices.},
booktitle = {Proceedings of the 2014 Workshop on Human Centered Big Data Research},
pages = {14–18},
numpages = {5},
keywords = {big data, SDN, human-centered, misconfigurations, Network management},
location = {Raleigh, NC, USA},
series = {HCBDR '14}
}

