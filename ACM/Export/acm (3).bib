@inproceedings{10.5555/2133429.2133465,
author = {Leem, Larkhoon and Cho, Hyungmin and Lee, Hsiao-Heng and Kim, Young Moon and Li, Yanjing and Mitra, Subhasish},
title = {Cross-Layer Error Resilience for Robust Systems},
year = {2010},
isbn = {9781424481927},
publisher = {IEEE Press},
abstract = {A large class of robust electronic systems of the future must be designed to perform correctly despite hardware failures. In contrast, today's mainstream systems typically assume error-free hardware. Classical fault-tolerant computing techniques are too expensive for this purpose. This paper presents an overview of new techniques that can enable a sea change in the design of cost-effective robust systems. These techniques utilize globally-optimized cross-layer approaches, i.e., across device, circuit, architecture, runtime, and application layers, to overcome hardware failures.},
booktitle = {Proceedings of the International Conference on Computer-Aided Design},
pages = {177–180},
numpages = {4},
keywords = {circuit failure prediction, reliability, CASP, robust system design, diagnostics, ERSA, error resilient system architecture, LEAP, on-line self-test, soft error},
location = {San Jose, California},
series = {ICCAD '10}
}

@inproceedings{10.1145/1882362.1882383,
author = {Easterbrook, Steve M.},
title = {Climate Change: A Grand Software Challenge},
year = {2010},
isbn = {9781450304276},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1882362.1882383},
doi = {10.1145/1882362.1882383},
abstract = {Software is a critical enabling technology in nearly all aspects of climate change, from the computational models used by climate scientists to improve our understanding of the impact of human activities on earth systems, through to the information and control systems needed to build an effective carbon-neutral society. Accordingly, we, as software researchers and software practitioners, have a major role to play in responding to the climate crisis. In this paper we map out the space in which our contributions are likely to be needed, and suggest a possible research agenda.},
booktitle = {Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research},
pages = {99–104},
numpages = {6},
keywords = {climate change},
location = {Santa Fe, New Mexico, USA},
series = {FoSER '10}
}

@inproceedings{10.1145/1880071.1880103,
author = {Savery, Cheryl and Graham, T. C. Nicholas and Gutwin, Carl},
title = {The Human Factors of Consistency Maintenance in Multiplayer Computer Games},
year = {2010},
isbn = {9781450303873},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1880071.1880103},
doi = {10.1145/1880071.1880103},
abstract = {Consistency maintenance (CM) techniques are a crucial part of many distributed systems, and are particularly important in networked games. In this paper we describe a framework of the human factors of CM, to help designers of networked games make better decisions about its use. The framework shows that there is wide variance in the CM requirements of different game situations, identifies the types of requirements that can be considered, and analyses the effects of several consistency schemes on user experience factors. To further explore these issues, we carried out a simulation study that compared four CM algorithms. The experiment confirms many of the predictions of the framework, and reveals additional subtleties of the algorithms. Our work is the first to look comprehensively at the tradeoffs and costs of CM, and our results are a strong starting point that will help designers improve on the user's quality of experience in distributed shared environments.},
booktitle = {Proceedings of the 16th ACM International Conference on Supporting Group Work},
pages = {187–196},
numpages = {10},
keywords = {game usablity, consistency maintenance, game development},
location = {Sanibel Island, Florida, USA},
series = {GROUP '10}
}

@inproceedings{10.1145/1891903.1891933,
author = {El Ali, Abdallah and Nack, Frank and Hardman, Lynda},
title = {Understanding Contextual Factors in Location-Aware Multimedia Messaging},
year = {2010},
isbn = {9781450304146},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1891903.1891933},
doi = {10.1145/1891903.1891933},
abstract = {Location-aware messages left by people can make visible some aspects of their everyday experiences at a location. To understand the contextual factors surrounding how users produce and consume location-aware multimedia messaging (LMM), we use an experience-centered framework that makes explicit the different aspects of an experience. Using this framework, we conducted an exploratory, diary study aimed at eliciting implications for the study and design of LMM systems. In an earlier pilot study, we found that subjects did not have enough time to fully capture their everyday experiences using an LMM prototype, which led us to conduct a longer study using a multimodal diary method. The diary study data (verified for reliability using a categorization task) provided a closer look at the different aspects (spatiotemporal, social, affective, and cognitive) of people's experience. From the data, we derive three main findings (predominant LMM domains and tasks, capturing experience vs. experience of capture, context-dependent personalization) to inform the study and design of future LMM systems.},
booktitle = {International Conference on Multimodal Interfaces and the Workshop on Machine Learning for Multimodal Interaction},
articleno = {22},
numpages = {8},
keywords = {location-aware multimedia messaging (LMM), context-aware systems, experience-centered framework, contextual factors},
location = {Beijing, China},
series = {ICMI-MLMI '10}
}

@inproceedings{10.1145/1967486.1967531,
author = {Al Hakeem, Nawar and Salem, Mohamed},
title = {Novel Algorithm for Enhancing Database Access in Interactive Applications: Performance Evaluation},
year = {2010},
isbn = {9781450304214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1967486.1967531},
doi = {10.1145/1967486.1967531},
abstract = {Online applications rely heavily on database management systems (DBMS), as an essential component of knowledge discovery. DBMS searching and querying has been extensively studied resulting in significant reduction of response time for access and consequently improving the online dialogue process between servers and clients. In this paper, a decision-making algorithm (SEQUESTER) has been developed in order to further improve the performance of interaction-based online applications. The proposed approach uses information theoretic measures in order to build efficient decision trees which form the basis to optimize interactions in a range of real life online applications. The decision-making model employs a question-and-answer (Q&amp;A) approach to guide users in an interactive process to explore for information such as products in a database. The salient feature of this approach is the significant reduction of the number of interactions (accesses) of a customer to a remote application.},
booktitle = {Proceedings of the 12th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {273–282},
numpages = {10},
keywords = {database mining, information-theoretic measures, electronic commerce (e-commerce), decision trees},
location = {Paris, France},
series = {iiWAS '10}
}

@inproceedings{10.1145/1967486.1967496,
author = {Mohebbi, Keyvan and Ibrahim, Suhaimi and Khezrian, Mojtaba and Munusamy, Kanmani and Tabatabaei, Sayed Gholam Hassan},
title = {A Comparative Evaluation of Semantic Web Service Discovery Approaches},
year = {2010},
isbn = {9781450304214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1967486.1967496},
doi = {10.1145/1967486.1967496},
abstract = {Currently, most enterprises deploy their services on the Web. This augments the request for tools to perform discovery, selection, composition and invocation of Web services. Among them, Web service discovery should be considered more important. Along with the growing number of available Web services, there is a need for tools not only to perform discovery, but also to realize them in an efficient and effective manner. A number of approaches to Web service discovery have been proposed. In this paper, we provide a taxonomy which categorizes Web service discovery systems from different points of view. Moreover, current approaches to Semantic Web service discovery are classified and described. In addition, we compare the approaches with respect to some criteria from different aspects of view. The results of this study can help researchers in both academia and industry to implement a new or to select the most appropriate existing approach for Semantic Web service discovery with the aid of different criteria.},
booktitle = {Proceedings of the 12th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {33–39},
numpages = {7},
keywords = {web service discovery, web services, semantic web services, semantic web},
location = {Paris, France},
series = {iiWAS '10}
}

@inproceedings{10.1145/1967486.1967615,
author = {Al Hosni, Noura and Ali, Saqib and Ashrafi, Rafi},
title = {The Key Success Factors to Mobile Commerce for Arab Countries in Middle East},
year = {2010},
isbn = {9781450304214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1967486.1967615},
doi = {10.1145/1967486.1967615},
abstract = {A number of studies have been conducted on the diffusion of mobile commerce, its challenges, opportunities, issues and obstacles. However, few have emphasized on its adoption within Middle East countries. This paper reviews the current literature in order to assess the mobile commerce adoption in Arab countries within Middle East and identify the key success factors in mobile commerce adoption in them.},
booktitle = {Proceedings of the 12th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {787–790},
numpages = {4},
keywords = {ICT, mobile penetration, mobile commerce, middle east, key success factors},
location = {Paris, France},
series = {iiWAS '10}
}

@article{10.1145/1882471.1882480,
author = {Gupta, Manish and Li, Rui and Yin, Zhijun and Han, Jiawei},
title = {Survey on Social Tagging Techniques},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {1931-0145},
url = {https://doi.org/10.1145/1882471.1882480},
doi = {10.1145/1882471.1882480},
abstract = {Social tagging on online portals has become a trend now. It has emerged as one of the best ways of associating metadata with web objects. With the increase in the kinds of web objects becoming available, collaborative tagging of such objects is also developing along new dimensions. This popularity has led to a vast literature on social tagging. In this survey paper, we would like to summarize different techniques employed to study various aspects of tagging. Broadly, we would discuss about properties of tag streams, tagging models, tag semantics, generating recommendations using tags, visualizations of tags, applications of tags and problems associated with tagging usage. We would discuss topics like why people tag, what influences the choice of tags, how to model the tagging process, kinds of tags, different power laws observed in tagging domain, how tags are created, how to choose the right tags for recommendation, etc. We conclude with thoughts on future work in the area.},
journal = {SIGKDD Explor. Newsl.},
month = nov,
pages = {58–72},
numpages = {15},
keywords = {folk taxonomy, collaborative tagging, bookmarking, social classification, ethnoclassification, social tagging, distributed classification, social indexing, tagging, folksonomy, folk classification}
}

@inproceedings{10.1145/1882992.1883010,
author = {Suh, Myung-kyung and Evangelista, Lorraine S. and Chen, Chien-An and Han, Kyungsik and Kang, Jinha and Tu, Michael Kai and Chen, Victor and Nahapetian, Ani and Sarrafzadeh, Majid},
title = {An Automated Vital Sign Monitoring System for Congestive Heart Failure Patients},
year = {2010},
isbn = {9781450300308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1882992.1883010},
doi = {10.1145/1882992.1883010},
abstract = {Congestive heart failure (CHF) is a cardiovascular disorder that affects approximately 4.6 million Americans and is a leading cause of death in the United States. Current research shows that strategies to promote early recognition and treatment of symptoms and enhance self-care management behaviors reduce unnecessary hospitalizations. However, mechanisms to monitor patients' health status and behaviors are limited by constraints imposed by the patient's geography, infirmity, or resources. Remote monitoring supports a more dynamic connection between healthcare providers and patients, improves health promotion and patient care through monitoring of health data, communicates health reminders, and makes provisions for patient feedback. This paper will describe two versions of Weight and Activity with Blood Pressure Monitoring System (WANDA [22]) that leverages sensor technology and wireless communication to monitor health status of patients with CHF. The WANDA system is built on a three-tier architecture consisting of sensors, a web server, and back-end database tiers. The system was developed in conjunction with the UCLA School of Nursing and the UCLA Wireless Health Institute to enable early detection of key clinical symptoms indicative of CHF-related decompensation in a real-time automated fashion and allows health professionals to offer surveillance, advice, and continuity of care and triggers early implementation of strategies to enhance adherence behaviors. The small study has enabled patients to reduce or maintain the number of readings which are out of the acceptable range. For diastolic, systolic, and heart rate values, the t-test results show that the WANDA study is effective for patients with CHF.},
booktitle = {Proceedings of the 1st ACM International Health Informatics Symposium},
pages = {108–117},
numpages = {10},
keywords = {telemedicine, congestive heart failure patients monitoring, health monitoring, wireless health, data integrity, real-time feedback, database backup},
location = {Arlington, Virginia, USA},
series = {IHI '10}
}

@inproceedings{10.1145/1882992.1883124,
author = {Khan, Danish U. and Siek, Katie A. and Meyers, Jane and Haverhals, Leah M. and Cali, Steven and Ross, Stephen E.},
title = {Designing a Personal Health Application for Older Adults to Manage Medications},
year = {2010},
isbn = {9781450300308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1882992.1883124},
doi = {10.1145/1882992.1883124},
abstract = {Older adults with multiple chronic conditions are prone to care transitions, such as seeing a new doctor or being discharged after a prolonged hospital stay. These transitions are often uncoordinated and can imperil patients by omitted, duplicative, or contradictory treatment plans. We developed an open source, web-based Personal Health Application (PHA) using an iterative participatory design process that provides older adults and their caregivers the ability to manage their personal health information during care transitions. We report our findings from six user studies that establish the imperative need for interdisciplinary research and collaboration among all stakeholders - patients, caregivers, health professionals, designers, and health informaticians - to create effective PHAs. We conclude with design guidelines that encourage researchers to gradually increase functionality as users become more proficient interacting with the PHA.},
booktitle = {Proceedings of the 1st ACM International Health Informatics Symposium},
pages = {849–858},
numpages = {10},
keywords = {personal health applications, healthcare, personal health records, elderly, medication management, participatory design},
location = {Arlington, Virginia, USA},
series = {IHI '10}
}

@inproceedings{10.1145/1952222.1952308,
author = {Satchell, Christine and Foth, Marcus},
title = {Fear and Danger in Nocturnal Urban Environments},
year = {2010},
isbn = {9781450305020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1952222.1952308},
doi = {10.1145/1952222.1952308},
abstract = {At the centre of this research is an ethnographic study that saw the researcher embedded within the fabric of inner city life to better understand what characteristics of user activity and interaction could be enhanced by technology. The initial research indicated that the experience of traversing the city after dark unified an otherwise divergent user group through a shared concern for personal safety. Managing this fear and danger represented an important user need. We found that mobile social networking systems are not only integral for bringing people together, they can help in the process of users safely dispersing as well. We conclude, however, that at a time when the average iPhone staggers under the weight of a plethora of apps that do everything from acting as a carpenter's level to a pregnancy predictor, we consider the potential for the functionality of a personal safety device to be embodied within a stand alone artifact.},
booktitle = {Proceedings of the 22nd Conference of the Computer-Human Interaction Special Interest Group of Australia on Computer-Human Interaction},
pages = {380–383},
numpages = {4},
keywords = {night, convergence, the city, surveillance, safety, privacy},
location = {Brisbane, Australia},
series = {OZCHI '10}
}

@inproceedings{10.1145/1952222.1952274,
author = {McKay, Dana and Sanchez, Silvia and Parker, Rebecca},
title = {What's My Name Again? Sociotechnical Considerations for Author Name Management in Research Databases},
year = {2010},
isbn = {9781450305020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1952222.1952274},
doi = {10.1145/1952222.1952274},
abstract = {Managing names in bibliographic databases so that they have a one-to-one match with individual authors is a longstanding and complex problem. Various solutions have been proposed, from labour-intensive but accurate manual matching, to machine-learning approaches to automated matching which require little input from people, but are not perfectly accurate. Researchers have a particular interest in name management: they are often authors, and receive academic credit based on their work and need correct citation records. However they are also searchers and have an interest in finding all the works by other authors. There has been little work on the tensions between these two needs, nor on how researchers manage their own identities with their choices of name. This paper reports on a study of researchers that investigates both their relationships with their own names, and what they would like from research databases when they are searching for specific authors.},
booktitle = {Proceedings of the 22nd Conference of the Computer-Human Interaction Special Interest Group of Australia on Computer-Human Interaction},
pages = {240–247},
numpages = {8},
keywords = {author names, information seeking, search interfaces, research databases, sociotechnical aspects of HCI, researchers},
location = {Brisbane, Australia},
series = {OZCHI '10}
}

@inproceedings{10.1145/1952222.1952278,
author = {Leong, Tuck Wah and Wright, Peter and Vetere, Frank and Howard, Steve},
title = {Understanding Experience Using Dialogical Methods: The Case of Serendipity},
year = {2010},
isbn = {9781450305020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1952222.1952278},
doi = {10.1145/1952222.1952278},
abstract = {McCarthy and Wright's (2004) approach to understanding user experience provides a rich conceptual framework. In this paper, we report how this framework was used to guide the development of an approach to researching the richness of a particular experience - serendipity. Three themes were identified; life as lived and felt, the whole person, and dialogical sense making. These were used to help understand the key qualities of the strategy, tools and techniques that were required in the empirical study of the experience of serendipity. The paper explains this process and illustrates the depth of understanding that our choice of tools afforded. After describing the case study we offer some guidance on how to choose appropriate tools and methods for researching other types of experience.},
booktitle = {Proceedings of the 22nd Conference of the Computer-Human Interaction Special Interest Group of Australia on Computer-Human Interaction},
pages = {256–263},
numpages = {8},
keywords = {serendipity, experience-centred design, digital music, user experience},
location = {Brisbane, Australia},
series = {OZCHI '10}
}

@article{10.1145/1899639.1899644,
author = {Beise, Catherine and Carte, Traci A. and Vician, Chelley and Chidambaram, Laku},
title = {A Case Study of Project Management Practices in Virtual Settings: Lessons from Working in and Managing Virtual Teams},
year = {2010},
issue_date = {November 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {4},
issn = {0095-0033},
url = {https://doi.org/10.1145/1899639.1899644},
doi = {10.1145/1899639.1899644},
abstract = {In this paper we report a case study examining the communication processes engaged in by virtual project teams and their management. Twenty-two teams, using widely available groupware to communicate, work together, share documents, discuss ideas, and solve problems, designed and implemented a database. These teams were managed by a geographically-distributed management team. The case study is analyzed qualitatively and quantitatively, from two perspectives--working in, and managing, virtual teams--using a framework that integrates virtual team dynamics and project management practices. Through the critical examination of communication content from the longitudinal experiences of multiple virtual project teams and their virtual management team, we identify successful project practices and uncover underlying interaction processes. Specifically, we found that high performing project teams differed from low performing teams in terms of process management, relational development, and proactive technology use behaviors. The five-person management team paralleled the project teams in evolving its own process management and relational development over time.},
journal = {SIGMIS Database},
month = nov,
pages = {75–97},
numpages = {23},
keywords = {groupware, database development, virtual teams, project management, computer mediated communications}
}

@article{10.1145/1874391.1874402,
author = {Mishra, Amit and Misra, Sanjay},
title = {People Management in Software Industry: The Key to Success},
year = {2010},
issue_date = {November 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {6},
issn = {0163-5948},
url = {https://doi.org/10.1145/1874391.1874402},
doi = {10.1145/1874391.1874402},
abstract = {Performance differences have been proved among software professionals even in the conditions of identical task. Companies and organizations are aware of the fact that talent has great effect on their success; still most of the software development organizations are focusing so much on tools and technology and little on people. In this paper, we are trying to uncover the relation between the people management-human resource management and software engineering.},
journal = {SIGSOFT Softw. Eng. Notes},
month = nov,
pages = {1–4},
numpages = {4},
keywords = {software development, people management, software industry}
}

@inproceedings{10.1145/1925013.1925015,
author = {Jaiantilal, Abhishek and Jiang, Yifei and Mishra, Shivakant},
title = {Modeling CPU Energy Consumption for Energy Efficient Scheduling},
year = {2010},
isbn = {9781450304504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1925013.1925015},
doi = {10.1145/1925013.1925015},
abstract = {In the past few years, we have seen the rising popularity of multi-core systems, including the 4, 6, and 8-cores present in i7 processors from Intel, and the 8 and 12 cores present in Magny-Cours processors from AMD. There is a general trend that newer processors have more and more number of cores. A study [6] showed that, in data centers, the CPU load is around 10-50%; thus, when multi-core processors are used in data centers, many of the cores will be unused for a majority of the time. Such a scenario is also true for a casual desktop PC user. As an idle core still consumes energy, from the perspective of saving energy, it is important to ensure that the idle cores are put in the lowest energy state and unnecessary wakeups for these idle cores are avoided. This will ensure the lowest energy consumption for a given set of tasks.The precursor step towards developing an energy efficient CPU scheduler requires an understanding of the relation between the type of tasks and their corresponding power profile. In this paper, we show that the power profile of a task is dependent on the type of processor cycles executed by the task. We further develop a model that can predict the power consumption based on the processor cycles executed by the task. We conclude our paper showing initial results on how such a model can be used to schedule tasks and save energy.},
booktitle = {Proceedings of the 1st Workshop on Green Computing},
pages = {10–15},
numpages = {6},
location = {Bangalore, India},
series = {GCM '10}
}

@inproceedings{10.5555/2023718.2023732,
author = {Bertier, Marin and Frey, Davide and Guerraoui, Rachid and Kermarrec, Anne-Marie and Leroy, Vincent},
title = {The GOSSPLE Anonymous Social Network},
year = {2010},
isbn = {9783642169540},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {While social networks provide news from old buddies, you can learn a lot more from people you do not know, but with whom you share many interests. We show in this paper how to build a network of anonymous social acquaintances using a gossip protocol we call Gossple, and how to leverage such a network to enhance navigation within Web 2.0 collaborative applications, \`{a} la LastFM and Delicious. Gossple nodes (users) periodically gossip digests of their interest profiles and compute their distances (in terms of interest) with respect to other nodes. This is achieved with little bandwidth and storage, fast convergence, and without revealing which profile is associated with which user. We evaluate Gossple on real traces from various Web 2.0 applications with hundreds of PlanetLab hosts and thousands of simulated nodes.},
booktitle = {Proceedings of the ACM/IFIP/USENIX 11th International Conference on Middleware},
pages = {191–211},
numpages = {21},
location = {Bangalore, India},
series = {Middleware '10}
}

@inproceedings{10.1145/1900441.1900443,
author = {Winschiers-Theophilus, Heike and Chivuno-Kuria, Shilumbe and Kapuire, Gereon Koch and Bidwell, Nicola J. and Blake, Edwin},
title = {Being Participated: A Community Approach},
year = {2010},
isbn = {9781450301312},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1900441.1900443},
doi = {10.1145/1900441.1900443},
abstract = {In this paper, we explore the concept of participatory design from a different viewpoint by drawing on an African philosophy of humanness -Ubuntu-, and African rural community practices. The situational dynamics of participatory interaction become obvious throughout the design experiences within our community project. Supported by a theoretical framework we reflect upon current participatory design practices. We intend to inspire and refine participatory design concepts and methods beyond the particular context of our own experiences.},
booktitle = {Proceedings of the 11th Biennial Participatory Design Conference},
pages = {1–10},
numpages = {10},
keywords = {rural interaction design, community participation, African context},
location = {Sydney, Australia},
series = {PDC '10}
}

@article{10.1145/1898147.1898149,
author = {Haber, Eben M. and Kandogan, Eser and Maglio, Paul},
title = {Collaboration in System Administration: For Sysadmins, Solving Problems Usually Involves Collaborating with Others. How Can We Make It More Effective?},
year = {2010},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {12},
issn = {1542-7730},
url = {https://doi.org/10.1145/1898147.1898149},
doi = {10.1145/1898147.1898149},
abstract = {George was in trouble. A seemingly simple deployment was taking all morning, and there seemed no end in sight. His manager kept coming in to check on his progress, as the customer was anxious to have the deployment done. He was supposed to be leaving for a goodbye lunch for a departing co-worker, adding to the stress. He had called in all kinds of help, including colleagues, an application architect, technical support, and even one of the system developers. He used e-mail, instant messaging, face-to-face contacts, his phone, and even his office mate’s phone to communicate with everyone. And George was no novice. He had been working as a Web-hosting administrator for three years, and he had a bachelor’s degree in computer science. But it seemed that all the expertise being brought to bear was simply not enough. Why was George in trouble? We’ll find out.},
journal = {Queue},
month = dec,
pages = {10–20},
numpages = {11}
}

@inproceedings{10.1145/1899475.1899481,
author = {Liu, Yefeng and Lehdonvirta, Vili and Kleppe, Mieke and Alexandrova, Todorka and Kimura, Hiroaki and Nakajima, Tatsuo},
title = {A Crowdsourcing Based Mobile Image Translation and Knowledge Sharing Service},
year = {2010},
isbn = {9781450304245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1899475.1899481},
doi = {10.1145/1899475.1899481},
abstract = {Travelers in countries that use an unfamiliar script cannot use pocket translators or online translation services to understand menus, maps, signs and other important information, because they are unable to write the text they see. Solutions based on optical character recognition provide very limited performance in real-world situations and for complex scripts such as Chinese and Japanese. In this paper, we propose an alternative image translation solution based on crowdsourcing. A large number of human workers on mobile terminals are used to carry out the tasks of image recognition, translation and quality assurance. Compared to purely technical solutions, this human computation approach is also able to account for context and non-textual cues, and provide higher level information to the end-user. In this paper, we describe a preliminary user study to create a model of end-user requirements.},
booktitle = {Proceedings of the 9th International Conference on Mobile and Ubiquitous Multimedia},
articleno = {6},
numpages = {9},
keywords = {mobile image translation, human computation, crowdsourcing, knowledge sharing, image-text recognition},
location = {Limassol, Cyprus},
series = {MUM '10}
}

@inproceedings{10.1145/1944999.1945005,
author = {Berezovskiy, Alexander and Carr, Leslie},
title = {A Framework for Dynamic Data Source Identification and Orchestration on the Web},
year = {2010},
isbn = {9781450304184},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944999.1945005},
doi = {10.1145/1944999.1945005},
abstract = {The current Web offers a very large number of solutions and services, ranging from social networking and content delivery services to business applications and management systems. However, in a general case the solutions provided are largely disintegrated, with each product operating in its own environment. Additionally, many of the products are unknown to the end user and finding the most suitable application is commonly a nontrivial task. The current project is an effort to provide an ubiquitous interface for Web application integration. The suggested approach allows for dynamic identification of the applications most suitable for a given task and access to their data using a unified interface in the REST architectural style. A novel algorithm for identification of the most appropriate data source is introduced within the study. Evaluation of the overall system and the obtained results is provided.},
booktitle = {Proceedings of the 3rd and 4th International Workshop on Web APIs and Services Mashups},
articleno = {6},
numpages = {8},
keywords = {data source identification, web integration, unified data access, information retrieval},
location = {Ayia Napa, Cyprus},
series = {Mashups '09/'10}
}

@article{10.1145/1880018.1880019,
author = {Blagodurov, Sergey and Zhuravlev, Sergey and Fedorova, Alexandra},
title = {Contention-Aware Scheduling on Multicore Systems},
year = {2010},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {4},
issn = {0734-2071},
url = {https://doi.org/10.1145/1880018.1880019},
doi = {10.1145/1880018.1880019},
abstract = {Contention for shared resources on multicore processors remains an unsolved problem in existing systems despite significant research efforts dedicated to this problem in the past. Previous solutions focused primarily on hardware techniques and software page coloring to mitigate this problem. Our goal is to investigate how and to what extent contention for shared resource can be mitigated via thread scheduling. Scheduling is an attractive tool, because it does not require extra hardware and is relatively easy to integrate into the system. Our study is the first to provide a comprehensive analysis of contention-mitigating techniques that use only scheduling. The most difficult part of the problem is to find a classification scheme for threads, which would determine how they affect each other when competing for shared resources. We provide a comprehensive analysis of such classification schemes using a newly proposed methodology that enables to evaluate these schemes separately from the scheduling algorithm itself and to compare them to the optimal. As a result of this analysis we discovered a classification scheme that addresses not only contention for cache space, but contention for other shared resources, such as the memory controller, memory bus and prefetching hardware. To show the applicability of our analysis we design a new scheduling algorithm, which we prototype at user level, and demonstrate that it performs within 2% of the optimal. We also conclude that the highest impact of contention-aware scheduling techniques is not in improving performance of a workload as a whole but in improving quality of service or performance isolation for individual applications and in optimizing system energy consumption.},
journal = {ACM Trans. Comput. Syst.},
month = dec,
articleno = {8},
numpages = {45},
keywords = {shared resource contention, scheduling, Multicore processors}
}

@inproceedings{10.1145/1899475.1899479,
author = {Vartiainen, Elina and V\"{a}\"{a}n\"{a}nen-Vainio-Mattila, Kaisa},
title = {User Experience of Mobile Photo Sharing in the Cloud},
year = {2010},
isbn = {9781450304245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1899475.1899479},
doi = {10.1145/1899475.1899479},
abstract = {Cloud computing is a new paradigm for how applications and services are designed, implemented and accessed through Internet. In the cloud, the user can access services and his personal data real-time from any device. There are already services available in the market using cloud computing, such as email, enterprise planning software, and social media services. Still, research on cloud is in its early phase, especially when considering the user experience of mobile cloud services. In this paper, we introduce Image Exchange, a photo sharing Internet service that was designed from the cloud computing perspective. We evaluated Image Exchange through two user studies and the results presented in this paper describe important implications for cloud computing on mobile devices. Furthermore, we found special types of social interactions that emerged within the users of Image Exchange due to its cloud computing nature. The results show that the current design of Image Exchange provides a rather positive user experience, but it could be developed further to fully utilize the benefits of cloud computing.},
booktitle = {Proceedings of the 9th International Conference on Mobile and Ubiquitous Multimedia},
articleno = {4},
numpages = {10},
keywords = {photo sharing, user experience, internet services, cloud computing},
location = {Limassol, Cyprus},
series = {MUM '10}
}

@inproceedings{10.1145/1899475.1899499,
author = {Walsh, Tanja and Nurkka, Piia and Walsh, Rod},
title = {Cultural Differences in Smartphone User Experience Evaluation},
year = {2010},
isbn = {9781450304245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1899475.1899499},
doi = {10.1145/1899475.1899499},
abstract = {Through globalization it has become increasingly important to understand how culture affects the user experience (UX) of mobile devices and services. Despite the importance of cultural factors in product design, not much research has been done to study them. Our aim was to discover cultural differences in the UX of a Smartphone with remote online sentence completion method. This paper presents the results of a remote online UX evaluation survey of a Smartphone with altogether 72 respondents from India, China, USA, UK and Denmark. The results indicate that there are cultural differences in how people experience the product and also in the way people respond to UX evaluation survey and share their experiences with the product. The results show that a remote online sentence completion survey is a relatively fast and easy way of gathering international user data, although the analysis can be challenging. The use of Hofstede's cultural dimensions in the analysis of the data gave us better understanding of the impact of specific culture on the results.},
booktitle = {Proceedings of the 9th International Conference on Mobile and Ubiquitous Multimedia},
articleno = {24},
numpages = {9},
keywords = {sentence completion technique, user experience, remote user study, mobile device, cross-cultural design},
location = {Limassol, Cyprus},
series = {MUM '10}
}

@article{10.1145/1824795.1824798,
author = {Mabroukeh, Nizar R. and Ezeife, C. I.},
title = {A Taxonomy of Sequential Pattern Mining Algorithms},
year = {2010},
issue_date = {November 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/1824795.1824798},
doi = {10.1145/1824795.1824798},
abstract = {Owing to important applications such as mining web page traversal sequences, many algorithms have been introduced in the area of sequential pattern mining over the last decade, most of which have also been modified to support concise representations like closed, maximal, incremental or hierarchical sequences. This article presents a taxonomy of sequential pattern-mining techniques in the literature with web usage mining as an application. This article investigates these algorithms by introducing a taxonomy for classifying sequential pattern-mining algorithms based on important key features supported by the techniques. This classification aims at enhancing understanding of sequential pattern-mining problems, current status of provided solutions, and direction of research in this area. This article also attempts to provide a comparative performance analysis of many of the key techniques and discusses theoretical aspects of the categories in the taxonomy.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {3},
numpages = {41},
keywords = {sequence mining, sequential patterns, Data mining, tree projection, frequent patterns, Web usage mining, apriori property, web log, lattice theory, early pruning, prediction, pattern growth, association rules, lexicographic order, recommender systems}
}

@article{10.1145/1824795.1824800,
author = {Kurian, Jinu and Sarac, Kamil},
title = {A Survey on the Design, Applications, and Enhancements of Application-Layer Overlay Networks},
year = {2010},
issue_date = {November 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/1824795.1824800},
doi = {10.1145/1824795.1824800},
abstract = {This article presents a survey of recent advancements in application-layer overlay networks. Some of the most important applications that have been proposed for overlays include multicast, QoS support, denial-of-service (DoS) defense, and resilient routing. We look at some of the important approaches proposed for these applications and compare the advantages and disadvantages of these approaches. We also examine some of the enhancements that have been proposed in overlay topology design, enhanced routing performance, failure resistance, and the issues related to coexistence of overlay and native layers in the Internet. We conclude the article with a comment on the purist vs pluralist argument of overlay networks that has received much debate recently. Finally, we propose a new deployment model for service overlays that seeks to interpose between these two approaches.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {5},
numpages = {34},
keywords = {performance, Overlay networks, deployment model, enhancements, service overlay networks}
}

@inproceedings{10.5555/2433508.2433861,
author = {Bouillet, Eric and Dube, Parijat},
title = {Streaming Workload Generator for Testing Billing Mediation Platform in Telecom Industry},
year = {2010},
isbn = {9781424498642},
publisher = {Winter Simulation Conference},
abstract = {Billing Mediation Platform (BMP) in Telco is used to process real-time streams of Call Detail Records (CDRs) which can number tens of billions a day. The comprehensive records generated by BMPs can be used for billing and accounting, fraud detection, campaign management, spam filtering, traffic analysis, and churn prediction. Many of these applications are characterized by real-time processing requiring high throughput, low-latency analysis of CDRs. Testing such BMPs has different dimensions, stress testing of analytics for scalability, correctness of analytics, what-if scenarios, all of which require CDRs with realistic volumetric and contextual properties. We propose WLG, a framework for testing and benchmarking BMPs which involves generating high volumes of CDRs representative of real-world data. The framework is flexible in its ability to express and tune the workload generation to simulate CDRs from broad range of traffic patterns while preserving different spatio-temporal correlations and content-level information observed in real-world CDRs.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2842–2852},
numpages = {11},
location = {Baltimore, Maryland},
series = {WSC '10}
}

@inproceedings{10.5555/2433508.2433540,
author = {van der Zee, Durk-Jouke and Pidd, Mike and Tolk, Andreas and Kotiadis, Kathy and Tako, Antuela A. and Balci, Osman and Elder, Mark},
title = {Panel Discussion: Education on Conceptual Modeling for Simulation - Challenging the Art},
year = {2010},
isbn = {9781424498642},
publisher = {Winter Simulation Conference},
abstract = {This panel seeks to initiate a discussion within the modeling and simulation community about the way we teach conceptual modeling for simulation with the view of bringing about improvements. The challenge addressed is how to educate and equip the novice analyst to become a professional rather than letting him become an artist -- being very much the current practice. The need for professionalism is related to good quality research and education in a straightforward way. Emerging insights from literature on the relevance of conceptual modeling for project success, increasing system complexity, and stakeholders taking up an active role in conceptual modeling, further stress this need. This paper highlights key observations motivating the panel, and presents "position papers" on panelists' views on the way forward for education in conceptual modeling. The paper concludes with some themes from the viewpoints in the format of a SWOT (Strengths, Weaknesses, Opportunities and Threats) analysis.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {290–304},
numpages = {15},
location = {Baltimore, Maryland},
series = {WSC '10}
}

@inproceedings{10.5555/2433508.2433870,
author = {Juan, Angel A. and Marqu\`{e}s, Joan M. and Ionescu, Dragos and Faulin, Javier},
title = {Reliability and Availability Issues in Large-Scale Distributed Systems},
year = {2010},
isbn = {9781424498642},
publisher = {Winter Simulation Conference},
abstract = {Large-scale distributed systems, such as Overnet, BOINC (SETI@home) or PlanetLab, provide attractive options through aggregation and sharing of heterogeneous and geographically dispersed computer resources. However, in order to be efficient, these systems need to consider some issues related to the Reliability and Availability (R&amp;A) levels of their nodes and the services they offer. These systems are usually characterized by extremely dynamic and heterogeneous environments, where nodes offering different computer capabilities and features can enter and leave freely. But dynamism and heterogeneity introduce uncertainty and make it difficult to develop accurate models to predict the temporal evolution of the R&amp;A levels in distributed environments. This paper reviews some R&amp;A issues in large-scale distributed systems and studies how they relate to the quality of service offered to the users. The paper also discusses the role of simulation as the most natural way to deal with these issues and introduces a simulation-based methodology that allows to design reliable and cost-efficient distributed services.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2915–2926},
numpages = {12},
location = {Baltimore, Maryland},
series = {WSC '10}
}

@inproceedings{10.1145/1920320.1920323,
author = {Anderson, Nick and Edwards, Kelly},
title = {Building a Chain of Trust: Using Policy and Practice to Enhance Trustworthy Clinical Data Discovery and Sharing},
year = {2010},
isbn = {9781450304467},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1920320.1920323},
doi = {10.1145/1920320.1920323},
abstract = {Advances and significant national infrastructure investment into clinical information systems are spurring a demand for secondary use and sharing of clinical and genetic data for translational research. In this paper, we describe the need for technically leveraged policy models and governance strategies to support data sharing between a range of disparate stakeholders where trust is not easily established or maintained.},
booktitle = {Proceedings of the 2010 Workshop on Governance of Technology, Information and Policies},
pages = {15–20},
numpages = {6},
keywords = {compliance with government regulations, data sharing, clinical data, translational health research, trust, policy governance},
location = {Austin, Texas, USA},
series = {GTIP '10}
}

@article{10.1145/1899928.1899946,
author = {Simons, Joshua E. and Buell, Jeffrey},
title = {Virtualizing High Performance Computing},
year = {2010},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {4},
issn = {0163-5980},
url = {https://doi.org/10.1145/1899928.1899946},
doi = {10.1145/1899928.1899946},
abstract = {While virtualization is widely used in commercial enterprise environments, it has not to date played any significant role in High Performance Computing (HPC). However, with the rise of cloud computing and its promise of computing on demand, the HPC community's interest in virtualization (a key cloud enabler) is increasing. Beyond cloud computing, virtualization offers additional potential benefits for HPC, among them reactive and proactive application fault tolerance, secure and fault-isolated use of shared-resource clusters, dynamic provisioning, job migration, and support for heterogeneous HPC facilities. This paper describes both the promises and challenges in this new, emerging area, including a discussion of performance-related issues},
journal = {SIGOPS Oper. Syst. Rev.},
month = dec,
pages = {136–145},
numpages = {10},
keywords = {virtualization, resilience, cloud computing, HPC}
}

@inproceedings{10.1145/2369220.2369254,
author = {Rao, Kasina V. and Ramamritham, Krithi and Sonar, R. M.},
title = {Examining the Viability of Mixed Framework for Evaluating Mobile Services Impact in Rural India},
year = {2010},
isbn = {9781450307871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2369220.2369254},
doi = {10.1145/2369220.2369254},
abstract = {This paper examines the proposed framework for evaluating the impact of the intervention of mobile-based services on socio-economic development of Indian rural areas. Framework suitability has been studied using case study method with pilot test data. Existing literature shows multiple ways of studying mobile impact through different frameworks. The need for uniform framework is the felt need as various user-centric mobile services launched across rural markets. India becomes a field-testing ground for most of the multinational firms who want to test their innovative business models. This framework provides a testing method for socioeconomic development impact on rural areas. This study adopted socio economic criteria (SEC) used by Indian marketers as basis for sample selection. The pilot study clearly shown that field is ready to test the proposed framework.},
booktitle = {Proceedings of the 4th ACM/IEEE International Conference on Information and Communication Technologies and Development},
articleno = {36},
numpages = {10},
keywords = {user needs, mobile services, socio-economic criteria, socio-economic impact},
location = {London, United Kingdom},
series = {ICTD '10}
}

@inproceedings{10.1145/1900520.1900525,
author = {Marcus, Aaron},
title = {Cross-Cultural User-Interface Design for Work, Home, Play, and on the Way},
year = {2010},
isbn = {9781450305273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1900520.1900525},
doi = {10.1145/1900520.1900525},
booktitle = {ACM SIGGRAPH ASIA 2010 Courses},
articleno = {5},
numpages = {160},
location = {Seoul, Republic of Korea},
series = {SA '10}
}

@inproceedings{10.1145/1900354.1900417,
author = {Koutepova, Tatyana and Liu, Yantong and Lan, Xiao and Jeong, Jihyun},
title = {Enhancing Video Games in Real Time with Biofeedback Data},
year = {2010},
isbn = {9781450305242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1900354.1900417},
doi = {10.1145/1900354.1900417},
abstract = {All video games have the ability to affect a player and the result can be seen in changes of his or her heart rate, perspiration, focus or concentration. This change is a large part of what draws a person to play a game in the first place but overtime players body starts to adjust to the stimuli in the game thus decreasing the interest. What if the game could continuously adjust to players biofeedback and keep the engagement and excitement levels high longer?},
booktitle = {ACM SIGGRAPH ASIA 2010 Posters},
articleno = {56},
numpages = {1},
location = {Seoul, Republic of Korea},
series = {SA '10}
}

@inproceedings{10.1145/1926180.1926203,
author = {Quinn, John A. and Okori, Washington and Gidudu, Anthony},
title = {Increased-Specificity Famine Prediction Using Satellite Observation Data},
year = {2010},
isbn = {9781450304733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1926180.1926203},
doi = {10.1145/1926180.1926203},
abstract = {This paper examines the use of remote sensing satellite data to predict food shortages among different categories of households in famine-prone areas. Normalized Difference Vegetation Index (NDVI) and rainfall estimate data, which can be derived from multi-spectral satellite radiometer images, has long been used to predict crop yields and hence famine. This gives an overall prediction of food insecurity in an area, though in a heterogeneous population it does not directly predict which sectors of society or households are most at risk.In this work we use information on 3094 households across Uganda collected between 2004--2005. We describe a method for clustering households in such a way that the cluster decision boundaries are both relevant for improved-specificity famine prediction and are easily communicated. We then give classification results for predicting food security status at a household level given different combinations of satellite data, demographic data, and household category indices found by our clustering method. The food security classification performance of this model demonstrates the potential of this approach for making predictions of famine for specific areas and demographic groups.},
booktitle = {Proceedings of the First ACM Symposium on Computing for Development},
articleno = {18},
numpages = {6},
location = {London, United Kingdom},
series = {ACM DEV '10}
}

@article{10.1145/1870085.1870089,
author = {Song, Yang and Fang, Yuguang},
title = {Cross-Layer Interactions in Multihop Wireless Sensor Networks: A Constrained Queueing Model},
year = {2010},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1049-3301},
url = {https://doi.org/10.1145/1870085.1870089},
doi = {10.1145/1870085.1870089},
abstract = {In this article, we propose a constrained queueing model to investigate the performance of multihop wireless sensor networks. Specifically, the cross-layer interactions of rate admission control, traffic engineering, dynamic routing, and adaptive link scheduling are studied jointly with the proposed queueing model. In addition, the stochastic network utility maximization problem in wireless sensor networks is addressed within this framework. We propose an adaptive network resource allocation scheme, called the ANRA algorithm, which provides a joint solution to the multiple-layer components of the stochastic network utility maximization problem. We show that the proposed ANRA algorithm achieves a near-optimal solution, that is, (1-ϵ) of the global optimum network utility where ϵ can be arbitrarily small, with a trade-off with the average delay experienced in the network. The proposed ANRA algorithm enjoys the merit of self-adaptability through its online nature and thus is of particular interest for time-varying scenarios such as multihop wireless sensor networks.},
journal = {ACM Trans. Model. Comput. Simul.},
month = dec,
articleno = {4},
numpages = {26},
keywords = {stochastic utility maximization, Cross-layer design, stochastic network optimization, online algorithms}
}

@article{10.1145/1877766.1877772,
author = {Choudhury, Munmun De and Sundaram, Hari and John, Ajita and Seligmann, Doree Duncan},
title = {Extraction, Characterization and Utility of Prototypical Communication Groups in the Blogosphere},
year = {2011},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/1877766.1877772},
doi = {10.1145/1877766.1877772},
abstract = {This article analyzes communication within a set of individuals to extract the representative prototypical groups and provides a novel framework to establish the utility of such groups. Corporations may want to identify representative groups (which are indicative of the overall communication set) because it is easier to track the prototypical groups rather than the entire set. This can be useful for advertising, identifying “hot” spots of resource consumption as well as in mining representative moods or temperature of a community. Our framework has three parts: extraction, characterization, and utility of prototypical groups. First, we extract groups by developing features representing communication dynamics of the individuals. Second, to characterize the overall communication set, we identify a subset of groups within the community as the prototypical groups. Third, we justify the utility of these prototypical groups by using them as predictors of related external phenomena; specifically, stock market movement of technology companies and political polls of Presidential candidates in the 2008 U.S. elections.We have conducted extensive experiments on two popular blogs, Engadget and Huffington Post. We observe that the prototypical groups can predict stock market movement/political polls satisfactorily with mean error rate of 20.32%. Further, our method outperforms baseline methods based on alternative group extraction and prototypical group identification methods. We evaluate the quality of the extracted groups based on their conductance and coverage measures and develop metrics: predictivity and resilience to evaluate their ability to predict a related external time-series variable (stock market movement/political polls). This implies that communication dynamics of individuals are essential in extracting groups in a community, and the prototypical groups extracted by our method are meaningful in characterizing the overall communication sets.},
journal = {ACM Trans. Inf. Syst.},
month = dec,
articleno = {6},
numpages = {53},
keywords = {social communication, prototypical groups, Blogosphere, social network analysis, Huffington Post, Engadget, political polls, stock market movement, communication dynamics}
}

@article{10.1145/1866739.1866755,
author = {Haber, Eben M. and Kandogan, Eser and Maglio, Paul P.},
title = {Collaboration in System Administration},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {1},
issn = {0001-0782},
url = {https://doi.org/10.1145/1866739.1866755},
doi = {10.1145/1866739.1866755},
abstract = {For sysadmins, solving problems usually involves collaborating with others. How can we make it more effective?},
journal = {Commun. ACM},
month = jan,
pages = {46–53},
numpages = {8}
}

@article{10.1145/1925019.1925023,
author = {Shepard, Clayton and Rahmati, Ahmad and Tossell, Chad and Zhong, Lin and Kortum, Phillip},
title = {LiveLab: Measuring Wireless Networks and Smartphone Users in the Field},
year = {2011},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {3},
issn = {0163-5999},
url = {https://doi.org/10.1145/1925019.1925023},
doi = {10.1145/1925019.1925023},
abstract = {We present LiveLab, a methodology to measure real-world smartphone usage and wireless networks with a reprogrammable indevice logger designed for long-term user studies. We discuss the challenges of privacy protection and power impact in LiveLab and offer our solutions. We present an iPhone 3GS based deployment of LiveLab with 25 users intended for one year. Early results from the data collection so far highlight the unique strengths and potential of LiveLab. We have two objectives in this position paper. First, we demonstrate the feasibility and capability of LiveLab. By sharing our experience, we seek to advocate LiveLab as a network and user measurement methodology. Second, we present our preliminary findings, and seek feedback from the community regarding what data to collect.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = jan,
pages = {15–20},
numpages = {6}
}

@inproceedings{10.5555/2002669.2002694,
author = {Petukhova, Volha and Bunt, Harry},
title = {Incremental Dialogue Act Understanding},
year = {2011},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {This paper presents a machine learning-based approach to the incremental understanding of dialogue utterances, with a focus on the recognition of their communicative functions. A token-based approach combining the use of local classifiers, which exploit local utterance features, and global classifiers which use the outputs of local classifiers applied to previous and subsequent tokens, is shown to result in excellent dialogue act recognition scores for unsegmented spoken dialogue. This can be seen as a significant step forward towards the development of fully incremental, on-line methods for computing the meaning of utterances in spoken dialogue.},
booktitle = {Proceedings of the Ninth International Conference on Computational Semantics},
pages = {235–244},
numpages = {10},
location = {Oxford, United Kingdom},
series = {IWCS '11}
}

@inproceedings{10.5555/2459296.2459302,
author = {Huda, Shamsul and Yearwood, John and Stranieri, Andrew},
title = {Hybrid Wrapper-Filter Approaches for Input Feature Selection Using Maximum Relevance-Minimum Redundancy and Artificial Neural Network Input Gain Measurement Approximation (ANNIGMA)},
year = {2011},
isbn = {9781920682934},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Feature selection processes improve the accuracy, computational efficiency and scalability of classification process in data mining applications. This paper proposes two filter and wrapper hybrid approaches for feature selection techniques by combining the filter's feature ranking score in the wrapper stage. The first approach hybridizes a Mutual Information (MI) based Maximum Relevance (MR) filter ranking heuristic with an Artificial Neural Network (ANN) based wrapper approach where Artificial Neural Network Input Gain Measurement Approximation (ANNIGMA) has been combined with MR (MR-ANNIGMA) to guide the search process in the wrapper. The second hybrid combines an improved version of MI based (Maximum Relevance and Minimum Redundancy; MaxRel-MinRed) filter ranking heuristic with the wrapper heuristic ANNIGMA (MaxRel-MinRed-ANNIGMA). The novelty of our approach is that we integrate the capability of wrapper approach to find better feature subset by combining filter's ranking score with the wrapper-heuristic's score that take advantages of both filter and wrapper heuristics. The performances of the hybrid approaches have been verified using synthetic, bench mark data sets and real life data set and compared to both independent filter and wrapper based approaches. Experimental results show that hybrid approaches (MR-ANNIGMA and MaxRel-MinRed-ANNIGMA) achieve more compact feature sets and higher accuracies than filter and wrapper approaches alone.},
booktitle = {Proceedings of the Thirty-Fourth Australasian Computer Science Conference - Volume 113},
pages = {43–52},
numpages = {10},
keywords = {ANNIGMA wrapper, wrapper, maximum-relevance and minimum redundancy, hybrid feature selection, filter maximum-relevance},
location = {Perth, Australia},
series = {ACSC '11}
}

@inproceedings{10.5555/2459936.2459953,
author = {Devey, Adrian and Carbone, Angela},
title = {Helping First Year Novice Programming Students PASS},
year = {2011},
isbn = {9781920682941},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {In this paper, we report the results of introducing a face-to-face Peer Assisted Study Scheme (PASS) and an electronic Peer Assisted Study Scheme (ePASS) into a first year introductory programming unit, core to four undergraduate IT degrees. PASS is a program of supplementary instruction through which successful senior students facilitate weekly face-to-face study sessions in targeted key first year units. Sessions are open to all students enrolled in the target units and participation in PASS is voluntary. ePASS is a discussion board monitored by PASS Leaders. Results show that although attendance at face-to-face sessions is less than 25%, the students that attended found the sessions very useful. Of those that participated in PASS, over 40% attended to help them achieve an excellent grade, and not purely to obtain a pass grade It was therefore not surprising that the proportion of regular PASS attendees who failed the target unit was much lower than in the unit overall, while the proportion of regular PASS attendees achieving Distinctions and High Distinctions was higher. ePASS did not meet our objectives either in terms of the volume or nature of use.},
booktitle = {Proceedings of the Thirteenth Australasian Computing Education Conference - Volume 114},
pages = {135–144},
numpages = {10},
keywords = {first year programming, peer assisted study},
location = {Perth, Australia},
series = {ACE '11}
}

@inproceedings{10.5555/2460416.2460425,
author = {Campbell, Scott and Chan, Stephen and Lee, Jason R.},
title = {Detection of Fast Flux Service Networks},
year = {2011},
isbn = {9781920682965},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Fast Flux Service Networks (FFSN) apply high availability server techniques to the business of malware distribution. FFSNs are similar to commercial content distribution networks (CDN), such as Akamai, in terms of size, scope, and business model, serving as an outsourced content delivery service for clients. Using an analysis of DNS traffic, we derive a sequential hypothesis-testing algorithm based entirely on traffic characteristics and dynamic white listing to provide real time detection of FFSNs in live traffic. We improve on existing work, providing faster and more accurate detection of FFSNs. We also investigate a category of hosts not fully explored in previous detectors - Open Content Distribution Networks (OCDN) that share many of the characteristics of FFSNs.},
booktitle = {Proceedings of the Ninth Australasian Information Security Conference - Volume 116},
pages = {57–66},
numpages = {10},
keywords = {fast flux, DNS, CDN},
location = {Perth, Australia},
series = {AISC '11}
}

@article{10.1145/1925861.1925879,
author = {Keshav, Srinivasan and Rosenberg, Catherine},
title = {How Internet Concepts and Technologies Can Help Green and Smarten the Electrical Grid},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0146-4833},
url = {https://doi.org/10.1145/1925861.1925879},
doi = {10.1145/1925861.1925879},
abstract = {Several powerful forces are gathering to make fundamental and irrevocable changes to the century-old grid. The next-generation grid, often called the 'smart grid,' will feature distributed energy production, vastly more storage, tens of millions of stochastic renewable-energy sources, and the use of communication technologies both to allow precise matching of supply to demand and to incentivize appropriate consumer behaviour. These changes will have the effect of reducing energy waste and reducing the carbon footprint of the grid, making it 'smarter' and 'greener.' In this position paper, we discuss how the concepts and techniques pioneered by the Internet, the fruit of four decades of research in this area, are directly applicable to the design of a smart, green grid. This is because both the Internet and the electrical grid are designed to meet fundamental needs, for information and for energy, respectively, by connecting geographically dispersed suppliers with geographically dispersed consumers. Keeping this and other similarities (and fundamental differences, as well) in mind, we propose several specific areas where Internet concepts and technologies can contribute to the development of a smart, green grid. We also describe some areas where the Internet operations can be improved based on the experience gained in the electrical grid. We hope that our work will initiate a dialogue between the Internet and the smart grid communities.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = jan,
pages = {109–114},
numpages = {6},
keywords = {electrical grid, green networking}
}

@article{10.1145/1925861.1925878,
author = {Krioukov, Andrew and Mohan, Prashanth and Alspaugh, Sara and Keys, Laura and Culler, David and Katz, Randy},
title = {NapSAC: Design and Implementation of a Power-Proportional Web Cluster},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0146-4833},
url = {https://doi.org/10.1145/1925861.1925878},
doi = {10.1145/1925861.1925878},
abstract = {Energy consumption is a major and costly problem in data centers. A large fraction of this energy goes to powering idle machines that are not doing any useful work. We identify two causes of this inefficiency: low server utilization and a lack of power-proportionality. To address this problem we present a design for an power-proportional cluster consisting of a power-aware cluster manager and a set of heterogeneous machines. Our design makes use of currently available energy-efficient hardware, mechanisms for transitioning in and out of low-power sleep states, and dynamic provisioning and scheduling to continually adjust to workload and minimize power consumption. With our design we are able to reduce energy consumption while maintaining acceptable response times for a web service workload based on Wikipedia. With our dynamic provisioning algorithms we demonstrate via simulation a 63% savings in power usage in a typically provisioned datacenter where all machines are left on and awake at all times. Our results show that we are able to achieve close to 90% of the savings a theoretically optimal provisioning scheme would achieve. We have also built a prototype cluster which runs Wikipedia to demonstrate the use of our design in a real environment.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = jan,
pages = {102–108},
numpages = {7},
keywords = {energy, data center, web application, power management, heterogenous hardware, web server, cluster, power proportional}
}

@inproceedings{10.5555/2133036.2133044,
author = {Im, Sungjin and Moseley, Benjamin},
title = {An Online Scalable Algorithm for Minimizing <i>l</i><sub><i>k</i></sub>-Norms of Weighted Flow Time on Unrelated Machines},
year = {2011},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
abstract = {We consider the problem of scheduling jobs that arrive online in the unrelated machine model to minimize lk norms of weighted flowtime. In the unrelated setting, the processing time and weight of a job depends on the machine it is assigned to, and it is perhaps the most general machine model considered in scheduling literature. Chadha et al. [10] obtained a recent breakthrough result in obtaining the first non-trivial algorithm for minimizing weighted flowtime (that is, the l1 norm) in this very general setting via a novel potential function based analysis. They described a simple algorithm and showed that for any ε &gt; 0 it is (1 + ε)-speed O(1/ε2)-competitive (a scalable algorithm).In this paper we give the first non-trivial and scalable algorithm for minimizing lk norms of weighted flowtime in the unrelated machine model; for any ε &gt; 0, the algorithm is O(k/ε2+2/k)-competitive. The algorithm is immediate-dispatch and non-migratory. Our result is of both practical and theoretical interest. Scheduling to minimize lk norms of flowtime for some small k &gt; 1 has been shown to balance total response time and fairness, which is desirable in practice. On the theoretical side, lk norms for k &gt; 1 pose substantial technical hurdles when compared to when k = 1 even for the single machine case. Our work develops a novel potential function as well as several tools that can be used to lower bound the optimal solution.},
booktitle = {Proceedings of the Twenty-Second Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {95–108},
numpages = {14},
location = {San Francisco, California},
series = {SODA '11}
}

@article{10.1145/1889681.1889687,
author = {Ward, Jamie A. and Lukowicz, Paul and Gellersen, Hans W.},
title = {Performance Metrics for Activity Recognition},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/1889681.1889687},
doi = {10.1145/1889681.1889687},
abstract = {In this article, we introduce and evaluate a comprehensive set of performance metrics and visualisations for continuous activity recognition (AR). We demonstrate how standard evaluation methods, often borrowed from related pattern recognition problems, fail to capture common artefacts found in continuous AR—specifically event fragmentation, event merging and timing offsets. We support our assertion with an analysis on a set of recently published AR papers. Building on an earlier initial work on the topic, we develop a frame-based visualisation and corresponding set of class-skew invariant metrics for the one class versus all evaluation. These are complemented by a new complete set of event-based metrics that allow a quick graphical representation of system performance—showing events that are correct, inserted, deleted, fragmented, merged and those which are both fragmented and merged. We evaluate the utility of our approach through comparison with standard metrics on data from three different published experiments. This shows that where event- and frame-based precision and recall lead to an ambiguous interpretation of results in some cases, the proposed metrics provide a consistently unambiguous explanation.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
articleno = {6},
numpages = {23},
keywords = {performance evaluation, Activity recognition, metrics}
}

@article{10.1145/1889681.1889689,
author = {Bao, Xinlong and Dietterich, Thomas G.},
title = {FolderPredictor: Reducing the Cost of Reaching the Right Folder},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/1889681.1889689},
doi = {10.1145/1889681.1889689},
abstract = {Helping computer users rapidly locate files in their folder hierarchies is a practical research problem involving both intelligent systems and user interface design. This article reports on FolderPredictor, a software system that can reduce the cost of locating files in hierarchical folders. FolderPredictor applies a cost-sensitive prediction algorithm to the user's previous file access information to predict the next folder that will be accessed. Experimental results show that, on average, FolderPredictor reduces the number of clicks spent on locating a file by 50%. Several variations of the cost-sensitive prediction algorithm are discussed. An experimental study shows that the best algorithm among them is a mixture of the most recently used (MRU) folder and the cost-sensitive predictions. Furthermore, FolderPredictor does not require users to adapt to a new interface, but rather meshes with the existing interface for opening files on the Windows platform.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
articleno = {8},
numpages = {23},
keywords = {intelligent systems, Activities, shortcuts, tasks, prediction, folders, recommendation, user interface, intelligent user interfaces, directories}
}

@inproceedings{10.1145/1926385.1926405,
author = {Prountzos, Dimitrios and Manevich, Roman and Pingali, Keshav and McKinley, Kathryn S.},
title = {A Shape Analysis for Optimizing Parallel Graph Programs},
year = {2011},
isbn = {9781450304900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1926385.1926405},
doi = {10.1145/1926385.1926405},
abstract = {Computations on unstructured graphs are challenging to parallelize because dependences in the underlying algorithms are usually complex functions of runtime data values, thwarting static parallelization. One promising general-purpose parallelization strategy for these algorithms is optimistic parallelization.This paper identifies the optimization of optimistically parallelized graph programs as a new application area, and develops the first shape analysis for addressing this problem. Our shape analysis identifies failsafe points in the program after which the execution is guaranteed not to abort and backup copies of modified data are not needed; additionally, the analysis can be used to eliminate redundant conflict checking. It uses two key ideas: a novel top-down heap abstraction that controls state space explosion, and a strategy for predicate discovery that exploits common patterns of data structure usage.We implemented the shape analysis in TVLA, and used it to optimize benchmarks from the Lonestar suite. The optimized programs were executed on the Galois system. The analysis was successful in eliminating all costs related to rollback logging for our benchmarks. Additionally, it reduced the number of lock acquisitions by a factor ranging from 10x to 50x, depending on the application and the number of threads. These optimizations were effective in reducing the running times of the benchmarks by factors of 2x to 12x.},
booktitle = {Proceedings of the 38th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {159–172},
numpages = {14},
keywords = {shape analysis, parallelism, cautious operators, synchronization overheads, optimistic parallelization, amorphous data-parallelism, irregular programs, abstract interpretation, concurrency, compiler optimization, static analysis},
location = {Austin, Texas, USA},
series = {POPL '11}
}

@article{10.1145/1925844.1926405,
author = {Prountzos, Dimitrios and Manevich, Roman and Pingali, Keshav and McKinley, Kathryn S.},
title = {A Shape Analysis for Optimizing Parallel Graph Programs},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0362-1340},
url = {https://doi.org/10.1145/1925844.1926405},
doi = {10.1145/1925844.1926405},
abstract = {Computations on unstructured graphs are challenging to parallelize because dependences in the underlying algorithms are usually complex functions of runtime data values, thwarting static parallelization. One promising general-purpose parallelization strategy for these algorithms is optimistic parallelization.This paper identifies the optimization of optimistically parallelized graph programs as a new application area, and develops the first shape analysis for addressing this problem. Our shape analysis identifies failsafe points in the program after which the execution is guaranteed not to abort and backup copies of modified data are not needed; additionally, the analysis can be used to eliminate redundant conflict checking. It uses two key ideas: a novel top-down heap abstraction that controls state space explosion, and a strategy for predicate discovery that exploits common patterns of data structure usage.We implemented the shape analysis in TVLA, and used it to optimize benchmarks from the Lonestar suite. The optimized programs were executed on the Galois system. The analysis was successful in eliminating all costs related to rollback logging for our benchmarks. Additionally, it reduced the number of lock acquisitions by a factor ranging from 10x to 50x, depending on the application and the number of threads. These optimizations were effective in reducing the running times of the benchmarks by factors of 2x to 12x.},
journal = {SIGPLAN Not.},
month = jan,
pages = {159–172},
numpages = {14},
keywords = {irregular programs, synchronization overheads, parallelism, concurrency, static analysis, abstract interpretation, optimistic parallelization, cautious operators, shape analysis, amorphous data-parallelism, compiler optimization}
}

@article{10.14778/1952376.1952382,
author = {Cao, Zhao and Sutton, Charles and Diao, Yanlei and Shenoy, Prashant},
title = {Distributed Inference and Query Processing for RFID Tracking and Monitoring},
year = {2011},
issue_date = {February 2011},
publisher = {VLDB Endowment},
volume = {4},
number = {5},
issn = {2150-8097},
url = {https://doi.org/10.14778/1952376.1952382},
doi = {10.14778/1952376.1952382},
abstract = {In this paper, we present the design of a scalable, distributed stream processing system for RFID tracking and monitoring. Since RFID data lacks containment and location information that is key to query processing, we propose to combine location and containment inference with stream query processing in a single architecture, with inference as an enabling mechanism for high-level query processing. We further consider challenges in instantiating such a system in large distributed settings and design techniques for distributed inference and query processing. Our experimental results, using both real-world data and large synthetic traces, demonstrate the accuracy, efficiency, and scalability of our proposed techniques.},
journal = {Proc. VLDB Endow.},
month = feb,
pages = {326–337},
numpages = {12}
}

@article{10.1145/1921632.1921634,
author = {Kang, U. and Tsourakakis, Charalampos E. and Appel, Ana Paula and Faloutsos, Christos and Leskovec, Jure},
title = {HADI: Mining Radii of Large Graphs},
year = {2011},
issue_date = {February 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {2},
issn = {1556-4681},
url = {https://doi.org/10.1145/1921632.1921634},
doi = {10.1145/1921632.1921634},
abstract = {Given large, multimillion-node graphs (e.g., Facebook, Web-crawls, etc.), how do they evolve over time? How are they connected? What are the central nodes and the outliers? In this article we define the Radius plot of a graph and show how it can answer these questions. However, computing the Radius plot is prohibitively expensive for graphs reaching the planetary scale.There are two major contributions in this article: (a) We propose HADI (HAdoop DIameter and radii estimator), a carefully designed and fine-tuned algorithm to compute the radii and the diameter of massive graphs, that runs on the top of the Hadoop/MapReduce system, with excellent scale-up on the number of available machines (b) We run HADI on several real world datasets including YahooWeb (6B edges, 1/8 of a Terabyte), one of the largest public graphs ever analyzed.Thanks to HADI, we report fascinating patterns on large networks, like the surprisingly small effective diameter, the multimodal/bimodal shape of the Radius plot, and its palindrome motion over time.},
journal = {ACM Trans. Knowl. Discov. Data},
month = feb,
articleno = {8},
numpages = {24},
keywords = {HADI, graph mining, Radius plot, hadoop, small web}
}

@article{10.1145/1897816.1897838,
author = {Wachs, Juan Pablo and K\"{o}lsch, Mathias and Stern, Helman and Edan, Yael},
title = {Vision-Based Hand-Gesture Applications},
year = {2011},
issue_date = {February 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/1897816.1897838},
doi = {10.1145/1897816.1897838},
abstract = {Body posture and finger pointing are a natural modality for human-machine interaction, but first the system must know what it's seeing.},
journal = {Commun. ACM},
month = feb,
pages = {60–71},
numpages = {12}
}

@article{10.1145/1925109.1925111,
author = {Lagar-Cavilla, H. Andr\'{e}s and Whitney, Joseph A. and Bryant, Roy and Patchin, Philip and Brudno, Michael and de Lara, Eyal and Rumble, Stephen M. and Satyanarayanan, M. and Scannell, Adin},
title = {SnowFlock: Virtual Machine Cloning as a First-Class Cloud Primitive},
year = {2011},
issue_date = {February 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {1},
issn = {0734-2071},
url = {https://doi.org/10.1145/1925109.1925111},
doi = {10.1145/1925109.1925111},
abstract = {A basic building block of cloud computing is virtualization. Virtual machines (VMs) encapsulate a user’s computing environment and efficiently isolate it from that of other users. VMs, however, are large entities, and no clear APIs exist yet to provide users with programatic, fine-grained control on short time scales.We present SnowFlock, a paradigm and system for cloud computing that introduces VM cloning as a first-class cloud abstraction. VM cloning exploits the well-understood and effective semantics of UNIX fork. We demonstrate multiple usage models of VM cloning: users can incorporate the primitive in their code, can wrap around existing toolchains via scripting, can encapsulate the API within a parallel programming framework, or can use it to load-balance and self-scale clustered servers.VM cloning needs to be efficient to be usable. It must efficiently transmit VM state in order to avoid cloud I/O bottlenecks. We demonstrate how the semantics of cloning aid us in realizing its efficiency: state is propagated in parallel to multiple VM clones, and is transmitted during runtime, allowing for optimizations that substantially reduce the I/O load. We show detailed microbenchmark results highlighting the efficiency of our optimizations, and macrobenchmark numbers demonstrating the effectiveness of the different usage models of SnowFlock.},
journal = {ACM Trans. Comput. Syst.},
month = feb,
articleno = {2},
numpages = {45},
keywords = {Virtualization, cloud computing}
}

@inproceedings{10.1145/1940761.1940792,
author = {Lopatovska, Irene},
title = {Researching Emotion: Challenges and Solutions},
year = {2011},
isbn = {9781450301213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1940761.1940792},
doi = {10.1145/1940761.1940792},
abstract = {Interest in emotions within the information use context is on the rise. Yet, the reports of the emotion studies rarely mention some of the methodological challenges involved in research. New researchers who are entering the field are often unaware of the challenges and potential solutions related to emotions' examinations. This paper attempts to educate researchers about some of the methodological options that are available at various stages of emotion study, including selection of theory and methods, data collection and analysis, extraction of meaning from data, and application of the findings to the real life problems. The paper offers recommendations for handling some of the challenges that might arise during a project.},
booktitle = {Proceedings of the 2011 IConference},
pages = {225–229},
numpages = {5},
keywords = {measurement, information behavior, research methodology, information retrieval, affect, information use, emotion},
location = {Seattle, Washington, USA},
series = {iConference '11}
}

@article{10.1145/1942776.1942782,
author = {Ahmad, Yanif and Burns, Randal and Kazhdan, Michael and Meneveau, Charles and Szalay, Alex and Terzis, Andreas},
title = {Scientific Data Management at the Johns Hopkins Institute for Data Intensive Engineering and Science},
year = {2011},
issue_date = {September 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {3},
issn = {0163-5808},
url = {https://doi.org/10.1145/1942776.1942782},
doi = {10.1145/1942776.1942782},
journal = {SIGMOD Rec.},
month = feb,
pages = {18–23},
numpages = {6}
}

@inproceedings{10.1145/1940761.1940924,
author = {Heverin, Thomas},
title = {Microblogging for Distributed Surveillance in Response to Violent Crises: Ethical Considerations},
year = {2011},
isbn = {9781450301213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1940761.1940924},
doi = {10.1145/1940761.1940924},
abstract = {The increased use of social media technologies over the past few years has altered the communication and information sharing activities surrounding crises. Local and non-local citizens can now create and distribute their own crisis-related information to a wide audience bypassing official communication channels. The purpose of our research is to identify patterns in citizen communications transmitted over Twitter and to identify ethical considerations of citizen participation through Twitter in response to violent crises. In a preliminary study, we examined the patterns of Twitter communications sent in response to a 2009 violent attack in the U.S. and found that the majority of communications contained information sharing content focused on the suspect and law enforcement activity. We also examined ethical considerations of the Twitter communications and found four main categories of behaviors that could potentially lead to more violence or harm to others including disseminating misinformation, promoting vigilante justice, conducting virtual attacks on fellow participants, and sharing real-time information on law enforcement locations. Data for four other U.S. 2009--2010 attacks have been collected and a more in depth analysis is in progress.},
booktitle = {Proceedings of the 2011 IConference},
pages = {827–828},
numpages = {2},
keywords = {crisis informatics, surveillance, microblogging},
location = {Seattle, Washington, USA},
series = {iConference '11}
}

@inproceedings{10.1145/1940761.1940799,
author = {Xie, Bo and Wang, Mo and Feldman, Robert},
title = {Preferences for Health Information and Decision-Making: Development of the Health Information Wants (HIW) Questionnaire},
year = {2011},
isbn = {9781450301213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1940761.1940799},
doi = {10.1145/1940761.1940799},
abstract = {The Health Information Wants (HIW) Questionnaire was developed to measure 1) a broad range of the types and amount of each type of information health consumers want to have in dealing with health-related issues; and 2) the degree to which health consumers want to participate in each type of decision-making in each corresponding area. With parallel items in each corresponding area of information and decision-making, this instrument can reveal the relationship between information and decision-making preferences in each area. This paper reports the multi-stage development process of this instrument that lasted for over two years. This process included: 1) a grounded theory-driven exploratory study that identified the core framework; 2) initial item development based on the literature and the exploratory study; 3) content validity testing; 4) cognitive testing; and 5) a pilot study testing the psychometrics of the instrument.},
booktitle = {Proceedings of the 2011 IConference},
pages = {273–280},
numpages = {8},
keywords = {decision-making, health information wants (HIW), instrument development, health information},
location = {Seattle, Washington, USA},
series = {iConference '11}
}

@inproceedings{10.1145/1935826.1935869,
author = {Nakashole, Ndapandula and Theobald, Martin and Weikum, Gerhard},
title = {Scalable Knowledge Harvesting with High Precision and High Recall},
year = {2011},
isbn = {9781450304931},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1935826.1935869},
doi = {10.1145/1935826.1935869},
abstract = {Harvesting relational facts from Web sources has received great attention for automatically constructing large knowledge bases. Stateof-the-art approaches combine pattern-based gathering of fact candidates with constraint-based reasoning. However, they still face major challenges regarding the trade-offs between precision, recall, and scalability. Techniques that scale well are susceptible to noisy patterns that degrade precision, while techniques that employ deep reasoning for high precision cannot cope with Web-scale data.This paper presents a scalable system, called PROSPERA, for high-quality knowledge harvesting. We propose a new notion of ngram-itemsets for richer patterns, and use MaxSat-based constraint reasoning on both the quality of patterns and the validity of fact candidates.We compute pattern-occurrence statistics for two benefits: they serve to prune the hypotheses space and to derive informative weights of clauses for the reasoner. The paper shows how to incorporate these building blocks into a scalable architecture that can parallelize all phases on a Hadoop-based distributed platform. Our experiments with the ClueWeb09 corpus include comparisons to the recent ReadTheWeb experiment. We substantially outperform these prior results in terms of recall, with the same precision, while having low run-times.},
booktitle = {Proceedings of the Fourth ACM International Conference on Web Search and Data Mining},
pages = {227–236},
numpages = {10},
keywords = {knowledhe harvesting, information extraction, scalability},
location = {Hong Kong, China},
series = {WSDM '11}
}

@article{10.1145/1921614.1921617,
author = {Grieser, Karl and Baldwin, Timothy and Bohnert, Fabian and Sonenberg, Liz},
title = {Using Ontological and Document Similarity to Estimate Museum Exhibit Relatedness},
year = {2011},
issue_date = {March 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {1556-4673},
url = {https://doi.org/10.1145/1921614.1921617},
doi = {10.1145/1921614.1921617},
abstract = {Exhibits within cultural heritage collections such as museums and art galleries are arranged by experts with intimate knowledge of the domain, but there may exist connections between individual exhibits that are not evident in this representation. For example, the visitors to such a space may have their own opinions on how exhibits relate to one another. In this article, we explore the possibility of estimating the perceived relatedness of exhibits by museum visitors through a variety of ontological and document similarity-based methods. Specifically, we combine the Wikipedia category hierarchy with lexical similarity measures, and evaluate the correlation with the relatedness judgements of visitors. We compare our measure with simple document similarity calculations, based on either Wikipedia documents or Web pages taken from the Web site for the museum of interest. We also investigate the hypothesis that physical distance in the museum space is a direct representation of the conceptual distance between exhibits. We demonstrate that ontological similarity measures are highly effective at capturing perceived relatedness and that the proposed RACO (Related Article Conceptual Overlap) method is able to achieve results closest to relatedness judgements provided by human annotators compared to existing state-of-the art measures of semantic relatedness.},
journal = {J. Comput. Cult. Herit.},
month = feb,
articleno = {10},
numpages = {20},
keywords = {museum exhibit, document similarity, WordNet, Wikipedia, Ontological similarity}
}

@inproceedings{10.1145/1941553.1941561,
author = {Chafi, Hassan and Sujeeth, Arvind K. and Brown, Kevin J. and Lee, HyoukJoong and Atreya, Anand R. and Olukotun, Kunle},
title = {A Domain-Specific Approach to Heterogeneous Parallelism},
year = {2011},
isbn = {9781450301190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1941553.1941561},
doi = {10.1145/1941553.1941561},
abstract = {Exploiting heterogeneous parallel hardware currently requires mapping application code to multiple disparate programming models. Unfortunately, general-purpose programming models available today can yield high performance but are too low-level to be accessible to the average programmer. We propose leveraging domain-specific languages (DSLs) to map high-level application code to heterogeneous devices. To demonstrate the potential of this approach we present OptiML, a DSL for machine learning. OptiML programs are implicitly parallel and can achieve high performance on heterogeneous hardware with no modification required to the source code. For such a DSL-based approach to be tractable at large scales, better tools are required for DSL authors to simplify language creation and parallelization. To address this concern, we introduce Delite, a system designed specifically for DSLs that is both a framework for creating an implicitly parallel DSL as well as a dynamic runtime providing automated targeting to heterogeneous parallel hardware. We show that OptiML running on Delite achieves single-threaded, parallel, and GPU performance superior to explicitly parallelized MATLAB code in nearly all cases.},
booktitle = {Proceedings of the 16th ACM Symposium on Principles and Practice of Parallel Programming},
pages = {35–46},
numpages = {12},
keywords = {parallel programming, domain-specific languages, runtimes, dynamic optimizations},
location = {San Antonio, TX, USA},
series = {PPoPP '11}
}

@article{10.1145/2038037.1941561,
author = {Chafi, Hassan and Sujeeth, Arvind K. and Brown, Kevin J. and Lee, HyoukJoong and Atreya, Anand R. and Olukotun, Kunle},
title = {A Domain-Specific Approach to Heterogeneous Parallelism},
year = {2011},
issue_date = {August 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {8},
issn = {0362-1340},
url = {https://doi.org/10.1145/2038037.1941561},
doi = {10.1145/2038037.1941561},
abstract = {Exploiting heterogeneous parallel hardware currently requires mapping application code to multiple disparate programming models. Unfortunately, general-purpose programming models available today can yield high performance but are too low-level to be accessible to the average programmer. We propose leveraging domain-specific languages (DSLs) to map high-level application code to heterogeneous devices. To demonstrate the potential of this approach we present OptiML, a DSL for machine learning. OptiML programs are implicitly parallel and can achieve high performance on heterogeneous hardware with no modification required to the source code. For such a DSL-based approach to be tractable at large scales, better tools are required for DSL authors to simplify language creation and parallelization. To address this concern, we introduce Delite, a system designed specifically for DSLs that is both a framework for creating an implicitly parallel DSL as well as a dynamic runtime providing automated targeting to heterogeneous parallel hardware. We show that OptiML running on Delite achieves single-threaded, parallel, and GPU performance superior to explicitly parallelized MATLAB code in nearly all cases.},
journal = {SIGPLAN Not.},
month = feb,
pages = {35–46},
numpages = {12},
keywords = {runtimes, dynamic optimizations, domain-specific languages, parallel programming}
}

@inproceedings{10.1145/1961634.1961636,
author = {Jancsary, Jeremy and Neubarth, Friedrich and Schreitter, Stephanie and Trost, Harald},
title = {Towards a Context-Sensitive Online Newspaper},
year = {2011},
isbn = {9781450306256},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1961634.1961636},
doi = {10.1145/1961634.1961636},
abstract = {We give a detailed account of our experiences in implementing a personalized online newspaper that draws---among other hints---on the context of the user. At the algorithmic core of our framework lies a machine learning model that incorporates numerous features of the eligible articles and the user's current situation. Some of the most important design decisions, however, concern the presentation of suggestions, the collection of explicit and implicit feedback, as well as diversity of the recommendations. We present numerical results obtained during the pilot phase of the project that address a number of these concerns and end with a discussion of open questions and future directions.},
booktitle = {Proceedings of the 2011 Workshop on Context-Awareness in Retrieval and Recommendation},
pages = {2–9},
numpages = {8},
keywords = {user profiling, context-awareness, online newspaper},
location = {Palo Alto, California, USA},
series = {CaRR '11}
}

@article{10.1145/1945023.1945026,
author = {Gupta, Vishakha and Knauerhase, Rob and Schwan, Karsten},
title = {Attaining System Performance Points: Revisiting the End-to-End Argument in System Design for Heterogeneous Many-Core Systems},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5980},
url = {https://doi.org/10.1145/1945023.1945026},
doi = {10.1145/1945023.1945026},
abstract = {Trends indicate a rapid increase in the number of cores on chip, exhibiting various types of performance and functional asymmetries present in hardware to gain scalability with balanced power vs. performance requirements. This poses new challenges in platform resource management, which are further exacerbated by the need for runtime power budgeting and by the increased dynamics in workload behavior observed in consolidated datacenter and cloudcomputing systems. This paper considers the implications of these challenges for the virtualization layer of abstraction, which is the base layer for resource management in such heterogeneous multicore platforms. Specifically, while existing and upcoming management methods routinely leverage system-level information available to the hypervisor about current and global platform state, we argue that for future systems there will be an increased necessity for additional information about applications and their needs. This 'end-to-end' argument leads us to propose 'performance points' as a general interface between the virtualization system and higher layers like the guest operating systems that run application workloads. Building on concrete examples from past work on APIs with which applications can inform systems of phase or workload changes and conversely, with which systems can indicate to applications desired changes in power consumption, performance points are shown to be an effective way to better exploit asymmetries and gain the power/performance improvements promised by heterogeneous multicore systems.},
journal = {SIGOPS Oper. Syst. Rev.},
month = feb,
pages = {3–10},
numpages = {8},
keywords = {asymmetry, heterogeneous multicore, virtualization}
}

@article{10.1145/1945023.1945029,
author = {Vasudevan, Vijay and Andersen, David G. and Kaminsky, Michael and Franklin, Jason and Kozuch, Michael A. and Moraru, Iulian and Pillai, Padmanabhan and Tan, Lawrence},
title = {Challenges and Opportunities for Efficient Computing with FAWN},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5980},
url = {https://doi.org/10.1145/1945023.1945029},
doi = {10.1145/1945023.1945029},
abstract = {This paper presents the architecture and motivation for a clusterbased, many-core computing architecture for energy-efficient, dataintensive computing. FAWN, a Fast Array of Wimpy Nodes, consists of a large number of slower but efficient nodes coupled with low-power storage. We present the computing trends that motivate a FAWN-like approach, for CPU, memory, and storage. We follow with a set of microbenchmarks to explore under what workloads these FAWN nodes perform well (or perform poorly), and briefly examine scenarios in which both code and algorithms may need to be re-designed or optimized to perform well on an efficient platform. We conclude with an outline of the longer-term implications of FAWN that lead us to select a tightly integrated stacked chip and-memory architecture for future FAWN development.},
journal = {SIGOPS Oper. Syst. Rev.},
month = feb,
pages = {34–44},
numpages = {11},
keywords = {design, performance, flash, measurement, energy efficiency, cluster computing}
}

@inproceedings{10.1145/1943513.1943537,
author = {Xi, Bowei and Kantarcioglu, Murat and Inan, Ali},
title = {Mixture of Gaussian Models and Bayes Error under Differential Privacy},
year = {2011},
isbn = {9781450304665},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943513.1943537},
doi = {10.1145/1943513.1943537},
abstract = {Gaussian mixture models are an important tool in Bayesian decision theory. In this study, we focus on building such models over statistical database protected under differential privacy. Our approach involves querying necessary statistics from a database and building a Bayesian classifier over the noise added responses generated according to differential privacy. We formally analyze the sensitivity of our query set. Since there are multiple methods to query a statistic, either directly or indirectly, we analyze the sensitivities for different querying methods. Furthermore we establish theoretical bounds for the Bayes error for the univariate (one dimensional) case. We study the Bayes error for the multivariate (high dimensional) case in experiments with both simulated data and real life data. We discover that adding Laplace noise to a statistic under certain constraint is problematic. For example variance-covariance matrix is no longer positive definite after noise addition. We propose a heuristic method to fix the noise added variance-covariance matrix.},
booktitle = {Proceedings of the First ACM Conference on Data and Application Security and Privacy},
pages = {179–190},
numpages = {12},
keywords = {differential privacy, classification, statistical databases, mixture models},
location = {San Antonio, TX, USA},
series = {CODASPY '11}
}

@inproceedings{10.1145/1980022.1980198,
author = {Siddesh, G. M. and Srinivasa, K. G. and Venugopal, K. R.},
title = {GRM: A Reliable and Fault Tolerant Data Replication Middleware for Grid Environment},
year = {2011},
isbn = {9781450304498},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1980022.1980198},
doi = {10.1145/1980022.1980198},
abstract = {Existing approaches to replication based middleware suffers from performance limitations with the additional traffic in the Grid. Hence the proposed approach provides a replication middleware which offers highly efficient, consistent and fully replicated system for the Grid environment. This paper proposes a highly available fault tolerant Grid based replication middleware, which achieves replication of data dynamically upon incoming transaction request from the clients. The Grid based Replication Middleware (GRM) offers: Semi active replication strategy based on Total Ordering-Multicasting, SOAP based message communication, Dijkstra and Scholten election algorithm, improved Membership service and Hash based replica Location service to achieve high availability, heterogeneity, Fault tolerance, improved scalability, efficient data management services respectively and security features like authentication, authorization, message confidentiality are also addressed. Proposed GRM reduces the system overhead by reducing the traffic in the Grid and thereby improving the performance of data management for large scale complex Grid based applications.},
booktitle = {Proceedings of the International Conference &amp; Workshop on Emerging Trends in Technology},
pages = {810–815},
numpages = {6},
keywords = {total ordering, middleware, data management, replication, grid environment},
location = {Mumbai, Maharashtra, India},
series = {ICWET '11}
}

@inproceedings{10.1145/2090116.2090131,
author = {Fournier, H\'{e}l\`{e}ne and Kop, Rita and Sitlia, Hanan},
title = {The Value of Learning Analytics to Networked Learning on a Personal Learning Environment},
year = {2011},
isbn = {9781450309448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2090116.2090131},
doi = {10.1145/2090116.2090131},
abstract = {Some might argue that the analytics tools at our disposal are currently mainly used for boring purposes, such as improving processes and making money. In this paper we will try to define learning analytics and their purpose for learning and education. We will ponder on the best possible fit of particular types of research methods and their analysis. Methodological concerns related to the analysis of Big Data collected on online networks as well as ethical and privacy concerns will also be highlighted and a case study of the use of learning analytics in a Massive Open Online Course explored.},
booktitle = {Proceedings of the 1st International Conference on Learning Analytics and Knowledge},
pages = {104–109},
numpages = {6},
keywords = {learning analytics, massive open online courses, analytics tools, big data, educational research},
location = {Banff, Alberta, Canada},
series = {LAK '11}
}

@inproceedings{10.1145/2090116.2090129,
author = {Vatrapu, Ravi and Teplovs, Chris and Fujita, Nobuko and Bull, Susan},
title = {Towards Visual Analytics for Teachers' Dynamic Diagnostic Pedagogical Decision-Making},
year = {2011},
isbn = {9781450309448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2090116.2090129},
doi = {10.1145/2090116.2090129},
abstract = {The focus of this paper is to delineate and discuss design considerations for supporting teachers' dynamic diagnostic decision-making in classrooms of the 21st century. Based on the Next Generation Teaching Education and Learning for Life (NEXT-TELL) European Commission integrated project, we envision classrooms of the 21st century to (a) incorporate 1:1 computing, (b) provide computational as well as methodological support for teachers to design, deploy and assess learning activities and (c) immerse students in rich, personalized and varied learning activities in information ecologies resulting in high-performance, high-density, high-bandwidth, and data-rich classrooms. In contrast to existing research in educational data mining and learning analytics, our vision is to employ visual analytics techniques and tools to support teachers dynamic diagnostic pedagogical decision-making in real-time and in actual classrooms. The primary benefits of our vision is that learning analytics becomes an integral part of the teaching profession so that teachers can provide timely, meaningful, and actionable formative assessments to on-going learning activities in-situ. Integrating emerging developments in visual analytics and the established methodological approach of design-based research (DBR) in the learning sciences, we introduce a new method called "Teaching Analytics" and explore a triadic model of teaching analytics (TMTA). TMTA adapts and extends the Pair Analytics method in visual analytics which in turn was inspired by the pair programming model of the extreme programming paradigm. Our preliminary vision of TMTA consists of a collocated collaborative triad of a Teaching Expert (TE), a Visual Analytics Expert (VAE), and a Design-Based Research Expert (DBRE) analyzing, interpreting and acting upon real-time data being generated by students' learning activities by using a range of visual analytics tools. We propose an implementation of TMTA using open learner models (OLM) and conclude with an outline of future work},
booktitle = {Proceedings of the 1st International Conference on Learning Analytics and Knowledge},
pages = {93–98},
numpages = {6},
keywords = {computer supported collaborative learning (CSCL), learning sciences, learning analytics, multivocality, teaching analytics, visual analytics},
location = {Banff, Alberta, Canada},
series = {LAK '11}
}

@inproceedings{10.1145/2090116.2090128,
author = {Brooks, Christopher and Epp, Carrie Demmans and Logan, Greg and Greer, Jim},
title = {The Who, What, When, and Why of Lecture Capture},
year = {2011},
isbn = {9781450309448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2090116.2090128},
doi = {10.1145/2090116.2090128},
abstract = {Video lecture capture is rapidly being deploying in higher-education institutions as a means of increasing student learning, outreach, and experience. Understanding how learners use these systems and relating this use back to pedagogical and institutional goals is a hard issue that has largely been unexplored. This work describes a novel web-based lecture presentation system which contains fine-grained user tracking features. These features, along with student surveys, have been used to help analyse the behaviour of hundreds of students over an academic term, quantifying both the learning approaches of students and their perceptions on learning with lecture capture.},
booktitle = {Proceedings of the 1st International Conference on Learning Analytics and Knowledge},
pages = {86–92},
numpages = {7},
keywords = {analytics, lecture capture, student experience, recollect, clustering, participation},
location = {Banff, Alberta, Canada},
series = {LAK '11}
}

@inproceedings{10.1145/2090116.2090135,
author = {Sharkey, Mike},
title = {Academic Analytics Landscape at the University of Phoenix},
year = {2011},
isbn = {9781450309448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2090116.2090135},
doi = {10.1145/2090116.2090135},
abstract = {The University of Phoenix understands that in order to serve its large population of non-traditional students, it needs to rely on data. We have created a strong foundation with an integrated data repository that connects data from all parts of the organization. With this repository in place, we can now undertake a variety of analytics projects. One such project is an attempt to predict a student's persistence in their program using available data indicators such as schedule, grades, content usage, and demographics.},
booktitle = {Proceedings of the 1st International Conference on Learning Analytics and Knowledge},
pages = {122–126},
numpages = {5},
keywords = {data modeling, integrated data, learning analytics, predictive analytics, Hadoop, academic data},
location = {Banff, Alberta, Canada},
series = {LAK '11}
}

@article{10.1145/1897852.1897870,
author = {Kamp, Poul-Henning},
title = {B.Y.O.C (1,342 Times and Counting)},
year = {2011},
issue_date = {March 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/1897852.1897870},
doi = {10.1145/1897852.1897870},
abstract = {Why can't we all use standard libraries for commonly needed algorithms?},
journal = {Commun. ACM},
month = mar,
pages = {56–58},
numpages = {3}
}

@article{10.14778/1978665.1978670,
author = {Jahani, Eaman and Cafarella, Michael J. and R\'{e}, Christopher},
title = {Automatic Optimization for MapReduce Programs},
year = {2011},
issue_date = {March 2011},
publisher = {VLDB Endowment},
volume = {4},
number = {6},
issn = {2150-8097},
url = {https://doi.org/10.14778/1978665.1978670},
doi = {10.14778/1978665.1978670},
abstract = {The MapReduce distributed programming framework has become popular, despite evidence that current implementations are inefficient, requiring far more hardware than a traditional relational databases to complete similar tasks. MapReduce jobs are amenable to many traditional database query optimizations (B+Trees for selections, column-store-style techniques for projections, etc), but existing systems do not apply them, substantially because free-form user code obscures the true data operation being performed. For example, a selection in SQL is easily detected, but a selection in a MapReduce program is embedded in Java code along with lots of other program logic. We could ask the programmer to provide explicit hints about the program's data semantics, but one of MapReduce's attractions is precisely that it does not ask the user for such information.This paper covers Manimal, which automatically analyzes MapReduce programs and applies appropriate data-aware optimizations, thereby requiring no additional help at all from the programmer. We show that Manimal successfully detects optimization opportunities across a range of data operations, and that it yields speedups of up to 1,121% on previously-written MapReduce programs.},
journal = {Proc. VLDB Endow.},
month = mar,
pages = {385–396},
numpages = {12}
}

@inproceedings{10.1145/1957656.1957669,
author = {Sabelli, Alessandra Maria and Kanda, Takayuki and Hagita, Norihiro},
title = {A Conversational Robot in an Elderly Care Center: An Ethnographic Study},
year = {2011},
isbn = {9781450305617},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1957656.1957669},
doi = {10.1145/1957656.1957669},
abstract = {This paper reports an ethnographic study on the use of a conversational robot. We placed a robot for 3.5 months in an elderly care center. Assuming a real deployment scenario, the robot was managed by a single non-programmer person during the field trial, who teleoperated the robot and updated the contents. The robot was designed to engage in daily greetings and chatting with elderly people. Through the ethnographic approach, we clarified how the elderly people interacted with this conversational robot, how the deployment process adopted to introduce the robot was designed, and how the organization's personnel involved themselves in this deployment.},
booktitle = {Proceedings of the 6th International Conference on Human-Robot Interaction},
pages = {37–44},
numpages = {8},
keywords = {robots in organizations, communication robots, robots for elderly, ethnography},
location = {Lausanne, Switzerland},
series = {HRI '11}
}

@inproceedings{10.1145/1953163.1953268,
author = {Turner, Scott and P\'{e}rez-Qui\~{n}ones, Manuel A. and Edwards, Stephen and Chase, Joseph},
title = {Student Attitudes and Motivation for Peer Review in CS2},
year = {2011},
isbn = {9781450305006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1953163.1953268},
doi = {10.1145/1953163.1953268},
abstract = {Computer science students need experience with essential concepts and professional activities. Peer review is one way to meet these goals. In this work, we examine the students' attitudes towards and engagement in the peer review process, in early, object-oriented, computer science courses. To do this, we used peer review exercises in two CS2 classes at neighboring universities over the course of a semester. Using three groups (one reviewing their peers, one reviewing the instructor, and one completing small design or coding exercises), we measured the students' attitudes, their perceptions of their abilities, and how many of the reviews they completed. We found moderately positive attitudes that generally increased over time but were not significantly different between groups. We also saw a lower completion rate for students reviewing peers than for the other groups. The students' internal motivation, as measured by their need for cognition, was not shown to be strongly related to their attitudes nor to the number of assignments completed. Overall, our results show a strong need for external motivation to help engage students in peer reviews.},
booktitle = {Proceedings of the 42nd ACM Technical Symposium on Computer Science Education},
pages = {347–352},
numpages = {6},
keywords = {peer review, peer assessment, learning, engagement, computer science education, attitude},
location = {Dallas, TX, USA},
series = {SIGCSE '11}
}

@inproceedings{10.1145/1953163.1953307,
author = {VanDeGrift, Tammy and Caruso, Tamara and Hill, Natalie and Simon, Beth},
title = {Experience Report: Getting Novice Programmers to THINK about Improving Their Software Development Process},
year = {2011},
isbn = {9781450305006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1953163.1953307},
doi = {10.1145/1953163.1953307},
abstract = {Expertise is developed through both a) self-reflection and b) making useful plans for improvement [3, 10]. Traditional novice-level programming assignments require neither of these skills to be used. Could we get students to think about improving their software development processes? What areas would they identify as needing improvement? Could they write effective plans for themselves? In this experience report, we analyze the results of an intervention with 236 CS1.5 students asking them to do these activities. We find that they most commonly make improvements in planning, compared to coding and testing. Additionally, over half of the plans they make are so vague as to be of little use in helping students identify if they have, in fact, improved. Finally, we asked students at the end of the term to reflect on how their experiences with programming assignments changed over the term. We discuss our results in light of how instructors can focus instruction to help students become more meta-cognitive about their own software development processes.},
booktitle = {Proceedings of the 42nd ACM Technical Symposium on Computer Science Education},
pages = {493–498},
numpages = {6},
keywords = {programming, software quality, metacognition, novice},
location = {Dallas, TX, USA},
series = {SIGCSE '11}
}

@inproceedings{10.1145/1953163.1953344,
author = {Cennamo, Katherine and Douglas, Sarah A. and Vernon, Mitzi and Brandt, Carol and Scott, Brigitte and Reimer, Yolanda and McGrath, Margarita},
title = {Promoting Creativity in the Computer Science Design Studio},
year = {2011},
isbn = {9781450305006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1953163.1953344},
doi = {10.1145/1953163.1953344},
abstract = {Revolutionary advances in technologies will require computer science professionals who are able to develop innovative software solutions. In order to identify techniques that can lead students to creative insights in their work, we have conducted an ethnographic study of the studio method as enacted in architecture, industrial design (ID), and human-computer interaction (HCI) classes. Our analysis of the activities conducted during studio critiques revealed that while the ID and architecture studios had a primary focus on experimentation, the primary emphasis of the HCI studios was on idea refinement. In this paper, we describe four barriers to creative thought observed in the HCI classrooms and identify ways that the architecture and ID instructors helped students to overcome similar challenges.},
booktitle = {Proceedings of the 42nd ACM Technical Symposium on Computer Science Education},
pages = {649–654},
numpages = {6},
keywords = {design, studio, computer science education research, creativity},
location = {Dallas, TX, USA},
series = {SIGCSE '11}
}

@inproceedings{10.1145/1958824.1958847,
author = {Hu, Bin and Zheng, Fang and Liu, Li},
title = {Ubiquitous Awareness and Intelligent Solutions Lab: Lanzhou University},
year = {2011},
isbn = {9781450305563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1958824.1958847},
doi = {10.1145/1958824.1958847},
booktitle = {Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work},
pages = {151–158},
numpages = {8},
keywords = {computer supported collaborative work, bio-data, human computer interaction},
location = {Hangzhou, China},
series = {CSCW '11}
}

@inproceedings{10.1145/1958824.1958876,
author = {Newman, Mark W. and Lauterbach, Debra and Munson, Sean A. and Resnick, Paul and Morris, Margaret E.},
title = {It's Not That i Don't Have Problems, i'm Just Not Putting Them on Facebook: Challenges and Opportunities in Using Online Social Networks for Health},
year = {2011},
isbn = {9781450305563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1958824.1958876},
doi = {10.1145/1958824.1958876},
abstract = {To understand why and how people share health information online, we interviewed fourteen people with significant health concerns who participate in both online health communities and Facebook. Qualitative analysis of these interviews highlighted the ways that people think about with whom and how to share different types of information as they pursue social goals related to their personal health, including emotional support, motivation, accountability, and advice. Our study suggests that success in these goals depends on how well they develop their social networks and how effectively they communicate within those networks. Effective communication is made more challenging by the need to strike a balance between sharing information related to specific needs and the desire to manage self-presentation. Based on these observations, we outline a set of design opportunities for future systems to support health-oriented social interactions online, including tools to help users shape their social networks and communicate effectively within those.},
booktitle = {Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work},
pages = {341–350},
numpages = {10},
keywords = {social support, Facebook, online health communities},
location = {Hangzhou, China},
series = {CSCW '11}
}

@inproceedings{10.1145/1958824.1958848,
author = {Chi, Changyan and Liao, Qinying and Pan, Yingxin and Zhao, Shiwan and Matthews, Tara and Moran, Thomas and Zhou, Michelle X. and Millen, David and Lin, Ching-Yung and Guy, Ido},
title = {Smarter Social Collaboration at IBM Research},
year = {2011},
isbn = {9781450305563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1958824.1958848},
doi = {10.1145/1958824.1958848},
abstract = {In this paper we feature a set of research projects done at several IBM Research laboratories across the world. The work featured here focuses on the topic of smart social collaboration, which studies, designs, and develops social collaboration principles and technologies that can help customize and enhance existing social collaboration tools to suit specific user needs, including cultural, business, and personal needs.},
booktitle = {Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work},
pages = {159–166},
numpages = {8},
keywords = {culture, social collaboration, business},
location = {Hangzhou, China},
series = {CSCW '11}
}

@inproceedings{10.1145/1958824.1958864,
author = {Wang, Hao-Chuan and Fussell, Susan R. and Cosley, Dan},
title = {From Diversity to Creativity: Stimulating Group Brainstorming with Cultural Differences and Conversationally-Retrieved Pictures},
year = {2011},
isbn = {9781450305563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1958824.1958864},
doi = {10.1145/1958824.1958864},
abstract = {Group brainstorming, or collaboratively generating ideas through idea sharing, demands diverse contributions to spark more ideas and improve creativity. One approach to supporting group brainstorming is to introduce conceptual diversity. In this study, we evaluate the effects of two sources of diversity on group brainstorming: cultural differences internal to multicultural groups and pictures related to the conversation retrieved by a computer agent. The pictures generally enhanced performance as measured by both originality and diversity of ideas. The pictures also helped to convert cultural diversity into a creative outcome, the diversity of ideas generated. We argue that with appropriate technology mediation, cultural diversity may be used strategically to enhance task outcomes.},
booktitle = {Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work},
pages = {265–274},
numpages = {10},
keywords = {group brainstorming, cultural diversity, creativity support tools, intercultural collaboration, group creativity},
location = {Hangzhou, China},
series = {CSCW '11}
}

@inproceedings{10.1145/1958824.1958875,
author = {Munson, Sean A. and Rosengren, Emily and Resnick, Paul},
title = {Thanks and Tweets: Comparing Two Public Displays},
year = {2011},
isbn = {9781450305563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1958824.1958875},
doi = {10.1145/1958824.1958875},
abstract = {Two public display systems, with different methods of posting, were deployed over several years. One, the Thank You Board, was designed to give people an outlet specifically for publicly thanking and acknowledging others in the community. The other, SI Display, showed any Twitter post directed to the display and did not have explicit usage guidelines. People preferred the flexibility of the latter, but ambiguity about its purpose and norms of usage persisted even six months after deployment and made some people hesitant to post. Also, using Twitter as the posting mechanism facilitated participation for some but also created barriers for those not using Twitter and for Twitter users who were wary of mixing their professional and non-professional contexts.},
booktitle = {Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work},
pages = {331–340},
numpages = {10},
keywords = {adoption, norms, interpretations, twitter, public displays},
location = {Hangzhou, China},
series = {CSCW '11}
}

@inproceedings{10.1145/1982185.1982209,
author = {Antonie, Luiza and Bessonov, Kyrylo},
title = {Classifying Microarray Data with Association Rules},
year = {2011},
isbn = {9781450301138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1982185.1982209},
doi = {10.1145/1982185.1982209},
abstract = {In this paper we investigate a method for classifying microarray data using association rules. Associative classifiers, classification systems based on association rules, show good performance level while being easy to read and understand. This feature is especially attractive for biological data where experts can read and validate the association rules. Relevant features are selected using Support Vector Machines with Recursive Feature Elimination. These features are discretized according to their relative expression levels (upregulated, downregulated or no change) and then they are used to build an associative classifier. The proposed combination proves highly accurate for the studied microarray data collection. In addition the classification rules discovered and employed in the classification process prove to be biologically relevant.},
booktitle = {Proceedings of the 2011 ACM Symposium on Applied Computing},
pages = {94–99},
numpages = {6},
keywords = {microarray data, classification, association rules},
location = {TaiChung, Taiwan},
series = {SAC '11}
}

@inproceedings{10.1145/1980422.1980428,
author = {Hyser, Chris and Gmach, Daniel and Ml, Umesh and Chen, Yuan and Suryanarayana, Vijay},
title = {Improving Server Power Management in Research and Development Data Centers},
year = {2011},
isbn = {9781450307505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1980422.1980428},
doi = {10.1145/1980422.1980428},
abstract = {Research data centers are often composed of thousands of diverse computer systems used for ongoing research, development, software regression and hardware compatibility testing. The usage patterns of many of these systems result in periodic non-use and extended periods of idleness. Users routinely fail to ensure that idle machines are powered down prior to overnight or extended absence periods. The annual amount of wasted energy in the HP Bangalore development data center is estimated at 14400 MWh resulting in over 8600 tons of CO2 emissions per year. In this paper, we propose Idle Machine Power Savings (IMPS), which seeks to address potential power cost savings and minimize environmental impact. IMPS consists of a low overhead, highly scalable data acquisition framework enabling the development of algorithms (an artificial neural network is used in the initial prototype) for automatic "extended idle" notifications and optional automatic shutdown of unused computers in data centers. This paper describes our approach, the framework, a prototype implementation and provides preliminary results. The results show an enormous potential for energy savings that translate directly into financial savings and lowered greenhouse gas emissions.},
booktitle = {Proceedings of the Fourth Annual ACM Bangalore Conference},
articleno = {6},
numpages = {6},
keywords = {data mining, power management, sustainability, sustainable computing, machine learning algorithms},
location = {Bangalore, India},
series = {COMPUTE '11}
}

@inproceedings{10.1145/1963192.1963341,
author = {Das, Dipankar},
title = {Analysis and Tracking of Emotions in English and Bengali Texts: A Computational Approach},
year = {2011},
isbn = {9781450306379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1963192.1963341},
doi = {10.1145/1963192.1963341},
abstract = {The present discussion highlights the aspects of an ongoing doctoral thesis grounded on the analysis and tracking of emotions from English and Bengali texts. Development of lexical resources and corpora meets the preliminary urgencies. The research spectrum aims to identify the evaluative emotional expressions at word, phrase, sentence, and document level granularities along with their associated holders and topics. Tracking of emotions based on topic or event was carried out by employing sense based affect scoring techniques. The labeled emotion corpora are being prepared from unlabeled examples to cope with the scarcity of emotional resources, especially for the resource constraint language like Bengali. Different unsupervised, supervised and semi-supervised strategies, adopted for coloring each outline of the research spectrum produce satisfactory outcomes},
booktitle = {Proceedings of the 20th International Conference Companion on World Wide Web},
pages = {343–348},
numpages = {6},
keywords = {bengwal, topic, syntactic argument structure, emotions, holder, expression, svm, blogs, tracking, crf},
location = {Hyderabad, India},
series = {WWW '11}
}

@inproceedings{10.1145/1963192.1963365,
author = {Pal, Joyojeet and Pradhan, Manas and Shah, Mihir and Babu, Rakesh},
title = {Assistive Technology for Vision-Impairments: Anagenda for the ICTD Community},
year = {2011},
isbn = {9781450306379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1963192.1963365},
doi = {10.1145/1963192.1963365},
abstract = {In recent years, ICTD (Information Communications Technology and Development) has grown in significance as an area of engineering research that has focused on low-cost appropriate technologies for the needs of a developing world largely underserved by the dominant modes of technology design. Assistive Technologies (AT) used by people with disabilities facilitate greater equity in the social and economic public sphere. However, by and large such technologies are designed in the industrialized world, for people living in those countries. This is especially true in the case of AT for people with vision impairments -- market-prevalent technologies are both very expensive and are built to support the language and infrastructure typical in the industrialized world. While the community of researchers in the Web Accessibility space have made significant strides, the operational concerns of networks in the developing world, as well as challenges in support for new languages and contexts raises a new set of challenges for technologists in this space. We discuss the state of various technologies in the context of the developing world and propose directions in scientific and community-contributed efforts to increase the relevance and access to AT and accessibility in the developing world.},
booktitle = {Proceedings of the 20th International Conference Companion on World Wide Web},
pages = {513–522},
numpages = {10},
keywords = {accessibility, assistive technology, visually impaired},
location = {Hyderabad, India},
series = {WWW '11}
}

@inproceedings{10.1145/1963192.1963358,
author = {Chen, Jay and Hutchful, David and Thies, William and Subramanian, Lakshminarayanan},
title = {Analyzing and Accelerating Web Access in a School in Peri-Urban India},
year = {2011},
isbn = {9781450306379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1963192.1963358},
doi = {10.1145/1963192.1963358},
abstract = {While computers and Internet access have growing penetration amongst schools in the developing world, intermittent connectivity and limited bandwidth often prevent them from being fully utilized by students and teachers. In this paper, we make two contributions to help address this problem. First, we characterize six weeks of HTTP traffic from a primary school outside of Bangalore, India, illuminating opportunities and constraints for improving performance in such settings. Second, we deploy an aggressive caching and prefetching engine and show that it accelerates a user's overall browsing experience (apart from video content) by 2.8x. Our accelerator leverages innovative techniques that have been proposed, but not evaluated in detail, including the effectiveness of serving stale pages, cached page highlighting, and client-side prefetching. Unlike proxy-based techniques, our system is bundled as an open-source Firefox plugin and runs directly on client machines. This allows easy installation and configuration by end users, which is especially important in developing regions where a lack of permissions or technical expertise often prevents modification of internal network settings.},
booktitle = {Proceedings of the 20th International Conference Companion on World Wide Web},
pages = {443–452},
numpages = {10},
keywords = {connectivity, web acceleration, browser extension},
location = {Hyderabad, India},
series = {WWW '11}
}

@inproceedings{10.1145/1982624.1982630,
author = {Moraru, Alexandra and Mladenic, Dunja and Vucnik, Matevz and Porcius, Maria and Fortuna, Carolina and Mohorcic, Mihael},
title = {Exposing Real World Information for the Web of Things},
year = {2011},
isbn = {9781450306201},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1982624.1982630},
doi = {10.1145/1982624.1982630},
abstract = {In this paper, we propose SemSense architecture for collecting real world data from a physical system of sensors and publishing it on the Web, thus contributing to the Web of Things. SemSense comprises of four components: (1) the data collection component, (2) the storage component (3) the semantic enrichment component and (4) the publishing component, which are described and implemented for an existing deployment of a sensor network. Through these components, the real world data is collected from the physical devices, processed, equipped with semantic information and published on the Web. The paper addresses challenges of efficiently collecting data and meta-data from sensors and publishing it following the linked data principles.},
booktitle = {Proceedings of the 8th International Workshop on Information Integration on the Web: In Conjunction with WWW 2011},
articleno = {6},
numpages = {6},
keywords = {semantic web, sensor, sensor network, web of things, linked data},
location = {Hyderabad, India},
series = {IIWeb '11}
}

@article{10.1145/1952383.1952385,
author = {Jeon, Myounghoon and Walker, Bruce N.},
title = {Spindex (Speech Index) Improves Auditory Menu Acceptance and Navigation Performance},
year = {2011},
issue_date = {April 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {1936-7228},
url = {https://doi.org/10.1145/1952383.1952385},
doi = {10.1145/1952383.1952385},
abstract = {Users interact with mobile devices through menus, which can include many items. Auditory menus have the potential to make those devices more accessible to a wide range of users. However, auditory menus are a relatively new concept, and there are few guidelines that describe how to design them. In this paper, we detail how visual menu concepts may be applied to auditory menus in order to help develop design guidelines. Specifically, we examine how to optimize the designs of a new contextual cue, called “spindex” (i.e., speech index). We developed and evaluated various design alternatives for spindex and iteratively refined the design with sighted users and visually impaired users. As a result, the “attenuated” spindex was the best in terms of preference as well as performance, across user groups. Nevertheless, sighted and visually impaired participants showed slightly different responses and feedback. Results are discussed in terms of acoustical theory, practical display design, and assistive technology design.},
journal = {ACM Trans. Access. Comput.},
month = apr,
articleno = {10},
numpages = {26},
keywords = {spindex, Auditory menus, assistive technology}
}

@inproceedings{10.1145/2107556.2107569,
author = {Aljenaa, E. and Al-Anzi, F. S. and Alshayeji, M.},
title = {Towards an Efficient E-Learning System Based on Cloud Computing},
year = {2011},
isbn = {9781450307932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2107556.2107569},
doi = {10.1145/2107556.2107569},
abstract = {The rapid development in Information and Communication Technology has had a significant impact on traditional educational systems and learning. Today, E-Learning has become a widely accepted way of learning. With increasing numbers of users, a wide range of learning services and the growth of educational content, E-Learning has emerged as the mode for future learning. However, the volatile user load and massive storage and transfer of rich multimedia content have lead to a need for effective utilization of server side system resources in providing E-Learning services. Cloud computing offers a dynamic provision of virtualized resources, elasticity, scalability, pays as you use and measured service with the ability to dynamically provision and de-provision computing resources as needed. Cloud computing is ideally suited for E-learning systems.In this paper, an E-Learning framework based on cloud computing is presented which efficiently addresses the current challenges in E-Learning. Specifically, the architecture and core components in an efficient E-Learning system are introduced for efficient deployment in the cloud. Moreover, the proposed new framework efficiently blends different components that serve for E-Learning systems as a general architecture and wraps it under---E-Learning as services|| (EaaS). Our case study-based evaluation suggests that the proposed framework of E-Learning using cloud computing is best suited for the Kuwait Ministry of Education. In addition to better performance and availability, the proposed framework delivers reliable and scalable services for E- Learning systems.},
booktitle = {Proceedings of the Second Kuwait Conference on E-Services and e-Systems},
articleno = {13},
numpages = {7},
keywords = {e-learning as a service, framework, automation, operation, e-learning, cloud computing, cloud ontology},
location = {Kuwait City, Kuwait},
series = {KCESS '11}
}

@inproceedings{10.1145/2107556.2107564,
author = {Hussain, Mohammed and Abdulsalam, Hanady},
title = {SECaaS: Security as a Service for Cloud-Based Applications},
year = {2011},
isbn = {9781450307932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2107556.2107564},
doi = {10.1145/2107556.2107564},
abstract = {Cloud computing is a great target for many applications since it provides the storage and computation needs for cloud users with relatively low-cost. Although the area of cloud computing has grown rapidly in the last few years, the area still lacks appropriate security measures that protect the data and/or applications for cloud users. We introduce a new architecture, namely Security as a Service (SECaaS) that addresses the security issues for cloud-based applications. SECaaS deals with existing services of cloud computing on its different levels. SECaaS takes a user-centric approach, in which cloud users have more control over their security. It provides security means for both cloud users and providers.},
booktitle = {Proceedings of the Second Kuwait Conference on E-Services and e-Systems},
articleno = {8},
numpages = {4},
keywords = {security, cloud computing, security as a service},
location = {Kuwait City, Kuwait},
series = {KCESS '11}
}

@inproceedings{10.1145/1966445.1966467,
author = {Wester, Benjamin and Chen, Peter M. and Flinn, Jason},
title = {Operating System Support for Application-Specific Speculation},
year = {2011},
isbn = {9781450306348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1966445.1966467},
doi = {10.1145/1966445.1966467},
abstract = {Speculative execution is a technique that allows serial tasks to execute in parallel. An implementation of speculative execution can be divided into two parts: (1) a policy that specifies what operations and values to predict, what actions to allow during speculation, and how to compare results; and (2) the mechanisms that support speculative execution, such as checkpointing, rollback, causality tracking, and output buffering.In this paper, we show how to separate policy from mechanism. We implement a speculation mechanism in the operating system, where it can coordinate speculations across all applications and kernel state. Policy decisions are delegated to applications, which have the most semantic information available to direct speculation.We demonstrate how custom policies can be used in existing applications to add new features that would otherwise be difficult to implement. Using custom policies in our separated speculation system, we can hide 85% of program load time by predicting the program's launch, decrease SSL connection latency by 15% in Firefox, and increase a BFT client's request rate by 82%. Despite the complexity of the applications, small modifications can implement these features since they only specify policy choices and rely on the system to realize those policies. We provide this increased programmability with a modest performance trade-off, executing only 8% slower than an optimized, application-implemented speculation system.},
booktitle = {Proceedings of the Sixth Conference on Computer Systems},
pages = {229–242},
numpages = {14},
keywords = {mechanism, policy, speculative execution},
location = {Salzburg, Austria},
series = {EuroSys '11}
}

@inproceedings{10.1145/1966445.1966477,
author = {Nightingale, Edmund B. and Douceur, John R. and Orgovan, Vince},
title = {Cycles, Cells and Platters: An Empirical Analysisof Hardware Failures on a Million Consumer PCs},
year = {2011},
isbn = {9781450306348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1966445.1966477},
doi = {10.1145/1966445.1966477},
abstract = {We present the first large-scale analysis of hardware failure rates on a million consumer PCs. We find that many failures are neither transient nor independent. Instead, a large portion of hardware induced failures are recurrent: a machine that crashes from a fault in hardware is up to two orders of magnitude more likely to crash a second time. For example, machines with at least 30 days of accumulated CPU time over an 8 month period had a 1 in 190 chance of crashing due to a CPU subsystem fault. Further, machines that crashed once had a probability of 1 in 3.3 of crashing a second time. Our study examines failures due to faults within the CPU, DRAM and disk subsystems. Our analysis spans desktops and laptops, CPU vendor, overclocking, underclocking, generic vs. brand name, and characteristics such as machine speed and calendar age. Among our many results, we find that CPU fault rates are correlated with the number of cycles executed, underclocked machines are significantly more reliable than machines running at their rated speed, and laptops are more reliable than desktops.},
booktitle = {Proceedings of the Sixth Conference on Computer Systems},
pages = {343–356},
numpages = {14},
keywords = {reliability, fault tolerance},
location = {Salzburg, Austria},
series = {EuroSys '11}
}

@inproceedings{10.1145/1991996.1992008,
author = {Li, Xirong and Snoek, Cees G. M. and Worring, Marcel and Smeulders, Arnold W. M.},
title = {Social Negative Bootstrapping for Visual Categorization},
year = {2011},
isbn = {9781450303361},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1991996.1992008},
doi = {10.1145/1991996.1992008},
abstract = {To learn classifiers for many visual categories, obtaining labeled training examples in an efficient way is crucial. Since a classifier tends to misclassify negative examples which are visually similar to positive examples, inclusion of such informative negatives should be stressed in the learning process. However, they are unlikely to be hit by random sampling, the de facto standard in literature. In this paper, we go beyond random sampling by introducing a novel social negative bootstrapping approach. Given a visual category and a few positive examples, the proposed approach adaptively and iteratively harvests informative negatives from a large amount of social-tagged images. To label negative examples without human interaction, we design an effective virtual labeling procedure based on simple tag reasoning. Virtual labeling, in combination with adaptive sampling, enables us to select the most misclassified negatives as the informative samples. Learning from the positive set and the informative negative sets results in visual classifiers with higher accuracy. Experiments on two present-day image benchmarks employing 650K virtually labeled negative examples show the viability of the proposed approach. On a popular visual categorization benchmark our precision at 20 increases by 34%, compared to baselines trained on randomly sampled negatives. We achieve more accurate visual categorization without the need of manually labeling any negatives.},
booktitle = {Proceedings of the 1st ACM International Conference on Multimedia Retrieval},
articleno = {12},
numpages = {8},
keywords = {social-tagged examples, negative bootstrapping},
location = {Trento, Italy},
series = {ICMR '11}
}

@article{10.1145/1963559.1963561,
author = {Yadgar, Gala and Factor, Michael and Li, Kai and Schuster, Assaf},
title = {Management of Multilevel, Multiclient Cache Hierarchies with Application Hints},
year = {2011},
issue_date = {May 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {0734-2071},
url = {https://doi.org/10.1145/1963559.1963561},
doi = {10.1145/1963559.1963561},
abstract = {Multilevel caching, common in many storage configurations, introduces new challenges to traditional cache management: data must be kept in the appropriate cache and replication avoided across the various cache levels. Additional challenges are introduced when the lower levels of the hierarchy are shared by multiple clients. Sharing can have both positive and negative effects. While data fetched by one client can be used by another client without incurring additional delays, clients competing for cache buffers can evict each other’s blocks and interfere with exclusive caching schemes.We present a global noncentralized, dynamic and informed management policy for multiple levels of cache, accessed by multiple clients. Our algorithm, MC2, combines local, per client management with a global, system-wide scheme, to emphasize the positive effects of sharing and reduce the negative ones. Our local management scheme, Karma, uses readily available information about the client’s future access profile to save the most valuable blocks, and to choose the best replacement policy for them. The global scheme uses the same information to divide the shared cache space between clients, and to manage this space. Exclusive caching is maintained for nonshared data and is disabled when sharing is identified.Previous studies have partially addressed these challenges through minor changes to the storage interface. We show that all these challenges can in fact be addressed by combining minor interface changes with smart allocation and replacement policies. We show the superiority of our approach through comparison to existing solutions, including LRU, ARC, MultiQ, LRU-SP, and Demote, as well as a lower bound on optimal I/O response times. Our simulation results demonstrate better cache performance than all other solutions and up to 87% better performance than LRU on representative workloads.},
journal = {ACM Trans. Comput. Syst.},
month = may,
articleno = {5},
numpages = {51},
keywords = {multilevel, hints, Cache}
}

@article{10.5555/2007456.2007459,
author = {Coursaris, Constantinos K. and Kim, Dan J.},
title = {A Meta-Analytical Review of Empirical Mobile Usability Studies},
year = {2011},
issue_date = {May 2011},
publisher = {Usability Professionals' Association},
address = {Bloomingdale, IL},
volume = {6},
number = {3},
issn = {1931-3357},
abstract = {In this paper we present an adapted usability evaluation framework to the context of a mobile computing environment. Using this framework, we conducted a qualitative meta-analytical review of more than 100 empirical mobile usability studies. The results of the qualitative review include (a) the contextual factors studied; (b) the core and peripheral usability dimensions measured; and (c) key findings in the form of a research agenda for future mobile usability research, including open and unstructured tasks are underutilized, interaction effects between interactivity and complexity warrant further investigation, increasing research on accessibility may improve the usability of products and services for often overlooked audiences, studying novel technology and environmental factors will deepen contextual mobile usability knowledge, understanding which hedonic factors impact the aesthetic appeal of a mobile device or service and in turn usability, and a high potential for neuroscience research in mobile usability. Numerous additional findings and takeaways for practitioners are also discussed.},
journal = {J. Usability Studies},
month = may,
pages = {117–171},
numpages = {55},
keywords = {satisfaction, efficiency, effectiveness, mobile device, mobile, wireless, Human Computer Interaction, meta-analysis, empirical, context, usability}
}

@inproceedings{10.5555/2030470.2030533,
author = {Rosenfeld, Avi and Kraus, Sarit},
title = {Using Aspiration Adaptation Theory to Improve Learning},
year = {2011},
isbn = {0982657153},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Creating agents that properly simulate and interact with people is critical for many applications. Towards creating these agents, models are needed that quickly and accurately predict how people behave in a variety of domains and problems. This paper explores how one bounded rationality theory, Aspiration Adaptation Theory (AAT), can be used to aid in this task. We extensively studied two types of problems -- a relatively simple optimization problem and two complex negotiation problems. We compared the predictive capabilities of traditional learning methods with those where we added key elements of AAT and other optimal and bounded rationality models. Within the extensive empirical studies we conducted, we found that machine learning models combined with AAT were most effective in quickly and accurately predicting people's behavior.},
booktitle = {The 10th International Conference on Autonomous Agents and Multiagent Systems - Volume 1},
pages = {423–430},
numpages = {8},
keywords = {bounded rationality, cognitive models, agent learning},
location = {Taipei, Taiwan},
series = {AAMAS '11}
}

@inproceedings{10.5555/2030470.2030513,
author = {Sollenberger, Derek J. and Singh, Munindar P.},
title = {Kokomo: An Empirically Evaluated Methodology for Affective Applications},
year = {2011},
isbn = {0982657153},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {The introduction of affect or emotion modeling into software opens up new possibilities for improving user experience. Yet, current techniques for building affective applications are limited, with the treatment of affect in essence handcrafted in each application. The multiagent middleware Koko attempts to reduce the burden of incorporating affect modeling into applications. However, Koko can be effective only if the models it needs to function are suitably constructed.We propose Kokomo, a methodology that employs expressive communicative acts as an organizing principle for affective applications. Kokomo specifies the steps needed to create an affective application in Koko. A key motivation is that Kokomo would facilitate the construction of an affective application by engineers who may lack a prior background in affective modeling.We empirically evaluate Kokomo's utility through a developer study. The results are positive and demonstrate that the developers who used Kokomo were able to develop an affective application in less time, with fewer lines of code, and with a reduced perception of difficulty than developers who worked without Kokomo.},
booktitle = {The 10th International Conference on Autonomous Agents and Multiagent Systems - Volume 1},
pages = {293–300},
numpages = {8},
keywords = {affective computing, computational architectures for learning, software engineering},
location = {Taipei, Taiwan},
series = {AAMAS '11}
}

@article{10.1145/1961189.1961194,
author = {Bonchi, Francesco and Castillo, Carlos and Gionis, Aristides and Jaimes, Alejandro},
title = {Social Network Analysis and Mining for Business Applications},
year = {2011},
issue_date = {April 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/1961189.1961194},
doi = {10.1145/1961189.1961194},
abstract = {Social network analysis has gained significant attention in recent years, largely due to the success of online social networking and media-sharing sites, and the consequent availability of a wealth of social network data. In spite of the growing interest, however, there is little understanding of the potential business applications of mining social networks. While there is a large body of research on different problems and methods for social network mining, there is a gap between the techniques developed by the research community and their deployment in real-world applications. Therefore the potential business impact of these techniques is still largely unexplored.In this article we use a business process classification framework to put the research topics in a business context and provide an overview of what we consider key problems and techniques in social network analysis and mining from the perspective of business applications. In particular, we discuss data acquisition and preparation, trust, expertise, community structure, network dynamics, and information propagation. In each case we present a brief overview of the problem, describe state-of-the art approaches, discuss business application examples, and map each of the topics to a business process classification framework. In addition, we provide insights on prospective business applications, challenges, and future research directions. The main contribution of this article is to provide a state-of-the-art overview of current techniques while providing a critical perspective on business applications of social network analysis and mining.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
articleno = {22},
numpages = {37},
keywords = {Social networks, networks dynamics and evolution, expert finding, community structure, viral marketing, influence propagation}
}

@inproceedings{10.1145/1978942.1978967,
author = {Chau, Duen Horng and Kittur, Aniket and Hong, Jason I. and Faloutsos, Christos},
title = {Apolo: Making Sense of Large Network Data by Combining Rich User Interaction and Machine Learning},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978967},
doi = {10.1145/1978942.1978967},
abstract = {Extracting useful knowledge from large network datasets has become a fundamental challenge in many domains, from scientific literature to social networks and the web. We introduce Apolo, a system that uses a mixed-initiative approach - combining visualization, rich user interaction and machine learning - to guide the user to incrementally and interactively explore large network data and make sense of it. Apolo engages the user in bottom-up sensemaking to gradually build up an understanding over time by starting small, rather than starting big and drilling down. Apolo also helps users find relevant information by specifying exemplars, and then using a machine learning method called Belief Propagation to infer which other nodes may be of interest. We evaluated Apolo with twelve participants in a between-subjects study, with the task being to find relevant new papers to update an existing survey paper. Using expert judges, participants using Apolo found significantly more relevant papers. Subjective feedback of Apolo was also very positive.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {167–176},
numpages = {10},
keywords = {sensemaking, large network, belief propagation},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979419,
author = {Nguyen, David H. and Bedford, Aurora and Bretana, Alexander Gerard and Hayes, Gillian R.},
title = {Situating the Concern for Information Privacy through an Empirical Study of Responses to Video Recording},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979419},
doi = {10.1145/1978942.1979419},
abstract = {In this paper, we present the results of an empirical study of perceptions towards pervasive video recording. We describe a commonly used model for understanding information privacy, the Concern for Information Privacy (CFIP) model, and present the ways that this model and its associated questionnaire can shed light on information privacy concerns about pervasive and ubiquitous computing technologies. Specifically, the CFIP model encourages analysis of data across four facets of experience: the collection of personal data, the risk of improper access, the potential for unauthorized secondary use, and the challenge of preventing or correcting errors in the data. We further identify areas not well handled by this model of information privacy and suggest avenues for future work, including research on how and when to notify people about recording technologies, awareness of data provenance and leakage, and understanding of and access to the data assemblage being created about individuals.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3207–3216},
numpages = {10},
keywords = {CFIP, video recording, CCTV, information privacy},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1978945,
author = {Raij, Andrew and Ghosh, Animikh and Kumar, Santosh and Srivastava, Mani},
title = {Privacy Risks Emerging from the Adoption of Innocuous Wearable Sensors in the Mobile Environment},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1978945},
doi = {10.1145/1978942.1978945},
abstract = {Wearable sensors are revolutionizing healthcare and science by enabling capture of physiological, psychological, and behavioral measurements in natural environments. However, these seemingly innocuous measurements can be used to infer potentially private behaviors such as stress, conversation, smoking, drinking, illicit drug usage, and others. We conducted a study to assess how concerned people are about disclosure of a variety of behaviors and contexts that are embedded in wearable sensor data. Our results show participants are most concerned about disclosures of conversation episodes and stress - inferences that are not yet widely publicized. These concerns are mediated by temporal and physical context associated with the data and the participant's personal stake in the data. Our results provide key guidance on the extent to which people understand the potential for harm and data characteristics researchers should focus on to reduce the perceived harm from such datasets.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {11–20},
numpages = {10},
keywords = {information disclosure, wearable sensors, user study, mobile health, privacy},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

